,commit_id,commit_time,diff,files,summary
0,223015a1facba4c2bfa1873235998cd845f0715e,2020-07-31 10:25:06-07:00,"f '' Could not find a DSN with alias { dsn } . `` fg= '' red '' , * More explicit error message when connecting using DSN alias and it is not found . exit ( 1 ) 'Please check the `` [ alias_dsn ] '' section in pgclirc . ' , except Exception : click.secho ( except KeyError : ) err=True , except :","['changelog.rst', 'pgcli/main.py']",More explicit error message when DSN alias is not found ( # 1198 )
1,df1b40ca2220b0211e8a86805788c70f674a1f1f,2020-07-31 10:21:58-07:00,"`` AGE '' , `` INET_SAME_FAMILY '' , `` REPEAT '' , Completion ( text= '' MASKLEN '' , start_position=-2 ) , `` TO_TIMESTAMP '' , `` ANY '' , `` CHR '' , `` ARRAY_REMOVE '' , `` UUID '' , `` FLOAT4 '' , `` LCASE '' , `` LINE '' , `` ARRAY_CAT '' , `` REGEXP_REPLACE '' , `` ROW_NUMBER '' , `` TRIGGER '' , Completion ( text= '' INTERNAL '' , display_meta= '' datatype '' ) , `` RECORD '' , `` CARDINALITY '' , `` MACADDR '' , `` ARRAY_APPEND '' , ] `` CONCAT '' , `` HOSTMASK '' , `` CHARACTER VARYING '' , Completion ( text= '' INTEGER '' , display_meta= '' datatype '' ) , `` PERCENT_RANK '' , `` JUSTIFY_INTERVAL '' , Completion ( text= '' MAKE_DATE '' , start_position=-2 ) , `` FDW_HANDLER '' , `` ARRAY_NDIMS '' , `` BOUND_BOX '' , `` STRPOS '' , `` PATH '' , `` FIRST '' , * Update functions , datatypes literals for auto-suggestion field `` SHA384 '' , `` NTH_VALUE '' , `` BIT '' , `` REGEXP_SPLIT_TO_TABLE '' , `` BOOL_AND '' , `` ISFINITE '' , `` ENCODE '' , `` POSITION '' , function ( `` CURRENT_TIME '' , -2 ) , `` TIME '' , `` INITCAP '' , `` LEFT '' , `` BOOL '' , `` INET '' , `` POINT '' , `` UPPER '' , `` SMALLSERIAL '' , `` TO_HEX '' , `` REGTYPE '' , `` TO_DATE '' , Completion ( text= '' INT4 '' , display_meta= '' datatype '' ) , `` TSVECTOR '' , `` TRANSLATE '' , `` QUOTE_NULLABLE '' , `` LOG '' , `` ARRAY_LENGTH '' , `` LOWER '' , `` REGPROCEDURE '' , `` MAKE_INTERVAL '' , `` VARBIT '' , `` MAKE_DATE '' , `` TRIM '' , `` NETMASK '' , `` CONVERT_FROM '' , `` AREA '' , `` CONCAT_WS '' , `` PCLOSE '' , `` RPAD '' , `` SHA512 '' , `` BIT VARYING '' , `` DATE_TRUNC '' , `` SCALE '' , `` SHA256 '' , `` RADIUS '' , `` REPLACE '' , text = `` SELECT price : :IN '' `` LOCALTIME '' , `` REGDICTIONARY '' , `` TO_CHAR '' , `` EXTRACT '' , `` ANYELEMENT '' , `` RTRIM '' , `` EXP '' , `` XML '' result = completions_to_set ( `` BTRIM '' , `` TRANSACTION_TIMESTAMP '' , `` LPAD '' , `` MONEY '' , Completion ( text= '' INET '' , display_meta= '' datatype '' ) , `` INTERVAL '' , `` NUM_NONNULLS '' , `` TOP '' , Completion ( text= '' INT8 '' , display_meta= '' datatype '' ) , `` SQRT '' , `` TRUNC '' , `` REGEXP_MATCH '' , `` BOOL_OR '' , `` BIGSERIAL '' , `` REGEXP_MATCHES '' , `` NPOINTS '' , `` DECODE '' , `` ANYNONARRAY '' , `` ENUM_RANGE '' , `` SUBSTRING '' , Completion ( text= '' INTERVAL '' , display_meta= '' datatype '' ) , `` REGNAMESPACE '' , completer.get_completions ( def test_datatype_name_completion ( completer , complete_event ) : `` TEXT '' , `` SET_BIT '' , `` MAKE_TIMESTAMP '' , `` MID '' , `` REGPROC '' , Completion ( text= '' INT2 '' , display_meta= '' datatype '' ) , function ( `` MAKE_TIME '' , -2 ) , `` TSQUERY '' , `` POPEN '' , `` STATEMENT_TIMESTAMP '' , `` PG_LSN '' , `` PARSE_IDENT '' , `` LOCALTIMESTAMP '' , `` ISOPEN '' , `` OVERLAY '' , `` PG_CLIENT_ENCODING '' , `` BIT_OR '' , `` REGOPERATOR '' , `` LEAD '' , `` ANYARRAY '' , `` STARTS_WITH '' , Completion ( text= '' MAKE_TIME '' , start_position=-2 ) , `` QUOTE_LITERAL '' , `` LAST_VALUE '' , `` ASCII '' , `` FLOAT8 '' , `` RANK '' , `` ARRAY_REPLACE '' , `` SERIAL4 '' , `` CEILING '' , `` WIDTH '' , `` DIAMETER '' , `` TIMESTAMP '' , `` MAKE_TIME '' , `` TXID_SNAPSHOT '' , function ( `` MASKLEN '' , -2 ) , `` VOID '' `` REGROLE '' , `` SMALLINT '' , `` STRING_TO_ARRAY '' , `` EVENT_TRIGGER '' , `` MASKLEN '' , `` LAG '' , smart_completion=True , `` XMLAGG '' `` UCASE '' Completion ( text= '' INT '' , display_meta= '' datatype '' ) , `` ABBREV '' , `` WIDTH_BUCKET '' , `` CIDR '' , `` BIT_AND '' , function ( `` CURRENT_TIMESTAMP '' , -2 ) , `` LANGUAGE_HANDLER '' , `` CURRENT_TIMESTAMP '' , `` HEIGHT '' , `` DEGREES '' , `` JSONB '' , `` GET_BYTE '' , `` ARRAY_TO_STRING '' , `` FLOOR '' , `` OPAQUE '' , `` NTILE '' , `` CIRCLE '' , `` SET_MASKLEN '' , `` GET_BIT '' , `` CEIL '' , function ( `` CUME_DIST '' , -2 ) , `` POWER '' , Completion ( text= '' MAKE_TIMESTAMPTZ '' , start_position=-2 ) , `` EVERY '' , `` SERIAL '' , `` REGEXP_SPLIT_TO_ARRAY '' , `` FAMILY '' , `` CHARACTER '' , `` REGCLASS '' , `` CHAR_LENGTH '' , `` RADIANS '' , `` JUSTIFY_DAYS '' , `` FIRST_VALUE '' , `` ANYRANGE '' , `` PI '' , `` SERIAL8 '' , `` TIMEOFDAY '' , `` ARRAY_UPPER '' , `` CONVERT_TO '' , `` QUOTE_IDENT '' , `` CURRENT_TIME '' , `` MD5 '' , `` POLYGON '' , position = len ( `` SELECT price : :IN '' ) `` CLOCK_TIMESTAMP '' , Completion ( text= '' MAKE_TIMESTAMP '' , start_position=-2 ) , `` DIV '' , `` SET_BYTE '' , `` JSON '' , `` ARRAY_AGG '' , function ( `` MAKE_INTERVAL '' , -2 ) , `` ENUM_FIRST '' , `` CENTER '' , `` CSTRING '' , `` ARRAY_POSITION '' , `` ARRAY_FILL '' , `` REGCONFIG '' , `` CBRT '' , `` INT4 '' , `` LTRIM '' , `` ANYENUM '' , function ( `` MAKE_TIMESTAMPTZ '' , -2 ) , `` RIGHT '' , `` BROADCAST '' , `` DENSE_RANK '' , `` CUME_DIST '' , `` ARRAY_POSITIONS '' , `` DATE_PART '' , `` MACADDR8 '' , `` ARRAY_PREPEND '' , `` ABS '' , complete_event , `` INT2 '' , `` REVERSE '' , `` OCTET_LENGTH '' , `` ARRAY_DIMS '' , `` TO_ASCII '' , `` TO_NUMBER '' , function ( `` MAKE_TIMESTAMP '' , -2 ) , `` LSEG '' , `` ENUM_LAST '' , `` CONVERT '' , function ( `` CURRENT_DATE '' , -2 ) , `` ISCLOSED '' , `` BOX '' , `` REGOPER '' , ) `` INTERNAL '' , `` UNNEST '' , `` MAKE_TIMESTAMPTZ '' , `` BYTEA '' , `` LEN '' , `` ARRAY_LOWER '' , `` SERIAL2 '' , `` LAST '' , `` SIGN '' , `` HOST '' , Completion ( text= '' MAKE_INTERVAL '' , start_position=-2 ) , `` SPLIT_PART '' , `` NETWORK '' , `` JUSTIFY_HOURS '' , `` LOG10 '' , `` INET_MERGE '' , Document ( text=text , cursor_position=position ) , `` CURRENT_DATE '' , `` MOD '' , `` SHA224 '' , `` INT8 '' , `` NUM_NULLS '' , `` DECIMAL '' , assert result == completions_to_set ( [ `` LN '' , `` LENGTH '' , `` BIT_LENGTH '' , function ( `` MAKE_DATE '' , -2 ) , ) `` VOID '' , `` SUBSTR '' , `` OID '' ,","['changelog.rst', 'pgcli/packages/pgliterals/pgliterals.json', 'tests/test_naive_completion.py', 'tests/test_smart_completion_public_schema_only.py']",Update suggestion literals ( # 1195 )
2,8f7e31450835bca5d9a8bb4de252efba6f4b7b10,2020-07-28 23:08:19-07:00,"import humanize * Move from ` humanize ` to ` pendulum ` for displaying query durations ( # 1015 ) pendulum.Duration ( seconds=query.total_time ) .in_words ( ) , `` pendulum > =2.1.0 '' , * Tom Caruso ( tomplex ) humanize.time.naturaldelta ( query.execution_time ) , `` humanize > = 0.5.1 '' , pendulum.Duration ( seconds=query.execution_time ) .in_words ( ) , humanize.time.naturaldelta ( query.total_time ) , import pendulum","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'setup.py']",Move from humanize to pendulum library for displaying query durations ( # 1199 )
3,41dd24e8da9a812cb41e022c33dbe9835361d7b6,2020-07-07 20:19:22-07:00,"Token.Literal.String : `` literal.string '' , keyword = 'bold # 008000 ' * Support setting color for null , string , number , keyword value Token.Keyword : `` keyword '' , literal.number = ' # 666666 ' Token.Literal.Number : `` literal.number '' , * Seungyong Kwak ( GUIEEN ) literal.string = ' # ba2121 ' * Support setting color for null value","['AUTHORS', 'changelog.rst', 'pgcli/pgclirc', 'pgcli/pgstyle.py']",Add custom color ( # 1196 )
4,77414aa9e75f89cca9d248d4c0f3b9f1959007c8,2020-06-28 10:12:17+08:00,"* Fix for list index out of range when executing commands from a file ( # 1193 ) . ( Thanks : ` Irina Truong ` _ ) formatted_sql = sqlparse.format ( query.lower ( ) , strip_comments=True ) sql = sqlparse.format ( sql , strip_comments=True ) .strip ( ) formatted_sql = sqlparse.format ( query.lower ( ) , strip_comments=True ) .strip ( )","['changelog.rst', 'pgcli/packages/parseutils/__init__.py', 'pgcli/pgexecute.py']",Merge pull request # 1194 from dbcli/j-bennet/fix-sql-comment
5,106c6c7bf889b0db5fe85eba31f3f7f6b52a0895,2020-06-26 14:01:24-07:00,"* Fix for list index out of range when executing commands from a file ( # 1193 ) . ( Thanks : ` Irina Truong ` _ ) formatted_sql = sqlparse.format ( query.lower ( ) , strip_comments=True ) sql = sqlparse.format ( sql , strip_comments=True ) .strip ( ) formatted_sql = sqlparse.format ( query.lower ( ) , strip_comments=True ) .strip ( )","['changelog.rst', 'pgcli/packages/parseutils/__init__.py', 'pgcli/pgexecute.py']",Fix for # 1193 list index out of range on sql comment .
6,0c24e8bda226f3dbd6ccb0381515a9c903847249,2020-05-28 15:29:50-07:00,"`` cli_helpers [ styles ] > = 1.2.0 '' , output.null = `` # 808080 '' * Support setting color for null value `` cli_helpers [ styles ] > = 2.0.0 '' , Token.Output.Null : `` output.null '' , except AttributeError : except AttributeError as err :","['changelog.rst', 'pgcli/pgclirc', 'pgcli/pgstyle.py', 'setup.py']",Support style for missing value . ( # 1186 )
7,4a98b37877050d0ff8cf475dc2fb8b3a93c7da89,2020-05-26 11:28:48-07:00,"# Possible values : `` always '' , never '' and `` if_more_than_one_table '' # Enables context sensitive auto-completion . If this is disabled , all # Enables context sensitive auto-completion . If this is disabled the all * Minor typo fixes in ` pgclirc ` . ( Thanks : ` anthonydb ` _ ) * Anthony DeBarros ( anthonydb ) # keyword casing preference . Possible values : `` lower '' , `` upper '' , `` auto '' .. _ ` anthonydb ` : https : //github.com/anthonydb # Timing of sql statments and table rendering . # keyword casing preference . Possible values `` lower '' , `` upper '' , `` auto '' # Possible values : `` always '' , `` never '' and `` if_more_than_one_table '' # Timing of sql statements and table rendering .","['AUTHORS', 'changelog.rst', 'pgcli/pgclirc']",Merge pull request # 1187 from anthonydb/master
8,b994c757013a2cfc6cdb9407120e53d94e8906f0,2020-05-11 09:51:23-07:00,FROM python:2.7 * Update python version in Dockerfile * Igor Kim ( igorkim ) FROM python:3.8,"['AUTHORS', 'Dockerfile', 'changelog.rst']",Update python version from 2.7 to 3.8 in Dockerfile ( # 1181 )
9,bcb0c8bce776a5eba9f5425c57c2ec8385f10e94,2020-04-23 10:17:40-07:00,"click.echo_via_pager ( text , color ) if status and table_format ! = `` csv '' : if status : # Only print the status if it 's not None . import platform if table_format == `` csv '' : # Nevertheless , we want to keep on using `` excel '' on Windows since it uses '\r\n ' * Add support for using [ pspg ] ( https : //github.com/okbob/pspg ) as a pager ( # 1102 ) output_kwargs [ `` dialect '' ] = dialect # The default CSV dialect is `` excel '' which is not handling newline values correctly elif `` pspg '' in os.environ [ `` PAGER '' ] and self.table_format == `` csv '' : # Only print the status if it 's not None and we are not producing CSV # as the line terminator # https : //github.com/dbcli/pgcli/issues/1102 * Panos Mavrogiorgos ( pmav99 ) dialect = `` excel '' if platform.system ( ) == `` Windows '' else `` unix ''","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Add support for using pspg as the pager . ( # 1173 )
10,936475258d501b7b1fed1c80080eabfae8179970,2020-04-17 22:58:13-07:00,"bottom_toolbar=get_toolbar_tokens , self.show_bottom_toolbar = c [ `` main '' ] .as_bool ( `` show_bottom_toolbar '' ) bottom_toolbar=get_toolbar_tokens if self.show_bottom_toolbar else None , * Add config option show_bottom_toolbar . # Use keyring to automatically save and load password in a secure manner # Use keyring to automatically save and load password in a secure manner show_bottom_toolbar = True # Show/hide the informational toolbar with function keymap at the footer . * Stephano Paraskeva","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc']",show_bottom_toolbar - Feature to Show/Hide Toolbar ( # 1170 )
11,f3ac5598448a0c2080ee267f00931ed556a6779d,2020-04-17 14:52:19-07:00,"`` `` '' password=much_secure pgcli.connect_service ( service , user ) return service_conf , service_file port= '' 5433 '' , if not service : elif os.environ.get ( `` PGSERVICE '' , None ) : user=a_user elif service is not None : user= '' another_user '' , host=b_host service = database [ 8 : ] if service not in service_file_config : elif `` = '' in database and service is None : pgcli.connect_dsn ( `` service= { 0 } '' .format ( os.environ [ `` PGSERVICE '' ] ) ) `` 5435 '' , database=service_config.get ( `` dbname '' ) , `` `` , `` b_host '' , passwd=service_config.get ( `` password '' ) , return None , service_file exit ( 1 ) host=service_config.get ( `` host '' ) , host= '' a_host '' , service = None port=5433 del os.environ [ `` PGSERVICEFILE '' ] import platform dbname=b_dbname ) service_conf.write ( service = os.getenv ( `` PGSERVICE '' ) port=5435 user=b_user port=service_config.get ( `` port '' ) , [ my_other_service ] passwd= '' much_secure '' , if database.startswith ( `` service= '' ) : if platform.system ( ) == `` Windows '' : elif os.getenv ( `` PGSERVICE '' ) is not None : def test_pg_service_file ( tmpdir ) : del os.environ [ `` PGPASSWORD '' ] if not service_file : `` very_secure '' , service_file = os.getenv ( `` PGSYSCONFDIR '' ) + `` \\pg_service.conf '' service = service or os.getenv ( `` PGSERVICE '' ) service_file = expanduser ( `` ~/.pg_service.conf '' ) database= '' a_dbname '' , click.secho ( `` `` '' [ myservice ] `` service ' % s ' was not found in % s '' % ( service , file ) , err=True , fg= '' red '' application_name= '' pgcli '' , with open ( tmpdir.join ( `` .pg_service.conf '' ) .strpath , `` w '' ) as service_conf : def connect_service ( self , service , user ) : from os.path import expanduser # try ~/.pg_service.conf ( if that exists ) from configobj import ConfigObj with mock.patch.object ( PGExecute , `` __init__ '' ) as mock_pgexecute : * Add support for ` pg_service.conf ` files def parse_service_info ( service ) : service_file = os.getenv ( `` PGSERVICEFILE '' ) cli.connect_service ( `` myservice '' , `` another_user '' ) self.connect ( mock_connect.assert_called_with ( else : service_file_config = ConfigObj ( service_file ) if service_config is None : mock_pgexecute.return_value = None elif os.getenv ( `` PGSYSCONFDIR '' ) : elif `` = '' in database : os.environ [ `` PGPASSWORD '' ] = `` very_secure '' # nothing to do service_conf = service_file_config.get ( service ) host=a_host os.environ [ `` PGSERVICEFILE '' ] = tmpdir.join ( `` .pg_service.conf '' ) .strpath service_file = os.path.join ( os.getenv ( `` PGSYSCONFDIR '' ) , `` .pg_service.conf '' ) dbname=a_dbname `` b_dbname '' , with mock.patch.object ( PGCli , `` connect '' ) as mock_connect : ) `` b_user '' , user=user or service_config.get ( `` user '' ) , ) mock_pgexecute.assert_called_with ( cli = PGCli ( pgclirc_file=str ( tmpdir.join ( `` rcfile '' ) ) ) service_config , file = parse_service_info ( service ) cli.connect_service ( `` my_other_service '' , None )","['changelog.rst', 'pgcli/main.py', 'tests/test_main.py']",Add pg_service.conf handling ( # 1155 )
12,63b87ba3a8003fb6c605fd5f9570b32e5087bb60,2020-04-10 15:14:56-07:00,3.0.0 ========= ===== Upcoming :,['changelog.rst'],New release 3.0.0 . ( # 1165 )
13,b6e2a229e5f122a9efa31666dee7965621eff031,2020-04-05 20:56:31-07:00,"* Upgrade python-prompt-toolkit to v3.0 . ( Thanks : ` laixintao ` _ ) wrappers.wait_prompt ( context ) `` prompt_toolkit > =2.0.6 , < 3.0.0 '' , os.environ [ `` PROMPT_TOOLKIT_NO_CPR '' ] = `` 1 '' `` prompt_toolkit > =3.0.0 , < 4.0.0 '' ,","['changelog.rst', 'setup.py', 'tests/features/environment.py', 'tests/features/steps/basic_commands.py']",upgrade prompt-toolit to 3.0 ( # 1149 )
14,93c14f844ee33e4d47ae07688f0e5ca7219df7de,2020-04-03 15:15:53-07:00,"h| -- host ) _pg_databases ( ) -- * ) COMPREPLY= ( -- ) complete -F _pgcli pgcli { # return list of available databases } U| -- user ) awk 'NF > 1 { print $ 1 } ' ) '' -- `` $ cur '' ) ) -- row-limit -- help ' -- `` $ cur '' ) ) - ) return 0 -- single-connection -- version -- dbname -- pgclirc -- dsn local cur prev words cword # only complete long options _pg_users ( ) COMPREPLY= ( $ ( compgen -W `` $ ( psql -AtqwlF $ '\t ' 2 > /dev/null | \ # -w was introduced in 8.4 , https : //launchpad.net/bugs/164772 * ) _pg_databases _pg_databases _pg_users # `` Access privileges '' in output may contain linefeeds , hence the NF > 1 compopt -o nospace _pgcli ( ) esac # return list of available options } & & ; ; COMPREPLY= ( $ ( compgen -W ' -- host -- port -- user -- password -- no-password ; ; case $ prev in [ [ $ COMPREPLY == * = ] ] & & compopt -o nospace help|-v| -- version|-p| -- port|-R| -- row-limit ) template1 2 > /dev/null ) '' -- `` $ cur '' ) ) _known_hosts_real `` $ cur '' _init_completion -s || return # all other arguments are noop with these return 0 COMPREPLY= ( $ ( compgen -W `` $ ( psql -Atqwc 'select usename from pg_user ' \ case `` $ cur '' in d| -- dbname )",['pgcli-completion.bash'],pgcli bash completion script ( # 892 )
15,d9ea18d3a0f93c7990bc5e7df76daf3e608ae3d9,2020-03-30 20:50:06+08:00,": : `` pgcli `` also supports many of the same ` environment variables ` _ as `` psql `` for login options ( e.g . `` PGHOST `` , `` PGPORT `` , `` PGUSER `` , `` PGPASSWORD `` , `` PGDATABASE `` ) . pgclirc PATH Location of pgclirc file . warn / -- no-warn Warn before running a destructive query . U , -- username TEXT Username to connect to the postgres database . Options : W , -- password Force password prompt . For more details : listening . row-limit INTEGER Set threshold for row limit prompt . Use 0 to disable help Show this message and exit . less-chatty Skip intro on startup and goodbye on exit . .. _environment variables : https : //www.postgresql.org/docs/current/libpq-envars.html prompt-dsn TEXT Prompt format for connections using DSN aliases list-dsn list of DSN configured into the [ alias_dsn ] section pgclirc file . result is wider than the terminal width . l , -- list list available databases , then exit . Usage : pgcli [ OPTIONS ] [ DBNAME ] [ USERNAME ] v , -- version Version of pgcli . w , -- no-password Never prompt for password . $ pgcli -- help of pgclirc file . p , -- port INTEGER Port number at which the postgres instance is d , -- dbname TEXT database name to connect to . prompt . u , -- user TEXT Username to connect to the postgres database . auto-vertical-output Automatically switch to vertical output mode if the single-connection Do not use a separate connection for completions . h , -- host TEXT Host address of the postgres database . D , -- dsn TEXT Use DSN configured into the [ alias_dsn ] section of",['README.rst'],Add -- help output to README ( # 1164 )
16,e9874e2f96c27e24aafbc54436465abd8f152f8a,2020-03-18 09:11:10-07:00,"* Drop Python3.5 support . ( Thanks : ` laixintao ` _ ) * Drop Python2.7 , 3.4 , 3.5 support . ( Thanks : ` laixintao ` _ ) * Drop Python3.4 support . ( Thanks : ` laixintao ` _ ) envlist = py36 , py37 * Drop Python2.7 support . ( Thanks : ` laixintao ` _ ) `` Programming Language : : Python : : 3.8 '' , envlist = py36 , py37 , py38 `` 3.8 '' * Support Python3.8 . ( Thanks : ` laixintao ` _ )","['.travis.yml', 'changelog.rst', 'setup.py', 'tox.ini']",python3.8 : add travis test and setup.py class . ( # 1157 )
17,0f3d4602efa2eda4cf5056d237cac36b2cc012ea,2020-03-12 13:45:59-07:00,if not settings.get ( `` single_connection '' ) and executor.conn : * Close open connection in completion_refresher thread executor.conn.close ( ) # close connection established with pgexecute.copy ( ) * Gantsev Denis,"['AUTHORS', 'changelog.rst', 'pgcli/completion_refresher.py']",Fix : Unable to drop previously connected-to database ( # 1152 )
18,bc7a5d01001df69f9f0c3dfeb94cca92768ab696,2020-03-11 13:58:13-07:00,"target-version = [ 'py36 ' ] `` Programming Language : : Python : : 3.5 '' , envlist = py36 , py37 * * kwargs , `` 3.5 '' * Drop Python3.5 support . ( Thanks : ` laixintao ` _ ) target-version = [ 'py35 ' ] envlist = py35 , py36 , py37 * * kwargs","['.travis.yml', 'changelog.rst', 'pgcli/pgexecute.py', 'pyproject.toml', 'setup.py', 'tox.ini']",Drop Python3.5 . ( # 1154 )
19,fd775497547bb51e3d3b38590cbc83e54afd9508,2020-03-09 20:14:51-07:00,"assert `` fooé '' in result [ 3 ] run ( executor , `` '' '' insert into jsonbtest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) `` Programming Language : : Python : : 2.7 '' , assert u '' fooé '' in result [ 3 ] target-version = [ 'py27 ' ] assert u ' { `` name '' : `` Éowyn '' } ' in result assert `` Description '' in result [ 2 ] assert `` é '' in run ( run ( executor , u '' create table jsontest ( d json ) '' ) executor , `` SELECT d FROM jsontest LIMIT 1 '' , join=True , expanded=expanded `` Programming Language : : Python : : 2 '' , run ( executor , `` '' '' insert into jsontest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) executor , u '' SELECT d FROM jsontest LIMIT 1 '' , join=True , expanded=expanded run ( executor , u '' INSERT INTO person VALUES ( 'Moe ' , '日本語 ' ) '' ) you should use install `` pgcli < = 2.2.0 `` . * Drop Python2.7 support . ( Thanks : ` laixintao ` _ ) target-version = [ 'py35 ' ] run ( executor , `` CREATE TYPE mood AS ENUM ( 'sad ' , 'ok ' , 'happy ' , '日本語 ' ) '' ) run ( executor , u '' '' '' insert into jsonbtest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) assert `` 日本語 '' in run ( executor , `` SELECT * FROM person '' , join=True ) envlist = py35 , py36 , py37 Pgcli only runs on Python3.6+ since 2.2.0 , if you use an old version of Python , run ( executor , `` CREATE TABLE person ( name TEXT , current_mood mood ) '' ) run ( executor , `` create table jsontest ( d json ) '' ) `` 2.7 '' `` select 'fooé ' ; invalid syntax é '' , assert u '' 日本語 '' in run ( executor , u '' SELECT '日本語 ' AS japanese ; '' , join=True ) assert u '' \\xdeadbeef '' in run ( executor , `` select * from binarydata '' , join=True ) run ( executor , u '' insert into unicodechars ( t ) values ( ' é ' ) '' ) assert `` \\xdeadbeef '' in run ( executor , `` select * from binarydata '' , join=True ) run ( executor , `` INSERT INTO person VALUES ( 'Moe ' , '日本語 ' ) '' ) run ( executor , `` insert into unicodechars ( t ) values ( ' é ' ) '' ) assert u '' Command '' in result [ 1 ] run ( executor , u '' CREATE TYPE mood AS ENUM ( 'sad ' , 'ok ' , 'happy ' , '日本語 ' ) '' ) * * self.pgexecute.extra_args , run ( executor , u '' '' '' insert into jsontest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) assert u '' é '' in run ( * * self.pgexecute.extra_args assert u '' 日本語 '' in run ( executor , u '' SELECT * FROM person '' , join=True ) run ( executor , u '' CREATE TABLE person ( name TEXT , current_mood mood ) '' ) envlist = py27 , py35 , py36 , py37 assert `` Command '' in result [ 1 ] u '' select 'fooé ' ; invalid syntax é '' , assert u '' Description '' in result [ 2 ] assert `` 日本語 '' in run ( executor , `` SELECT '日本語 ' AS japanese ; '' , join=True ) assert ' { `` name '' : `` Éowyn '' } ' in result","['.travis.yml', 'README.rst', 'changelog.rst', 'pgcli/main.py', 'pyproject.toml', 'setup.py', 'tests/test_pgexecute.py', 'tox.ini']",Deprecate Python2.7 . ( # 1153 )
20,91263c37b94a1a3b45be13d35ff1ea19c7b8e1b7,2020-02-13 14:24:37-08:00,"' f ' - foreign table def _relations ( self , kinds= ( `` r '' , `` p '' , `` f '' , `` v '' , `` m '' ) ) : for row in self._relations ( kinds= [ `` r '' , `` p '' , `` f '' ] ) : for row in self._columns ( kinds= [ `` r '' ] ) : * Yoni Nakache ( lazydba247 ) ' p ' - partitioned table for row in self._relations ( kinds= [ `` r '' ] ) : def _columns ( self , kinds= ( `` r '' , `` p '' , `` f '' , `` v '' , `` m '' ) ) : def _columns ( self , kinds= ( `` r '' , `` v '' , `` m '' ) ) : * Add support for partitioned tables ( relkind `` p '' ) . def _relations ( self , kinds= ( `` r '' , `` v '' , `` m '' ) ) : for row in self._columns ( kinds= [ `` r '' , `` p '' , `` f '' ] ) :","['AUTHORS', 'changelog.rst', 'pgcli/pgexecute.py']",Add Support for partitioned tables . ( # 1145 )
21,8fe316e5376738880c9cf4013f37ff357f428e19,2020-01-15 22:45:16-08:00,"pytest > =2.7.0 , < =3.0.7 pytest > =2.7.0 `` 3.4 '' # The maximum version requirement can be removed once Python 3.4 goes EOL .. _ ` laixintao ` : https : //github.com/laixintao `` Programming Language : : Python : : 3.4 '' , * Drop Python3.4 support . ( Thanks : ` laixintao ` _ ) envlist = py27 , py34 , py35 , py36 , py37 envlist = py27 , py35 , py36 , py37","['.travis.yml', 'changelog.rst', 'requirements-dev.txt', 'setup.py', 'tox.ini']",Drop Python 3.4 support ( # 1141 )
22,77a361966a6cbe73ba153710f10f32cc27d167f5,2020-01-14 20:56:07-08:00,if dsn is not `` '' : .. _ ` thegeorgeous ` : https : //github.com/thegeorgeous if dsn ! = `` '' : * George Thomas ( thegeorgeous ) * Fix warning raised for using ` is not ` to compare string literal Bug fixes :,"['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Fix warning raised for using ` is not ` to compare string literal ( # 1139 )
23,2b55da84812f94bc98d3586244f02749326062d5,2020-01-07 06:55:36-08:00,* Add support for ANSI escape sequences for coloring the prompt ( # 1123 ) . pgcli package main entry point Features : if __name__ == `` __main__ '' : * Add ` __main__.py ` file to execute pgcli as a package directly ( # 1123 ) . cli ( ) `` `` '' from .main import cli * Add support for ANSI escape sequences for coloring the prompt ( # 1122 ) .,"['changelog.rst', 'pgcli/__main__.py']",Merge pull request # 1123 from TheJJ/main-file
24,a5f7d9196c45519aef761692698875ce9d8d4f8c,2020-01-07 06:53:42-08:00,Integration tests use ` behave package < https : //behave.readthedocs.io/ > ` _ and * BrownShibaDog ========= Internal : .. _ ` BrownShibaDog ` : https : //github.com/BrownShibaDog * Fix dead link in development guide . ( Thanks : ` BrownShibaDog ` _ ) Upcoming : Integration tests use ` behave package < http : //pythonhosted.org/behave/ > ` _ and,"['AUTHORS', 'DEVELOP.rst', 'changelog.rst']",Merge pull request # 1135 from BrownShibaDog/master
25,901812a7bf1667117668e24211a99ab7b867b98d,2019-12-08 19:19:43-08:00,"return ANSI ( prompt ) prompt = prompt.replace ( `` \\x1b '' , `` \x1b '' ) * Add support for ANSI escape sequences for coloring the prompt ( # 1123 ) . from prompt_toolkit.formatted_text import ANSI return [ ( `` class : prompt '' , prompt ) ] # \x1b [ ... m - insert ANSI escape sequence * Jonas Jelten","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 1122 from TheJJ/prompt-colors
26,257d0f2786106c8061f5b1ca4cd130abebc6ab01,2019-12-08 19:18:42-08:00,"from pgcli import __version__ ) with open ( `` pgcli/__init__.py '' , `` rb '' ) as f : version = str ( import re _version_re = re.compile ( r '' __version__\s+=\s+ ( . * ) '' ) version=__version__ , version=version , import ast ast.literal_eval ( _version_re.search ( f.read ( ) .decode ( `` utf-8 '' ) ) .group ( 1 ) )",['setup.py'],Merge pull request # 1119 from mmtj/setup-cleanup
27,51d4d4a04c1bc50238accb49788039e43b9b84d5,2019-12-04 09:24:17-08:00,"====== `` prompt_toolkit > =2.0.6 , < 2.1.0 '' , `` pgspecial > =1.11.8 '' , ========= `` prompt_toolkit > =2.0.6 , < 3.0.0 '' , 2.2.0 : Upcoming : `` pgspecial > =1.11.5 '' ,","['changelog.rst', 'setup.py']",J bennet/release 2.2.0 ( # 1126 )
28,0f969aba0cbf9b1a93c679a442e74e13f00a1702,2019-10-29 10:05:56-07:00,"print ( `` Closed connection : { 0 } . `` .format ( cn.dsn ) ) print ( `` Config file ( ~/.pgclirc ) moved to new location '' , config_full_path ) print ( `` `` .join ( cmd ) ) print ( `` Version : '' , __version__ ) print ( `` Created connection : { 0 } . `` .format ( cn.dsn ) ) print ( `` Time : % 0.03fs '' % query.total_time ) print ( `` reading fixture data : { } '' .format ( fixture_dir ) ) print ( `` -- - Pretending to run ... '' ) print ( print ( `` Created connection : { 0 } . `` .format ( cn.dsn ) ) print ( `` Version : '' , __version__ ) print ( ' { } = '' { } '' '.format ( k , new_value ) ) print ( `` - '' * 20 ) print ( `` package root : '' , context.package_root ) config_full_path , print ( `` Config file is now located at '' , config_full_path ) print ( `` fixture dir : '' , fixture_dir ) print ( boundary ) print ( `` Connected : { } '' .format ( conn.name ) ) print ( `` Connected : { } '' .format ( conn.name ) ) print ( `` Releasing Version : '' , ver ) 'Default pager found in PAGER environment variable : `` { } '' '.format ( print ( `` Goodbye ! '' ) print ( `` Closed connection : { 0 } . `` .format ( cn.dsn ) ) print ( `` Releasing Version : '' , ver ) print ( `` -- - after_scenario { } : kill cli '' .format ( scenario.name ) ) `` Please move the existing config file ~/.pgclirc to '' , 'Default pager found in config file : `` { } '' '.format ( configured_pager ) print ( `` package root : '' , context.package_root ) * Martin Matejek ( mmtj ) print ( print ( `` -- - after_scenario { } : kill cli '' .format ( scenario.name ) ) os_environ_pager , `` Please move the existing config file ~/.pgclirc to '' , config_full_path , print ( os_environ_pager print ( `` Version : '' , __version__ ) ) print ( `` `` .join ( cmd ) ) print ( `` -- - os.environ changed values : -- - '' ) print ( ' { } = '' { } '' '.format ( k , new_value ) ) print ( `` Chat : https : //gitter.im/dbcli/pgcli '' ) print ( `` -- - os.environ changed values : -- - '' ) print ( `` Version : '' , __version__ ) print ( `` reading fixture data : { } '' .format ( fixture_dir ) ) print ( `` -- - Skipping ... '' ) print ( `` Config file is now located at '' , config_full_path ) print ( `` - '' * 20 ) print ( `` fixture dir : '' , fixture_dir ) print ( `` Home : http : //pgcli.com '' ) print ( `` Server : PostgreSQL '' , self.pgexecute.server_version ) print ( `` Chat : https : //gitter.im/dbcli/pgcli '' ) print ( `` -- - Skipping ... '' ) print ( `` Server : PostgreSQL '' , self.pgexecute.server_version ) 'Default pager found in config file : `` % s '' ' , configured_pager print ( `` -- - Pretending to run ... '' ) print ( boundary ) print ( print ( `` Time : % 0.03fs '' % query.total_time ) print ( `` Config file ( ~/.pgclirc ) moved to new location '' , config_full_path ) print ( `` Home : http : //pgcli.com '' ) 'Default pager found in PAGER environment variable : `` % s '' ' , print ( `` Goodbye ! '' )","['AUTHORS', 'pgcli/magic.py', 'pgcli/main.py', 'release.py', 'tests/features/db_utils.py', 'tests/features/environment.py', 'tests/features/fixture_utils.py', 'tests/features/wrappager.py']",Merge pull request # 1118 from mmtj/logging-cleanup
29,f3dc23a94b57ccd7c1909dc32174b3bc8c501919,2019-10-28 10:08:59-07:00,"self.user = dsn_parameters.get ( `` user '' ) dsn_parameters = conn.get_dsn_parameters ( ) if dsn_parameters : self.host = conn_params.get ( `` host '' ) `` psycopg2 > = 2.8 '' , dsn_parameters = { } _logger.info ( `` Exception in get_dsn_parameters : % r '' , x ) dsn_parameters = conn.info.dsn_parameters * Error connecting to PostgreSQL 12beta1 ( # 1058 ) . ( Thanks : ` Irina Truong ` _ and ` Amjith Ramanujam ` _ ) self.user = conn_params.get ( `` user '' ) if libpq_version > = 93000 : self.dbname = dsn_parameters.get ( `` dbname '' ) # TODO : use actual connection info from psycopg2.extensions.Connection.info as psycopg > 2.8 is available and required dependency # noqa self.port = dsn_parameters.get ( `` port '' ) # PQconninfo not available in libpq < 9.3 self.port = conn_params.get ( `` port '' ) self.port = dsn_parameters.get ( `` port '' ) # https : //github.com/dbcli/pgcli/issues/1110 # as libpq_version > 9.3 is available and required dependency # use actual connection info from psycopg2.extensions.Connection.info self.host = dsn_parameters.get ( `` host '' ) self.host = dsn_parameters.get ( `` host '' ) libpq_version = psycopg2.__libpq_version__ self.user = dsn_parameters.get ( `` user '' ) * Fix for PQconninfo not available in libpq < 9.3 ( # 1110 ) . ( Thanks : ` Irina Truong ` _ ) self.dbname = conn_params.get ( `` database '' ) `` psycopg2 > = 2.7.4 '' , try : except Exception as x : dsn_parameters = conn.get_dsn_parameters ( ) self.dbname = dsn_parameters.get ( `` dbname '' ) * Error connecting to PostgreSQL 12beta1 ( # 1058 ) . ( Thanks : ` Irina Truong ` _ ) else :","['changelog.rst', 'pgcli/pgexecute.py', 'setup.py']",Merge pull request # 1112 from dbcli/j-bennet/pqconninfo-1110
30,199a0223e044ec3116879e67d2b924050e4afa78,2019-10-25 22:21:51-07:00,"Send ` SELECT a ` to see completion . def step_see_error_message ( context ) : Scenario : run partial select command then we see dbcli prompt `` `` '' When we send partial select command def step_send_partial_select_command ( context ) : wrappers.wait_prompt ( context ) wrappers.expect_exact ( context , 'column `` a '' does not exist ' , timeout=2 ) then we see error message context.cli.sendline ( `` SELECT a '' )","['tests/features/basic_commands.feature', 'tests/features/steps/basic_commands.py']",Merge pull request # 1116 from dbcli/test_
31,f25e49555aa53c740baaf685e9ed4b34a0a5b6f2,2019-10-23 22:11:44+01:00,"language_version : python3.7 filter=~ ( has_completions | is_searching ) & buffer_should_be_handled ( pgcli ) , _logger.debug ( `` Detected enter key . '' ) _logger = logging.getLogger ( __name__ ) filter=~ ( completion_is_selected | is_searching ) _logger.debug ( `` Multi-line mode is set to 'safe ' . Do NOT handle the buffer . '' ) _logger.debug ( `` Detected enter key during completion selection . '' ) repo : https : //github.com/psf/black & buffer_should_be_handled ( pgcli ) , import logging repo : https : //github.com/ambv/black _logger.debug ( `` Not in multi-line mode . Handle the buffer . '' ) _logger.debug ( `` Detected enter key . '' ) language_version : python3.6","['.pre-commit-config.yaml', 'pgcli/key_bindings.py', 'pgcli/pgbuffer.py']",Fix the condition for < enter > key . ( # 1114 )
32,a713b5d08b0fae4e55066f5438522a173f79606b,2019-10-16 20:57:19-07:00,"if parent : assert set ( suggestions ) == set ( Function ( schema=parent ) , View ( schema=parent ) , Column ( Table ( schema= '' x '' ) , * Function argument completions now take account of table aliases ( # 1048 ) . ( Thanks : ` Owen Stephens ` _ ) Table ( schema=parent ) , View ( schema= '' x '' ) , table_refs=tables , local_tables=stmt.local_tables , qualifiable=True def test_function_arguments_with_alias_given ( ) : `` `` '' # Check for a table alias or schema qualification Keyword ( `` ( `` ) , testdata.columns ( `` products '' , `` custom '' ) tables = tuple ( t for t in tables if identifies ( parent , t ) ) Function ( schema=None ) , ] Column ( suggestions = suggest_type ( `` SELECT avg ( x . FROM tbl x , tbl2 y '' , `` SELECT avg ( x . '' ) table_refs=extract_tables ( stmt.full_text ) , return ( table_refs= ( TableReference ( None , `` tbl '' , `` x '' , False ) , ) , Table ( schema=parent ) , tables = stmt.get_tables ( ) tables = stmt.get_tables ( ) Function ( schema=None ) , Column ( table_refs= ( ( None , `` tbl '' , None , False ) , ) , qualifiable=True ) , Function ( schema=None ) , Column ( table_refs=tables , local_tables=stmt.local_tables ) , assert completions_to_set ( result ) == completions_to_set ( testdata.columns ( `` users '' ) ) Return suggestions for an expression , taking account of any partially-typed Keyword ( token_v.upper ( ) ) , ) Function ( schema= '' x '' ) , View ( schema=parent ) , return ( return ( parent = stmt.identifier.get_parent_name ( ) if stmt.identifier else [ ] [ Column ( table_refs= ( ( None , `` tbl '' , None , False ) , ) , qualifiable=True ) ] qualifiable=True , assert completions_to_set ( result ) == completions_to_set ( if parent : Column ( table_refs=tables , local_tables=stmt.local_tables , qualifiable=True ) , testdata.columns_functions_and_keywords ( `` products '' , `` custom '' ) def test_lparen_suggests_cols ( ) : return ( def test_lparen_suggests_cols_and_funcs ( ) : ) , ) identifier 's parent , which may be a table alias or schema name . ( testdata.columns_functions_and_keywords ( `` users '' ) ) tables = tuple ( t for t in tables if identifies ( parent , t ) ) ) , parent = ( stmt.identifier and stmt.identifier.get_parent_name ( ) ) or [ ] else : def _suggest_expression ( token_v , stmt ) : local_tables=stmt.local_tables , local_tables= ( ) , qualifiable=False , [ Column ( table_refs=tables , local_tables=stmt.local_tables ) , Column ( ) ) , Keyword ( token_v.upper ( ) ) , Function ( schema=parent ) , ) return _suggest_expression ( token_v , stmt )","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 1107 from owst/function_arg_completions_with_alias
33,2bf01a77844532cce9686a45b227209f85646dde,2019-10-16 20:54:28-07:00,"if pgcli.multiline_mode == `` safe '' : # inserted instead ) , so we force the handling if we 're not in a completion or # overrides the default behaviour of prompt_toolkit ) and is # there 's an open quote surrounding it , as is common when writing a or ( text == `` : q '' ) # Quit does n't need semi-colon text == `` '' def _multiline_exception ( text ) : multiline=True , def _is_complete ( sql ) : # distinct from prompt_toolkit 's multiline mode here , which # controls layout/display of the prompt/buffer ) # Just a plain enter without any text * Fix slow typing/movement when multi-line query ends in a semicolon ( # 994 ) . ( Thanks : ` Owen Stephens ` _ ) # N.b . pgcli 's multi-line mode controls submit-on-Enter ( which # there 's an open quote surrounding it , as is common when writing a # CREATE FUNCTION command * Fix broken multi-line history search ( # 1031 ) . ( Thanks : ` Owen Stephens ` _ ) def pg_is_multiline ( pgcli ) : # When using multi_line input mode the buffer is not handled on Enter ( a new line is is_searching , text = text.strip ( ) or ( text == `` quit '' ) # Quit does n't need semi-colon or ( text == `` exit '' ) # A complete SQL command or ( text == `` '' ) # Just a plain enter without any text return False def buffer_should_be_handled ( pgcli ) : text = doc.text.strip ( ) return False or ( text == `` exit '' ) # Exit does n't need semi-colon filter=~ ( has_completions | is_searching ) & buffer_should_be_handled ( pgcli ) , or text.endswith ( r '' \e '' ) # Special Command from .pgbuffer import buffer_should_be_handled ) text.startswith ( `` \\ '' ) # Special Command Returns True if the buffer contents should be handled ( i.e . the query/command text.startswith ( `` \\ '' ) ) or text.endswith ( r '' \G '' ) # Ended with \e which should launch the editor # A complete command is an sql statement that ends with a semicolon , unless `` enter '' , executed ) immediately . This is necessary as we use prompt_toolkit in multiline or _is_complete ( text ) # Ended with \e which should launch the editor def _is_complete ( sql ) : def _ ( event ) : return ( or text.endswith ( r '' \e '' ) # Special Command return cond # A complete command is an sql statement that ends with a semicolon , unless from .pgbuffer import pg_is_multiline else : return sql.endswith ( `` ; '' ) and not is_open_quote ( sql ) or ( text == `` : q '' ) # To all the vim fans out there doc = get_app ( ) .layout.get_buffer_by_name ( DEFAULT_BUFFER ) .document or ( # To all the vim fans out there or _is_complete ( text ) # A complete SQL command mode , which by default will insert new lines on Enter . doc = get_app ( ) .layout.get_buffer_by_name ( DEFAULT_BUFFER ) .document `` `` '' return sql.endswith ( `` ; '' ) and not is_open_quote ( sql ) ) # history search , and one of several conditions are True return ( # CREATE FUNCTION command multiline=pg_is_multiline ( self ) , return not _multiline_exception ( doc.text ) or ( text == `` quit '' ) # Exit does n't need semi-colon if pgcli.multiline_mode == `` safe '' : or text.endswith ( r '' \G '' ) # Special Command event.current_buffer.validate_and_handle ( ) return cond","['changelog.rst', 'pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgbuffer.py']",Merge pull request # 1109 from owst/use_keybinding_to_conditionally_force_handle_multiline_buffer
34,e9b18f9e84a5b26eb4a42633f6cee98597d70ad4,2019-10-16 23:33:43+01:00,"Return suggestions for an expression , taking account of the partially-typed identifier 's parent , which may be a table alias or schema name . Return suggestions for an expression , taking account of any partially-typed identifiers parent , which may be a table alias or schema name .",['pgcli/packages/sqlcompletion.py'],fixup ! fixup ! Take account of table aliases when completing function args ( # 1048 )
35,629a931aedd290bcf69ddcb6ac1e0fd807b5a448,2019-10-16 22:26:25+01:00,"if pgcli.multiline_mode == `` safe '' : # overrides the default behaviour of prompt_toolkit ) and is Returns True if the input mode is multi-line using psql mode , and the main # N.b . pgcli 's multi-line mode controls submit-on-Enter ( which multiline=True , if not pgcli.multi_line : # distinct from prompt_toolkit 's multiline mode here , which from prompt_toolkit.filters import HasFocus , IsDone # controls layout/display of the prompt/buffer * Fix slow typing/movement when multi-line query ends in a semicolon ( # 994 ) . ( Thanks : ` Owen Stephens ` _ ) return True def buffer_should_be_handled ( pgcli ) : def multi_line_buffer_should_be_handled ( pgcli ) : filter=~ ( has_completions | is_searching ) & buffer_should_be_handled ( pgcli ) , method is required since by default prompt_toolkit would not handle a buffer on from .pgbuffer import buffer_should_be_handled Returns True if the buffer contents should be handled ( i.e . the query/command multiline=Condition ( lambda : self.multi_line ) , buffer 's contents indicate that it should be handled , False otherwise . This Enter keypress when in multi-line mode . if not pgcli.multi_line or pgcli.multiline_mode == `` safe '' : executed ) immediately . This is necessary as we use prompt_toolkit in multiline from .pgbuffer import multi_line_buffer_should_be_handled from prompt_toolkit.filters import HasFocus , IsDone , Condition mode , which by default will insert new lines on Enter . filter=~ ( completion_is_selected | is_searching ) & multi_line_buffer_should_be_handled ( pgcli ) ,","['changelog.rst', 'pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgbuffer.py']",fixup ! fixup ! Handle a multi-line query on Enter key-press ( fixes # 1031 )
36,6763433a687cc651d9ce5c97eeb81d83c4d34f71,2019-10-13 13:50:36+01:00,"# inserted instead ) , so we force the handling if we 're not in a completion or & multi_line_buffer_should_be_handled ( pgcli ) , # inserted instead ) , so we force the handling if one of several conditions are True filter=~ ( completion_is_selected | is_searching ) filter=~completion_is_selected & multi_line_buffer_should_be_handled ( pgcli ) , # history search , and one of several conditions are True is_searching ,",['pgcli/key_bindings.py'],fixup ! Handle a multi-line query on Enter key-press ( fixes # 1031 )
37,7f44748149be47cc42261ff73465a82eb7174eca,2019-10-13 01:07:57+01:00,"or ( text == `` quit '' ) # Exit does n't need semi-colon text == `` '' or ( text == `` : q '' ) # Quit does n't need semi-colon def _multiline_exception ( text ) : if not pgcli.multi_line or pgcli.multiline_mode == `` safe '' : ) # Just a plain enter without any text # inserted instead ) , so we force the handling if one of several conditions are True Returns True if the input mode is multi-line using psql mode , and the main def pg_is_multiline ( pgcli ) : * Fix broken multi-line history search ( # 1031 ) . ( Thanks : ` Owen Stephens ` _ ) # When using multi_line input mode the buffer is not handled on Enter ( a new line is def cond ( ) : text = text.strip ( ) from prompt_toolkit.filters import HasFocus , IsDone or ( text == `` quit '' ) # Quit does n't need semi-colon buffer 's contents indicate that it should be handled , False otherwise . This or ( text == `` '' ) # Just a plain enter without any text return False or ( text == `` exit '' ) # A complete SQL command text = doc.text.strip ( ) return False or ( text == `` exit '' ) # Exit does n't need semi-colon multiline=Condition ( lambda : self.multi_line ) , or text.endswith ( r '' \e '' ) # Special Command ) text.startswith ( `` \\ '' ) # Special Command text.startswith ( `` \\ '' ) from prompt_toolkit.filters import HasFocus , IsDone , Condition ) or text.endswith ( r '' \G '' ) # Ended with \e which should launch the editor method is required since by default prompt_toolkit would not handle a buffer on `` enter '' , from .pgbuffer import multi_line_buffer_should_be_handled or _is_complete ( text ) # Ended with \e which should launch the editor def _ ( event ) : return ( or text.endswith ( r '' \e '' ) # Special Command return cond from .pgbuffer import pg_is_multiline return True else : if not pgcli.multi_line : or ( text == `` : q '' ) # To all the vim fans out there doc = get_app ( ) .layout.get_buffer_by_name ( DEFAULT_BUFFER ) .document or ( # To all the vim fans out there or _is_complete ( text ) # A complete SQL command or text.endswith ( r '' \G '' ) # Special Command doc = get_app ( ) .layout.get_buffer_by_name ( DEFAULT_BUFFER ) .document `` `` '' Enter keypress when in multi-line mode . ) return ( multiline=pg_is_multiline ( self ) , return not _multiline_exception ( doc.text ) def multi_line_buffer_should_be_handled ( pgcli ) : def cond ( ) : @ Condition if pgcli.multiline_mode == `` safe '' : filter=~completion_is_selected & multi_line_buffer_should_be_handled ( pgcli ) , event.current_buffer.validate_and_handle ( ) return cond","['changelog.rst', 'pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgbuffer.py']",Handle a multi-line query on Enter key-press ( fixes # 1031 )
38,a700f2b788fa8050abb23598db8282050fd18e24,2019-10-12 17:11:32+01:00,"assert completions_to_set ( result ) == completions_to_set ( testdata.columns_functions_and_keywords ( `` products '' , `` custom '' ) testdata.columns ( `` products '' , `` custom '' ) ) assert completions_to_set ( result ) == completions_to_set ( testdata.columns ( `` users '' ) ) ( testdata.columns_functions_and_keywords ( `` users '' ) )","['tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",fixup ! Take account of table aliases when completing function args ( # 1048 )
39,b401b16d9a4332b3af64a5ce12c8ce6727885917,2019-10-12 16:19:15+01:00,"if parent : assert set ( suggestions ) == set ( Function ( schema=parent ) , View ( schema=parent ) , Column ( Table ( schema= '' x '' ) , * Function argument completions now take account of table aliases ( # 1048 ) . ( Thanks : ` Owen Stephens ` _ ) Table ( schema=parent ) , View ( schema= '' x '' ) , table_refs=tables , local_tables=stmt.local_tables , qualifiable=True def test_function_arguments_with_alias_given ( ) : `` `` '' # Check for a table alias or schema qualification Keyword ( `` ( `` ) , tables = tuple ( t for t in tables if identifies ( parent , t ) ) Function ( schema=None ) , ] Column ( suggestions = suggest_type ( `` SELECT avg ( x . FROM tbl x , tbl2 y '' , `` SELECT avg ( x . '' ) table_refs=extract_tables ( stmt.full_text ) , return ( table_refs= ( TableReference ( None , `` tbl '' , `` x '' , False ) , ) , Table ( schema=parent ) , tables = stmt.get_tables ( ) tables = stmt.get_tables ( ) Function ( schema=None ) , Column ( table_refs= ( ( None , `` tbl '' , None , False ) , ) , qualifiable=True ) , Function ( schema=None ) , Column ( table_refs=tables , local_tables=stmt.local_tables ) , identifiers parent , which may be a table alias or schema name . Keyword ( token_v.upper ( ) ) , ) Function ( schema= '' x '' ) , View ( schema=parent ) , return ( return ( parent = stmt.identifier.get_parent_name ( ) if stmt.identifier else [ ] [ Column ( table_refs= ( ( None , `` tbl '' , None , False ) , ) , qualifiable=True ) ] qualifiable=True , Return suggestions for an expression , taking account of the partially-typed if parent : Column ( table_refs=tables , local_tables=stmt.local_tables , qualifiable=True ) , def test_lparen_suggests_cols ( ) : return ( def test_lparen_suggests_cols_and_funcs ( ) : ) , ) tables = tuple ( t for t in tables if identifies ( parent , t ) ) ) , parent = ( stmt.identifier and stmt.identifier.get_parent_name ( ) ) or [ ] else : def _suggest_expression ( token_v , stmt ) : local_tables=stmt.local_tables , local_tables= ( ) , qualifiable=False , [ Column ( table_refs=tables , local_tables=stmt.local_tables ) , Column ( ) ) , Keyword ( token_v.upper ( ) ) , Function ( schema=parent ) , ) return _suggest_expression ( token_v , stmt )","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Take account of table aliases when completing function args ( # 1048 )
40,67799b98ab2d6ced76b8e46c4d857943225beab9,2019-09-27 19:34:34-07:00,[ x ] Please squash merge this pull request ( uncheck if you 'd like us to merge as multiple commits ) Internal : * Add optional but default squash merge request to PULL_REQUEST_TEMPLATE,"['.github/PULL_REQUEST_TEMPLATE.md', 'changelog.rst']",add optional but default squash merge request to PULL_REQUEST_TEMPLATE ( # 1095 )
41,88b829aa824deef1166e01ee5fa0ab8813e25cac,2019-09-02 12:36:15-07:00,"cursor.execute ( self.version_query ) server_version = `` '' return server_version version_parts = result [ 0 ] .split ( ) self.server_version = conn.get_parameter_status ( `` server_version '' ) def get_server_version ( self , cursor ) : _logger.debug ( `` Version Query . sql : % r '' , self.version_query ) server_version = version_parts [ 1 ] self.superuser = conn.get_parameter_status ( `` is_superuser '' ) in ( `` on '' , `` 1 '' ) cursor.execute ( `` SHOW ALL '' ) # full version string looks like this : # let 's only retrieve version number self.server_version = self.get_server_version ( cursor ) # PostgreSQL 10.3 on x86_64-apple-darwin17.3.0 , compiled by Apple LLVM version 9.0.0 ( clang-900.0.39.2 ) , 64-bit # noqa * Ca n't connect to pgbouncer database ( # 1093 ) . ( Thanks : ` Irina Truong ` _ ) db_parameters = dict ( name_val_desc [ :2 ] for name_val_desc in cursor.fetchall ( ) ) result = cursor.fetchone ( ) if result : self.superuser = db_parameters.get ( `` is_superuser '' ) == `` 1 ''","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 1094 from dbcli/j-bennet/superuser-redundant-query
42,b2ebe0e95c6b9f28574804d5f1ea8d689ccd5211,2019-08-23 13:44:36-07:00,"from mock import Mock `` `` '' returns True if limit prompt should be shown , False otherwise . '' '' '' cli = PGCli ( ) if not sql : not self._has_limit ( sql ) def _should_show_limit_prompt ( self , status , cur ) : result = cli._should_show_limit_prompt ( stmt , over_limit ) result = cli._should_limit_output ( stmt , over_limit ) stmt = `` UPDATE students set name='Boby ' '' from mock import Mock result = cli._should_show_limit_prompt ( stmt , None ) limit = min ( self.row_limit , cur.rowcount ) stmt = `` SELECT * FROM students '' if not is_select ( sql ) : def test_row_limit_with_LIMIT_clause ( LIMIT , over_limit ) : def test_row_limit_without_LIMIT_clause ( LIMIT , over_limit ) : new_status = `` SELECT `` + str ( limit ) assert result is False cli = PGCli ( row_limit=0 ) and self.row_limit ! = 0 click.secho ( `` Aborted ! `` , err=True , fg= '' red '' ) def test_no_limit ( over_limit ) : assert result is False return False import pytest def test_set_row_limit ( over_default , over_limit , LIMIT ) : and cur.rowcount > self.row_limit if self._should_limit_output ( sql , cur ) : # Set threshold for row limit prompt . Use 0 to disable prompt . `` The result set has more than % s rows . '' % threshold , fg= '' red '' def test_row_limit_on_non_select ( over_default ) : result = cli._should_show_limit_prompt ( stmt , low_count ) if not is_select ( status ) : def _should_limit_output ( self , sql , cur ) : ) * Empty query caused error message ( Thanks : ` Sebastian Janko ` _ ) and cur `` `` '' returns True if the output should be truncated , False otherwise . '' '' '' if not click.confirm ( `` Do you want to continue ? `` ) : ) stmt = `` SELECT * FROM students LIMIT 1000 '' result = cli._should_show_limit_prompt ( stmt , over_default ) return ( cur , status = self._limit_output ( cur ) import pytest cli = PGCli ( row_limit=LIMIT ) def _has_limit ( self , sql ) : click.secho ( return new_cur , new_status def _limit_output ( self , cur ) : def test_default_row_limit ( low_count , over_default ) : def test_row_limit_on_non_select ( over_limit ) : return `` limit `` in sql.lower ( ) stmt = `` UPDATE students SET name='Boby ' '' assert result is True click.secho ( `` The result was limited to % s rows '' % limit , fg= '' red '' ) new_cur = itertools.islice ( cur , limit ) * Removed limit prompt and added automatic row limit on queries with no LIMIT clause ( # 1079 ) ( Thanks : ` Sebastian Janko ` _ ) break * Empty query caused error message ( # 1019 ) ( Thanks : ` Sebastian Janko ` _ ) # Set threshold for row limit . Use 0 to disable limiting . threshold = self.row_limit if self._should_show_limit_prompt ( status , cur ) : return self.row_limit > 0 and cur and ( cur.rowcount > self.row_limit )","['changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc', 'tests/test_rowlimit.py']",Issue 1018 display first 1k rows ( # 1092 )
43,19c3e0eeb81f4a231d0ebfd2c18c47215f85e572,2019-07-29 13:00:33-07:00,"`` `` '' Move up in history . '' '' '' completion_is_selected , event.current_buffer.history_backward ( count=event.arg ) has_selection , def _ ( event ) : from prompt_toolkit.filters import ( .. _ ` Pedro Ferrari ` : https : //github.com/petobens has_completions , * History navigation bindings in multiline queries ( # 1004 ) ( Thanks : ` Pedro Ferrari ` _ ) ) * Pedro Ferrari ( petobens ) event.current_buffer.history_forward ( count=event.arg ) `` `` '' Move down in history . '' '' '' from prompt_toolkit.filters import completion_is_selected , has_completions","['AUTHORS', 'changelog.rst', 'pgcli/key_bindings.py']",Add key bindings to consistently move up and down in history ( # 1084 )
44,f85642da67285a2b1d991d1d0970d261a715efb1,2019-07-12 17:24:39-07:00,* Empty query caused error message ( Thanks : ` Sebastian Janko ` _ ) continue .. _ ` Sebastian Janko ` : https : //github.com/sebojanko is_special = None if not sql : * Sebastian Janko ( sebojanko ),"['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgexecute.py']",Issue 1019 stacktrace on empty query ( # 1078 )
45,10cc4ce2b9e1d745f3be91373f48ef6ea9ca7f88,2019-06-09 17:05:28+02:00,"def.adsrc as default pg_catalog.pg_get_expr ( def.adbin , def.adrelid , true ) as default Bug fixes : * Error connecting to PostgreSQL 12beta1 ( # 1058 ) . ( Thanks : ` Irina Truong ` _ )","['changelog.rst', 'pgcli/pgexecute.py']",Partial fix for # 1058 . ( # 1068 )
46,f27ac1c110da6ba117ce93c5631c779bd9683a8a,2019-06-03 17:12:38-07:00,"finally : run ( executor , `` '' '' insert into test values ( True ) '' '' '' ) if sql.endswith ( `` \\G '' ) : self.reset_expanded = None pgspecial.expanded_output = True if not pgspecial.expanded_output : TODO # \G is treated specially since we have to set the expanded output . self.reset_expanded = True def test_expanded_slash_G ( executor , pgspecial ) : pgspecial.expanded_output = False sql = sql [ : -2 ] .strip ( ) if self.reset_expanded : Features : results = run ( executor , `` '' '' select * from test \G '' '' '' , pgspecial=pgspecial ) assert pgspecial.expanded_output == False or text.endswith ( r '' \G '' ) # Special Command # Tests whether we reset the expanded output after a \G . * Add ` \\G ` as a terminator to sql statements that will show the results in expanded mode . This feature is copied from mycli . ( Thanks : ` Amjith Ramanujam ` _ ) run ( executor , `` '' '' create table test ( a boolean ) '' '' '' ) self.reset_expanded = None","['changelog.rst', 'pgcli/pgbuffer.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 1064 from dbcli/amjith/slash-G
47,6d6ab3dab755759ea51ffdc7e7cc2e49379eca4f,2019-06-02 19:15:16-07:00,* Pablo A. Bianchi ( pabloab ) `` `` '' Introduces a line break regardless of multi-line mode or not . '' '' '' event.app.current_buffer.insert_text ( `` \n '' ) def _ ( event ) : * Pressing Alt-Enter will introduce a line break . This is a way to break up the query into multiple lines without switching to multi-line mode . ( Thanks : https : //github.com/pabloab ) . _logger.debug ( `` Detected alt-enter key . '' ),"['AUTHORS', 'changelog.rst', 'pgcli/key_bindings.py']",Add keybinding for alt-enter to introduce a line break ( # 1065 )
48,a2ed5e46d17020f75b5d11fdcc22fa4090b2ccdb,2019-05-30 17:10:15-07:00,2.1.1 ===== TODO,['changelog.rst'],Changelog update before release . ( # 1062 )
49,df4dd005857aba57353d7ff35040712ddc60c5bb,2019-05-30 10:03:47-07:00,"If you are restricted to using psycopg2 2.7.x then pip will try to install it from a binary . There are some known issues with the psycopg2 2.7 binary - see the ` psycopg docs ` _ for more information about this and how to force installation from source . psycopg2 2.8 has fixed these problems , and will build from source . $ pip install pgcli -- no-binary : all : psycopg2 * Update README in alignment with the usage of newer versions of psycopg2 ( Thanks : ` Alexander Zawadzki ` _ ) : : * Alexander Zawadzki If you have ` problems with psycopg2 wheels ` _ , use the following flags to install psycopg2 from source : .. _ ` Alexander Zawadzki ` : https : //github.com/zadacka .. _ ` problems with psycopg2 wheels ` : http : //initd.org/psycopg/articles/2018/02/08/psycopg-274-released/ .. _ ` psycopg docs ` : http : //initd.org/psycopg/docs/install.html # change-in-binary-packages-between-psycopg-2-7-and-2-8","['AUTHORS', 'README.rst', 'changelog.rst']",README.rst : tidy up redundant instructions ( # 1061 )
50,8c597751fdbc5a7082ec6f3053c1b066bbac5b3e,2019-05-29 21:14:32-07:00,".. _ ` Telmo `` Trooper '' ` : https : //github.com/telmotrooper `` psycopg2 > = 2.7.4 , < 2.8 '' , `` psycopg2 > = 2.7.4 '' , * Telmo `` Trooper '' ( telmotrooper ) * Allow usage of newer versions of psycopg2 ( Thanks : ` Telmo `` Trooper '' ` _ )","['AUTHORS', 'changelog.rst', 'setup.py']",Allow psycopg2 up to 2.8.2 ( # 1060 )
51,8cb7009bcd0f0062942932c853706a36178f566c,2019-05-25 13:08:56-07:00,"'INSERT INTO sch . ' , is_function = allow_functions and _identifier_is_function ( wrappers.expect_pager ( context , 'DROP TABLE\r\n ' , timeout=2 ) view_definition_query = `` ' testdata.columns ( 'select ' ) ) @ click.option ( ' -- row-limit ' , default=None , envvar='PGROWLIMIT ' , type=click.INT , prev_keyword , self.text_before_cursor = find_prev_keyword ( `` text , before , expected '' , self.user = dsn_parameters.get ( 'user ' ) url= '' http : //pgcli.com '' , text , display=display or text , start_position=pos , display_meta= '' function '' View ( schema='d ' ) , _logger.debug ( `` Search path query . sql : % r '' , fallback ) context.cli.sendline ( `` '' '' update a set x = 'yyy ' where x = 'xxx ' ; '' '' '' ) len ( 'select f . ' ) `` set_returning_func '' , `` SELECT * FROM foo bar `` , `` CREATE '' , _logger.debug ( `` New pgcli : % r '' , str ( u ) ) del os.environ [ 'PGPASSWORD ' ] default=5432 , self.logger.warning ( `` import keyring failed : % r . `` , e ) Function ( schema= ' a ' ) , Column ( [ column ( `` foo '' ) ] + testdata.functions_and_keywords ( ) `` users.id , users.phone_number '' assert set ( suggestions ) == set ( [ Table ( schema= '' sch '' ) ] ) result.append ( `` signature_arg_style '' , `` { arg_name } { arg_type } '' cr.execute ( `` drop database if exists % s '' , ( AsIs ( dbname ) , ) ) default=None , os.environ [ `` LESS '' ] = `` -SRXF '' context.env_config_home = tempfile.mkdtemp ( prefix= '' pgcli_home_ '' ) suggestion.qualifiable assert set ( suggestions ) == cols_etc ( `` tabl '' , last_keyword= '' SELECT '' ) 'foreignkeys ' : { @ kb.add ( 'f2 ' ) column = partial ( completion , 'column ' ) 'signature ' : self.signature_arg_style suggestions = suggest_type ( '\\dn xxx ' , '\\dn xxx ' ) not f.is_extension and ' $ $ $ a $ ' , testdata.schemas ( ) + aliased_rels print ( ' -- - Pretending to run ... ' ) @ when ( 'we wait for prompt ' ) text = `` SELECT blog.ee '' port , wrappers.expect_pager ( context , `` CREATE TABLE\r\n '' , timeout=2 ) FromClauseItem ( schema=None , table_refs=tables ) , `` users '' : [ `` id '' , `` phone_number '' ] , 'SELECT 1 : : ' , assert suggestions == ( Table ( schema= '' schema_name '' ) , ) conn = sql.connection.Connection.get ( parsed [ 'connection ' ] ) help= '' Automatically switch to vertical output mode if the result is wider than the terminal width . `` , '| { 1,2,3 } | { { 1,2 } , { 3,4 } } | { å , 魚 , текст } | ' , return arg.decode ( `` utf-8 '' ) return _ColumnMetadata ( name , datatype , foreignkeys or [ ] , default , has_default ) and len ( tables ) == 1 result = get_result ( completer , 'SELECT * FROM u ' ) view ( 'User_Emails UE ' ) , db_connection , # make sure this doesnt trigger special completion view_cols.extend ( [ self._make_col ( sch , tbl , col ) View ( schema='sch ' ) , assert set ( suggestions ) == set ( [ Function ( schema=None , usage= '' special '' ) , Schema ( ) ] ) run_step ( `` git '' , `` push '' , `` origin '' , `` master '' ) create_git_tag ( ' v { } '.format ( ver ) ) ) as mock_echo_via_pager , mock.patch.object ( cli , `` prompt_app '' ) as mock_app : 'SELECT * FROM foo ( ) AS bar ( baz INT , qux ' , `` WITH users as ( SELECT 1 AS foo ) SELECT from custom.users '' , Column ( table_refs= ( ) , qualifiable=True ) , run_step ( `` git '' , `` push '' , `` -- tags '' , `` origin '' ) self.multi_line = c [ 'main ' ] .as_bool ( 'multi_line ' ) full_text = full_text [ ctes [ -1 ] .stop : ] [ `` integer '' , `` integer '' ] , return [ `` SELECT * FROM users u1 JOIN users u2 USING ( email ) JOIN user_emails ue USING ( ) '' , @ then ( u'we see found ' ) function ( 'custom_func1 ( ) cf ' ) , modes = self.arg_modes or [ ' i ' ] * len ( self.arg_names ) if self.asterisk_column_order == 'alphabetic ' : c ( left.tbl ) , c ( left.col ) , rtbl.ref , c ( right.col ) _logger.debug ( 'Search path query . sql : % r ' , fallback ) `` enter_entry '' , assert u '' 日本語 '' in run ( executor , u '' SELECT '日本語 ' AS japanese ; '' , join=True ) self.full_databases_query ) return self.functions_and_keywords ( pos=pos ) + self.columns ( wrappers.expect_exact ( context , 'Expanded display is ' , timeout=2 ) for x in self.metadata.get ( 'functions ' , { } ) .get ( parent , [ ] ) assert first.display_text == `` extract_entry_symbols ( _entryid ) '' for sch , tbls in metadata.get ( 'views ' , { } ) .items ( ) : assert 'FROM tbl1 ' in result if arg == `` dsn_password '' : 'SELECT * FROM Custom . ' , == `` | 4713-01-01 00:00:00+00 BC | '' os.environ [ `` VISUAL '' ] = `` ex '' context.cli.sendline ( `` \e { 0 } '' .format ( os.path.basename ( context.editor_file_name ) ) ) tables = extract_tables ( 'SELECT * FROM foo.bar ( { 0 } ) '.format ( arg_list ) ) 'Query ' , View ( schema=parent ) , display='set_returning_func ( x , y ) srf ' assert set ( suggest_type ( text , text ) ) == set ( [ `` SELECT * FROM foo ( ) AS bar ( baz `` , schemata_query = `` ' suggestions = suggest_type ( 'select * from ; select * from ' , `` _custom_fun ( ) '' , self.prompt_format = ( def run ( run ( executor_copy , `` '' '' insert into test values ( 'abc ' ) '' '' '' ) MetaQuery.__new__.__defaults__ = ( `` , False , 0 , 0 , False , False , False , False ) Column ( table_refs= ( ( None , 'tabl ' , 't ' , False ) , ) ) , JOIN `` ' [ Special ( ) ] ) if self.return_type.lower ( ) == `` void '' : alias ( `` u '' ) , dedent ( completion , prio=None , meta=None , synonyms=None , prio2=None , display=None lastword ! = word_before_cursor cfg [ `` settings '' ] [ `` generate_aliases '' ] = aliasing text = 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON x.id = ' sslcert= '' my.pem '' , `` < null > '' , cased_schemas = [ schema ( x ) for x in ( `` public '' , `` blog '' , `` CUSTOM '' , ' '' Custom '' ' ) ] p.match ( col.default ) for p in self.insert_col_skip_patterns ( 'orders ' , 'datestamp ' ) : `` now ( ) '' , elif os.environ.get ( `` PGSERVICE '' , None ) : '+ -- -- -- -- -+ -- -- -- -- -+ ' , fks = ( ( fk , rtbl , rcol ) for rtbl , rcols in cols.items ( ) `` cross join '' , meta_query = MetaQuery ( text , all_success , total , execution , meta_changed , `` - [ RECORD 2 ] -- -- -- -- -- -- -- -- -- -- -- -- - '' , remainder = u '' .join ( str ( tok ) for tok in p.tokens [ idx : ] ) run_step ( 'python ' , 'setup.py ' , 'clean ' , ' -- all ' , 'sdist ' , 'bdist_wheel ' ) result.append ( ( `` class : bottom-toolbar.off '' , `` [ F2 ] Smart Completion : OFF `` ) ) Token.Toolbar.Transaction.Failed : `` bottom-toolbar.transaction.failed '' , name= '' completion_refresh '' , passwd= ' ] foo ' ) testdata.columns ( 'Users ' , 'custom ' ) ) TableReference ( None , `` tbl1 '' , `` y '' , False ) , Column ( table_refs= ( ( None , `` tabl1 '' , `` t1 '' , False ) , ) ) , self.qualify_columns = settings.get ( assert suggest_type ( sql , sql ) == ( Schema ( ) , ) cursor.execute ( 'SELECT NULL : :timestamp ' ) position = len ( result.append ( arg = `` -- username= { } '' .format ( context.conf [ `` user '' ] ) # Return column names from a set-returning function ( `` lower '' , `` select '' , ( `` '' , `` s '' , `` S '' , `` Sel '' ) ) , text = `` SELECT * FROM blog.Entries E JOIN blog.e '' 'head2 | def ' , elif platform.system ( ) == `` Windows '' : def schemas_and_from_clause_items ( self , parent= '' public '' , pos=0 ) : self , schema_name , func_name , arg_names , arg_types , arg_modes , except ( completer , `` SELECT * FROM Functions WHERE function : text '' [ : l ] text = 'SELECT * FROM blog.Entries E JOIN blog.e ' `` pager_boundary '' : `` -- -boundary -- - '' , context.currentdb = currentdb or context.conf [ `` dbname '' ] `` Quit pgcli . `` , @ when ( u'we stop teeing output ' ) if not text : # Empty string sql = `` '' '' SELECT * FROM foo WHERE bar GROUP BY baz ; dsn , kw = keyword ( 'SELECT ' , -1 ) ] + [ view ( 'User_Emails UE ' ) , view ( 'Functions F ' ) ] + [ Schema ( ) , 'Pygments > = 2.0 ' , # Pygments has to be Capitalcased . WTF ? `` expression '' , [ `` INSERT INTO sch . `` , `` COPY sch . `` , `` DESCRIBE sch . '' ] total , assert tables == ( ( `` foo '' , `` bar '' , None , True ) , ) @ parametrize ( 'text ' , [ 'WITH users as ( SELECT 1 AS foo ) SELECT from users ' , ] ) ( text == ' : q ' ) or # To all the vim fans out there return pgcli.pgexecute.PGExecute ( database='_test_db ' , user=POSTGRES_USER , host=POSTGRES_HOST , if char == ' '' ' or char == `` ' '' : not f.is_aggregate context.cli.sendline ( 'select 123456 ' ) if item.lower ( ) [ : len ( text ) + 1 ] in ( text , text + ' ' ) : idx , tok = parsed.token_next_by ( idx , ( Keyword , `` returning '' ) ) string = string.replace ( '\\t ' , self.now.strftime ( ' % x % X ' ) ) context.cli.sendline ( `` \pset pager always '' ) default=default , `` s '' , `` g '' , [ `` x '' ] , [ `` integer '' ] , [ ] , `` int '' , False , False , False , False , None text = `` '' '' `` parenttable '' , tbl = TableReference ( schema , rel , alias , reltype == `` functions '' ) 'SELECT * FROM tabl WHERE col_n ' ) self.port = dsn_parameters.get ( 'port ' ) assert 'missing required argument ' in status Datatype ( schema=None ) , suggestions = suggest_type ( 'INSERT INTO abc ( id , ' , 'INSERT INTO abc ( id , ' ) override_style , cursor.execute ( `` SELECT NULL : :timestamp with time zone '' ) len ( 'SELECT u.id , u . ' ) POSTGRES_PORT = getenv ( 'PGPORT ' , 5432 ) arg_default = 'NULL ' if arg.default is None else arg.default if mode in ( `` i '' , `` b '' , `` v '' ) # IN , INOUT , VARIADIC elif token_v == `` set '' : 'SELECT * FROM ( SELECT t . ' ) `` nested_numeric_array | < null > '' , 'SELECT a , b FROM tbl1 , ' ) `` single_connection '' , suggestions = suggest_type ( `` \\df xxx '' , `` \\df xxx '' ) executor , `` SELECT d FROM jsonbtest LIMIT 1 '' , join=True , expanded=expanded click.echo ( `` \n '' .join ( output ) , file=f ) `` shipments '' : [ `` id '' , `` address '' , `` user_id '' ] , keyword_casing = settings.get ( 'keyword_casing ' , 'upper ' ) .lower ( ) @ when ( 'we set expanded { mode } ' ) return self.find_matches ( word_before_cursor , views , meta='view ' ) language_version : python3.6 if log_level.upper ( ) == `` NONE '' : position = len ( `` SELECT U . '' ) Table ( schema= '' t1 '' ) , `` `` '' create function func1 ( ) returns int text = `` SELECT IN '' ( None , `` t3 '' , None , False ) , keyword_casing = `` upper '' if pgcli.multiline_mode == `` safe '' : elif token_v in { `` alter '' , `` create '' , `` drop '' } : `` select '' : [ `` id '' , `` insert '' , `` ABC '' ] , 'SELECT users.name , orders.id FROM users JOIN orders ON ' , Join = namedtuple ( 'Join ' , [ 'table_refs ' , 'schema ' ] ) ' '' insert into hij ( x , y , z ) 'PGPASSWORD ' : os.environ.get ( 'PGPASSWORD ' , None ) , tables = extract_tables ( `` select * from abc , def '' ) ( 'public ' , 'd ' ) ] ) Table ( schema='sch ' ) ] ) cased_schemas = [ schema ( x ) for x in ( 'public ' , 'blog ' , 'CUSTOM ' , ' '' Custom '' ' ) ] assert completions_to_set ( result ) == completions_to_set ( cased_schemas + [ testdata.columns ( 'set_returning_func ' , 'custom ' , 'functions ' ) ) function_meta_data ( assert set ( tables ) == set ( [ ( None , 'abc ' , None , False ) , self.functions ( parent , pos ) + self.builtin_functions ( pos ) executor , `` host '' , `` localhost1.example.org , localhost2.example.org '' arg = 'service=mock_postgres -- password ' arg_names= [ ' x ' , ' y ' ] , idx , tok = parsed.token_next_by ( idx , ( Keyword , 'returning ' ) ) maybe_alias = ( ' ' + alias ) if do_alias else `` @ then ( u'we see 123456 in tee output ' ) log_level = self.config [ `` main '' ] [ `` log_level '' ] ' '' result = executor.view_definition ( 'there_is_no_such_function ' ) position = len ( `` SELECT MA '' ) return 'set search_path ' in sql.lower ( ) fk_join ( 'u2.userid = u.id ' ) , `` INSERT INTO public.Orders ( * ) '' , help='Automatically switch to vertical output mode if the result is wider than the terminal width . ' ) [ 'user_action ' , 'user ' ] , elif persist_priorities == 'keywords ' : 'INSERT INTO public.orders ( ' , identifiers = extract_table_identifiers ( stream , allow_functions=not insert_stmt ) elif persist_priorities == `` keywords '' : `` Programming Language : : Python : : 3.5 '' , elif token_v == `` truncate '' : tuple ( local_tables=stmt.local_tables ) ) name=obj , arg = ' -- user= { } '.format ( context.conf [ 'user ' ] ) False , sql = `` '' '' WITH context , 'Entering Ex mode . Type `` visual '' to go to Normal mode . ' , timeout=2 suggestions = suggest_type ( '\d myschema . ' , '\d myschema . ' ) sslkey='my-key.pem ' , `` INSERT INTO public.orders ( * ) '' , text = '\\dT ' override_style = Style ( [ ( `` bottom-toolbar '' , `` noreverse '' ) ] ) else ' '' ' + self.name + ' '' ' Function = namedtuple ( `` Function '' , [ `` schema '' , `` table_refs '' , `` usage '' ] ) | build title = `` @ then ( 'we see database created ' ) Completion ( database , user , passwd , host , port , dsn , * * kwargs assert first.text == `` enter_entry ( _title : = , _text : = ) '' ( 10 , 10 , '- ' * 9 ) , 'SELECT * FROM foo bar ' , join ( `` Users Users2 ON Users2.ID = Users.PARENTID '' ) , prompt @ parametrize ( 'text ' , [ 'SELECT * FROM ' ] ) 'No default pager found in environment . Using os default pager ' ) 'is_function ' ] ) self.builtin_functions ( pos ) return arg.encode ( 'utf-8 ' ) context.cli.sendline ( yield ( assert suggestions == ( Function ( schema= '' myschema '' , usage= '' special '' ) , ) text_before_cursor = text_before_cursor [ ctes [ -1 ] .stop : current_position ] expanded = ( settings.expanded or settings.table_format == 'vertical ' ) if arg == ' -- user ' : @ parametrize ( 'completer ' , completers ( casing=False , qualify=qual ) ) click.secho ( db_name = context.config.userdata.get ( 'pg_test_db ' , 'pgcli_behave_tests ' ) tables = extract_tables ( `` SELECT t1 . FROM tabl1 t1 , tabl2 t2 '' ) 'df ' : Function , `` SELECT * FROM foo JOIN bar on bar.barid = foo.barid JOIN `` , [ ( `` schema1 '' , `` parent '' , `` parentid '' , `` schema2 '' , `` child '' , `` motherid '' ) ] def tables ( self , parent='public ' , pos=0 ) : _logger.debug ( 'Detected F2 key . ' ) Join ( tbls , 'sch ' ) , print ( 'Time : % 0.03fs ' % query.total_time ) context.cli.sendline ( `` select 1 '' ) `` INSERT INTO Orders ( * ) '' , exception_formatter=exception_formatter ) FromClauseItem , suggest_type , Special , Database , Schema , Table , 'host ' : host , `` -- dry-run '' , os.environ [ 'PGPORT ' ] = context.conf [ 'port ' ] column_suggestions = suggest_based_on_last_token ( `` where '' , stmt ) 'SELECT U . FROM `` custom '' .users U ' , [ `` public '' , `` pg_catalog '' , `` information_schema '' , `` schema1 '' , `` schema2 '' ] table ( `` Users U '' ) , text = `` 'SELECT * FROM set_returning_func ( ) f1 [ schema ( `` 'blog ' '' ) , schema ( `` 'Custom ' '' ) , schema ( `` 'custom ' '' ) , schema ( `` 'public ' '' ) ] INNER JOIN `` '' '' , bg_refresh.assert_called_with ( pgexecute , special , callbacks , None , add_cond ( c.name , c.name , rtbl.ref , prio , 'name join ' ) for f in all_functions if d [ 1 ] == psycopg2.extensions.INTEGER.values or \ `` SELECT users.id , users . from users u '' , table_refs= ( TableReference ( None , 'tbl ' , ' x ' , False ) , ) , 'path_changed ' , # True if any subquery changed the search path start_position=pos , [ join ( 'public.users ON users.id = `` Users '' .userid ' ) ] assert set ( tables ) == set ( [ ( None , 'Abc ' , ' a ' , False ) , Table ( schema= ' f ' ) , False , return [ ( None , None , None , message , `` '' , True , True ) ] 'select * from ' ) run_step ( `` git '' , `` tag '' , tag_name ) Schema ( ) ] ) '' , False , False , False , False ] ] , @ click.argument ( 'dbname ' , default=lambda : None , envvar='PGDATABASE ' , nargs=1 ) context.cli.sendline ( `` i '' ) sql = 'SELECT abc , 99 FROM xxx ' @ then ( 'we see record updated ' ) tbl , parent , typ , pos return ( and ( not item.value.upper ( ) == `` FROM '' ) 'auto_expand ' ) and prev_tok.value.lower ( ) .split ( `` `` ) [ -1 ] == `` using '' arg_types=None , fg= '' red '' , * * self.pgexecute.extra_args config_full_path = config_location ( ) + 'config ' assert set ( executor.view_columns ( ) ) > = set ( query = `` '' '' if ( identifier.ttype is Keyword and `` foo 'bar baz '' , `` % r % r listed in unrecognized schema % r '' , kind , relname , schema [ `` text '' , `` text '' , `` integer '' ] , assert extract_column_names ( sql ) == ( 'abc ' , ) yield ( None , None , None , `` Changed table format to { } '' .format ( pattern ) ) sql = 'WITH CTE AS ( SELECT F. * FROM Foo F WHERE F.Bar > 23 ) SELECT C. * FROM CTE C WHERE C.FooID BETWEEN 123 AND 234 ; ' cursor_position=len ( word_before_cursor ) ) `` call '' : self.call_arg_style , elif p.token_first ( ) .value.lower ( ) == 'select ' : or ( text == `` exit '' ) # A complete SQL command x AS `` '' '' _logger.debug ( 'Unsuccessful query - ignoring ' ) keyring = importlib.import_module ( `` keyring '' ) config_location , TableReference = namedtuple ( 'TableReference ' , [ 'schema ' , 'name ' , 'alias ' , print ( `` Connected : { } '' .format ( conn.name ) ) assert set ( suggestions ) == set ( [ Table ( schema= '' myschema '' ) , View ( schema= '' myschema '' ) ] ) testdata.schemas_and_from_clause_items ( ) ) cased_users2_col_names = [ 'UserID ' , 'UserName ' ] identifiers = extract_table_identifiers ( stream , os.path.basename ( context.editor_file_name ) ) ) `` Output longer than terminal width '' , suffix = self._arg_list_cache [ arg_mode ] [ tbl.meta ] if arg_mode else `` '' context.cli.sendline ( `` 'insert into a ( x ) values ( 'xxx ' ) ; ' '' ) hooks : parent=filteredtables [ -1 ] ) ) ( ( t.schema , t.name , c.name ) , t ) for t , c in cols if t.ref ! = lref 'head1 | abc ' , 'insert into hij select * from abc inner join def using ( ' , if ( mock_pgexecute.assert_called_with ( 'bar ' , 'bar ' , `` , 'baz.com ' , `` , `` , ) as e : 'select * from foo ( ) as bar ( baz ' text = `` SELECT MA '' pattern = '\\b ' + white_space_regex.sub ( r'\\s+ ' , keyword ) + '\\b ' run ( executor , `` '' '' insert into test values ( True ) '' '' '' ) `` Change the table format used to output results '' , tables = extract_tables ( `` select a , b from abc , def '' ) ( `` \\ns abc SELECT foo `` , `` SELECT foo `` , ( Keyword ( ) , ) ) , os_environ_pager = os.environ.get ( `` PAGER '' ) self.cli_style = c [ `` colors '' ] def test_distinct_and_order_by_suggestions_with_aliases ( context , run_args= [ arg ] , prompt_check=prompt_check , currentdb=currentdb 'INSERT INTO public.orders ( * ) ' , table_results = format_output ( self.is_public = self.schema_name and self.schema_name == `` public '' or ( res = self.pgexecute.run ( text , self.pgspecial , completer=ThreadedCompleter ( ) , assert actual [ 0 ] [ 3 ] == `` Auto-completion refresh started in the background . '' suggestions = suggest_type ( text , text [ : text.find ( ' ' ) + 1 ] ) smart_completion=True , settings=settings , pgspecial=PGSpecial ( ) result = get_result ( completer , '\\t ' ) text = 'SELECT MA ' testdata.columns_functions_and_keywords ( 'users ' ) ) func_name='func1 ' , View ( schema='t1 ' ) , message = '\\i : missing required argument ' executor , sql , join=False , expanded=False , pgspecial=None , exception_formatter=None pat = re.compile ( ' ( % s ) ' % regex ) for sch , tbls in metadata [ 'tables ' ] .items ( ) : `` never '' : False , elif usage == 'call ' and func.has_variadic ( ) : os.environ [ 'LINES ' ] = `` 100 '' table_refs= ( timeout=1 , 'custom_fun ( ) ' , exclude = `` ' print ( `` -- - os.environ changed values : -- - '' ) 'query ' , # The entire text of the command text = 'selt * ' pgcli.echo_via_pager ( `` \n '' .join ( formatted ) ) assert result [ 0 ] == join ( 'EntryTags ET ON ET.EntryID = E.EntryID ' , -2 ) 'SELECT * FROM users JOIN users u2 on foo . ' `` insert into binarydata ( c ) values ( decode ( 'DEADBEEF ' , 'hex ' ) ) '' ) [ 'custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , `` \\T '' , return_type='integer ' c_dest_warning = c [ 'main ' ] .as_bool ( 'destructive_warning ' ) `` text '' , [ `` SELECT DISTINCT `` , `` INSERT INTO foo SELECT DISTINCT `` ] metadata = self.dbmetadata [ 'tables ' ] Token.Menu.Completions.ProgressButton : 'scrollbar.arrow ' , # best guess if prev_prev_tok and prev_prev_tok.normalized == 'INTO ' : `` Change to a new database . `` , logical_operators = ( 'AND ' , 'OR ' , 'NOT ' , 'BETWEEN ' ) coldict = list_dict ( ( ( t.schema , t.name , c.name ) , t ) open ( filename , `` w '' ) .close ( ) Table ( schema= '' x '' ) , [ `` i '' , `` i '' , `` o '' ] , result = executor.function_definition ( 'the_number_three ' ) assert set ( suggestions ) == set ( [ FromClauseItem ( schema=None ) , Schema ( ) ] ) 'select * from `` ' , context.cli.sendline ( `` \\ '' + `` x { } '' .format ( mode ) ) matches = self.find_matches ( default=default `` select * from foo where bar '' , keyword = partial ( completion , `` keyword '' ) `` SELECT * FROM users u1 JOIN user_emails ue USING ( ) JOIN users u2 ue USING ( first_name , last_name ) '' , if cmd [ 1 : ] == 'd ' : 'INSERT INTO abc ( ) SELECT * FROM hij ; ' , context.conf [ 'pass ' ] , context.conf [ 'dbname ' ] , d [ 1 ] in psycopg2.extensions.FLOAT.values : identifier.value.upper ( ) == 'FROM ' ) : _logger.error ( COLOR_CODE_REGEX , do_qualify = ( context.conf [ 'pass ' ] , context.conf [ 'dbname ' ] , Datatype , Alias , Path , JoinCondition , Join ) self.dbmetadata = { `` tables '' : { } , `` views '' : { } , `` functions '' : { } , `` datatypes '' : { } } completer , 'SELECT users . from users ' , len ( 'SELECT users . ' ) for x in self.metadata.get ( `` datatypes '' , { } ) .get ( parent , [ ] ) ( `` functions '' : { } ) default_prompt = '\\u @ \\h : \\d > ' cased_funcs + cols + testdata.builtin_functions ( ) + testdata.keywords ( ) assert set ( suggestions ) == set ( [ Table ( schema=None ) , Schema ( ) ] ) history_file = self.config [ `` main '' ] [ `` history_file '' ] ] + [ function ( query = r '' '' '' display_meta='function ' smart_completion , pgspecial=self.pgspecial , settings=self.settings actual , [ Completion ( text='SELECT ' , start_position=-3 ) ] ) `` TABLE '' , run ( executor , `` 'create function schema1.func2 ( ) returns int os.environ [ `` LINES '' ] = `` 100 '' with mock.patch.object ( PGCli , 'connect ' ) as mock_connect : '\tport : % r ' , database , user , host , port ) ) , ( 'users ' , ' '' users '' ' , 'Users ' ) ) ) if persist_priorities == 'all ' : 'custom_func2 ( ) ' , 'entrytags ' : [ 'entryid ' , 'tagid ' ] , sql , on_error_resume=False , exception_formatter=exception_formatter executor , `` select * from unicodechars '' , join=True , expanded=expanded schema , table , view , function , column , wildcard_expansion , context.cn = dbutils.create_db ( `` quit '' , keyword ( 'CURRENT ' , -2 ) , string = string.replace ( '\\p ' , str ( if arg_mode in ( `` b '' , `` i '' ) View ( schema= '' t2 '' ) , for name , typ , mode in zip ( self.arg_names , self.arg_types , self.arg_modes ) ipython.run_line_magic ( `` load_ext '' , `` sql '' ) tuple ( c for c in item ) ) view ( 'Functions F ' ) , name_join = partial ( completion , 'name join ' ) ' '' select a.x , b.y def columns ( self , tbl , parent= '' public '' , typ= '' tables '' , pos=0 ) : fixture_dir = os.path.join ( context.package_root , `` tests/features/fixture_data '' ) processor=HighlightMatchingBracketProcessor ( chars= '' [ ] ( ) { } '' ) , cased_tbls = [ `` Users '' , `` Orders '' ] [ `` table_refs '' , `` require_last_table '' , `` local_tables '' , `` qualifiable '' , `` context '' ] , repo : https : //github.com/ambv/black 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = JOIN orders orders2 ON ' , stop_pos = len ( `` WITH a AS ( SELECT abc FROM xxx ) '' ) completion , prio=None , meta=None , synonyms=None , prio2=None , with mock.patch.object ( PGExecute , `` __init__ '' ) as mock_pgexecute : result = get_result ( completer , `` SELECT p. from custom.products p '' , len ( `` SELECT p . '' ) ) ) .format ( expected , actual , context.logfile.getvalue ( ) ) `` WARNING '' : logging.WARNING , [ 'table_refs ' , 'require_last_table ' , 'local_tables ' , 'qualifiable ' , 'context ' ] pgcli.connect_dsn ( 'service= { 0 } '.format ( os.environ [ 'PGSERVICE ' ] ) ) 'SELECT * FROM foo WHERE bar AND NOT EXISTS ( S ' , yield FunctionMetadata ( * row ) display_suffix = `` '' full_text , text_before_cursor , self.local_tables = \ repos : `` SELECT '' , @ parametrize ( 'completer ' , completers ( aliasing=True , casing=True ) ) [ `` Topic : : Database '' , 'schema ' , 'column ' , 'table alias ' , 'join ' , 'name join ' , 'fk join ' , if token.startswith ( `` Token . `` ) : `` INSERT INTO public.Orders ( * '' , meta = self.dbmetadata [ 'tables ' ] testdata.columns ( `` set_returning_func '' , `` custom '' , `` functions '' ) `` \\refresh '' , 'select * from ; select * from ' ) cfg.merge ( ConfigObj ( expanduser ( usr_cfg ) , interpolation=False , encoding='utf-8 ' ) ) with patch.object ( executor , `` host '' , `` localhost '' ) : mode='strict ' , meta='keyword ' ) return ( run ( executor , `` | -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- | '' , context.cli.sendline ( `` \\connect { 0 } '' .format ( db_name ) ) `` SELECT t1 . FROM tabl1 t1 , tabl2 t2 '' , Document ( text=text , cursor_position=position ) , @ pytest.mark.parametrize ( 'text , expected_length ' , [ _logger.debug ( `` pgcli magic called : % r '' , line ) context.cli.sendline ( '\\nd foo ' ) self.keywords ( pos ) stop1 = len ( `` 'WITH is_window , completer.extend_columns ( executor.view_columns ( ) , kind='views ' ) 'SELECT * FROM `` tabl1 '' t1 WHERE t1 . ' , result = get_result ( completer , 'SELECT cu ' ) assert set ( suggestions ) == set ( [ Keyword ( ) , Special ( ) ] ) conn_params.update ( { with open ( casing_file , ' w ' ) as f : t : [ col for col in cols if filter ( col ) ] dollar_quote_regex = re.compile ( r '' ^\ $ [ ^ $ ] * \ $ $ '' ) query = 'select 1 ' sql = 'SELECT * FROM abc a { 0 } JOIN def d ON a.id = d.num'.format ( join_type ) function ( `` custom_fun ( ) cf '' ) , 'SELECT t1 . FROM tabl1 t1 ' , `` -- list '' , 'custom ' : [ 'UPDATE foo SET x = 9 RETURNING x , y ' , os.getenv ( 'PGPORT ' , '5432 ' ) 'defaults ' : { cased_views matches = sorted ( matches , key=operator.attrgetter ( 'priority ' ) , self , ' $ $ `` foo '' ' , `` No default pager found in environment . Using os default pager '' def _columns ( self , kinds= ( ' r ' , ' v ' , 'm ' ) ) : package_data= { 'pgcli ' : [ 'pgclirc ' , text_before_cursor = full_text [ cte.start : current_position ] pgclirc_file = pgclirc_file or ' % sconfig ' % config_location ( ) function ( `` Func1 ( ) '' ) , 'PGPORT ' : os.environ.get ( 'PGPORT ' , None ) , and ( f.is_public or f.schema_name == suggestion.schema ) result = get_result ( completer , `` SELECT FROM `` + table , len ( `` SELECT `` ) ) is_special , 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ history=history , return [ ( None , None , None , str ( e ) , `` , False , True ) ] 'INSERT INTO users ( ) SELECT * FROM users u cross join orders o ' , `` qualify_columns '' : c [ `` main '' ] [ `` qualify_columns '' ] , 'DESCRIBE ' , title = `` List of databases '' if ( item_val in ( 'COPY ' , 'FROM ' , 'INTO ' , 'UPDATE ' , 'TABLE ' ) or Completion ( `` bar '' , 0 , display_meta= '' column '' ) , 'single_connection ' : single_connection , `` id , users.parentid , users.email , users.first_name , users.last_name '' , if typ == `` functions '' : return ( Schema ( ) , host=POSTGRES_HOST , run ( executor , `` 'create function func3 ( ) tbl_cols.extend ( [ self._make_col ( sch , tbl , col ) for col in cols ] ) text = 'ALTER ' logger.debug ( `` sql : % r '' , text ) context.conf [ 'pager_boundary ' ] ) context , 'Auto-completion refresh started in the background.\r\n ' , timeout=2 ) row_limit , assert tables == ( ( None , `` abc '' , None , False ) , ) if hasattr ( cur , 'description ' ) : def test_suggested_cased_always_qualified_column_names ( completer ) : return [ Match ( sql = `` DROP SCHEMA `` text = `` '' '' SELECT * FROM set_returning_func ( ) f1 tables = extract_tables ( 'select a , b from abc ' ) Completion ( text= '' MATERIALIZED VIEW '' , start_position=-2 ) , if not click.confirm ( 'Do you want to continue ? ' ) : envvar= '' PGHOST '' , ver = version ( `` pgcli/__init__.py '' ) 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) : ,\s ] + ) $ ' ) , comp.set_search_path ( [ `` public '' ] ) if history_file == `` default '' : if self.return_type.lower ( ) == 'void ' : function ( `` set_returning_func ( ) '' , -len ( `` func '' ) ) , use_pager_when_on = [ True , True , False , True , False , False ] `` INSERT INTO users ( ) '' , name_join ( `` y.product_name = x.product_name '' ) , `` expression '' , [ `` SELECT * FROM foo JOIN `` , `` SELECT * FROM foo JOIN bar '' ] func_name , assert first.display_text == 'enter_entry ( _title , _text ) ' arg = `` service=mock_postgres -- password '' `` dbname_tmp '' : db_name_full + `` _tmp '' , assert result == completions_to_set ( 'INSERT INTO users ( ) ' , 'public ' , word_before_cursor , keywords , mode= '' strict '' , meta= '' keyword '' `` Operating System : : Unix '' , [ schema ( `` PUBLIC '' ) ] for expected_line in context.fixture_data [ 'help_commands.txt ' ] : Token.SearchMatch.Current : 'search.current ' , ' '' , assert b '' postgres '' in context.cmd_output ) as e : arg_modes= [ `` t '' , `` t '' ] , _logger.debug ( 'Datatypes Query . sql : % r ' , query ) ( None , 'bcd ' , ' b ' , False ) ) passwd = os.environ.get ( 'PGPASSWORD ' , `` ) elif token_v.endswith ( `` , '' ) or token_v in ( `` = '' , `` and '' , `` or '' ) : function ( `` MAX '' , -2 ) , len ( COLOR_CODE_REGEX.sub ( `` '' , line ) ) assert first.text == `` extract_entry_symbols ( ) '' `` SELECT * FROM users JOIN custom.shipments ON `` , test_ids = [ self.dbmetadata = { 'tables ' : { } , 'views ' : { } , 'functions ' : { } , 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = JOIN orders o2 ON ' suggestions = suggest_type ( text , `` '' ) print ( `` Chat : https : //gitter.im/dbcli/pgcli '' ) `` id , Users.parentid , Users.email , Users.first_name , Users.last_name '' , socket_directory_query = `` ' assert suggestion == ( Keyword ( ) , ) pgspecial_logger = logging.getLogger ( `` pgspecial '' ) alias ( 'orders ' ) prompt_dsn , filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , prompt_text = ( `` You 're about to run a destructive command.\n '' arg_types , `` \\c '' , get_result , tables = extract_tables ( 'select a , from abc , def ' ) len ( `` SELECT * FROM Functions WHERE function : text '' ) + 1 , 'WITH users as ( SELECT 1 AS foo ) SELECT from custom.users ' , `` | head1 | head2 | '' , insert_stmt = parsed [ 0 ] .token_first ( ) .value.lower ( ) == `` insert '' quoted = prev_keyword and prev_keyword.value.lower ( ) == 'set ' return [ ( 'class : continuation ' , continuation ) ] return [ ColumnMetadata ( name , typ , [ ] ) self.arg_types , ref_prio = dict ( ( tbl.ref , num ) for num , tbl completer , 'SELECT u.id , u. from users u ' , len ( 'SELECT u.id , u . ' ) sql = 'SELECT abc FROM xxx ' pgclirc , `` Password for % s '' % user , white_space_regex = re.compile ( '\\s+ ' , re.MULTILINE ) Token.Output.OddRow : 'output.odd-row ' , on_error_resume = self.on_error == `` RESUME '' wrappers.expect_pager ( context , `` CREATE DATABASE\r\n '' , timeout=5 ) table ( 'Orders O2 ' ) , assert completions_to_set ( result ) == completions_to_set ( testdata.columns_functions_and_keywords ( is_function = ( allow_functions and assert token_start_pos ( p.tokens , idx ) == len ( 'SELECT * FROM \n ' ) 'integer ' , 'bigint ' , 'smallint ' ) else 0 text = 'SELECT p. * FROM custom.products p ' [ column ( 'foo ' ) ] + testdata.functions_and_keywords ( ) ) t2.id = t3 . ' '' print ( 'Goodbye ! ' ) cn = connect ( if self.output_file and not text.startswith ( ( '\\o ' , '\\ ? ' ) ) : for alias in cfg [ 'alias_dsn ' ] : c.name for t , cs in scoped_cols.items ( ) if t.ref ! = ltbl for c in cs `` select a.x , b.y from abc a join bcd b on a.id = `` , database = dbname_opt or dbname or `` '' [ alias ( `` users '' ) , alias ( ref ) ] @ parametrize ( 'completer ' , completers ( ) ) expected = join ( 'users ON users.id = u.userid ' , -len ( last_word ) ) for row in self._columns ( kinds= [ `` r '' ] ) : 'SELECT * FROM ( SELECT a , ' ) ( `` public '' , `` a '' , `` y '' , `` text '' , False , None ) , [ join ( `` custom.shipments ON shipments.user_id = { 0 } .id '' .format ( tbl ) ) ] ( 'schema1 ' , ' c ' , ' w ' , 'text ' , True , `` 'meow ' : :text '' ) , 'select * from a ; select * from ' ) raise RuntimeError ( 'Function { } does not exist . '.format ( spec ) ) 'INSERT INTO orders ( ' , 'SELECT * FROM tabl1 t1 WHERE t1 . ' , context.cli.expect_exact ( ' { 0 } > '.format ( dbname ) , timeout=15 ) if pgcli.multiline_mode == 'safe ' : `` EntryText '' , TabsProcessor ( char1= '' `` , char2= '' `` ) , if first_token.lower ( ) in ( `` use '' , `` \\c '' , `` \\connect '' ) : function ( 'set_returning_func ( ) ' , -len ( 'func ' ) ) ] ) context.cli.sendline ( `` drop database { 0 } ; '' .format ( context.conf [ `` dbname_tmp '' ] ) ) assert suggestions == ( Alias ( aliases= ( ' a ' , ' b ' , ) ) , ) 'PGUSER ' : os.environ.get ( 'PGUSER ' , None ) , _logger.debug ( `` Detected < Tab > key . '' ) 'SELECT foo : :bar . ' , ) : column_suggestions = suggest_based_on_last_token ( 'where ' , stmt ) alias ( ' o ' ) ] ) 'SELECT * FROM foo WHERE EXISTS ( SELECT * FROM ' , `` SELECT * FROM sch . `` , 'users ' : [ 'id ' , 'phone_number ' ] , 'Topic : : Database : : Front-Ends ' , `` | { 1,2,3 } | { { 1,2 } , { 3,4 } } | { å , 魚 , текст } | '' , `` $ a $ foo `` , Column ( table_refs= ( ( None , `` tabl1 '' , `` t1 '' , False ) , ) ) , and prev_tok.value Table ( schema='myschema ' ) , 'INSERT INTO ' , _identifier_is_function ( identifier ) ) Token.Toolbar.Search : `` search-toolbar '' , `` -- username '' , 78 , self.pgspecial.register ( refresh_callback , '\\ # ' , '\\ # ' , function ( `` func2 ( ) f '' ) , @ when ( 'we create database ' ) suggestions = suggest_type ( 'SELECT * FROM tabl WHERE col_n ' , HighlightMatchingBracketProcessor , table_refs=tables , local_tables=stmt.local_tables , qualifiable=True document = Document ( text=word_before_cursor , expected = [ Completion ( `` foo '' , 0 , display_meta= '' column '' ) ] assert tables == ( ( None , `` foo '' , None , True ) , ) schemata_query = `` '' '' self.decimal_format = c [ 'data_formats ' ] [ 'decimal ' ] if suggestion.usage == 'from ' : default=False , help= '' Print out , but not actually run any steps . '' 'SELECT from users U NATURAL JOIN `` Users '' ' , `` Do you want to proceed ? ( y/n ) '' ) function_meta_data ( _logger.error ( ' % r % r listed in unrecognized schema % r ' , return None , `` '' 'INSERT INTO public.Orders ( * ' , self.pgspecial.register ( self.info_connection , '\\conninfo ' , cased_func_names 'custom_func2 ( ) cf ' _logger.debug ( `` Trying a pgspecial command . sql : % r '' , sql ) return status.split ( None , 1 ) [ 0 ] .lower ( ) == `` select '' [ 'name ' , 'datatype ' , 'foreignkeys ' , 'default ' , 'has_default ' ] ( 'orders ' , 'id ' ) : `` nextval ( 'orders_id_seq ' : :regclass ) '' , schema_name , func_name , arg_names , arg_types , arg_modes , return_type , def test_distinct_and_order_by_suggestions_with_aliases ( text , text_before , port='2543 ' ) assert status == `` test '' qualifiable=False if tok_val in ( `` insert '' , `` update '' , `` delete '' ) : sslmode= '' verify-full '' , ( `` orders '' , `` status '' ) : `` 'PENDING ' : :text '' , if new_params [ `` password '' ] : rows=term_height , columns=term_width ) return ( last_tok.value.lower ( ) .endswith ( 'join ' ) `` custom_fun ( ) '' , completer.extend_relations ( executor.tables ( ) , kind= '' tables '' ) assert u '' é '' in run ( `` custom_fun ( ) cf '' , ( `` schema1 '' , `` c '' , `` w '' , `` text '' , True , `` 'meow ' : :text '' ) , 'SELECT t1 . FROM `` tabl1 '' t1 ' , str ( e ) 'Topic : : Software Development ' , new_value = env_new.get ( k , `` '' ) table ( `` users '' ) , if cmd == '\\dn ' : if history_file == 'default ' : `` SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . `` , complete_event , testdata.columns ( 'set_returning_func ' , typ='functions ' ) dbutils.drop_db ( context.conf [ 'host ' ] , context.conf [ 'user ' ] , [ 'func3 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , 'SELECT U . FROM `` custom '' . `` Users '' U ' history_file = config_location ( ) + 'history ' testdata.columns ( 'users ' , 'custom ' ) ) suggestions = suggest_type ( `` SELECT FROM func ( ) '' , `` SELECT `` ) print ( `` Config file is now located at '' , config_full_path ) or ( ref.schema and ( id == ref.schema + `` . '' + ref.name ) ) @ click.option ( '-D ' , ' -- dsn ' , default= '' , envvar='DSN ' , `` CREATE FUNCTION foo ( bar INT , baz `` , join ( ' '' Users '' ON `` Users '' .userid = Users.id ' ) , 'datatypes ' : [ 'custom_type1 ' , 'custom_type2 ' ] , [ table ( x ) for x in ( `` orders '' , ' '' select '' ' , `` custom.shipments '' ) ] database = `` postgres '' self.return_type , text = `` SEL '' None , None , None , ' < null > ' , False , None , lambda x : x , None `` Waiting for { 0 } seconds before repeating '' .format ( schema ( u '' 'public ' '' ) ] ) Match = namedtuple ( 'Match ' , [ 'completion ' , 'priority ' ] ) on_error_resume = self.on_error == 'RESUME ' 'Topic : : Database ' , query = special.get_editor_query ( [ `` SELECT '' , `` PUBLIC '' ] `` host '' : context.config.userdata.get ( test_ids = [ `` Output longer than terminal height '' , 'case_column_headers ' : c [ 'main ' ] .as_bool ( 'case_column_headers ' ) , ) : is_flag=True , return None , `` `` EntAccLog '' , context.conf [ `` pager_boundary '' ] @ refresher ( 'functions ' ) `` SELECT * FROM tabl WHERE 10 < `` , lines = text.split ( `` \n '' ) 'qualify_columns ' , 'if_more_than_one_table ' ) return last_tok.value.lower ( ) in ( `` on '' , `` and '' , `` or '' ) `` SELECT users.name , orders.id FROM users JOIN orders ON `` , if suggestion.context == 'insert ' : disable keyring in our configuration : add keyring = False to [ main ] '' '' '' meta = self.dbmetadata [ 'datatypes ' ] port=port , * * self.pgexecute.extra_args ) print ( 'fixture dir : ' , fixture_dir ) or ( text == `` : q '' ) # Quit does n't need semi-colon 'set_returning_func ' , typ='functions ' `` $ $ 'foo ' $ $ '' , sql , spec ) 'SELECT * FROM `` tabl '' WHERE ' , result = get_result ( completer , `` SEL '' ) completer , 'select f. from set_returning_func ( ) f ' , len ( 'select f . ' ) dsn , * * kwargs ) Column ( table_refs=tables , require_last_table=True ) , ] ) `` -- list-dsn '' , 'SELECT u.name , o.id FROM users u JOIN orders o ON ' , for row in self._relations ( kinds= [ ' v ' , 'm ' ] ) : tbls = tuple ( [ ( None , 'abc ' , tbl_alias or None , False ) ] ) Document ( text=text , cursor_position=cursor_positition ) , None ) ' '' other_tbls = set ( ( t.schema , t.name ) return `` 'pager_boundary ' : ' -- -boundary -- - ' , 'pg_test_host ' , parcolmeta = meta [ parentschema ] [ parenttable ] [ parcol ] from .config import ( get_casing_file , suggestions = suggest_type ( text , text [ : text.find ( ' ; ' ) + 1 ] ) Table ( schema= '' t2 '' ) , context.cli.sendline ( `` select 123456 '' ) @ kb.add ( 'f4 ' ) Alias , assert set ( suggest_type ( q , q ) ) == set ( [ * Apply ` black ` to code . ( Thanks : ` Irina Truong ` _ ) comp.extend_relations ( tables , kind='tables ' ) tables = extract_tables ( `` SELECT * FROM foo ( { 0 } ) '' .format ( arg_list ) ) testdata.schemas_and_from_clause_items ( ) less_chatty=None , return_type , except IndexError : # The user typed an incorrect table qualifier suggestions = suggest_type ( `` \\d '' , `` \\d '' ) ' $ $ `` foo '' $ $ ' , `` databases '' , Completion ( text='MATERIALIZED VIEW ' , start_position=-2 ) , 'UPDATE sch . ' , suggest.append ( version , `` SELECT t1 . `` , tbls = tuple ( [ ( None , 'foo ' , None , False ) ] ) return ' ( ' + ' , '.join ( a for a in args if a ) + ' ) ' `` pgcli `` uses ` black < https : //github.com/ambv/black > ` _ to format the source code . Make sure to install black . `` asterisk_column_order '' , `` table_order '' `` 22200K ....... \u001b [ 0m\u001b [ 91m ... .......... ... \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m ...... ......... \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m ...... 50 % 28.6K 12m55s '' , `` INSERT INTO orders ( `` , assert `` MIN '' not in result def tables ( self , parent= '' public '' , pos=0 ) : _logger.debug ( 'Version Query . sql : % r ' , self.version_query ) assert set ( tables ) == set ( [ ( None , `` abc '' , `` a '' , False ) , ( None , `` def '' , `` d '' , False ) ] ) def _relations ( self , kinds= ( `` r '' , `` v '' , `` m '' ) ) : `` SELECT * FROM ( `` , `` orders '' , return `` ( `` + `` , `` .join ( a for a in args if a ) + `` ) '' pid = self._select_one ( cursor , `` select pg_backend_pid ( ) '' ) [ 0 ] self.pgexecute.connect ( INNER JOIN set_returning_func ( ) f2 ON f1 . '' '' '' view ( escape ( x ) , pos ) q = 'select * from tbl1 inner join tbl2 using ( col1 , ' assert tables == ( ( None , 'abc ' , 'abc ' , False ) , ) return [ ( None , None , None , message , `` , True , True ) ] testdata.columns ( `` products '' , `` custom '' ) INNER JOIN set_returning_func ( ) f2 ON f1 . ' '' assert tables == ( ( None , `` foo '' , `` bar '' , True ) , ) ( None , 'tabl2 ' , 't2 ' , False ) ] ) TableExpression = namedtuple ( 'TableExpression ' , 'name columns start stop ' ) sql = `` SELECT abc def , ghi jkl FROM xxx '' 'postgres : //bar % 5E : % 5Dfoo @ baz.com/testdb % 5B ? ' `` Output shorter than terminal width '' ] assert u'日本語 ' in run ( executor , u '' SELECT * FROM person '' , join=True ) ] def functions_and_keywords ( self , parent= '' public '' , pos=0 ) : result.append ( ( 'class : bottom-toolbar.on ' , context.cli.sendline ( 'create table a ( x text ) ; ' ) aliased_rels = ( ( `` SELECT * FROM users JOIN nontable nt on `` , `` nt '' ) , functions = get_literals ( 'functions ' ) elif ( _logger.debug ( 'Reusing existing pgcli ' ) assert completions_to_set ( result ) == completions_to_set ( [ schema ( 'PUBLIC ' ) ] + cased_rels + [ return ( Table ( schema=schema ) , View ( schema=schema ) ) `` ColumnMetadata '' , [ `` name '' , `` datatype '' , `` foreignkeys '' , `` default '' , `` has_default '' ] filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) , Function ( schema=None ) , 'CREATE TABLE foo ( bar INT , baz TEXT , qux ' , [ join ( 'public.users ON users.id = `` Users '' .userid ' ) ] mock.patch.object ( cli , 'prompt_app ' ) as mock_app : result = completions_to_set ( completer.get_completions ( ` pep8radius < https : //github.com/hayd/pep8radius > ` _ . If you see a build failing because View ( schema='tabl ' ) , text = `` SELECT * FROM `` [ alias ( `` U '' ) , alias ( `` U2 '' ) , fk_join ( `` U2.userid = U.id '' ) ] def test_wildcard_column_expansion_with_table_qualifier ( == `` | 4713-01-01 00:00:00 BC | '' `` password '' : password , elif token_v.endswith ( ' , ' ) or token_v in ( '= ' , 'and ' , 'or ' ) : Table ( schema=None ) , sql = 'SELECT abc def FROM xxx ' x AS `` ' ) return _ColumnMetadata ( run ( executor , `` 'create function func1 ( ) returns int suggestions = suggest_type ( text , text [ : text.find ( `` `` ) + 1 ] ) single_connection=False , less_chatty=None , prompt=None , prompt_dsn=None , ' [ F3 ] Multiline : OFF ' ) ) View ( schema='myschema ' ) , context.cli.sendline ( `` \ ? '' ) 'Releasing version { } '.format ( ver ) ) run_step ( `` git '' , `` add '' , version_file ) fg= '' red '' , Column ( table_refs= ( ) , local_tables= ( ) , qualifiable=True ) , `` insert into numbertest ( a ) values ( { 0 } ) '' .format ( value ) ) arg_default = `` '' `` set_returning_func ( x : = , y : = ) '' , ) , name_join ( `` o.id = u.id '' ) , single_connection=False , [ schema ( `` PUBLIC '' ) ] + cased_rels 'custom_func1 ( ) ' , reason='setproctitle not available ' ) os.getenv ( 'PGUSER ' , 'postgres ' ) keyword ( 'MAXEXTENTS ' , -2 ) , keyword ( 'MATERIALIZED VIEW ' , -2 ) @ pytest.mark.parametrize ( 'initial_text ' , ( `` , ' ' , '\t \t ' , ) ) is_set_returning=True text = 'SELECT IN ' port=None , def connect ( 'less_chatty ' : less_chatty , keyword_casing = 'upper ' settings._replace ( max_width=1 ) , current = `` '' sql = r '' \ { command } { verbose } { pattern } '' .format ( * * locals ( ) ) expected = completions_to_set ( [ schema ( `` 'public ' '' ) ] ) assert set ( suggestion ) == set ( [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] ] , ] , text = 'SELECT blog.ee ' and ( not item.value.upper ( ) .endswith ( `` JOIN '' ) ) not JSONB_AVAILABLE , ) , sslrootcert='ca.pem ' ) @ pytest.mark.parametrize ( 'pattern ' , [ `` , ' x ' , ' * . * ' , ' x.y ' , ' x . * ' , ' * .y ' ] ) ) _logger.debug ( `` Function Definition Query . sql : % r\nspec : % r '' , sql , spec ) `` SELECT * FROM tabl1 t1 WHERE t1 . `` , self.pgspecial.register ( self.write_to_file , '\\o ' , '\\o [ filename ] ' , for rcol in rcols help='Set threshold for row limit prompt . Use 0 to disable prompt . ' ) root_logger = logging.getLogger ( 'pgcli ' ) [ 'func1 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , def views ( self , parent= '' public '' , pos=0 ) : function ( 'Func1 ( ) ' ) , if not os.environ.get ( 'LESS ' ) : @ pytest.mark.parametrize ( 'term_height , term_width , text ' , test_data , ids=test_ids ) ref_prio = dict ( ( tbl.ref , num ) for num , tbl in enumerate ( suggestion.table_refs ) ) @ then ( 'we see the named query saved ' ) timeout=1 ) `` , `` .join ( priority=priority ( None , `` t2 '' , None , False ) , ] 'SELECT DISTINCT FROM tbl x JOIN tbl1 y ' , _SchemaObject = namedtuple ( `` SchemaObject '' , `` name schema meta '' ) return expanduser ( '~/.config/pgcli/ ' ) passwd = click.prompt ( self.pgexecute.port ) if self.pgexecute.port is not None else '5432 ' ) long_description=open ( `` README.rst '' ) .read ( ) , == `` | -123456789 days , 12:23:56 | '' [ `` b '' , `` b '' ] , position = len ( 'SELECT MA ' ) func_name='func4 ' , `` You 're about to run a destructive command.\n '' `` Do you want to proceed ? ( y/n ) '' @ refresher ( 'databases ' ) `` SELECT u.name , o.id FROM users u JOIN orders o ON JOIN orders o2 ON '' , if t.value == `` ( `` or ( msg += `` \nCurrently set to : % s '' % self.table_format `` -- less-chatty '' , return click.style ( utf8tounicode ( str ( e ) ) , fg='red ' ) [ `` custom_func1 '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , `` `` '' \ tables = extract_tables ( `` SELECT * FROM foo JOIN bar ( ) '' ) casing = ( `` insert_col_skip_patterns '' , [ r '' ^now\ ( \ ) $ '' , r '' ^nextval\ ( `` ] context.conf [ `` port '' ] , database= '' _test_db '' , schema_name , real_name , identifier.get_alias ( ) , is_function self.pgspecial.pset_pager ( suggestions = suggest_type ( `` SELECT `` , `` SELECT `` ) sql = 'SELECT abc.def , ghi.jkl FROM xxx ' `` df '' : Function , cols = ( `` EntryID '' , `` EntryTitle '' ) yield FunctionMetadata ( * row ) style = pygments.styles.get_style_by_name ( `` native '' ) .styles settings._replace ( max_width=1 ) result = get_result ( completer , `` SELECT cu '' ) self.table_format = c [ 'main ' ] [ 'table_format ' ] ] 'SELECT U . FROM custom.users U ' , assert run ( executor , `` SELECT ( CAST ( '00:00:00+14:59 ' AS timetz ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ suggestions = suggest_type ( `` \\ '' , `` \\ '' ) casing_file = config_location ( ) + 'casing ' item.ttype is Keyword token_v in ( `` copy '' , `` from '' , `` update '' , `` into '' , `` describe '' , `` truncate '' ) `` `` '' create function func4 ( x int ) returns setof int language sql stop2 = len ( tables = extract_tables ( 'select a , b from abc , def ' ) 's ' , ' g ' , [ ' x ' ] , [ 'integer ' ] , [ arg_default=arg_default join ( `` users users2 ON users2.parentid = Users.id '' ) , ' $ $ foo $ $ ' , or _is_complete ( text ) # Ended with \e which should launch the editor 'pg_test_user ' , `` `` '' if hasattr ( context , `` tmpfile_sql_help '' ) and context.tmpfile_sql_help : word_before_cursor , self.all_completions , mode= '' strict '' Token.Toolbar.Off : 'bottom-toolbar.off ' , print ( `` `` .join ( cmd ) ) keyring.set_password ( 'pgcli ' , key , passwd ) flattened = flattened [ : len ( flattened ) -n_skip ] `` INSERT INTO OtherTabl SELECT * FROM tabl WHERE `` , @ click.option ( '-v ' , ' -- version ' , is_flag=True , help='Version of pgcli . ' ) fk_join = partial ( completion , 'fk join ' ) start_pos = len ( `` WITH a AS `` ) run ( executor , `` '' '' insert into test values ( 'abc ' ) '' '' '' ) y AS `` ' ) `` `` '' , single_connection , dbname_opt , username , version , pgclirc , dsn , row_limit , envvar= '' DSN '' , ( `` class : bottom-toolbar '' , `` ( Semi-colon [ ; ] will end the line ) `` ) table ( `` Orders '' ) , run_step ( 'git ' , 'commit ' , ' -- message ' , 'SELECT * FROM custom.set_returning_func ( ) ' , completion=Completion ( POSTGRES_HOST , arg ] , prompt_check=prompt_check , currentdb=currentdb ) del os.environ [ `` PGPASSWORD '' ] 'Intended Audience : : Developers ' , u '' select 'fooé ' ; invalid syntax é '' , suggestions = suggest_type ( 'SELECT * FROM ( SELECT FROM abc ' , assert u '' 日本語 '' in run ( executor , u '' SELECT * FROM person '' , join=True ) `` SELECT * FROM users natural join `` , err=True , fg='red ' ) `` custom '' : { cli.connect_uri ( 'postgres : //bar % 5E : % 5Dfoo @ baz.com/testdb % 5B ' ) NamedQuery , assert set ( tables ) == set ( [ ( None , 'tabl1 ' , 't1 ' , False ) , logger.debug ( `` Refreshing search path '' ) map ( Completion , completer.all_completions ) ) [ name_join ( `` y = f2.y '' ) , name_join ( `` x = f2.x '' ) ] from .parseutils.utils import last_word , find_prev_keyword , parse_partial_identifier Coding Style table_format='ascii ' , INNER JOIN set_returning_func ( ) f2 USING ( `` '' '' `` -- confirm-steps '' , self.functions ( parent , pos ) + self.views ( parent , pos ) assert types == [ ( `` public '' , `` foo '' ) ] 'SELECT * FROM sch . `` foo ' , `` % ( asctime ) s ( % ( process ) d/ % ( threadName ) s ) `` [ ( `` foo '' , `` bar '' , `` baz '' , False ) , ( `` bar '' , `` qux '' , `` quux '' , True ) ] `` select t.oid FROM pg_type t WHERE t.typname = 'hstore ' and t.typisdefined '' ) Table ( schema='tabl ' ) , schema ( u '' 'blog ' '' ) , ) , `` nested_numeric_array | { { 1,2 } , { 3,4 } } '' , return_type= '' record '' , Completion ( text= '' TABLE '' , display_meta='keyword ' ) , tempfile_suffix='.sql ' , return result [ 0 ] if result else `` '' join ( `` users u ON u.id = Users.parentid '' ) , tables = extract_tables ( 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' ) result.append ( ( `` class : bottom-toolbar '' , `` Refreshing completions ... '' ) ) schema ( u '' 'Custom ' '' ) , prompt=prompt , @ refresher ( 'types ' ) arg_names= [ `` x '' , `` y '' ] , return suggest_based_on_last_token ( `` type '' , stmt ) if 'XDG_CONFIG_HOME ' in os.environ : def types ( self , parent='public ' , pos=0 ) : [ join ( 'custom.shipments ON shipments.user_id = { 0 } .id'.format ( tbl ) ) ] cased_rels 'select a.x , b.y from abc a join bcd b on a.id = ' , 'Tags ' , 'EntryTags ' , 'EntAccLog ' , assert tuple ( ctes ) == ( ( ' a ' , ( 'abc ' , ) , start_pos , stop_pos ) , ) `` ERROR '' : logging.ERROR , `` INSERT INTO Orders ( * '' , cursor.execute ( `` SELECT NULL : :date '' ) assert first.display_text == `` enter_entry ( _title , _text ) '' callback , history=history , settings=self.settings ) expanded = settings.expanded or settings.table_format == `` vertical '' len ( prompt ) > self.max_len_prompt ) : 'postgres : //bar : foo @ baz1.com:2543 , baz2.com:2543 , baz3.com:2543/testdb ' ) `` port '' : context.config.userdata.get ( ( None , 'bar ' , None , True ) ] ) `` functions '' , text = 'DROP TABLE schema_name.table_name ' context.cli.sendline ( ' i ' ) ' % ( name ) s % ( levelname ) s - % ( message ) s ' ) timeout=5 , [ 'user_group ' , 'user ' ] , assert run ( executor , `` 'select * from test '' ' , join=True ) == dedent ( `` '' '' \ run_step ( `` git '' , `` commit '' , `` -- message '' , `` Releasing version { } '' .format ( ver ) ) ver = version ( 'pgcli/__init__.py ' ) ) : keyword_casing = c [ 'main ' ] [ 'keyword_casing ' ] os.environ [ 'PAGER ' ] = 'cat ' join ( 'users users2 ON users2.id = Users.parentid ' ) , OutputSettings , @ parametrize ( 'text ' , join_texts ) 'PGHOST ' : os.environ.get ( 'PGHOST ' , None ) , text = 'SELECT * FROM ' ( tbl + `` . '' + self.case ( col ) ) if do_qualify else self.case ( col ) Then commit and push the fixes . `` -- password '' , @ parametrize ( 'use_leading_double_quote ' , [ False , True ] ) new_value = env_new.get ( k , `` ) install_requirements.append ( 'setproctitle > = 1.1.9 ' ) `` $ $ $ a $ $ $ '' , settings = OutputSettings ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , context.cli.sendline ( 'drop table a ; ' ) 'COPY sch . ' , and not f.is_window 'SELECT t1 . FROM `` tabl1 '' t1 ' , sql = `` SELECT abc FROM xxx '' ' [ F2 ] Smart Completion : OFF ' ) ) `` disable_numparse '' : True , 'ALTER TABLE foo ALTER COLUMN bar TYPE custom . ' , 'Execute commands from file . ' ) from cli_helpers.tabular_output.preprocessors import ( align_decimals , self.refresh_completions ( persist_priorities='keywords ' ) position = len ( `` SELECT u.name , o.id FROM users u JOIN orders o ON `` ) if current == `` and char == ' ' : ) or item_val.endswith ( `` JOIN '' ) : current = `` '\tdatabase : % r ' database= '' testdb '' , host= '' baz.com '' , user= '' bar '' , passwd= '' foo '' , port= '' 2543 '' @ when ( 'we insert into table ' ) 'INSERT INTO OtherTabl SELECT * FROM tabl WHERE ' , if `` PGPASSWORD '' in os.environ : assert u'\\xdeadbeef ' in run ( executor , `` select * from binarydata '' , join=True ) logger.debug ( 'Refreshing search path ' ) elif editor_command == '\\ef ' : settings = OutputSettings ( expected = Column ( table_refs= ( ( None , `` sessions '' , None , False ) , ) , qualifiable=True ) view = partial ( completion , 'view ' ) pat = re.compile ( `` ( % s ) '' % regex ) FROM users u '' ' , [ function ( x + ' ( ) ' ) for x in ( 'func2 ' , ) ] SELECT * FROM a , b '' ' if os.path.exists ( os.path.expanduser ( `` ~/.pgclirc '' ) ) : return ( not f.is_aggregate and `` dT '' : Datatype , join = partial ( completion , 'join ' ) or left.schema not in ( right.schema , 'public ' ) ) : logical_operators = ( `` AND '' , `` OR '' , `` NOT '' , `` BETWEEN '' ) completer , 'SELECT MAX ( from custom.products ' , len ( 'SELECT MAX ( ' ) item_val.endswith ( 'JOIN ' ) ) : assert tables == ( ( None , `` abc '' , `` a '' , False ) , ( None , `` bcd '' , `` b '' , False ) ) test_line = `` - '' * 10 `` `` '' select a.x , b.y wrappers.run_cli ( context , run_args= [ [ `` _entryid '' , `` symbol '' ] , `` `` '' INSERT INTO `` Users '' tables = extract_tables ( 'update abc.def set id = 1 ' ) from metadata import ( MetaData , alias , name_join , fk_join , join , keyword , license= '' BSD '' , Column ( table_refs= ( ( None , `` tbl '' , None , False ) , ) , qualifiable=True ) , def drop_db ( hostname='localhost ' , username=None , password=None , def create_db ( hostname='localhost ' , username=None , password=None , dbname=None , port=None ) : comp.extend_columns ( tbl_cols , kind= '' tables '' ) ' '' insert into hij ( a , b , c ) col_list = 'id , parentid , email , first_name , last_name ' Token.SearchMatch.Current : `` search.current '' , 'test status ' quit_handler , result.append ( ( 'class : bottom-toolbar.transaction.failed ' , ' '' INSERT INTO `` Users '' return ( status == ext.TRANSACTION_STATUS_ACTIVE or else c [ `` main '' ] .get ( `` prompt '' , self.default_prompt ) POSTGRES_USER , ] keyword ( `` CURRENT '' , -2 ) , run_step ( `` python '' , `` setup.py '' , `` clean '' , `` -- all '' , `` sdist '' , `` bdist_wheel '' ) elif token_v == 'on ' : alias ( ' y ' ) , self.style_output = style_factory_output ( self.syntax_style , c [ `` colors '' ] ) @ click.option ( '-d ' , ' -- dbname ' , 'dbname_opt ' , help='database name to connect to . ' ) print ( `` Home : http : //pgcli.com '' ) name_join ( ' y.price = x.price ' ) , [ ( `` abc '' , `` def '' , None , False ) , ( `` def '' , `` ghi '' , None , False ) ] self.expanded_output = c [ `` main '' ] .as_bool ( `` expand '' ) `` CREATE TABLE foo ( bar DOU '' , @ parametrize ( 'text ' , texts ) context , 'You\ 're about to run a destructive command.\r\nDo you want to proceed ? ( y/n ) : ' , timeout=2 ) `` text '' , [ 'SELECT U . FROM custom . `` Users '' U ' , 'SELECT U . FROM `` custom '' . `` Users '' U ' ] cr.execute ( `` create database % s '' , ( AsIs ( dbname ) , ) ) @ pytest.mark.parametrize ( 'collection ' , [ prio2 , return merge_styles ( qual = [ 'if_more_than_one_table ' , 'always ' ] def connect ( self , database=None , user=None , password=None , host=None , click.secho ( 'Invalid DSNs found in the config file . '\ Function ( schema= ' x ' ) , sslmode='verify-full ' , ' '' INSERT INTO public . `` Users '' ( username ) db_changed , path_changed , mutated , is_special ) ( '\\ns abc SELECT t1 . FROM tabl1 t1 ' , 'SELECT t1 . ' , [ mutating = set ( [ `` insert '' , `` update '' , `` delete '' ] ) 'SELECT * FROM Custom.Set_Returning_Func ( ) ' context.cli.sendcontrol ( ' c ' ) @ parametrize ( ( 'query ' , 'tbl ' ) , itertools.product ( ( Token.Toolbar.Transaction.Failed : 'bottom-toolbar.transaction.failed ' , `` WITH cte AS ( SELECT foo , bar FROM baz ) SELECT FROM cte '' , [ r'^now\ ( \ ) $ ' , r'^nextval\ ( ' ] 'SELECT * FROM tabl WHERE ' , context='insert ' 'invalid sql ' , context.conf [ 'port ' ] ) self.multiline_mode = c [ 'main ' ] .get ( 'multi_line_mode ' , 'psql ' ) assert tables == ( ( `` abc '' , `` def '' , None , False ) , ) context.cli.sendline ( context.conf [ `` pass '' ] or `` DOES NOT MATTER '' ) return self.find_matches ( word_before_cursor , formats , meta='table format ' ) last_word , find_prev_keyword , parse_partial_identifier ) cfg [ 'settings ' ] [ 'search_path_filter ' ] = filtr FromClauseItem ( schema=None , table_refs=tables ) , # we want the latest possible version of pep8radius db_name = context.conf [ `` dbname '' ] os.environ [ 'LESS ' ] = '-SRXF ' expect_exact ( 'DELETE FROM foo WHERE x > y RETURNING x , y ' , `` Send all query results to file . `` , True , cased_users_col_names = [ 'ID ' , 'PARENTID ' , 'Email ' , 'First_Name ' , 'last_name ' ] 'sep_length ' : ( 1 , 25 ) , 'SELECT from users U NATURAL JOIN `` Users '' ' , if mode == 'fuzzy ' : `` casing '' , sql = `` SELECT 99 abc FROM xxx '' assert set ( executor.foreignkeys ( ) ) > = set ( `` user_emails '' , 'SELECT * FROM users u1 JOIN users u2 USING ( email ) JOIN user_emails ue USING ( ) ' , `` SELECT * FROM users INNER JOIN orders USING ( `` , table ( `` orders o '' if text == `` SELECT * FROM `` else `` orders o2 '' ) , 'SELECT * FROM `` sch '' . ' , `` Programming Language : : Python '' , if filename not in [ `` . `` , `` .. '' ] : bg_refresh.assert_called_with ( pgexecute , special , callbacks , None , None ) @ when ( 'we prepare the test data ' ) text = 'SELECT custom.func ' `` Launch Params : \n '' `` \tdatabase : % r '' `` \tuser : % r '' `` \thost : % r '' `` \tport : % r '' , or left.schema not in ( right.schema , `` public '' ) self.config [ `` main '' ] .as_bool ( `` enable_pager '' ) and `` on '' or `` off '' coltyp = namedtuple ( 'coltyp ' , 'name datatype ' ) self.row_limit = c [ `` main '' ] .as_int ( `` row_limit '' ) ) , COLOR_CODE_REGEX = re.compile ( r'\x1b ( \ [ . * ? [ @ -~ ] |\ ] . * ? ( \x07|\x1b\\ ) ) ' ) [ 'head1 ' , 'head2 ' ] , 'test status ' , settings ) print ( ORDER BY 1,2 ; ' '' `` \\q '' , `` SELECT * FROM tabl WHERE bar OR `` , self.is_aggregate , less_chatty , prompt , prompt_dsn , list_databases , auto_vertical_output , message = 'Wise choice . Command execution stopped . ' `` WITH cte AS ( SELECT foo FROM bar ) SELECT * FROM cte WHERE cte . `` , run ( executor , `` create schema schema1 '' ) SELECT * FROM a '' '' '' tables = ( ( None , `` abc '' , `` a '' , False ) , ( None , `` bcd '' , `` b '' , False ) ) `` SELECT * FROM ( SELECT FROM abc '' , `` SELECT * FROM ( SELECT `` functions = meta [ `` functions '' ] .get ( schema , { } ) .get ( relname ) 'SELECT * FROM public . { 0 } RIGHT OUTER JOIN ' , `` Socket directory Query . sql : % r '' , self.socket_directory_query `` Time : % 0.03fs ( % s ) , executed in : % 0.03fs ( % s ) '' for c in self.unescape_name ( item.lower ( ) ) col = namedtuple ( 'col ' , 'schema tbl col ' ) datatype = partial ( completion , `` datatype '' ) Column ( table_refs= ( ( None , ' b ' , None , False ) , ) , qualifiable=True ) , return ( sch , tbl , col , `` text '' , ( tbl , col ) in defaults , defaults.get ( ( tbl , col ) ) ) 'select * from foo where bar = 1 and baz or ' , cli.connect_uri ( 'postgres : //bar @ baz.com/ ? application_name=cow ' ) assert status == 'test ' View ( schema= ' f ' ) , completer , if tok1 and tok1.value.startswith ( `` \\ '' ) : ' $ $ ' , function ( `` set_returning_func ( x integer , y integer ) '' , -len ( `` set_ret '' ) ) arg_default = `` NULL '' if arg.default is None else arg.default `` PGUSER '' : os.environ.get ( `` PGUSER '' , None ) , query.execution_time , ' '' elif usage == 'call ' and len ( args ) < 2 : `` INTO '' , suggestions = suggest_type ( `` \\df myschema.xxx '' , `` \\df myschema.xxx '' ) @ then ( 'we see record deleted ' ) assert set ( executor.schemata ( ) ) > = set ( `` orders '' : [ `` id '' , `` ordered_date '' , `` status '' , `` datestamp '' ] , view ( 'user_emails ue ' ) , assert result [ 0 ] == table ( `` Entries E '' , -1 ) t.is_keyword and ( t.value.upper ( ) not in logical_operators ) sep = `` , `` + word_before_cursor [ : -1 ] `` Users '' : [ `` userid '' , `` username '' ] , ref.schema and ( id == ref.schema + ' . ' + ref.name ) ) `` UPDATE foo SET x = 9 RETURNING x , y '' , return last_tok.value.lower ( ) in ( 'on ' , 'and ' , 'or ' ) context.cli.sendline ( `` \\ns foo SELECT 12345 '' ) metadata = self.dbmetadata [ `` functions '' ] `` SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON JOIN public.orders z ON z.id > y.id '' , text = 'SELECT * FROM tabl WHERE foo = ANY ( ' ' u.id , u.parentid , u.email , u.first_name , u.last_name ' ) test_line = '- ' * 10 keyword , Column ( table_refs= ( ( None , 'abc ' , None , False ) , ) , qualifiable=True ) , cli = PGCli ( ( 'SELECT Users . * FROM Users ' , if ( lastword ! = word_before_cursor and len ( tables ) == 1 ( 10 , 10 , `` - '' * 11 ) , `` create database foo with template `` , `` create database foo with template `` suggestions = suggest_type ( `` SELECT a , b , FROM tbl '' , `` SELECT a , b , '' ) run ( executor , `` create view vw1 AS SELECT * FROM tbl1 '' ) `` $ a $ $ $ $ a $ '' , self.arg_defaults [ num - num_args + num_defaults ] position = len ( `` SELECT users.name , orders.id FROM users JOIN orders ON `` ) meta = self.dbmetadata [ `` datatypes '' ] `` Output equal to terminal width '' , table ( 'orders o2 ' ) , tables = extract_tables ( 'SELECT * FROM my_table AS m WHERE m.a > 5 ' ) with open ( os.path.expanduser ( pattern ) , encoding='utf-8 ' ) as f : context.cli.sendline ( `` create table a ( x text ) ; '' ) View ( schema='t2 ' ) , t.value.upper ( ) not in logical_operators ) ) : def cols_etc ( 'SELECT U . FROM custom . `` Users '' U ' , @ click.option ( ' -- warn/ -- no-warn ' , default=None , [ ] I installed pre-commit hooks ( ` pip install pre-commit & & pre-commit install ` ) , and ran ` black ` on my code . print ( `` Version : '' , __version__ ) table ( 'Orders ' ) , help= '' Skip intro on startup and goodbye on exit . `` , new_params [ `` dsn '' ] , password=new_params.pop ( `` password '' ) result = get_result ( cli = PGCli ( pgexecute=executor , pgclirc_file=rcfile ) MetaQuery.__new__.__defaults__ = ( `` '' , False , 0 , 0 , False , False , False , False ) keywords_tree = get_literals ( 'keywords ' , type_=dict ) text = 'SELECT * FROM blog.e ' testdata.columns ( 'products ' , 'custom ' ) ) '| -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- | ' , assert set ( tables ) == set ( [ ( None , `` Abc '' , None , False ) , ( None , `` Def '' , None , False ) ] ) user= '' bar '' , `` SELECT * FROM foo WHERE bar AND NOT EXISTS ( `` , database=db , ' '' completer=ThreadedCompleter ( DynamicCompleter ( lambda : self.completer ) ) , if not suggestion.schema and ( qualified [ normalize_ref ( rtbl.ref ) ] 'EntAccLog EAL ON EAL.EntryID = E.EntryID ' , -1 ) ] completer = PGCompleter ( smart_completion , pgspecial=self.pgspecial , prio = 1000 if c.datatype in ( assert ( 'SELECT * FROM `` Users '' u JOIN id ' , `` EntryID '' , '| -- -- -- -- -+ -- -- -- -- -| ' , wrappers.expect_exact ( context , '12345 ' , timeout=1 ) from metadata import ( MetaData , alias , name_join , fk_join , join , suggestions = suggest_type ( `` INSERT INTO abc ( id , '' , `` INSERT INTO abc ( id , '' ) from pgspecial.main import PGSpecial , NO_QUERY , PAGER_OFF , PAGER_LONG_OUTPUT Schema ( ) , self.schema_name , self.func_name , self.arg_names , self.user = dsn_parameters.get ( `` user '' ) assert `` \n '' .join ( results ) == `` \n '' .join ( expected ) Completion ( 'bar ' , 0 , display_meta='column ' ) , `` collection '' , ( text == 'exit ' ) or # Exit does n't need semi-colon return -float ( 'Infinity ' ) , -match_point rel_type = { 'table ' : Table , 'view ' : View , 'function ' : Function } [ token_v ] get_result , result_set , qual , no_qual , parametrize ) [ 'custom_func1 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , Table ( schema=schema ) ] arg_default_type_strip_regex = re.compile ( r '' : : [ \w\ . ] + ( \ [ \ ] ) ? $ '' ) `` SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON `` 3 display_meta = display_meta [ :47 ] + `` ... '' extract_column_names as _extract_column_names ) JoinCondition ( table_refs=tables , parent=None ) , for row in self._columns ( kinds= [ ' v ' , 'm ' ] ) : 'disable_numparse ' : True , full_text = full_text [ cte.start : cte.stop ] os.path.expanduser.side_effect = IOError ( 'test ' ) cur.execute ( `` ' text = 'user ' @ then ( 'we see { which } data selected ' ) if prev_tok == `` exists '' : def _bg_refresh ( self , pgexecute , special , callbacks , history=None , settings=None ) : View ( schema=schema ) , ) keywords = ( 'drop ' , 'shutdown ' , 'delete ' , 'truncate ' , 'alter ' ) suggestion.usage , `` call '' short_host , _ , _ = host.partition ( ' . ' ) 'Topic : : Software Development : : Libraries : : Python Modules ' , return ( Column ( table_refs=extract_tables ( stmt.full_text ) , [ Column ( table_refs=tables , require_last_table=True ) ] [ alias ( ' u ' ) , alias ( ' o ' ) ] ) arg_mode = { `` signature '' : `` signature '' , `` special '' : None } .get ( from prompt_toolkit.layout.processors import ( sql = `` 'SELECT * FROM foo WHERE bar GROUP BY baz ; @ then ( u'we send password ' ) 'packages/pgliterals/pgliterals.json ' ] } , self.on_error = c [ 'main ' ] [ 'on_error ' ] .upper ( ) passwd = keyring.get_password ( `` pgcli '' , key ) config_full_path = config_location ( ) + `` config '' smart_completion = c [ `` main '' ] .as_bool ( `` smart_completion '' ) return ipython.run_cell_magic ( `` sql '' , line , q.query ) PROMPT_STYLE_TO_TOKEN = { v : k for k , v in TOKEN_TO_PROMPT_STYLE.items ( ) } DROP SCHEMA IF EXISTS schema2 CASCADE '' ' ) timeout=2 , Table ( schema= '' tabl '' ) , dsn= '' , * * kwargs ) : self.is_extension , assert set ( suggestions ) == set ( ( JoinCondition ( table_refs=tables , parent=None ) , executor , `` alphanum_underscore '' : re.compile ( r '' ( \w+ ) $ '' ) , @ click.option ( '-W ' , ' -- password ' , 'prompt_passwd ' , is_flag=True , default=False , def test_suggested_column_names_from_shadowed_visible_table ( completer , table ) : 'SELECT * FROM users INNER JOIN orders USING ( ' , passwd = click.prompt ( 'Password for % s ' % user , hide_input=True , # Get an array of FunctionMetadata objects suggestions = suggest_type ( 'select * from a ; select * from ' , 'preserve_whitespace ' : True , _logger.debug ( 'Databases Query . sql : % r ' , set ( [ Keyword ( ) , Special ( ) ] ) if self.pgexecute.host.startswith ( '/ ' ) : position = len ( FROM users u '' '' '' , for sch in self._get_schemas ( `` functions '' , schema ) cli.connect_uri ( 'postgres : //bar : foo @ baz.com:2543/testdb ' ) return self.find_matches ( word_before_cursor , self.databases , ( 10 , 10 , '\n'.join ( [ test_line ] * 6 ) ) , yield ( None , None , None , qualifiable=False , InputMode.INSERT_MULTIPLE : 'M ' , Token.Toolbar.On : 'bottom-toolbar.on ' , ( None , 't2 ' , None , False ) , result = get_result ( completer , 'SELECT u. from users u ' , len ( 'SELECT u . ' ) ) JOIN bar.qux ( x , y , z ) quux '' '' '' 'ORDER BY ' , string = string.replace ( '\\h ' , self.pgexecute.short_host or ' ( none ) ' ) matches = self.find_matches ( word_before_cursor , funcs , meta= '' function '' ) completer = PGCompleter ( smart_completion=True , pgspecial=special , with io.open ( version_file , encoding= '' utf-8 '' ) as f : if hasattr ( sql.connection.Connection , `` get '' ) : word_before_cursor , NamedQueries.instance.list ( ) , meta='named query ' ) @ then ( 'we see data selected ' ) assert `` \n '' .join ( expanded_results ) == `` \n '' .join ( expanded ) `` -- no-password '' , len ( 'SELECT * FROM Functions WHERE function : text ' ) + 1 text_before_cursor , include='many_punctuations ' ) `` Programming Language : : Python : : 2.7 '' , 'SELECT DISTINCT x . ' 'test status ' , settings ) return [ assert set ( suggestions ) == cols_etc ( 'tabl ' , last_keyword='WHERE ' ) word_before_cursor , self.functions , mode='strict ' , tables = ( ( None , 'abc ' , None , False ) , ( None , 'bcd ' , None , False ) ) `` CREATE FUNCTION foo ( bar `` , `` \\q '' , q = 'ALTER TABLE foo ALTER COLUMN bar TYPE ' position = text.index ( ' ( ) ' ) + 1 ' '' INSERT INTO public.orders ( orderid ) logger.error ( `` Unhandled style / class name : % s '' , token ) _logger.debug ( Table ( schema= ' x ' ) , arg_modes=None , ( 10 , 10 , `` \n '' .join ( [ test_line ] * 6 ) ) , ext.register_type ( ext.new_type ( ( 17 , ) , 'BYTEA_TEXT ' , psycopg2.STRING ) ) function ( `` func3 ( ) '' , -len ( `` func '' ) ) , self._on_completions_refreshed , persist_priorities=persist_priorities not item.value.upper ( ) .endswith ( 'JOIN ' ) ) : `` entrytags '' : [ `` entryid '' , `` tagid '' ] , Column ( table_refs= ( TableReference ( schema , table , alias , is_function ) , ) , assert set ( suggest_type ( text , text ) ) == set ( 'INSERT INTO orders ( * ) ' , context.cli.sendline ( `` drop table if exists a ; '' ) print ( `` fixture dir : '' , fixture_dir ) return Candidate ( qualify ( name , ref ) , 0 , `` column '' , synonyms ) assert run ( executor , `` '' '' select * from test '' '' '' , join=True ) == dedent ( testdata.columns ( `` set_returning_func '' , typ= '' functions '' ) message = 'File output disabled ' assert `` 123456 '' in f.read ( ) sql = 'SELECT * FROM xxx ' Table ( schema='sch ' ) , 'SELECT 1 AS ' , except IndexError : # The user typed an incorrect table qualifier text , text_before , last_keyword make_cand ( c.name , t.ref ) if not text : # Empty string `` SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = `` 'INSERT INTO public.Orders ( * ) ' , assert set ( suggestions ) == set ( [ FromClauseItem ( schema='sch ' ) ] ) expected = Completion ( `` COLUMN '' , start_position=0 , display_meta= '' keyword '' ) 'SELECT * FROM tabl WHERE bar OR ' , os.environ [ `` EDITOR '' ] = `` ex '' f_sug = Function ( s.schema , s.table_refs , usage='from ' ) @ then ( 'we see small results in horizontal format ' ) 'special ' : None , process_title = re.sub ( r '' password= ( .+ ? ) ( ( \s [ a-zA-Z ] += ) | $ ) '' , r '' password=xxxx\2 '' , process_title ) Join ( ( ( None , 'foo ' , None , False ) , ) , None ) , pgspecial.register ( quit_handler , '\\q ' , '\\q ' , 'Quit pgcli . ' , old_value = env_old.get ( k , `` '' ) `` $ a $ foo `` , envvar='PGCLIRC ' , help='Location of pgclirc file . ' , type=click.Path ( dir_okay=False ) ) ] ) `` search_path_filter '' : c [ `` main '' ] .as_bool ( `` search_path_filter '' ) , message = `` Wise choice . Command execution stopped . '' text = 'SELECT * FROM blog.Entries E JOIN blog.et ' suggestions = suggest_type ( 'INSERT INTO abc ( i ' , 'INSERT INTO abc ( i ' ) Column ( table_refs= ( ( None , 'foo ' , None , False ) , ) , qualifiable=True ) , context.cli.sendcontrol ( 'd ' ) assert extract_column_names ( sql ) == ( 'abc ' , 'def ' ) executor.run ( sql , on_error_resume=True , exception_formatter=exception_formatter ) tbls = tuple ( [ ( None , 'foo ' , ' f ' , False ) ] ) assert extract_column_names ( sql ) == ( `` def '' , ) TableExpression = namedtuple ( `` TableExpression '' , `` name columns start stop '' ) `` SELECT * FROM foo ( ) AS bar ( baz INT , qux `` , tables = extract_tables ( `` ) schema = partial ( completion , `` schema '' ) suggestions = suggest_type ( `` \\dn `` , `` \\dn `` ) dest= '' confirm_steps '' , Table ( schema= '' f '' ) , `` PGPASSWORD '' : os.environ.get ( `` PGPASSWORD '' , None ) , View ( schema= '' tabl '' ) , arg_default = `` `` float_format '' : settings.floatfmt , names = [ 'foo ' , 'bar ' , 'baz ' ] humanize.time.naturaldelta ( query.execution_time ) ) ) [ FromClauseItem ( schema=None , table_refs=tbls ) , Schema ( ) , Join ( tbls , None ) ] elif token_v in ( ' c ' , 'use ' , 'database ' , 'template ' ) : \.eggs text = 'ALTER TABLE users ALTER ' return [ ( None , None , None , message , `` , False , True ) ] text = `` ALTER TABLE users ALTER `` 'insert_col_skip_patterns ' , executor , `` SELECT ( CAST ( '4713-01-01 00:00:00 BC ' AS timestamp ) ) '' , join=True @ parametrize ( 'completer ' , completers ( casing=True , qualify= [ 'always ' ] ) ) table_refs=tables , 'SELECT foo FROM ( SELECT bar ' result = get_result ( completer , 'SELECT om ' ) self.syntax_style = c [ 'main ' ] [ 'syntax_style ' ] @ parametrize ( 'action ' , [ 'ALTER ' , 'DROP ' , 'CREATE ' , 'CREATE OR REPLACE ' ] ) ) % ( ( self.__class__.__name__ , ) + self._signature ( ) ) if self.destructive_warning : return `` '' .join ( if self.pgexecute.host.startswith ( `` / '' ) : cased_users_col_names + cased_users2_col_names 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' , smart_completion=True , pgspecial=special , settings=settings tables = ( ( None , 'abc ' , ' a ' , False ) , ( None , 'bcd ' , ' b ' , False ) ) suggestions = suggest_type ( sql [ : i+1 ] , sql [ : i+1 ] ) Table ( schema='d ' ) , 'SELECT * FROM users u1 JOIN user_emails ue USING ( ) JOIN users u2 ue USING ( first_name , last_name ) ' , display_suffix = self._arg_list_cache [ 'call_display ' ] [ tbl.meta ] '_custom_fun ( ) ' , _logger.debug ( 'Dangerous query detected -- ignoring ' ) `` `` '' create function func3 ( ) if not ipython.find_line_magic ( `` sql '' ) : path_changed , `` dv '' : View , if token.startswith ( 'Token . ' ) : timeout=timeout , `` Set password in keyring returned : '' , None , ) : if full_text.startswith ( `` \\i `` ) : arg_modes , id == ref.alias pre-commit > =1.16.0 passwd = keyring.get_password ( 'pgcli ' , key ) word_before_cursor , self.datatypes , mode= '' strict '' , meta= '' datatype '' ) == completions_to_set ( result ) ' Failed transaction ' ) ) True , os.environ [ `` COVERAGE_PROCESS_START '' ] = os.path.join ( ( `` class : bottom-toolbar.transaction.failed '' , `` Failed transaction '' ) 'call ' : self.call_arg_style , host=None , whitespace = ' ' [ table ( x ) for x in ( `` orders o '' , ' '' select '' s ' , `` custom.shipments s '' ) ] ( `` -\u001b ] 23\u0007- '' , 2 ) , TabsProcessor ) 'Candidate ' , 'completion prio meta synonyms prio2 display ' else ' '' ' + self.name + ' '' ' ) ) 'Operating System : : Unix ' , SELECT * FROM users U JOIN `` Users '' U2 ON `` ' , assert set ( executor.views ( ) ) > = set ( [ ( `` public '' , `` d '' ) ] ) os.environ [ 'XDG_CONFIG_HOME ' ] = str ( tmpdir_factory.mktemp ( 'data ' ) ) print ( 'Please move the existing config file ~/.pgclirc to ' , [ `` SELECT * FROM Custom . `` , `` SELECT * FROM custom . `` , 'SELECT * FROM `` custom '' . ' ] , wrappers.expect_pager ( context , 'DROP DATABASE\r\n ' , timeout=2 ) completer , `` select f. from set_returning_func ( ) f '' , len ( `` select f . '' ) self.host = dsn_parameters.get ( 'host ' ) [ ( `` abc '' , `` def '' , None , False ) , ( `` ghi '' , `` jkl '' , None , False ) ] escape ( x [ 0 ] ) + ' ( ' + ' , '.join ( 'SELECT * FROM ( ' , stop1 = len ( `` views '' : { `` user_emails '' : [ `` id '' , `` email '' ] , `` functions '' : [ `` function '' ] } , is_set_returning=False , is_extension=False , arg_defaults=None `` NONE '' : logging.CRITICAL , expect_exact ( context , `` { 0 } > `` .format ( context.conf [ `` dbname '' ] ) , timeout=5 ) return [ ( None , None , None , message , `` '' , False , True ) ] 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT FROM cte ' , result = get_result ( completer , `` SELECT om '' ) Completion ( text= '' MAXEXTENTS '' , start_position=-2 ) , # Get an array of FunctionMetadata objects view_type = 'MATERIALIZED ' if result [ 2 ] == 'm ' else `` `` list_databases '' , result = executor.view_definition ( `` mvw1 '' ) POSTGRES_PASSWORD = getenv ( `` PGPASSWORD '' , `` '' ) def datatypes ( self , parent= '' public '' , pos=0 ) : raise RuntimeError ( `` View { } does not exist . `` .format ( spec ) ) tables = ( ( None , 'abc ' , ' a ' , False ) , ( None , 'def ' , 'd ' , False ) ) `` Have you updated the ` Usage ` section of the README ? `` , `` `` '' @ parametrize ( 'completer ' , completers ( casing=True , qualify=no_qual ) ) [ `` custom_func2 '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , `` mutated '' , # True if any subquery executed insert/update/delete 'SELECT * FROM ( SELECT * FROM ' , self.less_chatty = bool ( less_chatty ) or c [ 'main ' ] .as_bool ( 'less_chatty ' ) 'call_display ' : self.call_arg_display_style , if typ == 'functions ' : Function ( schema=None , usage='special ' ) , ) os.environ [ 'VISUAL ' ] = 'ex ' executor , `` SELECT ( CAST ( '-123456789 days 12:23:56 ' AS interval ) ) '' , join=True os.environ [ 'PGSERVICEFILE ' ] = os.path.join ( for x in self.metadata.get ( 'datatypes ' , { } ) .get ( parent , [ ] ) ] refresh_callback , name_join ( ' o.id = u.id ' ) , tables = extract_tables ( `` '' ) token_start_pos , extract_ctes , tables = tuple ( [ ( None , 'foo ' , None , False ) , ( None , 'bar ' , None , False ) ] ) `` less_chatty '' : less_chatty , function ( 'set_returning_func ( x integer , y integer ) ' , -len ( 'set_ret ' ) ) rev : stable testdata.schemas_and_from_clause_items ( ) literal_file = os.path.join ( root , 'pgliterals.json ' ) SELECT * FROM users U JOIN `` Users '' U2 ON `` '' '' , pgcli.echo_via_pager ( '\n'.join ( formatted ) ) def get_tables ( self , scope= '' full '' ) : schema_names = [ s for s in schema_names if not s.startswith ( `` pg_ '' ) ] [ ( `` public '' , `` a '' ) , ( `` public '' , `` b '' ) , ( `` schema1 '' , `` c '' ) ] return last_tok.value.lower ( ) .endswith ( `` join '' ) and last_tok.value.lower ( ) not in ( 'SELECT * FROM `` custom '' . ' , assert first.text == 'enter_entry ( _title : = , _text : = ) ' query = `` select 1 '' `` list_dsn '' , col_list = 'id , p.product_name , p.price ' `` casing_file '' : get_casing_file ( c ) , assert result [ :2 ] == [ JSONB_AVAILABLE = 'jsonb ' in json_types Datatype , [ 'text ' , 'text ' , 'integer ' ] , [ ' i ' , ' i ' , ' o ' ] , | dist envvar= '' PGPORT '' , context.package_root , 'tee_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) ) assert `` FROM tbl1 '' in result completer.extend_columns ( executor.table_columns ( ) , kind='tables ' ) `` preprocessors '' : ( format_numbers , format_arrays ) , column , 'functions ' , len ( 'SELECT users.id , users . ' ) function ( `` custom_fun ( ) '' , -2 ) , assert set ( suggestions ) == cols_etc ( 'abc ' ) TableFormat , FromClauseItem ( 'select abc.x , bcd.y from abc join bcd on ' , 'SELECT * FROM Orders o CROSS JOIN ' ] ) ] # OUT , INOUT , TABLE ( None , 't3 ' , None , False ) ) 'SELECT U . FROM users U ' if hasattr ( context , `` cli '' ) and context.cli and not context.exit_sent : smart_completion=True , assert executor.search_path ( ) == [ 'pg_catalog ' , 'public ' ] assert get_result ( completer , action + `` FUNCTION set_ret '' ) == [ `` pgcli.main.click.echo_via_pager '' `` \\o [ filename ] '' , 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' , if item.ttype is DML and item.value.upper ( ) in ( if arg == `` -- port '' : self.prompt_format = prompt if prompt is not None else c [ 'main ' ] .get ( 'prompt ' , self.default_prompt ) self.completer.set_search_path ( return_type=None , `` set_returning_func '' , assert set ( tables ) == set ( [ ( None , `` abc '' , None , False ) , ( None , `` def '' , None , False ) ] ) cli_cmd = context.conf.get ( `` cli_command '' ) '+ -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- + ' , with open ( os.path.expanduser ( pattern ) , encoding= '' utf-8 '' ) as f : testdata.keywords ( ) assert b'postgres ' in context.cmd_output or id == ref.name context.conf [ 'pager_boundary ' ] , expected ) , timeout=timeout ) startup= ' ; '.join ( [ 'Waiting for { 0 } seconds before repeating ' 'SELECT * FROM `` tabl1 '' t1 WHERE t1 . ' , ' '' SELECT * join = ' { 0 } { 4 } ON { 4 } . { 1 } = { 2 } . { 3 } '.format ( for usage in ( 'call ' , 'call_display ' , 'signature ' ) `` INSERT INTO Orders ( * '' , `` custom_func1 ( ) '' , case_sensitive=False , def columns_functions_and_keywords ( table_refs= ( TableReference ( None , `` tbl '' , `` x '' , False ) , ) , if mode == `` fuzzy '' : `` SELECT * FROM foo WHERE bar AND NOT EXISTS ( SELECT * FROM `` , from prompt_toolkit.layout.processors import ( ConditionalProcessor , `` tables '' : { result = get_result ( completer , `` SELECT et FROM blog.Entries E '' , len ( `` SELECT et '' ) ) for p in self.insert_col_skip_patterns [ 'user_group ' , 'user_action ' ] , from pgspecial.main import PAGER_OFF , PAGER_LONG_OUTPUT , PAGER_ALWAYS `` tables '' , Column ( table_refs= ( ( None , 'abc ' , ' a ' , False ) , ) ) , 'SELECT * FROM `` Users '' u JOIN u ' , 'INSERT INTO public.Orders ( * ' , Join ( tables , None ) , r '' password= ( .+ ? ) ( ( \s [ a-zA-Z ] += ) | $ ) '' , r '' password=xxxx\2 '' , process_title context.conf [ 'port ' ] ) def datatypes ( self , parent='public ' , pos=0 ) : `` INSERT INTO public.users SELECT u . * FROM users u '' , `` orders '' : [ `` id '' , `` ordered_date '' , `` status '' , `` email '' ] , None , testdata.columns ( `` orders '' ) def connect ( self , database= '' , host= '' , user= '' , port= '' , passwd= '' , join ( 'Users Users2 ON Users2.PARENTID = Users.ID ' ) , `` Custom_Func1 '' , return ' { ' + ' , '.join ( text_type ( format_array ( e ) ) for e in val ) + ' } ' `` Load your password from keyring returned : '' , str ( e ) `` text '' , [ `` SELECT foo : :bar . `` , `` SELECT foo : :bar.baz '' , `` SELECT ( x + y ) : :bar . '' ] local_tables=stmt.local_tables , text = 'SEL ' d [ 1 ] == psycopg2.extensions.INTEGER.values 'SELECT * FROM public . `` Users '' RIGHT OUTER JOIN ' , for sch , funcs in self.dbmetadata [ 'functions ' ] .items ( ) wrappers.expect_exact ( context , ' { 0 } > '.format ( db_name ) , timeout=5 ) 'SELECT ( x + y ) : :bar . ' , t : [ col for col in cols if filter ( col ) ] for t , cols in scoped_cols.items ( ) wrappers.expect_pager ( context , `` DELETE 1\r\n '' , timeout=2 ) cmd = [ `` pgcli '' , `` -- list '' ] print ( 'Created connection : { 0 } . '.format ( cn.dsn ) ) Column ( table_refs= ( ( None , `` foo '' , `` f '' , False ) , ) ) , if ( self._must_raise ( e ) Token.Menu.Completions.ProgressBar : 'scrollbar ' , # best guess ( 10 , 10 , '- ' * 11 ) , keyword_casing = settings.get ( `` keyword_casing '' , `` upper '' ) .lower ( ) assert 'MATERIALIZED VIEW ' in result `` keyword '' , click.secho ( `` Not Yet Implemented . `` , fg= '' yellow '' ) 'SELECT * FROM custom . ' , arg_types= ( 'integer ' , ) , elif ' : // ' in database : ) server_version = `` '' start_pos = len ( 'WITH a AS ' ) envvar= '' PGROWLIMIT '' , query.total_time ) , return self.arg_modes and any ( arg_mode == `` v '' for arg_mode in self.arg_modes ) Column ( table_refs= ( ( None , `` b '' , None , False ) , ) , qualifiable=True ) , continuation = self.multiline_continuation_char * ( width - 1 ) + `` `` self.arg_types , self.arg_modes , self.return_type , self.is_aggregate , [ function ( x ) for x in ( `` func2 ( ) f '' , ) ] text = `` foo '' language sql as $ $ select 2 $ $ ' '' ) ( None , None , None , `` Auto-completion refresh started in the background . '' ) cli_cmd = context.conf.get ( 'cli_command ' ) 'ALTER TABLE foo ALTER COLUMN ' , ConditionalProcessor , `` integer_format '' : settings.dcmlfmt , FromClauseItem , @ pytest.mark.parametrize ( 'text , before , expected ' , [ return not f.is_extension and ( `` table format '' , log_file = config_location ( ) + 'log ' tables = extract_tables ( 'select * from abc ' ) 'set_returning_func ( x : = , y : = ) srf ' , _logger.debug ( `` Functions Query . sql : % r '' , query ) table_refs=extract_tables ( stmt.full_text ) , completer , 'SELECT id , from custom.products ' , len ( 'SELECT id , ' ) elif token_v == `` on '' : suggestions = suggest_type ( 'select * from a ; select * from ; select * from c ' , return self.find_matches ( word_before_cursor , joins , meta= '' join '' ) `` `` '' \ if settings.get ( `` single_connection '' ) : sql = 'drop database foo ; ' text = `` SELECT * FROM blog.Entries E JOIN blog.et '' 'SELECT * FROM foo AS bar ' , is_extension=False , assert types == [ ( 'public ' , 'foo ' ) ] @ parametrize ( 'text ' , [ 'SELECT * FROM Orders o CROSS JOIN ' ] ) host= '' baz1.com , baz2.com , baz3.com '' , TableFormat = namedtuple ( 'TableFormat ' , [ ] ) `` INSERT INTO foo ( x , y , z ) VALUES ( 5 , 6 , 7 ) RETURNING x , y '' , result.append ( ( 'class : bottom-toolbar.off ' , 'SELECT U . FROM custom.Users U ' , for typ in datatypes assert tables == ( ( None , 'Abc ' , ' a ' , False ) , ) tables = extract_tables ( `` SELECT * FROM abc.def x JOIN ghi.jkl y ON x.id = y.num '' ) text , self.pgspecial , exception_formatter , on_error_resume c.name for t , cs in scoped_cols.items ( ) if t.ref ! = ltbl for c in cs ) suggestions = suggest_type ( '\d myschema.xxx ' , '\d myschema.xxx ' ) `` if_more_than_one_table '' : len ( tables ) > 1 , `` -D '' , create_db ( `` _test_db '' ) ) col = namedtuple ( `` col '' , `` schema tbl col '' ) @ parametrize ( 'text ' , [ 'SELECT * FROM ' , self.casing_file = settings.get ( `` casing_file '' ) join ( 'Users Users2 ON Users2.ID = Users.PARENTID ' ) , assert funcs > = set ( [ help='Do not use a separate connection for completions . ' ) os.environ [ `` XDG_CONFIG_HOME '' ] = str ( tmpdir_factory.mktemp ( `` data '' ) ) expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) _logger.debug ( `` Schemata Query . sql : % r '' , self.schemata_query ) [ alias ( ' U ' ) , alias ( 'U2 ' ) , fk_join ( 'U2.UserID = U.ID ' ) ] display=None % threshold , fg='red ' ) 0 if ( left.schema , left.tbl ) in other_tbls else 1 'WARNING ' : logging.WARNING , Completion ( `` cte1 '' , 0 , display_meta= '' table '' ) , @ pytest.mark.parametrize ( 'join_type ' , ( `` , 'INNER ' , 'LEFT ' , 'RIGHT OUTER ' , ) ) `` Output equal to terminal height '' , @ when ( 'we run dbcli ' ) [ schema ( 'PUBLIC ' ) ] + cased_rels ) ] ) , ( None , 'Def ' , 'd ' , False ) ] ) if which == 'expanded ' : if current == `` '' and char == `` `` : `` -W '' , text = last_word ( text , include='most_punctuations ' ) .lower ( ) `` set_returning_func ( x : = , y : = ) srf '' , 'SELECT U . FROM `` custom '' .Users U ' , column = partial ( completion , `` column '' ) suggestions = suggest_type ( 'create database foo with template ' , arg_name + ' : = ' `` | -- -- -- -- -+ -- -- -- -- -| '' , view ( `` User_Emails UE '' ) , host=POSTGRES_HOST , datatypes = get_literals ( 'datatypes ' ) `` INSERT INTO users SELECT * FROM users u '' , 'SELECT DISTINCT ' , Table ( schema= '' a '' ) , | \.cache `` select * from abc inner join def using ( col1 , `` , `` join '' , 'SELECT 1 : :custom . ' , completer = testdata.get_completer ( { 'keyword_casing ' : keyword_casing } ) if arg == ' -- port ' : Keyword ( last_keyword ) ] ) expected = completions_to_set ( [ suggestions = suggest_type ( text , `` ) 'database_name ' : context.conf [ 'dbname_tmp ' ] elif item.ttype is Keyword and ( self.row_limit = c [ 'main ' ] .as_int ( 'row_limit ' ) ( 10 , 10 , '\n'.join ( [ test_line ] * 5 ) ) , self.expanded_output = c [ 'main ' ] .as_bool ( 'expand ' ) return ( Function ( schema=schema , usage= '' signature '' ) , ) `` PGDATABASE '' : os.environ.get ( `` PGDATABASE '' , None ) , `` INSERT INTO public.orders ( * ) '' , WITH a AS `` ' ) return ( Column ( table_refs=stmt.get_tables ( `` insert '' ) , context= '' insert '' ) , ) Style ( prompt_styles ) for row in self._relations ( kinds= [ `` r '' ] ) : remap = { `` term_height , term_width , text , use_pager '' , pager_on_test_data , ids=test_ids alias ( `` u '' ) , or ( name.upper ( ) in self.functions ) ) : `` 配列 | { < null > } '' , `` execution_time '' , # Time elapsed executing the query stdin = click.get_text_stream ( 'stdin ' ) ) 'entries ' : [ 'entryid ' , 'entrytitle ' , 'entrytext ' ] , `` call_display '' : self.call_arg_display_style , self.pgspecial.register ( refresh_callback , '\\refresh ' , '\\refresh ' , if statement.get_type ( ) in ( 'CREATE ' , 'CREATE OR REPLACE ' ) : def run ( assert Column ( table_refs= ( ( None , 't3 ' , None , False ) , ) ) in set ( suggestions ) `` select * from foo where bar = 1 and baz between qux and `` , @ parametrize ( 'completer ' , completers ( casing=True , aliasing=True ) ) `` text '' , `` Entries '' , `` -l '' , executor , print ( 'Mail : https : //groups.google.com/forum/ # ! forum/pgcli ' ) assert u '' \\xdeadbeef '' in run ( executor , `` select * from binarydata '' , join=True ) url='http : //pgcli.com ' , '' , INNER JOIN users u3 ON u2.id = u3 . '' '' '' return `` ( ) '' if cmd in [ '\\n ' , '\\ns ' , '\\nd ' ] : function ( `` custom_func2 ( ) '' , -2 ) , click.secho ( `` Aborted ! `` , err=True , fg= '' red '' ) users = table ( `` users '' ) conn = psycopg2.connect ( user=POSTGRES_USER , 'func ' , is_function=True , last_keyword='SELECT ' ) [ schema ( `` PUBLIC '' ) ] + [ function ( f ) for f in cased_func_names ] table ( ' '' select '' ' ) , join ( 'users users2 ON users2.parentid = Users.id ' ) , context.cli.sendline ( context.conf [ 'pass ' ] or 'DOES NOT MATTER ' ) context.cli.sendline ( `` \pset pager off '' ) ) + ' ) ' , database , `` Quit pgcli . `` , columns_query = `` '' '' default= '' '' , for x in self.metadata.get ( 'tables ' , { } ) .get ( parent , [ ] ) ] is_aggregate , suggestions = suggest_type ( `` SELECT tabl . FROM tabl '' , `` SELECT tabl . '' ) _logger.debug ( `` Version Query . sql : % r '' , self.version_query ) 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' , @ click.option ( ' -- prompt ' , help='Prompt format ( Default : `` \\u @ \\h : \\d > `` ) . ' ) load_config , print ( `` Mail : https : //groups.google.com/forum/ # ! forum/pgcli '' ) @ when ( 'we delete from table ' ) TableReference.ref = property ( `` fk join '' , 'Programming Language : : Python : : 3.4 ' , string = string.replace ( `` \\h '' , self.pgexecute.short_host or `` ( none ) '' ) pattern = `` \\b '' + white_space_regex.sub ( r '' \\s+ '' , keyword ) + `` \\b '' 'Title ' , position = text.find ( ' * ' ) + 1 `` defaults '' : { [ `` i '' , `` o '' ] , for c in self.unescape_name ( item.lower ( ) ) ) + ( 1 , ) self.completer.case return ( sch , tbl , col , 'text ' , ( tbl , col ) in defaults , defaults.get ( ( tbl , col ) ) ) if not click.confirm ( `` Are you sure ? `` , default=False ) : 'SELECT * FROM users INNER JOIN orders USING ( id , ' , 'INSERT INTO public.orders ( ' schema_names = self.dbmetadata [ `` tables '' ] .keys ( ) print ( '- ' * 20 ) | \.git except ( RuntimeError , keyring.errors.KeyringError ) as e : include = '\.pyi ? $ ' 'INSERT INTO orders ( * ' , `` table_format dcmlfmt floatfmt missingval expanded max_width case_function style_output '' , 'user_emails ' , _logger.debug ( `` Suggestion type : % r '' , suggestion_type ) d [ 1 ] in psycopg2.extensions.LONGINTEGER.values : os.environ [ 'PGHOST ' ] = context.conf [ 'host ' ] help= '' list `` `` available databases , then exit . `` , self.name join = partial ( completion , `` join '' ) @ parametrize ( 'completer ' , completers ( filtr=True , casing=False , qualify=no_qual ) ) assert result [ :2 ] == [ table ( 'Entries ' , -1 ) , join ( `` u.id , u.parentid , u.email , u.first_name , u.last_name '' `` Please move the existing config file ~/.pgclirc to '' , on_error_resume=False ) : / ( `` select abc.x , bcd.y from abc join bcd on abc.id = bcd.id and `` , position = len ( 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = ' ) `` sql '' , [ `` create table foo ( bar int , baz `` , `` select * from foo ( ) as bar ( baz `` ] result = get_result ( completer , r'\df ' ) testdata.columns_functions_and_keywords ( `` set_returning_func '' , typ= '' functions '' ) Join = namedtuple ( `` Join '' , [ `` table_refs '' , `` schema '' ] ) Keyword ( token_v.upper ( ) ) , ) 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id and ' , q = `` SELECT * FROM foo f WHERE EXISTS ( SELECT 1 FROM bar WHERE f . '' kind , relname , schema ) JoinCondition ( table_refs=tables , parent= ( None , `` abc '' , `` a '' , False ) ) , fk_join ( 'u2.userid = users.id ' ) , collection = [ `` Foo '' , `` FOO '' , `` fOO '' ] `` SELECT * FROM tabl WHERE ( bar AND ( baz OR ( qux AND ( `` , TabsProcessor , start_position=-2 , _logger.debug ( 'Search path query . sql : % r ' , self.search_path_query ) cols = [ column ( 'users . ' + c ) for c in cased_users_col_names ] display=display , self._make_cand ( f , alias , suggestion , arg_mode ) for f in all_functions yield TableReference ( self.last_token = parsed and parsed.token_prev ( len ( parsed.tokens ) ) [ 1 ] or `` if tok1 and tok1.value.startswith ( '\\ ' ) : assert suggestions == ( Datatype ( schema= '' foo '' ) , ) display_suffix = `` result.append ( ( `` class : bottom-toolbar.off '' , `` [ F3 ] Multiline : OFF `` ) ) view_type = `` MATERIALIZED '' if result [ 2 ] == `` m '' else `` '' os.environ [ 'EDITOR ' ] = 'ex ' `` keyword_casing , expected , texts '' , for c in flat_cols ( ) ) suggestions = suggest_type ( 'SELECT FROM func ( ) ' , 'SELECT ' ) ( 'SELECT * FROM users JOIN nontable nt on ' , 'nt ' ) alias ( ' '' Users '' ' ) , ) if dsn is not `` : testdata.columns ( 'Users ' ) ) text = `` user '' text = `` '' .join ( tok.value for tok in flattened [ : idx + 1 ] ) priority= ( 1 , 1 , 1 ) , types = self.populate_schema_objects ( suggestion.schema , `` datatypes '' ) shutil.move ( os.path.expanduser ( '~/.pgclirc ' ) , config_full_path ) checks = [ 'Have you updated the AUTHORS file ? ' , 'SELECT users.name , orders.id FROM users JOIN orders ON JOIN orders orders2 ON ' `` coverage.process_startup ( ) '' , processor=HighlightMatchingBracketProcessor ( short_host , _ , _ = host.partition ( `` . '' ) text = `` SELECT FROM users '' _logger.debug ( `` No rows in result . '' ) socket_directory_query = `` '' '' Datatype ( schema='bar ' ) , arg_default_type_strip_regex = re.compile ( r ' : : [ \w\ . ] + ( \ [ \ ] ) ? $ ' ) assert run ( executor , `` SELECT ( CAST ( '-123456789 days 12:23:56 ' AS interval ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ qualifiable=True ) , context.cli.sendline ( `` create table a ( x integer , y real , z numeric ( 10 , 4 ) ) ; '' ) sql = `` SELECT * FROM sessions WHERE session = 1 AND `` return ( not f.is_extension and modes = self.arg_modes or [ `` i '' ] * len ( self.arg_names ) `` sqlparse > =0.3.0 , < 0.4 '' , Function ( schema='t2 ' ) , function ( `` _custom_fun ( ) '' , -2 ) , 'entacclog ' : [ 'entryid ' , 'username ' , 'datestamp ' ] , mock.patch ( 'pgcli.main.click.echo_via_pager ' ) as mock_echo_via_pager , \ join ( `` Users Users2 ON Users2.PARENTID = Users.ID '' ) , POSTGRES_USER = getenv ( `` PGUSER '' , `` postgres '' ) assert set ( tables ) == set ( _logger.debug ( 'No rows in result . ' ) for line in codecs.open ( filename , 'rb ' , encoding='utf-8 ' ) : context.cli.sendline ( `` \o { 0 } '' .format ( os.path.basename ( context.tee_file_name ) ) ) ( 'blog ' , 'tags ' , 'tagid ' , 'blog ' , 'entrytags ' , 'tagid ' ) , format_array ( val ) if isinstance ( val , list ) else val 'SELECT * FROM tabl WHERE foo BETWEEN ' , cased_users_cols cur , headers , format_name= '' vertical '' , column_types=None , * * output_kwargs 'is_special ' , # True if the query is a special command `` Load your password from keyring returned : '' , click.secho ( `` Your call ! '' ) cr.execute ( 'drop database if exists % s ' , ( AsIs ( dbname ) , ) ) 'foo $ $ bar $ $ ; foo $ $ ' , expected = Completion ( 'COLUMN ' , start_position=0 , display_meta='keyword ' ) is_join = token_v.endswith ( 'join ' ) and token.is_keyword @ when ( 'we run dbcli with { arg } ' ) 'postgres instance is listening . ' , envvar='PGPORT ' , type=click.INT ) host , return ( Column ( table_refs=stmt.get_tables ( ) , 'SELECT 1 FROM tabl AS ' , 'sslmode=verify-full & sslcert=m % 79.pem & sslkey=my-key.pem & sslrootcert=c % 61.pem ' ) keywords = get_literals ( `` keywords '' ) } prev_tok assert tables == ( ( None , 'abc ' , None , False ) , ) assert `` missing required argument '' in status result = executor.view_definition ( `` vw1 '' ) `` case_column_headers '' : c [ `` main '' ] .as_bool ( `` case_column_headers '' ) , run ( executor , `` SELECT ( CAST ( '4713-01-01 BC ' AS date ) ) '' , join=True ) .split ( `` \n '' ) [ tables = extract_tables ( `` select a , from abc , def '' ) Completion ( text='MAX ' , start_position=-2 ) , or d [ 1 ] in psycopg2.extensions.FLOAT.values string = string.replace ( `` \\u '' , self.pgexecute.user or `` ( none ) '' ) 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . ' , context.cli.sendline ( `` \\refresh '' ) sql = `` SELECT * FROM ( SELECT FROM abc '' keyring.errors.InitError if has_default if not name.islower ( ) or name in ( 'select ' , 'localtimestamp ' ) : with mock.patch.object ( cli.pgspecial , 'pager_config ' , PAGER_OFF ) : 'generate_aliases ' : c [ 'main ' ] .as_bool ( 'generate_aliases ' ) , force_passwd_prompt=False , [ `` SELECT U . FROM Users U '' , `` SELECT U . FROM USERS U '' , `` SELECT U . FROM users U '' ] , context.cli.expect_exact ( `` { 0 } > `` .format ( dbname ) , timeout=15 ) Schema = namedtuple ( `` Schema '' , [ `` quoted '' ] ) Keyword ( 'SELECT ' ) WITH a AS ( SELECT abc def FROM x ) '' '' '' self.port = dsn_parameters.get ( `` port '' ) if cmd in [ `` \\n '' , `` \\ns '' , `` \\nd '' ] : @ click.option ( ' -- prompt-dsn ' , help='Prompt format for connections using DSN aliases ( Default : `` \\u @ \\h : \\d > `` ) . ' ) @ kb.add ( ' c-space ' ) start2 = len ( `` 'WITH @ pytest.mark.parametrize ( 'expression ' , [ self.change_db , print ( 'Config file ( ~/.pgclirc ) moved to new location ' , `` prompt_passwd '' , view_cols.extend ( [ self._make_col ( sch , tbl , col ) for col in cols ] ) suggestions = suggest_type ( 'SELECT ' , 'SELECT ' ) Path = namedtuple ( `` Path '' , [ ] ) completions_to_set ( [ Completion ( text= '' CREATE '' , display_meta= '' keyword '' ) ] ) 'DESCRIBE sch . ' , query = `` ' `` INSERT INTO public.orders ( `` , elif token_v in ( 'table ' , 'view ' ) : show_default=False , _logger.debug ( `` Tables Query . sql : % r '' , sql ) table_refs= ( ( None , 'abc ' , None , False ) , ) , Column ( table_refs= ( ( None , 'foo ' , None , False ) , ) ) , local_tables=stmt.local_tables ) , ) _Candidate = namedtuple ( `` Candidate '' , `` completion prio meta synonyms prio2 display '' ) fixture_dir = os.path.join ( current_dir , 'fixture_data/ ' ) c ( left.tbl ) , c ( left.col ) , rtbl.ref , c ( right.col ) , lref [ `` _title '' , `` _text '' , `` entryid '' ] , testdata.builtin_functions ( ) if prev_keyword and prev_keyword.value == `` ( `` : Document ( text=text , cursor_position=cursor_positition ) , None len ( `` SELECT * FROM Functions WHERE function : '' ) , self.logger.warning ( 'import keyring failed : % r . ' , e ) `` SELECT * FROM foo WHERE EXISTS ( `` , self.pgspecial.register ( assert b'List of databases ' in context.cmd_output Keyword = namedtuple ( 'Keyword ' , [ 'last_token ' ] ) Token.SearchMatch : 'search ' , RuntimeError , Datatype = namedtuple ( 'Datatype ' , [ 'schema ' ] ) text = 'SELECT * FROM blog.et ' timeout=1 ) 'ALTER TABLE foo ALTER COLUMN bar TYPE ' , 'SELECT foo AS bar ' , `` functions '' : [ assert set ( suggestions ) == cols_etc ( `` tabl '' , last_keyword= '' WHERE '' ) if ( self.destructive_warning ) : `` parentschema '' , for sch , datatypes in metadata [ `` datatypes '' ] .items ( ) assert executor.short_host == `` localhost '' `` INSERT INTO users ( ) SELECT * FROM orders ; '' , ( `` blog '' , `` tags '' , `` tagid '' , `` blog '' , `` entrytags '' , `` tagid '' ) , Token.Toolbar : `` bottom-toolbar '' , q = 'SELECT * FROM foo f WHERE EXISTS ( SELECT 1 FROM bar WHERE f . ' callback = functools.partial ( self._on_completions_refreshed , dbname_opt , `` INSERT INTO orders ( * '' , is_set_returning=False , obfuscate_process_password , dsn=None , extract_column_names as _extract_column_names , if self.settings [ `` case_column_headers '' ] completer , 'SELECT p. from custom.products p ' , len ( 'SELECT p . ' ) 'available databases , then exit . ' ) ( 'public ' , 'users ' , 'id ' , 'custom ' , 'shipments ' , 'user_id ' ) executor , `` select invalid command '' , exception_formatter=exception_formatter context.cli.sendline ( `` select { } '' .format ( `` , '' .join ( [ str ( n ) for n in range ( 1 , 50 ) ] ) ) ) suggestions = suggest_type ( 'SELECT tabl . FROM tabl ' , 'SELECT tabl . ' ) for col in cols ] ) context.cli.sendline ( ' x ' ) Table ( schema= ' a ' ) , [ function ( x + `` ( ) '' ) for x in ( `` func2 '' , ) ] `` SELECT U . FROM custom.users U '' , self.null_string = c [ 'main ' ] .get ( 'null_string ' , ' < null > ' ) FromClauseItem = namedtuple ( `` FromClauseItem '' , `` schema table_refs local_tables '' ) run ( executor , `` create materialized view mvw1 AS SELECT * FROM tbl1 '' ) join ( `` users users2 ON users2.id = Users.parentid '' ) , statement = u '' '' '' position = len ( '\\ ' ) assert extract_column_names ( sql ) == ( `` abc '' , `` def '' ) `` \\c [ onnect ] database_name '' , addcols ( schema , relname , tbl.alias , 'functions ' , cols ) self.socket_directory_query ) add_cond ( left.col , right.col , rtbl.ref , 2000 , `` fk join '' ) return ( Schema ( ) , Table ( schema=None ) , View ( schema=None ) ) MetaData , NamedQuery = namedtuple ( `` NamedQuery '' , [ ] ) 'INSERT INTO Orders ( * ' , return ( Column ( table_refs=tables , local_tables=stmt.local_tables , 'tables ' : { humanize.time.naturaldelta ( query.execution_time ) , sql = 'DROP SCHEMA ' completer , `` SELECT id , from custom.products '' , len ( `` SELECT id , `` ) matches.extend ( self.find_matches ( word_before_cursor , self.datatypes , if lastword == `` * '' : [ 'SELECT ' , 'PUBLIC ' ] + cased_func_names + cased_tbls + cased_views fg='red ' or ( name.upper ( ) in self.functions ) return_type='record ' , Token.SearchMatch : `` search '' , @ pytest.mark.parametrize ( 'sql ' , [ 'preprocessors ' : ( format_numbers , format_arrays ) , 'search_path_filter ' : c [ 'main ' ] .as_bool ( 'search_path_filter ' ) , tables = ( ( None , 'abc ' , None , False ) , ( None , 'def ' , None , False ) ) conn_params.update ( { k : unicode2utf8 ( v ) for k , v in new_params.items ( ) if v } ) comp = PGCompleter ( smart_completion=True , `` ) '' , 'style ' : settings.style_output text.startswith ( '\\ ' ) or # Special Command `` sep_character '' : `` - '' , self.echo_via_pager ( '\n'.join ( output ) ) sql = 'SELECT abc , 99 , def FROM xxx ' qualifiable=True , @ then ( 'we see table created ' ) `` ( `` for row in self._relations ( kinds= [ ' r ' ] ) : if keyword_casing not in ( 'upper ' , 'lower ' , 'auto ' ) : passwd= ' ] foo ' , return [ ( 'class : prompt ' , prompt ) ] sep = ' , ' + word_before_cursor [ : -1 ] dedent ( `` '\ for x in self.metadata.get ( 'views ' , { } ) .get ( parent , [ ] ) ] wrappers.expect_exact ( context , 'SELECT 1 ' , timeout=1 ) table_results = format_output ( 'Title ' , [ ( 'abc ' , 'def ' ) ] , cond = prefix + case ( lcol ) + `` = `` + rref + `` . '' + case ( rcol ) err=True , from utils import ( `` asterisk_column_order '' : c [ `` main '' ] [ `` asterisk_column_order '' ] , [ ( 'abc ' , 'def ' ) ] , `` Output equal to terminal height '' , def from_clause_items ( self , parent= '' public '' , pos=0 ) : `` `` '' ) , timeout=5 ) 'ALTER TABLE foo ALTER ' , @ pytest.mark.parametrize ( 'command ' , [ 'di ' , 'dv ' , 'ds ' , 'df ' , 'dT ' ] ) and word_before_cursor [ -len ( lastword ) - 1 ] == ' . ' ) : assert completions [ 0 ] .text == `` VIEW '' [ alias ( 'users ' ) , alias ( 'orders ' ) ] ) return_type='integer ' , context.conf [ 'dbname_tmp ' ] ) ) join , keywords = ( `` drop '' , `` shutdown '' , `` delete '' , `` truncate '' , `` alter '' ) `` SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = `` , `` pgspecial > =1.11.5 '' , text = 'create v ' `` SELECT Users . * FROM Users '' , elif token_v in { 'alter ' , 'create ' , 'drop ' } : text_before_cursor = full_text [ cte.start : current_position ] auto_vertical_output=False , warn=None ) : self.find_matches ( 'shipments ' : [ 'id ' , 'address ' , 'user_id ' ] @ pytest.mark.parametrize ( 'text ' , ( if self._must_raise ( e ) or not exception_formatter : t2.id = t3 . '' '' '' [ `` head1 '' , `` head2 '' ] , query.total_time , sort_key , or ( name.upper ( ) in self.reserved_words ) with mock.patch.object ( cli.pgspecial , `` pager_config '' , PAGER_LONG_OUTPUT ) : @ when ( 'we create table ' ) Path = namedtuple ( 'Path ' , [ ] ) kwargs.setdefault ( 'application_name ' , 'pgcli ' ) result.append ( ( `` class : bottom-toolbar '' , `` `` ) ) 'SELECT users.id , users . from users u ' , 'INSERT INTO OtherTabl ( ID , Name ) SELECT * FROM tabl WHERE ' , aliased_rels string = string.replace ( '\\dsn_alias ' , self.dsn_alias or `` ) 'nested_numeric_array | < null > ' , 'psycopg2 > = 2.7.4 , < 2.8 ' , return ( Schema ( ) , Function ( schema=None , usage='special ' ) , ) join ( ' '' Users '' ON `` Users '' .userid = Users.id ' ) , `` SELECT foo AS bar `` , == `` | 00:00:00 | '' click.secho ( `` Wise choice ! '' ) INNER JOIN users u3 ON u2.id = u3 . ' '' if prev in ( 'drop ' , 'alter ' , 'create ' , 'create or replace ' ) : reason='Postgres server unavailable or jsonb type not defined ' ) ( `` y '' , ( `` ghi '' , `` jkl '' ) , start2 , stop2 ) , @ parametrize ( 'completer ' , completers ( casing=False , aliasing=True ) ) testdata.columns ( `` Users '' , `` custom '' ) ForeignKey = namedtuple ( `` port '' : port , Special , require_last_table=True , matches = self.find_matches ( word_before_cursor , types , meta='datatype ' ) maybe_alias = ( `` `` + alias ) if do_alias else `` '' arg_modes= [ 't ' , 't ' ] , named_query_regex = re.compile ( r'^\s * \\ns\s+ [ A-z0-9\-_ ] +\s+ ' ) tables = extract_tables ( `` SELECT * FROM foo.bar ( { 0 } ) '' .format ( arg_list ) ) if cmd == `` \\dn '' : click.secho ( `` Reconnected ! `` , fg= '' green '' ) assert u '' Command '' in result [ 1 ] formatted = '\n'.join ( formatted ) ( `` =\u001b [ m= '' , 2 ) , ] + [ view ( 'user_emails ue ' ) , view ( 'functions f ' ) ] + [ Alias ( aliases= ( 'abc ' , 'bcd ' , ) ) , ) ) not JSON_AVAILABLE , reason= '' Postgres server unavailable or json type not defined '' @ pytest.mark.parametrize ( 'verbose ' , [ `` , '+ ' ] ) orders = table ( 'orders ' ) single_connection , assert column ( `` id '' ) in result JOIN `` '' '' , `` SELECT * FROM Custom.set_returning_func ( ) '' , `` `` , vi = `` _ '' .join ( [ str ( x ) for x in sys.version_info [ :3 ] ] ) self.completion_refresher.refresh ( self.pgexecute , self.pgspecial , local_tables= ( ) , ( 'SELECT users . * FROM users ' , assert set ( executor.table_columns ( ) ) > = set ( 'password ' : new_params [ 'password ' ] context.package_root , `` .coveragerc '' _SchemaObject = namedtuple ( 'SchemaObject ' , 'name schema meta ' ) arg_default = arg_default_type_strip_regex.sub ( `` '' , arg_default ) schema_name , fixture_dir = os.path.join ( current_dir , `` fixture_data/ '' ) assert set ( tables ) == set ( [ ( None , `` foo '' , None , False ) , ( None , `` bar '' , None , True ) ] ) show_default=False , type=str ) message = `` \\i : missing required argument '' 'INSERT INTO users SELECT * FROM users u ' , name_join = partial ( completion , `` name join '' ) print ( boundary ) FromClauseItem ( schema=None ) , schema ( 'PUBLIC ' ) , result = get_result ( completer , `` SELECT users . from users '' , len ( `` SELECT users . '' ) ) wrappers.expect_exact ( 'keyword ' , 'function ' , 'view ' , 'table ' , 'datatype ' , 'database ' , _logger.debug ( `` Detected F3 key . '' ) assert set ( suggestion ) == set ( [ or ( name.upper ( ) in self.reserved_words ) ] , def _columns ( self , kinds= ( `` r '' , `` v '' , `` m '' ) ) : 'Custom ' : { ORDER BY 1 `` '' '' `` Title '' , % ( self.pgexecute.dbname , self.pgexecute.user , host , self.pgexecute.port ) , `` SELECT U . FROM custom.USERS U '' , Completion ( text= '' TABLE '' , display_meta= '' keyword '' ) , fallback = `` SELECT * FROM current_schemas ( true ) '' @ when ( 'we list databases ' ) for f in ( `` Custom_Fun ( ) '' , `` _custom_fun ( ) '' , `` Custom_Func1 ( ) '' , `` custom_func2 ( ) '' ) @ parametrize ( 'text ' , join_condition_texts ) return self.find_matches ( word_before_cursor , aliases , `` pgcli.main.cli ( ) '' ] ) ) ) , assert extract_column_names ( sql ) == ( ' x ' , ' y ' ) texts = [ `` SELECT * FROM `` , `` SELECT * FROM public.Orders O CROSS JOIN `` ] `` entries '' : [ `` entryid '' , `` entrytitle '' , `` entrytext '' ] , if cmd == '\\T ' : ' '' create function func2 ( int , varchar ) 'host ' : context.config.userdata.get ( for line in codecs.open ( filename , `` rb '' , encoding= '' utf-8 '' ) : for func_meta in funcs ] wrappers.expect_pager ( context , `` UPDATE 1\r\n '' , timeout=2 ) context.currentdb = currentdb or context.conf [ 'dbname ' ] table , schema=None , alias=None , is_function=False , parent=None , last_keyword=None '_custom_fun ( ) cf ' , 'custom_fun ( ) cf ' , 'custom_func1 ( ) cf ' , `` SELECT * FROM tabl WHERE ( `` , `` INSERT INTO Orders ( * ) '' , host='baz1.com , baz2.com , baz3.com ' , 'Send all query results to file . ' ) lexical_priority = ( tuple ( 0 if c in ( ' _ ' ) else -ord ( c ) if new_params [ 'dsn ' ] : casing = 'lower ' root_logger.debug ( `` Log file % r . `` , log_file ) schema=schema , table_refs=tables , local_tables=stmt.local_tables context.cli.sendline ( `` drop table a ; '' ) function ( `` custom_func2 ( ) cf '' ) , fk_join = partial ( completion , `` fk join '' ) `` Topic : : Software Development '' , extract_ctes , self.name if self.name.islower ( ) or self.name [ 0 ] == ' '' ' run ( executor , 'create type foo AS ( a int , b text ) ' ) `` Users '' : [ `` userid '' , `` username '' ] , ( ( '\\ns abc SELECT ' , 'SELECT ' , [ tables = self.populate_schema_objects ( suggestion.schema , `` tables '' ) for sch , funcs in metadata [ `` functions '' ] .items ( ) 'PGDATABASE ' : os.environ.get ( 'PGDATABASE ' , None ) , extras_require= { 'INSERT INTO abc ( ' , assert set ( suggestions ) == set ( [ ' '' , `` pg_test_host '' , os.getenv ( `` PGHOST '' , `` localhost '' ) Column ( table_refs= ( ) , local_tables= ( ) , qualifiable=True ) , `` custom_func2 ( ) cf '' , @ parametrize ( ( 'text ' , 'ref ' ) , [ alias = partial ( completion , 'table alias ' ) mutated , ( 'auto ' , 'select ' , ( 's ' , 'sel ' , 'SEl ' ) ) , 'SELECT * FROM Custom.set_returning_func ( ) ' , return `` % s/pgcli/ '' % expanduser ( os.environ [ `` XDG_CONFIG_HOME '' ] ) return `` .join ( [ l for l in tbl if l.isupper ( ) ] or `` text '' , [ `` INSERT INTO abc ( `` , `` INSERT INTO abc ( ) SELECT * FROM hij ; '' ] [ alias ( `` users '' ) , alias ( `` orders '' ) ] wrappers.expect_pager ( context , `` foo : Deleted\r\n '' , timeout=1 ) new_params = { `` dsn '' : new_params [ `` dsn '' ] , `` password '' : new_params [ `` password '' ] } Function ( schema= '' f '' ) , tables = extract_tables ( 'SELECT * FROM foo ( { 0 } ) bar'.format ( arg_list ) ) ( schema , relname , colname ) = self.escaped_names ( [ schema , relname , colname ] ) cased_schemas elif p.token_first ( ) .value.lower ( ) == `` select '' : `` ; ; ; $ $ '' , `` custom '' : [ assert set ( suggestions ) == set ( [ Column ( table_refs= ( ( None , `` foo '' , None , False ) , ) ) ] ) col_list = `` id , p.product_name , p.price '' } help= '' Print out , but not actually run any steps . `` , View = namedtuple ( `` View '' , [ `` schema '' , `` table_refs '' ] ) completer , 'SELECT et FROM blog.Entries E ' , len ( 'SELECT et ' ) tables = extract_tables ( `` select a , b from abc.def , def.ghi '' ) result = list ( executor.run ( sql , on_error_resume=True , os.getenv ( 'PGHOST ' , 'localhost ' ) if not click.confirm ( `` -- - { } '' .format ( question ) , default=False ) : names = [ `` foo '' , `` bar '' , `` baz '' ] `` INSERT INTO public.orders ( * '' , alias ( `` u2 '' ) , self.echo_via_pager ( `` \n '' .join ( output ) ) ( None , `` t1 '' , None , False ) , arg_defaults , Completion ( text= '' SYSTEM '' , display_meta= '' keyword '' ) , settings=settings , pgspecial=PGSpecial ( ) ) [ 'enter_entry ' , [ '_title ' , '_text ' , 'entryid ' ] , 'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) : ,\s ] + ) $ ' ) , root_logger.debug ( 'Log file % r . ' , log_file ) remainder = `` '' .join ( str ( tok ) for tok in p.tokens [ idx : ] ) assert tuple ( ctes ) == ( ( `` a '' , ( `` abc '' , ) , start_pos , stop_pos ) , ) rowcount=DEFAULT + 10 assert u '' fooé '' in result [ 3 ] position = len ( `` SELECT * '' ) `` SELECT 2 '' , suggestions = suggest_type ( '\\ ' , '\\ ' ) 'Change to a new database . ' , aliases= ( 'use ' , '\\connect ' , 'USE ' ) ) casing = `` upper '' @ when ( 'we refresh completions ' ) _logger.debug ( 'Detected < C-Space > key . ' ) user='bar ' , pgcli.logger.debug ( 'Launch Params : \n ' join , prio , dedent ( string = string.replace ( @ parametrize ( 'completer ' , completers ( aliasing=True , casing=False , filtr=True ) ) Table ( schema=parent ) , table ( 'users u ' ) , Column ( table_refs= ( ( None , `` def '' , `` d '' , False ) , ) ) , timeout=5 text = `` ' assert kw.value == ' ( ' and q2 == 'select * from tbl1 inner join tbl2 using ( ' os.environ [ 'PGDATABASE ' ] = context.conf [ 'dbname ' ] `` `` , `` table alias '' , `` call_arg_display_style '' , `` { arg_name } '' sql = `` 'WITH return ( Schema ( ) , Function ( schema=None , usage= '' special '' ) ) schema_name= '' public '' , click.secho ( str ( e ) , err=True , fg='red ' ) Match = namedtuple ( `` Match '' , [ `` completion '' , `` priority '' ] ) BY baz '' '' '' os.environ [ 'PAGER ' ] = `` { 0 } { 1 } { 2 } '' .format ( with patch.object ( refresher , '_bg_refresh ' ) as bg_refresh : 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id AND ' , if full_text.startswith ( '\\i ' ) : suggest_type , Special , Database , Schema , Table , Column , View , Keyword , 'SELECT * FROM public . `` Users '' JOIN ' , for expected_line in context.fixture_data [ `` help_commands.txt '' ] : `` $ $ foo $ a $ '' , result = get_result ( completer , 'SELECT MA ' ) if log_level.upper ( ) == 'NONE ' : POSTGRES_HOST = getenv ( 'PGHOST ' , 'localhost ' ) 'SELECT * FROM `` sch '' . `` ' , 'pgspecial > =1.11.5 ' , `` INSERT INTO orders ( * ) '' , 'SELECT * FROM public . `` Users '' JOIN ' , if t.value == ' ( ' or ( t.is_keyword and ( tables = extract_tables ( 'select a , b from abc.def , def.ghi ' ) result_set , context.cli.sendline ( `` \\nd foo '' ) `` foo $ $ bar $ $ ; foo $ $ '' , `` cli_command '' : ( cur.execute ( `` '' '' CREATE DATABASE _test_db '' '' '' ) functions = get_literals ( `` functions '' ) 'custom ' : { func_name='func3 ' , for fk in rcol.foreignkeys Schema ( ) `` import coverage '' , view ( `` functions f '' ) , expected = [ wildcard_expansion ( 'ordered_date , status ' ) ] `` select * from a ; select from b ; select * from c '' , `` select * from a ; select `` tables = extract_tables ( 'select * from abc.def , ghi.jkl ' ) style_output=self.style_output , assert result == completions_to_set ( [ Completion ( text= '' SELECT '' , start_position=-3 ) ] ) run ( executor , `` 'create function func4 ( x int ) returns setof int language sql ( 'def ' , 'ghi ' , None , False ) ] ) if ( prev_tok and prev_tok.value `` public '' : [ 'INSERT INTO Orders SELECT from users ' , suggestions = suggest_type ( `` TRUNCATE sch . `` , `` TRUNCATE sch . '' ) TableFormat = namedtuple ( `` TableFormat '' , [ ] ) @ when ( 'we connect to dbserver ' ) if hasattr ( context , 'tmpfile_sql_help ' ) and context.tmpfile_sql_help : context.cli.sendline ( 'drop database { 0 } ; '.format ( 'XDG_CONFIG_HOME ' : os.environ.get ( 'XDG_CONFIG_HOME ' , None ) , ( 10 , 10 , `` - '' * 9 ) , assert set ( suggestions ) == cols_etc ( text = `` '' prio2 , lexical_priority if __name__ == `` __main__ '' : `` pgcli.main.cli ( ) '' , _logger.debug ( 'pgcli magic called : % r ' , line ) pgexecute=executor , fixture_dir , 'mock_pg_service.conf ' ) settings=None ) : err=True , fg='red ' ) ( `` blog '' , `` entries '' , `` entryid '' , `` blog '' , `` entacclog '' , `` entryid '' ) , 'Default pager found in config file : `` { } '' '.format ( configured_pager ) comp.extend_columns ( view_cols , kind='views ' ) cfg [ `` settings '' ] [ `` qualify_columns '' ] = qualify completer , 'SELECT id , from users u ' , len ( 'SELECT id , ' ) `` $ $ foo $ $ '' , `` -- port '' , with open ( casing_file , `` w '' ) as f : click.secho ( str ( e ) , err=True , fg= '' red '' ) display_suffix = self._arg_list_cache [ `` call_display '' ] [ tbl.meta ] `` \\p '' , Token.Menu.Completions.MultiColumnMeta : `` completion-menu.multi-column-meta '' , 'SELECT * FROM foo where created > now ( ) - ' , self.casing_file = settings.get ( 'casing_file ' ) suggestions = suggest_type ( '\\df myschema.xxx ' , '\\df myschema.xxx ' ) display_suffix = self._arg_list_cache [ `` signature '' ] [ tbl.meta ] entry_points= '' '' '' `` SELECT t1.a , t2 . FROM tabl1 t1 , tabl2 t2 '' , `` SELECT t1.a , t2 . '' q = `` select * from tbl1 inner join tbl2 using ( col1 , `` tempfile_suffix= '' .sql '' , `` Output shorter than terminal height '' , ORDER BY 1 '' '' '' ( `` query '' , `` tbl '' ) , function ( 'Func1 ( ) F ' ) , [ l for l in tbl if l.isupper ( ) ] 'signature ' : 'signature ' , warnings.filterwarnings ( `` ignore '' , category=UserWarning , module= '' psycopg2 '' ) testdata.keywords ( ) + testdata.specials ( ) @ kb.add ( 'enter ' , filter=completion_is_selected ) cfg [ 'settings ' ] [ 'qualify_columns ' ] = qualify [ FromClauseItem ( schema=None , table_refs=tables ) , Join ( tables , None ) , Schema ( ) ] ) ] output_kwargs [ `` preprocessors '' ] = ( align_decimals , ) 'COPY ' , assert executor.short_host == `` localhost1 '' `` pg_test_port '' , os.getenv ( `` PGPORT '' , `` 5432 '' ) self.float_format = c [ `` data_formats '' ] [ `` float '' ] 'ALTER TABLE foo DROP COLUMN bar ' , ( not self.name_pattern.match ( name ) ) `` vi '' : vi , raise RuntimeError ( 'View { } does not exist . '.format ( spec ) ) `` -- row-limit '' , TableReference ( None , `` tbl '' , `` x '' , False ) , col_list = 'id , u.parentid , u.email , u.first_name , u.last_name ' result = run ( executor , '\\ ? ' , pgspecial=pgspecial ) [ 1 ] .split ( '| ' ) @ when ( u'we run query to check application_name ' ) if casing == 'upper ' : position = len ( `` SELECT p. * '' ) @ refresher ( 'views ' ) user= '' bar^ '' , meta='table alias ' ) functions = meta [ 'functions ' ] .get ( schema , { } ) .get ( relname ) prompt , ( 'SELECT * FROM users JOIN NonTable on ' , 'NonTable ' ) , sql = `` SELECT * FROM xxx '' view ( `` Functions F '' ) , [ conn.set_client_encoding ( `` utf8 '' ) self.style_output = style_factory_output ( cfg [ 'settings ' ] [ 'generate_aliases ' ] = aliasing return [ ( None , None , None , str ( e ) , `` '' , False , True ) ] result = list ( cased_views = [ `` User_Emails '' , `` Functions '' ] new_params [ 'dsn ' ] , password=new_params.pop ( 'password ' ) ) ( 'public ' , ' a ' , ' y ' , 'text ' , False , None ) , 'select ' ) 'Programming Language : : SQL ' , no_qual , text = `` .join ( tok.value for tok in flattened [ : idx+1 ] ) ' '' 'public ' : [ 'typ1 ' , 'typ2 ' ] , Table ( schema=None ) , 'SELECT * FROM foo JOIN sch . ' , result = executor.view_definition ( 'mvw1 ' ) assert result [ 0 ] == table ( `` EntryTags ET '' , -2 ) context.cli.sendline ( `` 'delete from a where x = 'yyy ' ; ' '' ) context.cli.sendline ( '\e { 0 } '.format ( sql = 'SELECT 99 abc FROM xxx ' auto_vertical_output , 'qualify_columns ' : c [ 'main ' ] [ 'qualify_columns ' ] , schema ( `` PUBLIC '' ) , Completion ( text='MAXEXTENTS ' , start_position=-2 ) ] ) full_text , text_before_cursor , parsed = _split_multiple_statements ( hide_input=True , show_default=False , suggestions = suggest_type ( `` \\dn xxx '' , `` \\dn xxx '' ) c ( left.tbl ) , c ( left.col ) , rtbl.ref , c ( right.col ) , lref ) @ then ( 'dbcli exits ' ) position = len ( 'SELECT users . * ' ) 'Changed table format to { } '.format ( pattern ) ) return_type= '' integer '' , never_passwd_prompt=False , 'INSERT INTO Orders ( * ) ' , @ refresher ( 'casing ' ) ( 'class : bottom-toolbar.transaction.valid ' , ' Transaction ' ) ) def functions ( self , parent= '' public '' , pos=0 ) : [ FromClauseItem ( schema= '' sch '' , table_refs=tbls ) , Join ( tbls , `` sch '' ) ] stop_pos = len ( `` ' -- blah blah blah if context.conf [ 'pass ' ] : ( `` auto '' , `` SELECT '' , ( `` '' , `` S '' , `` SEL '' , `` seL '' ) ) , assert set ( suggestions ) == cols_etc ( `` b '' , last_keyword= '' SELECT '' ) result = get_result ( completer , `` \\t '' ) DROP SCHEMA IF EXISTS schema2 CASCADE '' '' '' assert result [ 0 ] == table ( 'Entries E ' , -1 ) def types ( self , parent= '' public '' , pos=0 ) : table_format = ( 'vertical ' if settings.expanded else raise RuntimeError ( `` Function { } does not exist . `` .format ( spec ) ) fk_join , persist_priorities=persist_priorities ) [ metadata = self.dbmetadata [ `` tables '' ] self.text_before_cursor , n_skip=n_skip def cli ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , max_width=100 ) schema_names = [ s self.logger.debug ( 'Database connection failed : % r . ' , e ) run ( executor , 'create table tbl1 ( a text , b numeric ) ' ) matches = sorted ( matches , key=operator.attrgetter ( `` priority '' ) , reverse=True ) click.secho ( 'Invalid DSNs found in the config file . ' @ then ( 'we see table dropped ' ) 'SELECT u . * FROM users u ' , [ FromClauseItem ( schema=None , table_refs=tbls ) , Schema ( ) ] context.cli.sendline ( ' y ' ) text_before_cursor , include= '' many_punctuations '' return status.split ( None , 1 ) [ 0 ] .lower ( ) == 'select ' context.cli.sendline ( '\\connect { 0 } '.format ( db_name ) ) '| abc | def | ' , over_default_cursor.configure_mock ( Token.Toolbar.Arg.Text : `` arg-toolbar.text '' , `` import pgcli.main '' , context.tmpfile_sql_help.write ( b '' \ ? '' ) JOIN custom.shipments ON `` ' print ( `` Goodbye ! '' ) ) ] suggestions = suggest_type ( `` SELECT FROM tabl '' , `` SELECT `` ) `` SELECT * FROM abc a JOIN def d ON a.id = d.id AND a . `` , TableReference.ref = property ( lambda self : self.alias or ( text = `` SET SCHEMA `` 'foo bar $ $ baz $ $ ' , result = get_result ( completer , `` SELECT from users '' , len ( `` SELECT `` ) ) View ( schema= ' a ' ) , new_type = psycopg2.extensions.new_type ( oids , `` DATE '' , cast_date ) [ `` func2 '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , regex = '. * ? '.join ( map ( re.escape , text ) ) [ result = list ( executor.run ( sql , on_error_resume=False , `` entacclog '' : [ `` entryid '' , `` username '' , `` datestamp '' ] , 'execution_time ' , # Time elapsed executing the query JOIN custom.shipments ON `` '' '' , [ dbname , logger.debug ( 'sql : % r ' , text ) `` pass '' : context.config.userdata.get ( completer , `` SELECT E.ei FROM blog.Entries E '' , len ( `` SELECT E.ei '' ) if d [ 1 ] in psycopg2.extensions.DECIMAL.values or \ datatypes = get_literals ( `` datatypes '' ) ( 'class : bottom-toolbar ' , ' ( [ Esc ] [ Enter ] to execute ] ) ' ) ) meta=meta `` select * from ; select * from `` , `` select * from ; select * from `` string = string.replace ( '\\d ' , self.pgexecute.dbname or ' ( none ) ' ) if last_word ( stmt.text_before_cursor , if mode in ( ' o ' , ' b ' , 't ' ) ] # OUT , INOUT , TABLE stop2 = len ( `` 'WITH line-length = 88 `` SELECT * FROM users '' , 'create table foo ( bar int , baz ' , allow_functions=not insert_stmt ) def test_wildcard_column_expansion_with_table_qualifier ( completer , text , expected ) : named_query_regex = re.compile ( r '' ^\s * \\ns\s+ [ A-z0-9\-_ ] +\s+ '' ) sql = `` SELECT * FROM abc a { 0 } JOIN def d ON a.id = d.num '' .format ( join_type ) port=None , dsn=None , * * kwargs ) : if arg == `` -- user '' : tables = extract_tables ( 'SELECT * FROM foo JOIN bar ( ) ' ) context , 'Entering Ex mode . Type `` visual '' to go to Normal mode . ' , timeout=2 ) def create_db ( result = get_result ( completer , 'SELECT from users ' , len ( 'SELECT ' ) ) self.vi_mode = c [ `` main '' ] .as_bool ( `` vi '' ) cased_tbls = [ 'Users ' , 'Orders ' ] from .config import ( cursor.execute ( 'SELECT NULL : :timestamp with time zone ' ) elif token_v in ( `` type '' , `` : : '' ) : InputMode.NAVIGATION : `` N '' , @ pytest.mark.parametrize ( 'value ' , [ '10000000 ' , '10000000.0 ' , '10000000000000 ' ] ) `` -- prompt-dsn '' , 'SELECT * FROM `` sch '' . `` ' , childcolmeta = meta [ childschema ] [ childtable ] [ childcol ] @ when ( 'we connect to test database ' ) ( 'auto ' , 'SELECT ' , ( `` , 'S ' , 'SEL ' , 'seL ' ) ) , self.execute_from_file , `` \\i '' , `` \\i filename '' , `` Execute commands from file . '' return self.find_matches ( word_before_cursor , aliases , meta= '' table alias '' ) message = `` File output disabled '' len ( `` WITH cte AS ( SELECT foo , bar FROM baz ) SELECT `` ) , JoinCondition ( table_refs=tables , parent= ( None , 'abc ' , ' a ' , False ) ) View ( schema=None ) , ) from pgspecial.main import ( PAGER_OFF , PAGER_LONG_OUTPUT , PAGER_ALWAYS ) result = executor.view_definition ( `` there_is_no_such_function '' ) ( 1 , ) aliases= ( `` use '' , `` \\connect '' , `` USE '' ) , arg = `` -- user= { } '' .format ( context.conf [ `` user '' ] ) @ parametrize ( 'table ' , [ 'users ' , ' '' users '' ' ] ) `` select t.oid FROM pg_type t WHERE t.typname = 'hstore ' and t.typisdefined '' db_changed , 'blog ' : [ @ when ( 'we execute a small query ' ) os.environ [ `` PGSERVICEFILE '' ] = os.path.join ( fixture_dir , `` mock_pg_service.conf '' ) position = text.find ( ' ( ' ) + 1 testdata.schemas_and_from_clause_items ( ) + [ if prev in ( `` drop '' , `` alter '' , `` create '' , `` create or replace '' ) : sql = 'SELECT * FROM \nxxx ' default=False , `` ALTER TABLE foo ALTER COLUMN bar TYPE custom . `` , if ' , ' in self.host : assert suggest_type ( sql , sql ) == ( Schema ( ) , ) elif persist_priorities == 'none ' : textwrap.dedent ( `` '\ @ click.option ( '-w ' , ' -- no-password ' , 'never_prompt ' , is_flag=True , if cmd == `` \\T '' : View ( schema= '' t1 '' ) , run ( executor_copy , `` 'insert into test values ( 'abc ' ) ' '' ) | \.tox 'select ' : [ 'id ' , 'localtime ' , 'ABC ' ] assert set ( suggestions ) == set ( [ Special ( ) ] ) reason='Postgres server unavailable or json type not defined ' ) use_pager_when_on = [ True , position = len ( `` SELECT `` ) keyword ( `` MAXEXTENTS '' , -2 ) , assert set ( suggestions ) == set ( [ Schema ( ) , Datatype ( schema=None ) ] ) parcolmeta = meta [ parentschema ] [ parenttable ] [ parcol ] `` Set password in keyring returned : '' , str ( e ) function ( 'custom_func2 ( ) cf ' ) , or d [ 1 ] in psycopg2.extensions.LONGINTEGER.values views = [ v for v in views if not v.name.startswith ( 'pg_ ' ) ] text = `` SELECT * FROM abc { 0 } { 1 } JOIN `` .format ( tbl_alias , join_type ) @ parametrize ( 'completer ' , completers ( casing=False , qualify=no_qual ) ) 'ERROR ' : logging.ERROR , self.null_string = c [ `` main '' ] .get ( `` null_string '' , `` < null > '' ) self , statement , pgspecial=None , exception_formatter=None , on_error_resume=False function ( `` custom_func1 ( ) cf '' ) , _logger.debug ( `` Detected < Esc > key . '' ) `` \n '' collection = [ `` user_action '' , ' '' user '' ' ] cols = [ column ( `` U . '' + c.lower ( ) ) for c in cased_users_col_names ] 'CREATE FUNCTION foo ( bar ' , new_type = psycopg2.extensions.new_type ( oids , 'DATE ' , cast_date ) re.compile ( pattern ) for pattern in settings.get ( `` `` '' WITH `` click > = 4.1 '' , self.min_num_menu_lines = c [ `` main '' ] .as_int ( `` min_num_menu_lines '' ) if prev_tok == 'exists ' : [ table ( x ) for x in ( 'Orders ' , ' '' select '' ' , 'CUSTOM.shipments ' ) ] @ pytest.mark.parametrize ( 'text ' , functions ) sql = 'SELECT * FROM sessions WHERE session = 1 AND ' return ipython.run_cell_magic ( 'sql ' , line , q.query ) 'users ' , 'custom ' _split_multiple_statements ( full_text , text_before_cursor , parsed ) cased_views = [ 'User_Emails ' , 'Functions ' ] 'SELECT ( x + y ) : : ' , return ( [ ] , `` '' ) or [ l for l , prev in zip ( tbl , `` _ '' + tbl ) if prev == `` _ '' and l ! = `` _ '' ] row_limit=row_limit , single_connection=single_connection , as $ $ select generate_series ( 1,5 ) $ $ ; ' '' ) `` user '' : user , [ tool.black ] table ( `` Entries '' , -1 ) , hide_input=True , 'user ' : user , context.cli.sendcontrol ( `` c '' ) mock_connect.assert_called_with ( 'Programming Language : : Python : : 3.7 ' , alias ( `` users '' ) , assert set ( suggestions ) == set ( return ( escape ( x [ 0 ] ) suggestions = suggest_type ( 'select * from a ; select from b ; select * from c ' , context.conf [ `` pass '' ] , 'select * from foo where bar = 1 and baz between qux and ' , context.cli.sendline ( `` '' '' delete from a where x = 'yyy ' ; '' '' '' ) not f.is_window and assert `` _test_db '' in databases click.secho ( 'Wise choice ! ' ) function ( 'func3 ( ) ' , -len ( 'func ' ) ) , position = text.find ( `` ( `` ) + 1 alias ( 'u2 ' ) , if which == `` expanded '' : `` -d '' , `` -- dry-run '' , action= '' store_true '' , dest= '' dry_run '' , display or completion col_list = `` x '' `` Topic : : Database : : Front-Ends '' , `` SELECT users . * FROM users '' , 'SELECT U . FROM Users U ' , Function ( schema= '' t2 '' ) , return self.find_matches ( word_before_cursor , conds , meta='join ' ) self.views ( parent , pos ) language sql as $ $ select 1 $ $ '' '' '' , termsize = namedtuple ( 'termsize ' , [ 'rows ' , 'columns ' ] ) isolate_query_ctes ( full_text , text_before_cursor ) cfg = { `` settings '' : { } } Join ( ( ( None , `` foo '' , None , False ) , ) , None ) , FROM f '' '' '' return [ ( `` class : continuation '' , continuation ) ] multiline = usage == `` call '' and len ( args ) > self.call_arg_oneliner_max cased_aliased_rels = ( context.cli.sendline ( `` select * from abc '' ) testdata.columns_functions_and_keywords ( `` users '' , `` custom '' ) list_dsn , comp.extend_relations ( views , kind='views ' ) function ( `` Custom_Fun ( ) CF '' ) , case_sensitive=True , Column ( table_refs=tables , local_tables=stmt.local_tables ) , alias ( `` y '' ) , `` Custom '' : { `` projects '' : [ `` projectid '' , `` name '' ] } , name , datatype , foreignkeys or [ ] , default , has_default expect_exact ( context , `` { 0 } \r\n { 1 } { 0 } \r\n '' .format ( smart_completion=True ) ) 'SELECT * FROM users ' , tables = stmt.get_tables ( 'before ' ) yield ( None , None , None , 'You are connected to database `` % s '' as user ' _logger.debug ( 'View Definition Query . sql : % r\nspec : % r ' , return not click.confirm ( `` -- - Run this step ? `` , default=True ) keywords = [ 'SELECT ' , 'FROM ' , 'GROUP BY ' ] 'INSERT INTO orders ( * ' , sugs = [ Column ( table_refs=filteredtables , click.secho ( alias + `` : `` + cfg [ 'alias_dsn ' ] [ alias ] ) pgexecute = PGExecute ( and not f.is_extension 'table format ' text = `` SELECT * FROM blog.Entries JOIN blog.e '' return len ( COLOR_CODE_REGEX.sub ( `` , line ) ) > self.prompt_app.output.get_size ( ) .columns self.is_window , self.is_set_returning , self.is_extension , self.arg_defaults context.config.userdata.get ( 'pg_cli_command ' , None ) or 'float_format ' : settings.floatfmt , reason= '' Need a postgres instance at localhost accessible by user 'postgres ' '' ) return self.find_matches ( word_before_cursor , self.databases , meta= '' database '' ) application_name='cow ' ) ) None ) except ( 'dt ' : Table , db_name = context.conf [ 'dbname ' ] user=POSTGRES_USER , _logger.debug ( `` Search path query . sql : % r '' , self.search_path_query ) help= '' Username to connect to the postgres database . `` , InputMode.REPLACE : `` R '' , ( None , 'Def ' , None , False ) ] ) function ( 'func1 ( ) f ' ) , port=None , dsn=None , * * kwargs ) : schema , aliases= ( `` exit '' , ) , mode='strict ' ) `` coverage.process_startup ( ) '' , Token.Output.EvenRow : `` output.even-row '' , `` SELECT * FROM tabl WHERE col_n '' , `` SELECT * FROM tabl WHERE col_n '' if self.destructive_warning and confirm_destructive_query ( query ) is False : 'user `` % s '' ' % ( self.pgexecute.dbname , self.pgexecute.user ) , completer.extend_relations ( executor.views ( ) , kind= '' views '' ) 'SELECT U . FROM `` custom '' .Users U ' , 'SELECT * FROM foo WHERE EXISTS ( S ' , 'SELECT * FROM tabl WHERE foo IN ( ' , format_array ( val ) if isinstance ( val , list ) else val for val in row string = string.replace ( `` \\n '' , `` \n '' ) Function ( schema= '' t '' ) , commit_for_release ( 'pgcli/__init__.py ' , ver ) `` `` '' , `` custom '' : [ ( `` public '' , `` users '' , `` id '' , `` custom '' , `` shipments '' , `` user_id '' ) ] , click.secho ( 'Reconnect Failed ' , fg='red ' ) ensure_dir_exists , [ `` x '' ] , from cli_helpers.tabular_output.preprocessors import align_decimals , format_numbers @ pytest.mark.skipif ( not setproctitle , function ( 'Custom_Func1 ( ) CF ' ) , Column ( table_refs= ( ( None , 'foo ' , ' f ' , False ) , ) ) , text.endswith ( r'\e ' ) or # Ended with \e which should launch the editor ( JoinCondition ( table_refs=tables , parent=None ) , Alias ( aliases= ( `` abc '' , `` bcd '' ) ) ) assert '123456 ' in f.read ( ) suggestions = suggest_type ( text , `` INSERT INTO abc ( `` ) elif token_v in ( 'type ' , ' : : ' ) : `` name join '' , ORDER BY 1,2 ; '' '' '' `` custom_func2 '' , table ( 'orders o ' if text == 'SELECT * FROM ' else 'orders o2 ' ) , assert actual [ 0 ] [ 3 ] == 'Auto-completion refresh started in the background . ' return id == ref.alias or id == ref.name or ( self._make_cand ( f , alias , suggestion , arg_mode ) smart_completion = c [ 'main ' ] .as_bool ( 'smart_completion ' ) 0 if c in ( `` _ '' ) else -ord ( c ) sql , message = special.open_external_editor ( filename , sql=query ) function ( `` _custom_fun ( ) cf '' ) , is_aggregate=False , local_tables=stmt.local_tables , qualifiable=True ) , ) expected , 'Please check the `` [ alias_dsn ] '' section in pgclirc . ' , `` Custom_Func1 ( ) CF '' , Column ( table_refs= ( ( None , `` tabl '' , None , False ) , ) ) , result = get_result ( completer , `` SELECT MAX ( from users '' , len ( `` SELECT MAX ( `` ) ) < ! -- We would appreciate if you comply with our code style guidelines . -- > 'Change the table format used to output results ' ) `` tags '' : [ `` tagid '' , `` name '' ] , [ `` integer '' , `` text '' ] , checks = [ assert suggestions == ( Keyword ( ) , ) f.is_public or f.schema_name == suggestion.schema `` CREATE TABLE foo ( bar `` , `` SELECT * FROM foo JOIN bar USING ( barid ) JOIN `` , text , 'views ' : { tbl = TableReference ( schema , rel , alias , reltype == 'functions ' ) Completion ( text= '' DATABASE '' , display_meta= '' keyword '' ) , text_before_cursor = text_before_cursor [ : -len ( word_before_cursor ) ] self.auto_expand = auto_vertical_output or c [ 'main ' ] .as_bool ( Completion ( text= '' MAX '' , start_position=-2 ) , assert set ( suggestions ) == cols_etc ( `` foo '' , last_keyword= '' WHERE '' ) 'datatypes ' : { } } id : black context.cli.sendline ( `` . '' ) assert set ( suggestions ) == set ( [ Table ( schema= '' sch '' ) , View ( schema= '' sch '' ) ] ) password=POSTGRES_PASSWORD , port=POSTGRES_PORT , dsn=None ) text = `` selt * '' template = 'CREATE OR REPLACE { 6 } VIEW { 0 } . { 1 } AS \n { 3 } ' tbls = tuple ( [ ( None , `` abc '' , tbl_alias or None , False ) ] ) sql = `` 'select * from t1 assert extract_column_names ( sql ) == ( `` x '' , `` y '' ) 'Programming Language : : Python : : 2.7 ' , tables = ( ( None , `` abc '' , `` a '' , False ) , ( None , `` def '' , `` d '' , False ) ) `` `` '' INSERT INTO public . `` Users '' ( username ) text == `` '' self.multiline_continuation_char = c [ 'main ' ] [ 'multiline_continuation_char ' ] function ( _logger.debug ( 'Databases Query . sql : % r ' , self.databases_query ) arg = ' -- password ' last_keyword=None ) : alias ( ' U ' ) , alias ( 'U2 ' ) , fk_join ( 'U2.userid = U.id ' ) exception_formatter=exception_formatter , self.func_name , host='baz.com ' , Token.Toolbar.Arg.Text : 'arg-toolbar.text ' , View ( schema= '' t1 '' ) , run ( executor , `` create table schema2.child ( childid int PRIMARY KEY , motherid int REFERENCES schema1.parent ) '' ) position = len ( `` \\ '' ) self.is_set_returning , `` CREATE TABLE foo ( bar INT , baz TEXT , qux `` , `` % s ( schema_name= % r , func_name= % r , arg_names= % r , `` sslkey= '' my-key.pem '' , `` Query '' , with open ( casing_file , ' r ' ) as f : _logger.debug ( 'Detected F3 key . ' ) warn=None , wrappers.expect_pager ( context , `` DROP TABLE\r\n '' , timeout=2 ) 'SELECT * FROM sch . `` ' , wrappers.run_cli ( context , run_args=arg.split ( '= ' ) ) def __init__ ( comp.extend_relations ( tables , kind= '' tables '' ) result = get_result ( completer , `` SELECT MA '' ) click.secho ( str ( e ) , err=True , fg='red ' ) style = pygments.styles.get_style_by_name ( `` native '' ) reserved_words = set ( get_literals ( 'reserved ' ) ) 'functions ' : { ( `` orders '' , `` datestamp '' ) : `` now ( ) '' , Table ( schema= '' t '' ) , text = `` '' '' SELECT * FROM users u1 print ( ' '.join ( cmd ) ) database= '' testdb [ `` , table_format = `` vertical '' if settings.expanded else settings.table_format suggest.append ( FromClauseItem ( schema=schema , assert u'Description ' in result [ 2 ] $ pep8radius master -- docformatter -- in-place # apply the fixes 'nested_numeric_array | { { 1,2 } , { 3,4 } } ' , assert executor.short_host == 'localhost1 ' view ( `` user_emails ue '' ) , collist , row_limit=row_limit , for t , cols in scoped_cols.items ( ) 'CREATE FUNCTION foo ( bar INT , baz custom . ' , itertools.product ( 'pass ' : context.config.userdata.get ( string = string.replace ( '\\u ' , self.pgexecute.user or ' ( none ) ' ) Token.Menu.Completions.Meta.Current : `` completion-menu.meta.completion.current '' , conn = psycopg2.connect ( self.change_table_format , not item.value.upper ( ) == 'FROM ' ) and ( Token.Menu.Completions.Completion : 'completion-menu.completion ' , 'SELECT ' , assert result == completions_to_set ( map ( Completion , completer.all_completions ) ) == `` | -123456789 days , 12:23:56 | '' `` custom_func1 ( ) cf '' , collist , -1 , display_meta= '' columns '' , display= '' * '' print ( `` reading fixture data : { } '' .format ( fixture_dir ) ) self.arg_modes , Function ( schema='d ' ) , _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) 'integer ' , False , False , True , False ] ] , if casing_file == `` default '' : sql = `` SELECT abc , 99 , def FROM xxx '' `` childschema '' , with patch.object ( executor , 'host ' , 'localhost ' ) : ( 10 , 10 , `` \n '' .join ( [ test_line ] * 7 ) ) , sql = `` '' '' -- blah blah blah os.environ [ 'PAGER ' ] = configured_pager and word_before_cursor [ -len ( lastword ) - 1 ] == `` . '' arg_names=None , fk = ForeignKey ( expected = [ print ( 'Version : ' , __version__ ) _logger.debug ( 'Functions Query . sql : % r ' , query ) wrappers.expect_pager ( context , 'UPDATE 1\r\n ' , timeout=2 ) os.environ [ 'COLUMNS ' ] = `` 100 '' Column ( table_refs= ( ( None , 'tabl ' , None , False ) , ) ) , @ parametrize ( 'completer ' , completers ( filtr=True , casing=False ) ) if suggestion.context == `` insert '' : assert kw.value == `` where '' and stripped == `` select * from foo where '' texts = [ 'SELECT * FROM ' , 'SELECT * FROM public.Orders O CROSS JOIN ' ] 'SELECT x : :y ' , self.syntax_style = c [ `` main '' ] [ `` syntax_style '' ] mode='strict ' , meta='datatype ' ) ) `` SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON `` , assert first.text == 'extract_entry_symbols ( ) ' print ( `` Releasing Version : '' , ver ) assert set ( tables ) == set ( [ ( 'abc ' , 'def ' , ' x ' , False ) , `` test status '' , Document ( text=text , cursor_position=position ) , Completion ( `` foo '' , 0 , display_meta= '' column '' ) , table ( ' '' Users '' U ' ) , assert executor.short_host == 'localhost ' text = `` SELECT * FROM tabl WHERE foo = ANY ( `` 'table_format dcmlfmt floatfmt missingval expanded max_width case_function style_output ' @ click.option ( '-h ' , ' -- host ' , default= '' , envvar='PGHOST ' , join = `` { 0 } { 4 } ON { 4 } . { 1 } = { 2 } . { 3 } '' .format ( if arg == 'dsn_password ' : assert completions_to_set ( result ) == completions_to_set ( testdata.columns ( `` Users '' ) ) [ alias ( `` U '' ) , alias ( `` U2 '' ) , fk_join ( `` U2.UserID = U.ID '' ) ] @ parametrize ( 'completer ' , completers ( filtr=True , casing=False , qualify=qual ) ) wrappers.expect_pager ( context , 'CREATE DATABASE\r\n ' , timeout=5 ) x AS ( SELECT abc , def FROM x ) '' '' '' POSTGRES_HOST = getenv ( `` PGHOST '' , `` localhost '' ) tables = [ t for t in tables if not t.name.startswith ( 'pg_ ' ) ] * * kwargs ) self.wider_completion_menu = c [ `` main '' ] .as_bool ( `` wider_completion_menu '' ) string = string.replace ( '\\i ' , str ( self.pgexecute.pid ) or ' ( none ) ' ) addcols ( None , tbl.name , 'CTE ' , tbl.alias , cols ) meta_query = MetaQuery ( @ click.option ( ' -- pgclirc ' , default=config_location ( ) + 'config ' , reason='Not applicable in windows ' ) Function ( schema= '' x '' ) , @ pytest.mark.parametrize ( 'text ' , [ 'SELECT * FROM foo . ' , 'SELECT 123 AS foo ' ] ) 'select * from abc.def ' , table ( ' '' select '' s ' ) , ( `` auto '' , `` select '' , ( `` s '' , `` sel '' , `` SEl '' ) ) , elif persist_priorities == `` none '' : with open ( 'pgcli/__init__.py ' , 'rb ' ) as f : 'db_changed ' , # True if any subquery changed the database `` \\T [ format ] '' , kwargs.setdefault ( `` application_name '' , `` pgcli '' ) Column ( if cmd [ 1 : ] == `` d '' : suggestions = suggest_type ( `` \d `` , `` \d `` ) for func in functions or [ ] : os.environ [ `` COLUMNS '' ] = `` 100 '' FROM f '' ' 'dbname ' : 'database ' , refresh_callback = lambda : self.refresh_completions ( pid = self._select_one ( cursor , 'select pg_backend_pid ( ) ' ) [ 0 ] == `` | 00:00:00 | '' priority=priority , sql = `` drop database foo ; '' 0 if ( left.schema , left.tbl ) in other_tbls else 1 ) function ( 'custom_func2 ( ) ' , -2 ) , Token.Toolbar.System : 'system-toolbar ' , ) [ 3 ] os_environ_pager ) ) self.completer.case if self.settings [ 'case_column_headers ' ] @ parametrize ( 'completer ' , completers ( aliasing=False , casing=True ) ) 'products ' , 'custom ' Token.Toolbar.Off : `` bottom-toolbar.off '' , col = column ( 'status ' , -1 ) `` users '' : [ `` id '' , `` parentid '' , `` email '' , `` first_name '' , `` last_name '' ] , for sch , funcs in self.dbmetadata [ `` functions '' ] .items ( ) `` SELECT * FROM tabl WHERE ( bar > 10 AND `` , dedent ( `` '\ testdata.builtin_functions ( ) + testdata.keywords ( ) ) function ( 'custom_fun ( ) cf ' ) , _logger.debug ( 'Socket directory Query . sql : % r ' , assert set ( suggestions ) == cols_etc ( 'foo ' , last_keyword='WHERE ' ) run ( executor , `` '' '' create table test ( a text ) '' '' '' ) as $ $ select 1 , 2 from generate_series ( 1,5 ) $ $ ; '' '' '' , kw = keyword ( `` SELECT '' , -1 ) tables = extract_tables ( `` 'SELECT * FROM foo.bar baz name='completion_refresh ' ) if casing_file == 'default ' : text = ( 'SET SCHEMA ' ) [ ( `` abc '' , `` def '' ) ] , view_definition_query = `` '' '' help= ( `` | abc | def | '' , ] + [ function ( 'set_returning_func ( x : = , y : = ) ' , display='set_returning_func ( x , y ) ' ) ] prompt_passwd , assert set ( suggestions ) == cols_etc ( 'tabl ' , 'sch ' , last_keyword='SELECT ' ) def columns ( self , tbl , parent='public ' , typ='tables ' , pos=0 ) : suggestion = suggest_type ( 'INSERT INTO ' , 'INSERT INTO ' ) alias ( `` orders '' ) , self.schema_name , `` \r '' Token.Output.OddRow : `` output.odd-row '' , ) ) mock_pgexecute.assert_called_with ( `` Programming Language : : Python : : 3.7 '' , persist_priorities='all ' ) return not click.confirm ( ' -- - Run this step ? ' , default=True ) log_file = config_location ( ) + `` log '' testdata.columns_functions_and_keywords ( `` select '' ) if word_before_cursor [ -1 ] == `` ( `` or word_before_cursor [ 0 ] == `` \\ '' : qualify ( c.name , t.ref ) for t , cs in scoped_cols.items ( ) for c in cs view , text = 'SELECT * FROM orders WHERE s ' InputMode.INSERT_MULTIPLE : `` M '' , query = `` ' ForeignKey ( * fk ) for fks in metadata [ `` foreignkeys '' ] .values ( ) for fk in fks join = ' { 0 } ON { 0 } . { 1 } = { 2 } . { 3 } '.format ( 'OutputSettings ' , text = 'SELECT * FROM blog.Entries JOIN blog.et ' return self.find_matches ( word_before_cursor , tables , meta= '' table '' ) return self.find_matches ( word_before_cursor , joins , meta='join ' ) @ when ( u'we tee output ' ) for reltype in ( `` tables '' , `` views '' ) : @ kb.add ( 'f3 ' ) process_title = re.sub ( `` -- host '' , 'EntryTags ON EntryTags.EntryID = Entries.EntryID ' , -2 ) `` SELECT `` , `` select * from abc inner join def using ( `` , return set ( ( completion.display_text , completion.display_meta_text ) for completion in completions ) result = run ( executor , 'invalid syntax ! ' , cols + testdata.functions_and_keywords ( ) ) print ( 'Version : ' , __version__ ) 'missing_value ' : settings.missingval , cmd = `` `` .join ( cmd_parts ) prio = 1000 if c.datatype in ( `` integer '' , `` bigint '' , `` smallint '' ) else 0 `` $ $ '' , display_suffix = self._arg_list_cache [ 'signature ' ] [ tbl.meta ] assert result [ 0 ] == table ( 'Entries ' , -1 ) self.generate_casing_file = settings.get ( 'generate_casing_file ' ) ) .split ( `` \n '' ) [ 3 ] name_join ( ' y.product_name = x.product_name ' ) , self.min_num_menu_lines = c [ 'main ' ] .as_int ( 'min_num_menu_lines ' ) suggestions = suggest_type ( `` SELECT a , b FROM tbl1 , `` , `` SELECT a , b FROM tbl1 , `` ) 'Users ' : [ 'userid ' , 'username ' ] , log_file = self.config [ `` main '' ] [ `` log_file '' ] position = text.index ( ' ' ) + 1 `` % ( name ) s % ( levelname ) s - % ( message ) s '' collection = [ 'Foo ' , 'FOO ' , 'fOO ' ] [ table ( t ) for t in ( `` Users U '' , ' '' Users '' U ' , `` Orders O '' , ' '' select '' s ' ) ] [ `` SELECT * FROM tabl WHERE foo IN ( `` , `` SELECT * FROM tabl WHERE foo IN ( bar , `` ] , qualifiable=True ORDER BY 1 '' ' 'users ' , 'SELECT * FROM users INNER JOIN orders USING ( id , ' , for ( func , metas ) in self.dbmetadata [ 'functions ' ] [ sch ] .items ( ) self.search_path_filter = settings.get ( `` search_path_filter '' ) is_join = token_v.endswith ( `` join '' ) and token.is_keyword 'SELECT * FROM foo JOIN ' , new_params [ `` dsn '' ] = make_dsn ( `` SELECT * FROM tabl1 t1 , tabl2 t2 WHERE t1 . `` , self.refresh_completions ( history=history , self.logger.debug ( `` Database connection failed : % r . `` , e ) os.environ [ `` PAGER '' ] = `` cat '' [ `` SELECT * FROM users u1 JOIN users u2 USING ( email ) JOIN user_emails ue USING ( ) '' , WITH a AS `` '' '' logger.debug ( `` Search path : % r '' , self.completer.search_path ) license='BSD ' , run ( executor , `` insert into numbertest ( a ) values ( { 0 } ) '' .format ( value ) ) context.conf [ `` pager_boundary '' ] , `` psycopg2 > = 2.7.4 , < 2.8 '' , @ click.option ( ' -- list-dsn ' , 'list_dsn ' , is_flag=True , suggestions = suggest_type ( users = table ( 'users ' ) cur.execute ( self.table_format = c [ `` main '' ] [ `` table_format '' ] assert set ( executor.schemata ( ) ) > = set ( [ Column ( table_refs= ( ( None , `` abc '' , None , False ) , ) , context= '' insert '' ) , DynamicCompleter ( lambda : self.completer ) ) , res = self.pgexecute.run ( @ when ( 'we update table ' ) executor.run ( 'Column ' , user='bar^ ' , wrappers.expect_exact ( context , `` You are now connected to database '' , timeout=2 ) self.dbname = dsn_parameters.get ( `` dbname '' ) text = 'SELECT * FROM blog.Entries JOIN blog.e ' wrappers.expect_exact ( context , `` { 0 } > `` .format ( db_name ) , timeout=5 ) text = `` SELECT * FROM orders WHERE s '' return suggest_based_on_last_token ( 'type ' , stmt ) assert set ( suggestions ) == cols_etc ( `` abc '' ) for sch , tbls in metadata [ `` tables '' ] .items ( ) : cfg [ `` casing '' ] = casing 'Users ' : [ 'userid ' , 'username ' ] , _logger.debug ( `` Casing Query . sql : % r '' , query ) Token.Menu.Completions.ProgressBar : `` scrollbar '' , # best guess } [ self.qualify_columns ] func_name='func2 ' , persist_priorities='none ' ) return sorted ( completions , key=operator.attrgetter ( 'text ' ) ) len ( `` SELECT users.id , users . `` ) , if editor_command == `` \\ev '' : fk_join ( 'shipments.user_id = users.id ' ) ] ) if casing == `` auto '' : 'user_emails ' : [ 'id ' , 'email ' ] , `` `` '' return -float ( `` Infinity '' ) , -match_point ast.literal_eval ( _version_re.search ( f.read ( ) .decode ( `` utf-8 '' ) ) .group ( 1 ) ) `` dsn '' : dsn , 'ALTER ' , `` is_special '' , # True if the query is a special command self.columns ( tbl , parent , typ , pos ) assert set ( executor.foreignkeys ( ) ) > = set ( [ print ( `` -- - Pretending to run ... '' ) exception_formatter=exception_formatter ) ) auto_vertical_output=auto_vertical_output , `` sep_length '' : ( 1 , 25 ) , assert 'MIN ' not in result `` Custom_Fun ( ) CF '' , self.refresh_completions ( persist_priorities= '' keywords '' ) on_error_resume = ( self.on_error == 'RESUME ' ) type=str , logger.debug ( 'Search path : % r ' , print ( `` Version : '' , __version__ ) db_name_full = `` { 0 } _ { 1 } '' .format ( db_name , vi ) JoinCondition = namedtuple ( 'JoinCondition ' , [ 'table_refs ' , 'parent ' ] ) priority= ( 1 , 1 , 1 ) 'bigint_array | { 1,2,3 } ' , 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' , 'datestamp ' ] , metadata = dict ( ( k , { `` public '' : v } ) for k , v in metadata.items ( ) ) context.cli.sendline ( '\\ns foo SELECT 12345 ' ) metadata = dict ( ( k , { 'public ' : v } ) for k , v in metadata.items ( ) ) table ( `` Orders O '' if text == `` SELECT * FROM `` else `` Orders O2 '' ) , `` import pgcli.main '' , conn = sql.connection.Connection.set ( parsed [ `` connection '' ] ) q = `` ALTER TABLE foo ALTER COLUMN bar TYPE `` conn.set_client_encoding ( 'utf8 ' ) @ when ( 'we start external editor providing a file name ' ) `` $ $ $ a $ `` , default=config_location ( ) + `` config '' , tables = extract_tables ( `` SELECT * FROM foo ( { 0 } ) bar '' .format ( arg_list ) ) @ then ( 'we see help output ' ) string = string.replace ( `` \\d '' , self.pgexecute.dbname or `` ( none ) '' ) `` text , text_before , last_keyword '' , 'sf ' : Function , db_name = context.config.userdata.get ( `` pg_test_db '' , `` pgcli_behave_tests '' ) ( '\\ns abc SELECT foo ' , 'SELECT foo ' , ( Keyword ( ) , ) ) , root_logger = logging.getLogger ( `` pgcli '' ) `` CREATE FUNCTION foo ( bar INT , baz custom . `` , string = string.replace ( `` \\ # '' , `` # '' if ( self.pgexecute.superuser ) else `` > '' ) 'id , Users.parentid , Users.email , Users.first_name , Users.last_name ' ) , Function ( schema=parent ) ] pgexecute=None , pgclirc_file=None , row_limit=None , assert completions_to_set ( result ) == completions_to_set ( testdata.schemas ( ) + [ text = `` SELECT blog.ees '' text = 'SELECT FROM users ' if arg_mode == `` call '' : print ( boundary ) suggestions = suggest_type ( 'select * from ; select * from b ' , host , _ , _ = self.host.partition ( ' , ' ) self.less_chatty = bool ( less_chatty ) or c [ `` main '' ] .as_bool ( `` less_chatty '' ) context , Keyword , 'users.id , users.phone_number ' ) 'Quit pgcli . ' , arg_type=NO_QUERY , case_sensitive=True , `` Pygments > = 2.0 '' , # Pygments has to be Capitalcased . WTF ? 'humanize > = 0.5.1 ' , `` SELECT * FROM tabl WHERE foo = 1 AND `` , 'SELECT 1 ; select error ; ' , display= '' set_returning_func ( x , y ) srf '' , context.cli.sendline ( '\i { 0 } '.format ( context.tmpfile_sql_help.name ) ) yield ( None , None , None , 'You are now connected to database `` % s '' as ' 'select * from abc inner join def using ( ' , self.quit , `` -- dsn '' , self.pgspecial.register ( self.quit , 'quit ' , 'quit ' , `` INSERT INTO public.Orders ( * ) '' , } .get ( suggestion.usage , 'call ' ) alias ( ' '' Users '' ' ) 'SELECT * FROM sch . ' , if first_token.lower ( ) in ( 'alter ' , 'create ' , 'drop ' , 'commit ' , 'rollback ' ) : if not suggestion.schema and ( casing_file = config [ `` main '' ] [ `` casing_file '' ] ( 'schema1 ' , 'parent ' , 'parentid ' , 'schema2 ' , 'child ' , 'motherid ' ) ] ) suggestion = suggest_type ( `` INSERT INTO `` , `` INSERT INTO `` ) assert u'fooé ' in result [ 3 ] c_dest_warning = c [ `` main '' ] .as_bool ( `` destructive_warning '' ) ' $ $ $ a $ $ $ ' , assert set ( suggestions ) == cols_etc ( 'tabl ' , last_keyword='SELECT ' ) `` \\ns abc SELECT t1 . FROM tabl1 t1 '' , sql = 'SELECT abc def , ghi jkl FROM xxx ' 'SELECT 2 ' Database , 'SELECT * FROM tabl WHERE foo = ' , return ( [ ] , `` ) def cols_etc ( table , schema=None , alias=None , is_function=False , parent=None , click.secho ( `` Reconnect Failed '' , fg= '' red '' ) completer.extend_columns ( executor.view_columns ( ) , kind= '' views '' ) `` Confirm every step . If the step is not `` `` confirmed , it will be skipped . '' position = text.index ( `` `` ) + 1 print ( `` - '' * 20 ) cased_users2_col_names if arg == `` -- username '' : 'SELECT foo bar ' , POSTGRES_PORT , run ( executor , `` create type foo AS ( a int , b text ) '' ) ( 'ghi ' , 'jkl ' , None , False ) ] ) and { document = Document ( [ `` o '' ] , msg = `` Table format { } not recognized . Allowed formats : '' .format ( pattern ) row_limit=None , old_value = env_old.get ( k , `` ) text = last_word ( text , include= '' most_punctuations '' ) .lower ( ) 'SELECT t1.a , t2 . ' ) NamedQuery = namedtuple ( 'NamedQuery ' , [ ] ) if casing == 'auto ' : TableReference ( None , 'tbl ' , ' x ' , False ) , name_join ( `` orders.email = users.email '' ) , tables = extract_tables ( `` update abc.def set id = 1 '' ) print ( `` Created connection : { 0 } . `` .format ( cn.dsn ) ) self.pgspecial.timing_enabled = c [ `` main '' ] .as_bool ( `` timing '' ) arg = ' -- username= { } '.format ( context.conf [ 'user ' ] ) settings = OutputSettings ( table_format= '' psql '' , dcmlfmt= '' d '' , floatfmt= '' g '' ) assert actual2 [ 0 ] [ 3 ] == `` Auto-completion refresh restarted . '' self.functions ( parent , pos ) 'ALTER TABLE foo DROP COLUMN ' , 'select f. from custom.set_returning_func ( ) f ' , assert completions_to_set ( result ) == completions_to_set ( cased_funcs + cols @ pytest.mark.parametrize ( 'text , text_before ' , [ ( 'public ' , 'users ' , 'id ' , 'public ' , 'users ' , 'parentid ' ) , FromClauseItem ( schema=None , table_refs=tbls ) , `` Title '' , [ ( `` abc '' , `` def '' ) ] , [ `` head1 '' , `` head2 '' ] , `` test status '' , settings `` -d '' , result = get_result ( completer , 'SELECT from `` select '' ' , len ( 'SELECT ' ) ) False , str ( self.pgexecute.port ) if self.pgexecute.port is not None else `` 5432 '' , 'UPDATE ' , 'CREATE ' , 'DELETE ' ) : collist = sep.join ( self.case ( c.completion ) for c in flat_cols ( ) ) return `` { `` + `` , '' .join ( text_type ( format_array ( e ) ) for e in val ) + `` } '' name_join ( 'shipments.id = users.id ' ) , 'create database foo with template ' ) Column ( table_refs= ( ( None , `` tabl2 '' , `` t2 '' , False ) , ) ) , ] + testdata.functions_and_keywords ( ) @ when ( 'we type sql in the editor ' ) _logger.debug ( `` Detected < C-Space > key . '' ) sql = sql.rstrip ( ' ; ' ) not JSONB_AVAILABLE , reason= '' Postgres server unavailable or jsonb type not defined '' if tok_val in ( 'insert ' , 'update ' , 'delete ' ) : return self.parsed.token_first ( ) .value.lower ( ) == 'insert ' prompt = self.get_prompt ( `` \\d > `` ) self.wider_completion_menu = c [ 'main ' ] .as_bool ( 'wider_completion_menu ' ) hostname= '' localhost '' , username=None , password=None , dbname=None , port=None if token_v == 'from ' or is_join : `` `` '' create function schema1.func2 ( ) returns int 'custom ' : [ 'typ3 ' , 'typ4 ' ] , prompt_format == self.default_prompt result = completions_to_set ( get_result ( completer , text , text.find ( `` `` ) + 1 ) ) `` INSERT INTO public.Orders ( * '' , function ( 'func2 ( ) ' ) ] ) elif token_v.endswith ( ' ( ' ) : [ name_join ( ' y = f2.y ' ) , name_join ( ' x = f2.x ' ) ] } 'select * from a ; select ' ) remap = { `` dbname '' : `` database '' , `` password '' : `` passwd '' } } root_logger.debug ( `` Initializing pgcli logging . '' ) 'test status ' , select * from abc inner join def using ( col1 , `` '' '' , context.cli.sendcontrol ( 'd ' ) ' '' ) , completer , `` SELECT p.id , p. from custom.products p '' , len ( `` SELECT u.id , u . '' ) history_file = self.config [ 'main ' ] [ 'history_file ' ] settings=self.settings , if last_word ( stmt.text_before_cursor , `` all_punctuations '' ) .startswith ( `` ( `` ) : 'keyring ' : [ 'keyring > = 12.2.0 ' ] , run ( executor , `` '' '' create table test ( a boolean ) '' '' '' ) `` SELECT 1 : :custom . `` , `` -- warn/ -- no-warn '' , default=None , help= '' Warn before running a destructive query . '' function_meta_data ( func_name= '' func1 '' , return_type= '' integer '' ) , startup= '' ; `` .join ( print ( `` -- - after_scenario { } : kill cli '' .format ( scenario.name ) ) msg = 'Table format { } not recognized . Allowed formats : '.format ( @ then ( u'we confirm the destructive warning ' ) ( 10 , 10 , '\n'.join ( [ test_line ] * 7 ) ) , Keyword ( token_v.upper ( ) ) , aliases= ( 'exit ' , ) ) ( ' x ' , ( 'abc ' , 'def ' ) , start1 , stop1 ) , stop_pos = len ( 'WITH a AS ( SELECT abc FROM xxx ) ' ) keyword = partial ( completion , 'keyword ' ) context.cli.sendline ( '\\refresh ' ) SELECT * FROM unnest ( current_schemas ( true ) ) '' '' '' return `` ( `` + `` , '' .join ( `` \n `` + a for a in args if a ) + `` \n ) '' wrappers.expect_pager ( context , 'INSERT 0 1\r\n ' , timeout=2 ) def functions ( self , parent='public ' , pos=0 ) : if persist_priorities == `` all '' : full_text , text_before_cursor , parsed assert suggestions == ( Datatype ( schema='foo ' ) , ) status == ext.TRANSACTION_STATUS_ACTIVE ' '' INSERT INTO users ( id , parentid , email , first_name , last_name ) maybe_schema = ( self.case ( tbl.schema ) + `` . '' ) if tbl.schema else `` '' from pgspecial.main import ( PGSpecial , NO_QUERY , PAGER_OFF , PAGER_LONG_OUTPUT ) meta='database ' ) schema_names = self.dbmetadata [ 'tables ' ] .keys ( ) orders = table ( `` orders '' ) 'functions ' : [ sort_key , type_priority , prio , priority_func ( item ) , joins.append ( Candidate ( join , prio , `` join '' , synonyms=synonyms ) ) local_tables=stmt.local_tables ) , @ parametrize ( 'completer ' , completers ( casing=False , aliasing=False ) ) assert Column ( table_refs= ( ( None , `` t3 '' , None , False ) , ) ) in set ( suggestions ) yield TableReference ( schema_name , real_name , for rcol in rcols for fk in rcol.foreignkeys ) self.info_connection , `` \\conninfo '' , `` \\conninfo '' , `` Get connection details '' col = column ( `` status '' , -1 ) Token.Output.Header : `` output.header '' , Token.Menu.Completions.ProgressButton : `` scrollbar.arrow '' , # best guess `` -- pgclirc '' , LEFT JOIN `` ' mock_connect.assert_called_with ( database='testdb ' , return self.find_matches ( word_before_cursor , keywords , disable keyring in our configuration : add keyring = False to [ main ] '' '' '' ) function ( 'Custom_Fun ( ) CF ' ) , on `` ' , position = len ( 'SELECT users.name , orders.id FROM users JOIN orders ON ' ) ( 'public ' , ' a ' , ' x ' , 'text ' , False , None ) , ( text == 'quit ' ) or # Quit does n't need semi-colon context.cli.sendline ( 'select * from a ; ' ) `` s '' , `` f '' , [ `` x '' ] , [ `` integer '' ] , [ ] , `` int '' , False , False , False , False , None expected = completions_to_set ( position = len ( 'SEL ' ) self.generate_aliases = settings.get ( `` generate_aliases '' ) `` `` '' SELECT * tables = ( ( None , `` abc '' , None , False ) , ( None , `` bcd '' , None , False ) ) Function ( schema='t1 ' ) text= '' \\timing '' , 'Please check the `` [ alias_dsn ] '' section in pgclirc . ' , self.tables ( parent , pos ) 'pg_test_pass ' , `` _custom_fun ( ) cf '' , new_params [ 'dsn ' ] = make_dsn ( context.conf [ `` pager_boundary '' ] , Function ( schema=None ) , `` schema '' , context.cli.sendline ( 'select 1 ' ) '' , context.cli.before ) 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , `` select * from a ; select * from `` , return ( Column ( table_refs=stmt.get_tables ( ) , local_tables=stmt.local_tables ) , ) @ click.option ( ' -- less-chatty ' , 'less_chatty ' , is_flag=True , elif token_v == 'truncate ' : ( 'blog ' , 'entries ' , 'entryid ' , 'blog ' , 'entacclog ' , 'entryid ' ) , display_meta = display_meta [ :47 ] + u ' ... ' get_comp ( * * c ) for c in _cfgs ( casing , filtr , aliasing , qualify ) `` SELECT t1 . FROM tabl1 t1 '' , 'parentcolumn ' , 'childschema ' , 'childtable ' , 'childcolumn ' ] ) help='list of DSN configured into the [ alias_dsn ] section of pgclirc file . ' ) assert len ( COLOR_CODE_REGEX.sub ( `` , text ) ) == expected_length create_git_tag ( `` v { } '' .format ( ver ) ) token_type , style_value = parse_pygments_style ( self.logger.info ( comp.extend_columns ( view_cols , kind= '' views '' ) name , datatype , foreignkeys=None , default=None , has_default=False datatype = partial ( completion , 'datatype ' ) suggestions = suggest_type ( 'SELECT * FROM ( SELECT t. FROM tabl t ' , assert completions_to_set ( result ) == completions_to_set ( testdata.columns ( `` users '' ) ) except ( RuntimeError , keyring.errors.InitError ) as e : context.cli.sendline ( 'drop table if exists a ; ' ) single_connection=single_connection , Column ( table_refs= ( ( None , `` foo '' , None , False ) , ) , qualifiable=True ) , `` select * from a ; select * from `` , `` select * from a ; select * from `` table_refs= ( ' $ $ foo $ a $ ' , if not s.startswith ( 'pg_ ' ) ] ] + [ function ( `` set_returning_func ( x : = , y : = ) '' , display= '' set_returning_func ( x , y ) '' ) ] assert run ( executor , `` SELECT ( CAST ( '4713-01-01 00:00:00 BC ' AS timestamp ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ @ when ( 'we use a named query ' ) table_format= '' psql '' , dcmlfmt= '' d '' , floatfmt= '' g '' , max_width=100 return [ Completion ( text=k , start_position=pos , display_meta=v.description ) for k , v in iteritems ( self.completer.pgspecial.commands ) ] assert set ( tables ) == set ( [ ( None , 'Abc ' , None , False ) , `` SELECT * FROM public . { 0 } RIGHT OUTER JOIN `` , _logger.debug ( `` Detected F4 key . '' ) ( `` class : bottom-toolbar '' , `` [ F4 ] Vi-mode ( `` + _get_vi_mode ( ) + `` ) '' ) run ( executor , `` create table tbl1 ( a text , b numeric ) '' ) ( 'orders ' , 'status ' ) : `` 'PENDING ' : :text '' , 'SELECT foo : :bar.baz ' , if not os.environ.get ( `` LESS '' ) : help='Host address of the postgres database . ' ) `` Programming Language : : Python : : 3.4 '' , database=dbname ) 'WITH cte AS ( SELECT foo FROM bar ) SELECT * FROM cte WHERE cte . ' , os.environ [ `` PAGER '' ] = os_environ_pager Document ( text=text , cursor_position=position ) , complete_event `` `` '' SELECT * if filename not in [ ' . ' , ' .. ' ] : os.path.dirname ( os.path.dirname ( os.path.dirname ( __file__ ) ) ) os.environ [ `` PGUSER '' ] = context.conf [ `` user '' ] `` dbname '' : db_name_full , wrappers.expect_exact ( context , `` 12345 '' , timeout=1 ) Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) , qualifiable=True ) , formatted = `` \n '' .join ( formatted ) self.syntax_style , c [ 'colors ' ] ) text = `` \\dT foo . '' passwd= '' foo '' , keywords_tree = get_literals ( `` keywords '' , type_=dict ) wrappers.expect_pager ( context , `` INSERT 0 1\r\n '' , timeout=2 ) collist = ' , '.join ( qualify ( c.name , t.ref ) full_text , text_before_cursor `` Func1 '' , defaults = self.metadata.get ( 'defaults ' , { } ) .get ( sch , { } ) [ ( None , `` tabl1 '' , `` t1 '' , False ) , ( None , `` tabl2 '' , `` t2 '' , False ) ] for name , typ , mode in zip ( $ pip install pep8radius [ alias ( 'users ' ) , alias ( ref ) ] ) SELECT * FROM a , b '' '' '' ) : `` username_opt '' , if editor_command == `` \\e '' : tables = extract_tables ( `` select * from abc.def , ghi.jkl '' ) self.vi_mode = c [ 'main ' ] .as_bool ( 'vi ' ) Token.Toolbar.System : `` system-toolbar '' , _logger.debug ( 'Detected < Esc > key . ' ) assert token_start_pos ( p.tokens , idx ) == len ( 'SELECT * FROM ' ) run ( executor , 'create view vw1 AS SELECT * FROM tbl1 ' ) ) `` -w '' , self.arg_names , elif token_v in ( `` c '' , `` use '' , `` database '' , `` template '' ) : 'cli_command ' : ( host , if ( self.destructive_warning and table ( `` orders o2 '' ) , text , assert set ( suggestions ) == set ( [ Table ( schema=None ) , View ( schema=None ) , Schema ( ) ] ) 'SELECT U . FROM USERS U ' , join ( `` EntAccLog ON EntAccLog.EntryID = Entries.EntryID '' , -1 ) , cfg [ `` settings '' ] [ `` search_path_filter '' ] = filtr f_sug = Function ( s.schema , s.table_refs , usage= '' from '' ) assert run ( executor , `` SELECT ( CAST ( '00:00:00 ' AS time ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ default_config = os.path.join ( package_root , 'pgclirc ' ) click.secho ( 'Reconnecting ... ' , fg='green ' ) for t , c in cols if t.ref ! = lref ) `` ALTER TABLE foo ALTER COLUMN `` , help='Force password prompt . ' ) == `` | 4713-01-01 00:00:00 BC | '' return self.find_matches ( word_before_cursor , schema_names , meta= '' schema '' ) Function ( schema='tabl ' ) , 'SELECT * FROM users CROSS JOIN ' , `` CRITICAL '' : logging.CRITICAL , return ' ( ) ' arg_names= ( ' x ' , ) , tables = ( ( None , `` abc '' , None , False ) , ( None , `` def '' , None , False ) ) `` public '' : { return ( Function ( schema=schema , usage='signature ' ) , ) col_list = `` id , parentid , email , first_name , last_name '' if os.path.exists ( os.path.expanduser ( '~/.pgclirc ' ) ) : 'INSERT INTO orders ( ' , 'SELECT * FROM abc a JOIN def d ON a.id = d.id AND a.id2 = d. ' , sql = `` SELECT abc def FROM xxx '' join ( ' '' Users '' U ON U.userid = Users.id ' ) , results = format_output ( @ pytest.mark.parametrize ( 'text , text_before , last_keyword ' , [ ) : help='Use DSN configured into the [ alias_dsn ] section of pgclirc file . ' ) elif ( token_v.endswith ( 'join ' ) and token.is_keyword ) or ( token_v in 'CREATE TABLE foo ( bar ' , status == ext.TRANSACTION_STATUS_INTRANS ) 'SELECT * FROM sch . `` foo ' , Table ( schema= '' d '' ) , @ pytest.mark.parametrize ( 'join_type ' , [ `` , 'INNER ' , 'LEFT ' , 'RIGHT OUTER ' ] ) 'SELECT U . FROM `` custom '' .users U ' `` \\o '' , assert tuple ( ctes ) == ( ( ' a ' , ( 'def ' , ) , start_pos , stop_pos ) , ) alias , testdata.columns ( `` users '' , `` custom '' ) context.cn = dbutils.create_db ( context.conf [ 'host ' ] , context.conf [ 'user ' ] , Table ( schema='t ' ) , from metadata import ( return os.getenv ( `` USERPROFILE '' ) + `` \\AppData\\Local\\dbcli\\pgcli\\ '' return self.arg_modes and any ( arg_mode == ' v ' for arg_mode in self.arg_modes ) return [ ( None , None , None , message , `` , False , True ) ] `` | { } | < null > | { < null > } | '' , ( 'bar ' , 'qux ' , 'quux ' , True ) ] ) long_description=open ( 'README.rst ' ) .read ( ) , if pgcli.multiline_mode == 'safe ' : `` PGHOST '' : os.environ.get ( `` PGHOST '' , None ) , fk_join ( `` u2.userid = users.id '' ) , rows=term_height , columns=term_width meta = self.dbmetadata [ `` tables '' ] ' '' ) .format ( 'pg_test_port ' , 'password ' : 'passwd ' , `` ALTER TABLE foo DROP COLUMN bar '' , '| { } | < null > | { < null > } | ' , completion , prio , meta , synonyms or [ completion ] , prio2 , display or completion 'call_arg_style ' , ' { arg_name : < { max_arg_len } } : = { arg_default } ' casing = `` lower '' @ parametrize ( 'completer ' , completers ( casing=False , filtr=False , aliasing=True ) ) def test_suggested_column_names_from_shadowed_visible_table ( completer , table ) : assert Keyword ( 'ALTER ' ) in set ( suggest_type ( sql , sql ) ) context.cli.sendline ( `` y '' ) @ when ( 'we exit the editor ' ) 'SELECT * FROM `` sch '' . ' , text = 'SELECT * FROM abc { 0 } { 1 } JOIN '.format ( tbl_alias , join_type ) help= '' Do not use a separate connection for completions . `` , @ then ( 'we see dbcli prompt ' ) text = `` 'SELECT * FROM users u1 if log_file == `` default '' : 'SELECT * FROM abc a JOIN def d ON a.id = d. ' , `` preserve_whitespace '' : True , ) + ' ) ' for t , cols in scoped_cols.items ( ) elif token_v == `` column '' : fk = ForeignKey ( parentschema , parenttable , parcol , return ( Table ( schema=schema ) , return self.find_matches ( word_before_cursor , formats , meta= '' table format '' ) @ parametrize ( 'text ' , [ table ( 'Users U ' ) , return self.find_matches ( word_before_cursor , flat_cols ( ) , meta= '' column '' ) ' ( ' , result = get_result ( completer , `` SELECT id , from users u '' , len ( `` SELECT id , `` ) ) print ( ' { } = '' { } '' '.format ( k , new_value ) ) keyword_casing = c [ `` main '' ] [ `` keyword_casing '' ] ) : `` Programming Language : : Python : : 3 '' , 'SELECT * FROM users natural join ' host= '' baz.com '' , name_join , with io.open ( version_file , encoding='utf-8 ' ) as f : join ( 'users u ON u.id = Users.parentid ' ) , Column ( table_refs=filteredtables , local_tables=stmt.local_tables ) , `` sslmode=verify-full & sslcert=m % 79.pem & sslkey=my-key.pem & sslrootcert=c % 61.pem '' lastword = last_word ( word_before_cursor , include= '' most_punctuations '' ) `` SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = JOIN orders o2 ON '' , if item_val in ( 'tags ' : [ 'tagid ' , 'name ' ] , result.append ( ( 'class : bottom-toolbar ' , ' ' ) ) y AS `` '' '' 'INSERT INTO public.orders ( * ' , aliases= ( `` : q '' , ) , elif token_v.endswith ( `` ( `` ) : print ( ' { } = '' { } '' '.format ( k , new_value ) ) text = 'SELECT blog.ees ' expected = [ wildcard_expansion ( `` ordered_date , status '' ) ] query = `` '' '' maybe_schema = ( self.case ( tbl.schema ) + ' . ' ) if tbl.schema else `` assert extract_column_names ( sql ) == ( 'def ' , ) context.cli.sendcontrol ( `` c '' ) `` set_returning_func '' , position = len ( 'SELECT U . ' ) POSTGRES_PORT = getenv ( `` PGPORT '' , 5432 ) ) / 'database ' : database , @ when ( 'we select from table ' ) @ parametrize ( 'keyword_casing , expected , texts ' , [ run ( for f in ( `` SELECT * FROM abc a JOIN def d ON a . `` , @ click.argument ( 'username ' , default=lambda : None , envvar='PGUSER ' , nargs=1 ) cols.sort ( key=operator.attrgetter ( `` name '' ) ) Function ( schema= '' tabl '' ) , [ 'set_returning_func ' , [ ' x ' ] , [ 'integer ' ] , [ ' o ' ] , pgclirc_file = pgclirc_file or `` % sconfig '' % config_location ( ) humanize.time.naturaldelta ( query.total_time ) , `` SELECT foo FROM bar `` , addcols ( None , tbl.name , `` CTE '' , tbl.alias , cols ) JOIN bar.qux ( x , y , z ) quux '' ' ) `` DELETE FROM foo WHERE x > y RETURNING x , y '' , pgcli.connect_dsn ( `` service= { 0 } '' .format ( os.environ [ `` PGSERVICE '' ] ) ) `` INSERT INTO orders ( * '' , self.float_format = c [ 'data_formats ' ] [ 'float ' ] 'blog ' : { if not suggestion.schema and ( not word_before_cursor.startswith ( `` pg_ '' ) ) : run_step ( 'git ' , 'tag ' , tag_name ) result = get_result ( completer , `` SELECT u. from users u '' , len ( `` SELECT u . '' ) ) suggestions = suggest_type ( `` TRUNCATE `` , `` TRUNCATE `` ) return self.find_matches ( assert completions_to_set ( result ) == completions_to_set ( text = 'select * from foo f left join bar b , ' `` call_arg_style '' , `` { arg_name : < { max_arg_len } } : = { arg_default } '' cols.sort ( key=operator.attrgetter ( 'name ' ) ) cased_tbls @ pytest.mark.parametrize ( 'arg_list ' , [ `` , 'arg1 ' , 'arg1 , arg2 , arg3 ' ] ) aliases= ( ' : q ' , ) ) 'products ' : [ 'id ' , 'product_name ' , 'price ' ] , 'configobj > = 5.0.6 ' , text = `` \\ '' full_text , text_before_cursor , parsed = \ position = len ( 'SELECT u.name , o.id FROM users u JOIN orders o ON ' ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] } , ] + testdata.functions_and_keywords ( ) click.echo ( `` '' , file=f ) # extra newline 'SELECT * FROM tabl WHERE ( ' , ext.register_type ( ext.new_type ( ( 17 , ) , `` BYTEA_TEXT '' , psycopg2.STRING ) ) 'select * from foo where bar ' , tuple ( c for c in item ) never_prompt , 'INSERT INTO Orders SELECT from users U NATURAL JOIN `` Users '' ' , return isinstance ( other , self.__class__ ) and self.__dict__ == other.__dict__ [ table ( x ) for x in ( `` Orders '' , ' '' select '' ' , `` CUSTOM.shipments '' ) ] sql , message = special.open_external_editor ( 'set_returning_func ( x : = , y : = ) srf ' , executor , u '' SELECT d FROM jsontest LIMIT 1 '' , join=True , expanded=expanded position = len ( `` SELECT users . * '' ) port=POSTGRES_PORT , print ( 'Config file is now located at ' , config_full_path ) Completion ( text=k , start_position=pos , display_meta=v.description ) result = get_result ( completer , r '' \df `` ) less_chatty=less_chatty , ( None , 't1 ' , None , False ) , testdata.from_clause_items ( `` custom '' , start_position ) result = get_result ( completer , `` select from set_returning_func ( ) '' , len ( `` select `` ) ) passwd= '' ] foo '' , assert extract_column_names ( sql ) == ( `` def '' , `` jkl '' ) context.env_config_home = tempfile.mkdtemp ( prefix='pgcli_home_ ' ) history = `` SELECT * FROM users ; SELECT * FROM orders ; SELECT * FROM users '' _logger.debug ( 'Schemata Query . sql : % r ' , self.schemata_query ) collection = [ `` api_user '' , `` user_group '' ] matches = self.find_matches ( word_before_cursor , funcs , meta='function ' ) Token.Toolbar.Arg : `` arg-toolbar '' , local_tables=stmt.local_tables ) , ) View = namedtuple ( 'View ' , [ 'schema ' , 'table_refs ' ] ) for completion in completions table = partial ( completion , `` table '' ) } , position = text.index ( `` * '' ) + 1 'SELECT * FROM Users JOIN ' , result = executor.view_definition ( 'vw1 ' ) 'arg_types= % r , arg_modes= % r , return_type= % r , is_aggregate= % r , ' Database = namedtuple ( 'Database ' , [ ] ) with open ( self.output_file , ' a ' , encoding='utf-8 ' ) as f : `` `` '' SELECT * assert u'Command ' in result [ 1 ] View ( schema= '' x '' ) , results = format_output ( 'Title ' , [ ( 'abc ' , 'def ' ) ] , [ 'head1 ' , 'head2 ' ] , if not word_before_cursor.startswith ( 'pg_ ' ) : if self.name.islower ( ) or self.name [ 0 ] == ' '' ' help= '' Host address of the postgres database . `` , [ view ( `` User_Emails UE '' ) , view ( `` Functions F '' ) ] } priority_func ( item ) , auto_vertical_output=auto_vertical_output , warn=warn ) 'EntAccLog ON EntAccLog.EntryID = Entries.EntryID ' , -1 ) ] `` INSERT INTO public.orders ( * '' , % ( 'SELECT * FROM users JOIN custom.shipments ON ' , casing = ( 'SELECT ' , 'Orders ' , 'User_Emails ' , 'CUSTOM ' , 'Func1 ' , 'Entries ' , keyring = importlib.import_module ( 'keyring ' ) testdata.columns ( 'users ' ) ) result = get_result ( completer , 'SEL ' ) `` views '' , arg_names= ( `` x '' , ) , `` INSERT INTO OtherTabl ( ID , Name ) SELECT * FROM tabl WHERE `` , def functions_and_keywords ( self , parent='public ' , pos=0 ) : @ then ( 'we see large results in vertical format ' ) TabsProcessor ( char1= ' ' , char2= ' ' ) ] , elif token_v == `` function '' : self.pgspecial , `` `` '' create function func2 ( int , varchar ) `` OutputSettings '' , assert tables == ( ( None , `` Abc '' , `` a '' , False ) , ) `` -u '' , `` -- user '' , `` username_opt '' , help= '' Username to connect to the postgres database . '' if scope == `` insert '' : cmd = '\\dn ' alias ( 'shipments ' ) , `` SELECT * FROM users CROSS JOIN `` , find_prev_keyword ( self.text_before_cursor , n_skip=n_skip ) if `` XDG_CONFIG_HOME '' in os.environ : run_step ( 'twine ' , 'upload ' , 'dist/ * ' ) assert actual1 [ 0 ] [ 3 ] == 'Auto-completion refresh started in the background . ' assert completions_to_set ( arg_types= [ 'integer ' , 'integer ' ] , display_meta='columns ' , @ then ( 'we see database connected ' ) alias ( `` x '' ) , keyring_error_message = dedent ( `` '' '' \ join ( `` EntAccLog EAL ON EAL.EntryID = E.EntryID '' , -1 ) , password=POSTGRES_PASSWORD , with patch.object ( refresher , `` _bg_refresh '' ) as bg_refresh : display= ' * ' self.superuser = db_parameters.get ( 'is_superuser ' ) == ' 1 ' 'dT ' : Datatype , @ pytest.mark.parametrize ( 'tbl_alias ' , ( `` , 'foo ' , ) ) for row in self._columns ( kinds= [ ' r ' ] ) : return ( cmd = `` \\dn `` title = 'List of databases ' '| head1 | head2 | ' , 'SELECT * FROM tabl1 t1 , tabl2 t2 WHERE t1 . ' , `` INSERT '' , ( completion.display_text , completion.display_meta_text ) if `` , '' in self.host : [ view ( `` user_emails ue '' ) , view ( `` functions f '' ) ] `` `` '' SELECT * FROM foo.bar baz or text.endswith ( r '' \e '' ) # Special Command cased_funcs click.secho ( str ( e ) , err=True , fg= '' red '' ) ( 'public ' , ' a ' ) , ( 'public ' , ' b ' ) , ( 'schema1 ' , ' c ' ) ] ) keyring.errors.KeyringError , View ( schema= ' x ' ) , user=user , assert set ( suggestions ) == cols_etc ( ' a ' , last_keyword='SELECT ' ) Completion ( text= '' DATABASE '' , display_meta='keyword ' ) , '\tuser : % r ' `` TableReference '' , [ `` schema '' , `` name '' , `` alias '' , `` is_function '' ] 'WITH cte AS ( SELECT foo FROM bar ) SELECT * FROM cte c WHERE c. ' , sql = `` SELECT abc , 99 FROM xxx '' f.read ( ) .decode ( 'utf-8 ' ) ) .group ( 1 ) ) ) return ( View ( schema= '' f '' ) , @ click.option ( ' -- single-connection ' , 'single_connection ' , is_flag=True , [ ( `` public '' , `` d '' , `` e '' , `` integer '' , False , None ) ] [ `` x '' , `` y '' ] , context.cli.sendline ( `` \\connect postgres '' ) self.multiline_mode = c [ `` main '' ] .get ( `` multi_line_mode '' , `` psql '' ) pgspecial_logger = logging.getLogger ( 'pgspecial ' ) name_join ( ' y.id = x.id ' ) ] ) `` COPY '' , ' '' select '' .id , `` select '' . `` localtime '' , `` select '' . `` ABC '' , ' or ( # To all the vim fans out there passwd='foo ' , or not exception_formatter ) : ( 'class : bottom-toolbar ' , ' ( Semi-colon [ ; ] will end the line ) ' ) ) current = `` 'NONE ' : logging.CRITICAL alias ( `` users '' ) , if settings.get ( 'single_connection ' ) : cn = connect ( host=hostname , user=username , database=dbname , result = get_result ( completer , `` ) [ `` SELECT * FROM foo where created > now ( ) - `` , `` select * from foo where bar `` ] , context.conf [ `` host '' ] , def __init__ ( self , database=None , user=None , password=None , host=None , Table ( schema=parent ) , suggestions = suggest_type ( sql [ : i + 1 ] , sql [ : i + 1 ] ) Token.SelectedText : 'selected ' , Function ( schema=None ) , [ column ( 'id ' ) , column ( 'email ' ) ] ) suggestions = suggest_type ( `` \d myschema . `` , `` \d myschema . '' ) completer.get_completions ( # check for black code compliance , 3.6 only return sorted ( completions , key=operator.attrgetter ( `` text '' ) ) assert set ( tables ) == set ( [ ( None , 'abc ' , ' a ' , False ) , function ( text = 'SELECT from users ' return [ ( None , None , None , `` Auto-completion refresh restarted . '' ) ] testdata.columns_functions_and_keywords ( 'select ' ) ) if not click.confirm ( ' -- - { } '.format ( question ) , default=False ) : function ( `` Func1 ( ) F '' ) , [ Datatype ( schema=None ) , Table ( schema=None ) , Schema ( ) ] os.environ [ `` PAGER '' ] = `` { 0 } { 1 } { 2 } '' .format ( txt = named_query_regex.sub ( `` '' , txt ) table ( 'users ' ) , timing 'signature_arg_style ' , ' { arg_name } { arg_type } ' _logger.debug ( 'Casing Query . sql : % r ' , query ) connection = db_connection ( '_test_db ' ) '_custom_fun ( ) cf ' , 'Custom_Fun ( ) CF ' , 'Custom_Func1 ( ) CF ' , 'custom_func2 ( ) cf ' name_join ( `` y.price = x.price '' ) , type=click.Path ( dir_okay=False ) , self.is_window , # check for pep8 errors , only looking at branch vs master . If there are errors , show diff and return an error code . print ( 'package root : ' , context.package_root ) ' '' ) 'select { } '.format ( ' , '.join ( [ str ( n ) for n in range ( 1 , 50 ) ] ) ) ) is_set_returning , result = get_result ( completer , 'SELECT from `` select '' ' , len ( `` SELECT `` ) ) table_refs=tables , `` `` '' -- blah blah blah search_ignore_case=True , multiline = usage == 'call ' and len ( args ) > self.call_arg_oneliner_max port , `` Password for % s '' % user , hide_input=True , show_default=False , type=str return self.parsed.token_first ( ) .value.lower ( ) == `` insert '' ForeignKey = namedtuple ( 'ForeignKey ' , [ 'parentschema ' , 'parenttable ' , return result [ 0 ] if result else `` `` Programming Language : : Python : : 3.6 '' , refresh_callback = lambda : self.refresh_completions ( persist_priorities= '' all '' ) if cmd in ( `` \\c '' , `` \\connect '' ) : text_before_cursor = text_before_cursor [ : -len ( word_before_cursor ) ] Special = namedtuple ( 'Special ' , [ ] ) name=obj , schema= ( self._maybe_schema ( schema=sch , parent=schema ) ) `` bar '' , `` bar '' , `` '' , `` baz.com '' , `` '' , `` '' , application_name= '' cow '' ( None , 'def ' , 'd ' , False ) ] ) [ 'func2 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] ] , PGCli , 'SELECT * FROM foo JOIN bar ' False ] run ( executor , 'create materialized view mvw1 AS SELECT * FROM tbl1 ' ) `` SELECT foo bar `` , 'all_punctuations ' : re.compile ( r ' ( [ ^\s ] + ) $ ' ) , name_join ( 'orders.id = users.id ' ) , text='\\timing ' , start_position=-2 , display_meta='Toggle timing of commands . ' ) ] ) 'INSERT INTO foo SELECT DISTINCT ' obfuscate_process_password , format_output , PGCli , OutputSettings , COLOR_CODE_REGEX `` select a.x , b.y from abc a join bcd b on a.id = b.id AND a.id2 = `` , ( `` class : bottom-toolbar.transaction.valid '' , `` Transaction '' ) identifier 'id , users.parentid , users.email , users.first_name , users.last_name ' ) , `` EntryTags '' , completer , text , expected run_step ( `` git '' , `` reset '' ) less_chatty=less_chatty , prompt=prompt , prompt_dsn=prompt_dsn , alias ( `` o '' ) , 'SELECT * FROM tabl WHERE foo IN ( bar , ' , result = executor.view_definition ( `` mvw1 '' ) run ( executor_copy , `` '' '' create table test ( a text ) '' '' '' ) `` select * from a ; select * from ; select * from c '' , text = `` create v '' self.call_arg_oneliner_max = settings.get ( `` call_arg_oneliner_max '' , 2 ) return self.find_matches ( word_before_cursor , tables , meta='table ' ) os_environ_pager = os.environ.get ( 'PAGER ' ) ' '' JoinCondition = namedtuple ( `` JoinCondition '' , [ `` table_refs '' , `` parent '' ] ) `` { 0 } ON { 0 } . { 1 } = { 2 } . { 3 } '' .format ( elif os.environ.get ( 'PGSERVICE ' , None ) : pgexecute = PGExecute ( database , user , passwd , host , port , `` -- single-connection '' , logger.error ( 'Unhandled style / class name : % s ' , token ) return [ ( `` class : prompt '' , prompt ) ] `` -c '' , `` -- confirm-steps '' , action= '' store_true '' , dest= '' confirm_steps '' , qualifiable=True ) , wrappers.expect_exact ( context , context.conf [ `` pager_boundary '' ] + `` \r\n '' , timeout=5 ) self.cli_style = c [ 'colors ' ] context.logfile.getvalue ( ) ' { python } -c `` { startup } '' '.format ( assert result [ 0 ] == table ( 'EntryTags ' , -2 ) `` CREATE TABLE foo ( bar INT , baz `` , suggestions = suggest_type ( sql , `` SELECT t1 . '' ) ver = _version_re.search ( f.read ( ) ) .group ( `` version '' ) self.generate_casing_file = settings.get ( `` generate_casing_file '' ) Keyword ( last_keyword ) , Completion ( text= '' SYSTEM '' , display_meta='keyword ' ) , 'bigint_array | { } ' , description = 'CLI for Postgres Database . With auto-completion and syntax highlighting . ' Table ( schema='t2 ' ) , assert suggestions == ( Keyword ( ) , ) cn = create_cn ( hostname , password , username , 'postgres ' , port ) context.package_root , 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) ) FromClauseItem , Function , Datatype , Alias , JoinCondition , Join ) db_name = getattr ( context , `` currentdb '' , context.conf [ 'dbname ' ] ) ( `` x '' , ( `` abc '' , `` def '' ) , start1 , stop1 ) , print ( 'Home : http : //pgcli.com ' ) join ( ' '' Users '' ON `` Users '' .UserID = Users.ID ' ) , wrappers.expect_pager ( context , dedent ( `` '' '' \ 'Auto-completion refresh started in the background . ' ) ] print ( ' -- - Skipping ... ' ) assert suggestions == ( Alias ( aliases= ( `` a '' , `` b '' ) ) , ) testdata.columns ( `` set_returning_func '' , typ= '' functions '' ) config_full_path ) Function ( schema=None ) , assert set ( executor.tables ( ) ) > = set ( `` sep_title '' : `` RECORD { n } '' , @ when ( 'we launch dbcli using { arg } ' ) result.append ( ( 'class : bottom-toolbar ' , ' [ F4 ] Emacs-mode ' ) ) `` select abc.x , bcd.y from abc join bcd on `` , suggestions = suggest_type ( 'TRUNCATE ' , 'TRUNCATE ' ) arg = `` -- port= { } '' .format ( context.conf [ `` port '' ] ) suggestions = suggest_type ( `` SELECT FROM sch.tabl '' , `` SELECT `` ) prompt_passwd , password=None , keyring_error_message = dedent ( alias ( ' x ' ) , ( `` SELECT DISTINCT FROM tbl x JOIN tbl1 y '' , `` SELECT DISTINCT '' , `` SELECT '' ) , self.superuser = db_parameters.get ( `` is_superuser '' ) == `` 1 '' 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , expected = join ( `` users ON users.id = u.userid '' , -len ( last_word ) ) cmd = [ 'pgcli ' , ' -- list ' ] return [ ( None , None , None , message , `` , True , True ) ] Keyword ( last_keyword ) override_style = Style ( [ ( 'bottom-toolbar ' , 'noreverse ' ) ] ) casing_file = config [ 'main ' ] [ 'casing_file ' ] views = self.populate_schema_objects ( suggestion.schema , 'views ' ) '- [ RECORD 2 ] -- -- -- -- -- -- -- -- -- -- -- -- - ' , from utils import ( POSTGRES_HOST , POSTGRES_PORT , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , SELECT * FROM unnest ( current_schemas ( true ) ) ' '' def test_suggested_cased_always_qualified_column_names ( assert remainder.strip ( ) == 'SELECT * FROM a ' if identifier.ttype is Keyword and identifier.value.upper ( ) == `` FROM '' : self.dbname = dsn_parameters.get ( 'dbname ' ) ( testdata.columns_functions_and_keywords ( `` users '' ) ) 'all_punctuations ' ) .startswith ( ' ( ' ) : `` keyword_casing '' : keyword_casing , text = `` SELECT from users '' Join , `` EntryTitle '' , 'enable_pager ' ) and `` on '' or `` off '' ) 'vi ' : vi , 'SELECT * FROM foo WHERE bar AND NOT EXISTS ( SELECT * FROM ' , tables = stmt.get_tables ( `` before '' ) col_list = `` id , u.parentid , u.email , u.first_name , u.last_name '' with mock.patch ( `` pgcli.main.click.echo '' ) as mock_echo , mock.patch ( text=word_before_cursor , cursor_position=len ( word_before_cursor ) def __init__ ( self , force_passwd_prompt=False , never_passwd_prompt=False , return self.find_matches ( word_before_cursor , cmds , mode='strict ' ) 'SELECT x : : ' , if not ipython.find_line_magic ( 'sql ' ) : author= '' Pgcli Core Team '' , 'casing_file ' : get_casing_file ( c ) , Keyword ( `` SELECT '' ) , Join ( tbls , None ) , fallback = 'SELECT * FROM current_schemas ( true ) ' `` select a.x , b.y from abc a join bcd b on a.id = b.id OR `` , reserved_words = set ( get_literals ( `` reserved '' ) ) `` dt '' : Table , def ColumnMetadata ( fg='red ' testdata.schemas ( ) + aliased_rels ) cursor.execute ( 'SELECT NULL : :date ' ) if __name__ == '__main__ ' : cfg.merge ( ConfigObj ( expanduser ( usr_cfg ) , interpolation=False , encoding= '' utf-8 '' ) ) matches = self.find_matches ( word_before_cursor , types , meta= '' datatype '' ) 'INFO ' : logging.INFO , flattened = flattened [ : len ( flattened ) - n_skip ] context.conf [ `` user '' ] , if ' : // ' in process_title : cur.execute ( sql , ( spec , ) ) @ pytest.mark.parametrize ( 'term_height , term_width , text , use_pager ' , pager_on_test_data , ids=test_ids ) 'select * from abc . `` def '' ' , function_body_pattern = re.compile ( r ' ( \ $ . * ? \ $ ) ( [ \s\S ] * ? ) \1 ' , re.M ) collist = `` , `` .join ( assert suggestions == ( Function ( schema='myschema ' , usage='special ' ) , ) assert set ( suggestions ) == cols_etc ( `` tabl '' , `` sch '' , last_keyword= '' SELECT '' ) `` INFO '' : logging.INFO , dollar_quote_regex = re.compile ( r'^\ $ [ ^ $ ] * \ $ $ ' ) with patch ( `` pgcli.completion_refresher.PGExecute '' , pgexecute_class ) : `` SELECT * FROM users INNER JOIN orders USING ( id , '' , comp.extend_columns ( tbl_cols , kind='tables ' ) context.cli.sendline ( `` select * from a ; '' ) @ when ( 'we save a named query ' ) 'You are now connected to database `` % s '' as ' print ( `` Closed connection : { 0 } . `` .format ( cn.dsn ) ) [ schema ( `` PUBLIC '' ) ] + cased_aliased_rels self.pgexecute.connect ( database=db , user=user , host=host , context.package_root , 'tests/features/fixture_data ' ) assert u ' é ' in run ( executor , `` select * from unicodechars '' , prompt_text = ( ORDER BY 1 , 2 , att.attnum '' ' `` select a.x , b.y from abc a join bcd b on `` , cfg [ 'casing ' ] = casing View , for ( func , metas ) in self.dbmetadata [ `` functions '' ] [ sch ] .items ( ) sql = r'\ { command } { verbose } { pattern } '.format ( * * locals ( ) ) click.secho ( `` cancelled query '' , err=True , fg='red ' ) click.secho ( `` Reconnecting ... '' , fg= '' green '' ) ) , cols = ( ' '' select '' .id , `` select '' .insert , `` select '' . `` ABC '' , ' `` ORDER BY '' , host=hostname , user=username , database=dbname , password=password , port=port `` The result set has more than % s rows . '' % threshold , fg= '' red '' assert tables == ( ( None , 'Abc ' , None , False ) , ) run ( executor , `` SELECT ( CAST ( '00:00:00 ' AS time ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] callback , click.secho ( alias + `` : `` + cfg [ `` alias_dsn '' ] [ alias ] ) `` PGSERVICEFILE '' : os.environ.get ( `` PGSERVICEFILE '' , None ) , assert get_result ( completer , action + ' FUNCTION set_ret ' ) == [ text = `` function ( f ) table_refs= ( TableReference ( schema , table , alias , is_function ) , ) , no_qual = [ 'if_more_than_one_table ' , 'never ' ] `` Orders '' , load_config , config_location , ensure_dir_exists , get_config ) tables = stmt.get_tables ( `` before '' ) sql = `` '' '' select * from t1 return ( isinstance ( other , self.__class__ ) `` ALTER TABLE foo DROP COLUMN `` , @ when ( 'we drop database ' ) if mode in ( `` o '' , `` b '' , `` t '' ) ] ) assert '\n'.join ( results ) == '\n'.join ( expected ) return [ token_type , style_value = parse_pygments_style ( token , style , cli_style ) metadata = self.dbmetadata [ 'functions ' ] view = partial ( completion , `` view '' ) prefix = `` '' if suggestion.parent else ltbl.ref + `` . '' os_environ_pager position = len ( `` SEL '' ) Schema ( ) , for match in 'select * from abc'.split ( ' ' ) : aliases= ( `` : q '' , ) , 'SELECT * FROM users u1 JOIN users u2 USING ( email ) JOIN user_emails ue USING ( ) ' , Token.SelectedText : `` selected '' , 'public ' , 'pg_catalog ' , 'information_schema ' , 'schema1 ' , 'schema2 ' ] ) | \.venv Column ( table_refs= ( ) , qualifiable=True ) , print ( `` Server : PostgreSQL '' , self.pgexecute.server_version ) `` SELECT * FROM ( SELECT a , FROM abc '' , `` SELECT * FROM ( SELECT a , `` `` SELECT u.name , o.id FROM users u JOIN orders o ON `` , 'SELECT p.id , p. from custom.products p ' , cased_users2_col_names = [ `` UserID '' , `` UserName '' ] `` db_changed '' , # True if any subquery changed the database assert result [ 0 ] == table ( `` EntryTags '' , -2 ) Function ( schema=parent ) , 'Programming Language : : Python : : 3.6 ' , tbls = tuple ( [ ( None , `` foo '' , None , False ) ] ) ( u '' 22200K ....... \u001b [ 0m\u001b [ 91m ... .......... ... \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m ...... ......... \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m ...... 50 % 28.6K 12m55s '' , 78 ) , return None , `` log_file = self.config [ 'main ' ] [ 'log_file ' ] os.environ [ 'PAGER ' ] = os_environ_pager 'SELECT foo FROM bar ' , local_tables= ( ) , expected = cols_etc ( `` tabl '' , alias= ' '' tabl '' ' , last_keyword= '' WHERE '' ) sql = sql.rstrip ( `` ; '' ) `` SELECT * FROM tabl WHERE `` , pgcli = PGCli ( ( `` upper '' , `` SELECT '' , ( `` '' , `` s '' , `` S '' , `` Sel '' ) ) , `` SELECT 1 : : '' , if new_params [ `` dsn '' ] : completer for val in row p.match ( col.default ) `` INSERT INTO orders ( `` , warnings.filterwarnings ( `` ignore '' , category=UserWarning , module='psycopg2 ' ) cur.execute ( `` 'CREATE DATABASE _test_db '' ' ) with open ( `` pgcli/__init__.py '' , `` rb '' ) as f : _logger.debug ( 'Suggestion type : % r ' , suggestion_type ) assert completions_to_set ( result ) == completions_to_set ( testdata.types ( `` custom '' ) ) result = completions_to_set ( `` Output equal to terminal width '' , _version_re = re.compile ( r'__version__\s+=\s+ ( . * ) ' ) host , _ , _ = self.host.partition ( `` , '' ) click.secho ( 'Reconnected ! ' , fg='green ' ) return_type , is_aggregate , is_window , is_set_returning , is_extension , history = 'CREATE VIEW v AS SELECT 1 ' 'users ' : [ 'id ' , 'parentid ' , 'email ' , 'first_name ' , 'last_name ' ] , [ 'custom_func2 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , JOIN v ON ( c.oid = v.v_oid ) ' '' Function ( schema= ' f ' ) , elif `` : // '' in database : os.environ [ `` PGPASSWORD '' ] = context.conf [ `` pass '' ] regex = `` . * ? `` .join ( map ( re.escape , text ) ) whitespace = `` `` elif ( token_v.endswith ( `` join '' ) and token.is_keyword ) or ( '\thost : % r ' for alias in cfg [ `` alias_dsn '' ] : search_ignore_case=True ) `` -- auto-vertical-output '' , `` extract_entry_symbols '' , for name in [ 'json ' , 'jsonb ' ] : Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) , qualifiable=True ) ] ) text = `` SELECT custom.func '' `` SELECT * FROM Users JOIN `` , 'INSERT INTO public.orders ( * ' , types = self.populate_schema_objects ( suggestion.schema , 'datatypes ' ) r'__version__\s+=\s+ ( ? P < quote > [ \ ' '' ] ) ( ? P < version > . * ) ( ? P=quote ) ' 'SELECT * FROM `` Users '' u JOIN uid ' , 'SELECT * FROM `` tabl1 '' t1 , tabl2 t2 WHERE t1 . ' , `` _custom_fun '' , @ click.option ( '-u ' , ' -- user ' , 'username_opt ' , help='Username to connect to the postgres database . ' ) `` ForeignKey '' , # make sure this doesnt trigger special completion function ( `` custom_func1 ( ) '' , -2 ) , ( 'class : bottom-toolbar ' , ' [ F4 ] Vi-mode ( ' + _get_vi_mode ( ) + ' ) ' ) ) 'prompt_toolkit > =2.0.6 , < 2.1.0 ' , assert suggestions == ( Table ( schema='schema_name ' ) , ) FromClauseItem = namedtuple ( 'FromClauseItem ' , 'schema table_refs local_tables ' ) `` sf '' : Function , if context.conf [ `` pass '' ] : def last_word ( text , include='alphanum_underscore ' ) : if first_token.lower ( ) in ( 'use ' , '\\c ' , '\\connect ' ) : `` SELECT U . FROM custom.Users U '' , port='2543,2543,2543 ' ) with mock.patch.object ( cli.pgspecial , `` pager_config '' , PAGER_OFF ) : suggestions = suggest_type ( 'SELECT t1.a , t2 . FROM tabl1 t1 , tabl2 t2 ' , language sql as $ $ select 1 $ $ ' '' ) insert_stmt = parsed [ 0 ] .token_first ( ) .value.lower ( ) == 'insert ' token_start_pos , wrappers.run_cli ( context , run_args=arg.split ( `` = '' ) ) run ( completer = PGCompleter ( join = left.schema + `` . '' + join `` CREATE TABLE foo ( dt d '' , WITH a AS ( SELECT abc def FROM x ) ' '' ) context , context.conf [ 'pager_boundary ' ] + '\r\n ' , timeout=5 ) wrappers.expect_exact ( context , `` Saved . `` , timeout=2 ) `` Output shorter than terminal height '' , tab_insert_text = ' ' * 4 do_qualify = suggestion.qualifiable and { 'always ' : True , 'never ' : False , with mock.patch.object ( PGCli , `` connect '' ) as mock_connect : return [ _cfg ( * p ) for p in product ( casings , filtrs , aliases , qualifys ) ] assert actual1 [ 0 ] [ 3 ] == `` Auto-completion refresh started in the background . '' ) history = 'SELECT * FROM users ; SELECT * FROM orders ; SELECT * FROM users ' return self.find_matches ( word_before_cursor , views , meta= '' view '' ) text = `` SELECT * FROM blog.Entries JOIN blog.et '' 'select * from `` foo ' , assert token_start_pos ( p.tokens , idx ) == len ( `` SELECT * FROM `` ) print ( ' -- - os.environ changed values : -- - ' ) 'SELECT t1 . FROM `` tabl1 '' t1 , `` tabl2 '' t2 ' , 'sqlparse > =0.3.0 , < 0.4 ' , JSONB_AVAILABLE = `` jsonb '' in json_types wrappers.expect_exact ( context , 'Saved . ' , timeout=2 ) ( u '' =\u001b [ m= '' , 2 ) , last_keyword ) : `` `` '' return [ ( None , None , None , message , `` '' , False , True ) ] for typ in datatypes ] passwd = click.prompt ( pattern ) context.cli.sendline ( `` \\n foo '' ) sql = 'WITH a AS ( SELECT abc FROM xxx ) SELECT * FROM a ' alias ( `` shipments '' ) , for t in list ( cols ) [ : -1 ] ) Column , [ '_custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , 'SELECT * FROM `` Users '' u JOIN userid ' , start1 = len ( `` 'WITH addcols ( schema , relname , tbl.alias , `` functions '' , cols ) result = get_result ( completer , `` SELECT from custom.products '' , len ( `` SELECT `` ) ) if arg == ' -- password ' : func_name= '' func3 '' , normalize_ref = lambda ref : ref if ref [ 0 ] == ' '' ' else ' '' ' + ref.lower ( ) + ' '' ' table ( t , pos=-1 ) for t in ( `` users '' , 'custom . `` Users '' ' , `` custom.users '' ) text = '\\dT foo . ' os.environ [ `` PGPORT '' ] = context.conf [ `` port '' ] cfg = { 'settings ' : { } } 'INSERT INTO foo ( x , y , z ) VALUES ( 5 , 6 , 7 ) RETURNING x , y ' , with mock.patch.object ( cli.pgspecial , 'pager_config ' , PAGER_LONG_OUTPUT ) : Token.Toolbar.Search.Text : 'search-toolbar.text ' , View ( schema= '' d '' ) , cols = ( 'EntryID ' , 'EntryTitle ' ) sql = `` 'select a.x , b.y alias ( 'users ' ) , `` foreignkeys '' : [ 'SELECT * FROM `` Users '' u JOIN uid ' , with patch.object ( self.pgexecute.port ) ) return ( @ parametrize ( 'completer ' , completers ( casing=True ) ) `` SELECT u . * FROM users u '' , Token.Toolbar.Arg : 'arg-toolbar ' , tables = [ t for t in tables if not t.name.startswith ( `` pg_ '' ) ] print ( 'Chat : https : //gitter.im/dbcli/pgcli ' ) [ ' b ' , ' b ' ] , `` , False , False , True , False ] ] , if self.output_file and not text.startswith ( ( `` \\o `` , `` \\ ? `` ) ) : result.append ( ( `` class : bottom-toolbar '' , `` [ F4 ] Emacs-mode '' ) ) assert len ( COLOR_CODE_REGEX.sub ( `` '' , text ) ) == expected_length for t , cs in scoped_cols.items ( ) for c in cs ) meta='function ' ) conn = sql.connection.Connection.set ( parsed [ 'connection ' ] ) wrappers.expect_exact ( context , `` Expanded display is '' , timeout=2 ) result.append ( ( 'class : bottom-toolbar.on ' , ' [ F3 ] Multiline : ON ' ) ) context.cli.sendline ( `` \i { 0 } '' .format ( context.tmpfile_sql_help.name ) ) if [ [ `` $ TRAVIS_PYTHON_VERSION '' == `` 3.6 '' ] ] ; then pip install black & & black -- check . ; else echo `` Skipping black for $ TRAVIS_PYTHON_VERSION '' ; fi self.refresh_completions ( persist_priorities= '' all '' ) 'successful ' , # True If all subqueries were successful 'public ' : { `` SELECT foo `` , elif usage == `` call '' and func.has_variadic ( ) : Token.Menu.Completions.Meta : 'completion-menu.meta.completion ' , result = completions_to_set ( get_result ( warn=warn , Column ( table_refs= ( ) , qualifiable=True ) , assert counter.keyword_count ( `` NOSUCHKEYWORD '' ) == 0 context.cli.sendcontrol ( ' c ' ) `` all_punctuations '' : re.compile ( r '' ( [ ^\s ] + ) $ '' ) , settings=self.settings ) `` SELECT from custom.users '' , output_kwargs [ 'preprocessors ' ] = ( align_decimals , ) `` SELECT * FROM users INNER JOIN orders USING ( `` , # Return column names from a set-returning function conn = sql.connection.Connection.get ( parsed [ `` connection '' ] ) function ( `` func2 ( ) '' ) , sugs.append ( JoinCondition ( table_refs=tables , parent=filteredtables [ -1 ] ) ) view ( 'functions f ' ) , 'projects ' : [ 'projectid ' , 'name ' ] `` select '' : [ `` id '' , `` localtime '' , `` ABC '' ] , `` ALTER TABLE foo ALTER COLUMN bar TYPE `` , ( `` public '' , `` users '' , `` id '' , `` public '' , `` Users '' , `` userid '' ) , `` expression '' , assert completions_to_set ( result ) == completions_to_set ( [ alias ( `` x '' ) , alias ( `` y '' ) ] ) result = executor.view_definition ( 'mvw1 ' ) with open ( casing_file , `` r '' ) as f : lexical_priority = ( meta='column ' ) [ 'head1 ' , 'head2 ' ] , suggestion = suggest_type ( `` SELECT MAX ( FROM tbl '' , `` SELECT MAX ( `` ) `` always '' : True , assert result [ 0 ] == table ( 'EntryTags ET ' , -2 ) database=None , Function ( schema='t ' ) , SELECT 1 '' '' '' [ 'set_returning_func ' , [ ' x ' , ' y ' ] , [ 'integer ' , 'integer ' ] , history = `` CREATE VIEW v AS SELECT 1 '' JoinCondition , suffix = self._arg_list_cache [ arg_mode ] [ tbl.meta ] if arg_mode else `` `` head1 | abc '' , assert first.display_text == 'extract_entry_symbols ( _entryid ) ' self.change_db , '\\c ' , '\\c [ onnect ] database_name ' , _logger.debug ( `` Databases Query . sql : % r '' , self.full_databases_query ) arg_types= [ `` integer '' , `` integer '' ] , os.getenv ( 'PGPASSWORD ' , None ) 'public ' : [ elif usage == `` call '' and len ( args ) < 2 : on a.id = `` ' `` datatype '' , function_definition_query = `` '' '' qualifys = qualify or [ `` always '' , `` if_more_than_one_table '' , `` never '' ] ) ( `` text '' , `` ref '' ) , childschema , childtable , childcol ) cols = ( 'SELECT * FROM tabl WHERE ( bar AND ( baz OR ( qux AND ( ' , _logger.debug ( `` Reusing existing pgcli '' ) os.environ [ `` PAGER '' ] = configured_pager join ( `` users u ON u.parentid = Users.id '' ) , [ `` custom_fun '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , Completion ( `` cte2 '' , 0 , display_meta= '' table '' ) , name_join ( `` shipments.id = users.id '' ) , `` function '' , arg_default=arg_default , '配列 | { < null > } ' , parentschema , parenttable , parcol , childschema , childtable , childcol _cfg ( * p ) for p in product ( casings , filtrs , aliases , qualifys ) _logger.debug ( `` Unsuccessful query - ignoring '' ) envvar= '' PGCLIRC '' , text_before_cursor = text_before_cursor [ ctes [ -1 ] .stop : current_position ] Function ( schema= '' t1 '' ) , assert kw.value == 'where ' and stripped == 'select * from foo where ' TableFormat , Function , Column , View , Keyword , NamedQuery , testdata.types ( 'custom ' ) ) expected = Column ( table_refs= ( ( None , 'sessions ' , None , False ) , ) , cased_users_col_names = [ `` ID '' , `` PARENTID '' , `` Email '' , `` First_Name '' , `` last_name '' ] `` style '' : settings.style_output , full_text , text_before_cursor , self.local_tables = isolate_query_ctes ( `` SELECT * FROM users INNER JOIN orders USING ( id , '' , 'foo bar $ $ baz ' , alias ( ' u ' ) , exception_formatter , on_error_resume ) elif token_v == 'set ' : | buck-out `` sql '' , 'user ' : context.config.userdata.get ( context.tmpfile_sql_help = tempfile.NamedTemporaryFile ( prefix='pgcli_ ' ) ' '' % s '' on % s at port `` % s '' . ' elif token_v == 'schema ' : `` childtable '' , Function = namedtuple ( 'Function ' , [ 'schema ' , 'table_refs ' , 'usage ' ] ) is_extension , `` create table schema2.child ( childid int PRIMARY KEY , motherid int REFERENCES schema1.parent ) '' , 'CREATE TABLE foo ( dt d ' , assert result == completions_to_set ( [ comp = PGCompleter ( `` `` , `` -U '' , cur , headers , format_name='vertical ' , column_types=None , * * output_kwargs ) function ( `` func1 ( ) f '' ) , context.cli.sendline ( 'select * from abc ' ) def run ( executor , sql , join=False , expanded=False , pgspecial=None , `` Custom_Fun '' , from .parseutils.utils import ( `` SELECT * FROM `` , assert result > completions_to_set ( [ `` host '' : host , click.echo ( '\n'.join ( output ) , file=f ) exception_formatter=None ) : join = `` { 0 } ON { 0 } . { 1 } = { 2 } . { 3 } '' .format ( text = `` SELECT * FROM blog.e '' 'SELECT * FROM tabl WHERE ( bar > 10 AND ' , TableReference ( None , 'tbl1 ' , ' y ' , False ) , context.package_root , `` test_file_ { 0 } .sql '' .format ( context.conf [ `` vi '' ] ) | \.mypy_cache [ `` _custom_fun '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , callback = functools.partial ( columns_query = `` ' ( `` orders '' , `` id '' ) : `` nextval ( 'orders_id_seq ' : :regclass ) '' , `` parentcolumn '' , `` 配列 | { å , 魚 , текст } '' , def get_tables ( self , scope='full ' ) : if not word_before_cursor.startswith ( `` pg_ '' ) : table ( t ) for t in ( 'Users U ' , ' '' Users '' U ' , 'Orders O ' , ' '' select '' s ' ) context.cli.sendline ( `` 'insert into a ( x , y , z ) values ( 1 , 1.0 , 1.0 ) ; ' '' ) Table = namedtuple ( 'Table ' , [ 'schema ' , 'table_refs ' , 'local_tables ' ] ) Token.Menu.Completions.Completion.Current : `` completion-menu.completion.current '' , > self.prompt_app.output.get_size ( ) .columns Alias ( aliases=aliases ) , 'SELECT DISTINCT ' , stop_pos = len ( complete_event ) ) fk_join ( `` u2.userid = u.id '' ) , [ alias ( ' x ' ) , alias ( ' y ' ) ] ) qualified [ normalize_ref ( rtbl.ref ) ] return ( Column ( table_refs=tables , ( 10 , 10 , '- ' * 10 ) , 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON ' , tables = extract_tables ( `` select a , b from abc '' ) wrappers.expect_exact ( context , 'You are now connected to database ' , timeout=2 ) `` database '' , `` SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = JOIN orders orders2 ON '' , run ( executor , `` insert into binarydata ( c ) values ( decode ( 'DEADBEEF ' , 'hex ' ) ) '' ) tables = extract_tables ( `` update abc set id = 1 '' ) 'Default pager found in PAGER environment variable : `` { } '' '.format ( tables = extract_tables ( 'update abc set id = 1 ' ) filename , sql=query ) `` INSERT INTO orders ( * ) '' , `` foo 'bar baz '' , sql = `` '' '' select a.x , b.y POSTGRES_USER = getenv ( 'PGUSER ' , 'postgres ' ) testdata.builtin_functions ( ) + testdata.keywords ( ) ) `` CUSTOM '' , * * kwargs @ parametrize ( 'completer ' , completers ( casing=False ) ) and self.__dict__ == other.__dict__ ) `` generate_casing_file '' : c [ `` main '' ] .as_bool ( `` generate_casing_file '' ) , ( 'public ' , 'd ' , ' e ' , 'integer ' , False , None ) ] ) timeout=1 , ( None , 'def ' , None , False ) ] ) table ( t , pos=-1 ) for t in ( 'users ' , 'custom . `` Users '' ' , 'custom.users ' ) _logger.debug ( 'New pgcli : % r ' , str ( u ) ) assert set ( executor.view_columns ( ) ) > = set ( [ arg_name + `` : = `` self.host = dsn_parameters.get ( `` host '' ) display=display or text , expected = completions_to_set ( [ schema ( u '' 'public ' '' ) ] ) return ' ( ' + ' , '.join ( '\n ' + a for a in args if a ) + '\n ) ' return Completion ( cols , start_position=pos , display_meta= '' columns '' , display= '' * '' ) `` -c '' , def last_word ( text , include= '' alphanum_underscore '' ) : testdata.from_clause_items ( `` Custom '' , start_position ) pgexecute=None , def columns_functions_and_keywords ( self , tbl , parent= '' public '' , typ= '' tables '' , pos=0 ) : result.append ( ( `` class : bottom-toolbar '' , `` ( [ Esc ] [ Enter ] to execute ] ) `` ) ) Function ( schema= '' a '' ) , run_step ( 'git ' , 'reset ' ) _logger.debug ( `` Columns Query . sql : % r '' , sql ) return ( Function ( schema=schema , usage='special ' ) , ) Token.Toolbar.Search.Text : `` search-toolbar.text '' , run_step ( 'git ' , 'add ' , version_file ) result = get_result ( completer , 'SELECT U . FROM `` Users '' U ' , len ( `` SELECT U . '' ) ) `` products '' : [ `` id '' , `` product_name '' , `` price '' ] , wrappers.run_cli ( if not name.islower ( ) or name in ( `` select '' , `` localtimestamp '' ) : for row in self._relations ( kinds= [ `` v '' , `` m '' ] ) : sql = `` WITH CTE AS ( SELECT F. * FROM Foo F WHERE F.Bar > 23 ) SELECT C. * FROM CTE C WHERE C.FooID BETWEEN 123 AND 234 ; '' completer , 'SELECT E.ei FROM blog.Entries E ' , len ( 'SELECT E.ei ' ) user , keywords = [ `` SELECT '' , `` FROM '' , `` GROUP BY '' ] completer , `` select f. from custom.set_returning_func ( ) f '' , len ( `` select f . '' ) suggestions = suggest_type ( `` INSERT INTO abc ( i '' , `` INSERT INTO abc ( i '' ) `` \\ns abc SELECT `` , if platform.system ( ) ! = `` Windows '' and not platform.system ( ) .startswith ( `` CYGWIN '' ) : return self.find_matches ( word_before_cursor , cmds , mode= '' strict '' ) pgclirc_file=rcfile , local_tables=stmt.local_tables , message = str ( e ) + '\nFile output disabled ' tab_insert_text = `` `` * 4 if `` : // '' in process_title : @ parametrize ( 'completer ' , completers ( casing=True , aliasing=False ) ) `` SELECT * FROM tabl WHERE foo BETWEEN `` , ForeignKey ( * fk ) for fks in metadata [ 'foreignkeys ' ] .values ( ) search_path_query = `` '' '' 'CREATE TABLE foo ( bar INT , baz ' , 'user `` % s '' ' % ( self.pgexecute.dbname , self.pgexecute.user ) ) if 'PGPASSWORD ' in os.environ : `` foo bar $ $ baz '' , warn , os.environ [ 'PGPASSWORD ' ] = context.conf [ 'pass ' ] elif token_v == `` schema '' : sql = `` SELECT * FROM \nxxx '' assert b '' List of databases '' in context.cmd_output keywords = get_literals ( 'keywords ' ) 'INSERT INTO orders ( * ) ' , ( `` public '' , `` b '' , `` z '' , `` text '' , False , None ) , Column ( no_qual = [ `` if_more_than_one_table '' , `` never '' ] wrappers.expect_pager ( context , 'CREATE TABLE\r\n ' , timeout=2 ) `` SELECT foo FROM ( SELECT bar `` , log_level = self.config [ 'main ' ] [ 'log_level ' ] less_chatty , new_params = { 'call_arg_display_style ' , ' { arg_name } ' root_logger.debug ( 'Initializing pgcli logging . ' ) function ( 'custom_fun ( ) ' , -2 ) , Column ( table_refs= ( ( None , `` abc '' , `` a '' , False ) , ) ) , tables_query = `` '' '' y AS ( SELECT ghi , jkl FROM y ) '' '' '' 'SELECT * FROM `` Custom '' . ' , InputMode.NAVIGATION : ' N ' , '配列 | { å , 魚 , текст } ' , if not click.confirm ( 'Are you sure ? ' , default=False ) : dbutils.drop_db ( ] , 'foreignkeys ' : [ [ table ( x ) for x in ( 'orders o ' , ' '' select '' s ' , 'custom.shipments s ' ) ] '- [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- - ' , meta=meta , if scope == 'insert ' : if prev_keyword and prev_keyword.value == ' ( ' : ( tables = self.populate_schema_objects ( suggestion.schema , 'tables ' ) 'ColumnMetadata ' , self.pgspecial.pset_pager ( self.config [ 'main ' ] .as_bool ( suggestions = suggest_type ( 'SELECT a , b FROM tbl1 , ' , schema , table , function , wildcard_expansion , column , `` datatypes '' : [ `` custom_type1 '' , `` custom_type2 '' ] , @ refresher ( 'schemata ' ) ( 'lower ' , 'select ' , ( `` , 's ' , 'S ' , 'Sel ' ) ) , suggestions = suggest_type ( `` select * from ; select * from b '' , `` select * from `` ) `` Programming Language : : SQL '' , _logger.debug ( `` Detected F2 key . '' ) suggestions = suggest_type ( sql , 'SELECT t1 . ' ) POSTGRES_PASSWORD , context.cli.sendline ( '\pset pager off ' ) return `` '' `` foreignkeys '' : { ( ' y ' , ( 'ghi ' , 'jkl ' ) , start2 , stop2 ) ) result = get_result ( completer , 'SELECT FROM ' + table , len ( 'SELECT ' ) ) text = ( 'SELECT * FROM ' ) suggestions = suggest_type ( 'SELECT a , b , FROM tbl ' , 'SELECT a , b , ' ) @ when ( 'we drop table ' ) def list_dict ( pairs ) : # Turns [ ( a , b ) , ( a , c ) ] into { a : [ b , c ] } collection = [ 'api_user ' , 'user_group ' ] help= '' Never prompt for password . `` , completer , 'SELECT U . FROM `` Users '' U ' , len ( 'SELECT U . ' ) return `` result = get_result ( completer , text , position=text.find ( `` `` ) + 1 ) return [ make_cand ( c.name , t.ref ) for t , cols in scoped_cols.items ( ) for c in cols ] context.cli.sendline ( 'create database { 0 } ; '.format ( assert set ( tables ) == set ( [ ( `` abc '' , `` def '' , `` x '' , False ) , ( `` ghi '' , `` jkl '' , `` y '' , False ) ] ) self.pgspecial.timing_enabled = c [ 'main ' ] .as_bool ( 'timing ' ) 'SELECT * FROM tabl WHERE 10 < ' , self.pgspecial.register ( self.quit , '\\q ' , '\\q ' , Token.Output.EvenRow : 'output.even-row ' , database=dbname , result = run ( executor , u '' SELECT d FROM jsontest LIMIT 1 '' , author='Pgcli Core Team ' , @ kb.add ( 'tab ' ) assert tables == ( ( None , 'my_table ' , 'm ' , False ) , ) Table ( schema='bar ' ) ] ) self.pgexecute.search_path ( ) ) name_join ( `` y.id = x.id '' ) , `` \\ # '' , assert completions_to_set ( result ) == completions_to_set ( cased_funcs + cased_users_cols return `` '' col_list = ' x ' text = `` SELECT * FROM blog.et '' assert result == completions_to_set ( sql = 'SELECT * FROM ( SELECT FROM abc ' Completion ( 'cte2 ' , 0 , display_meta='table ' ) , _logger.debug ( 'Tables Query . sql : % r ' , sql ) @ parametrize ( 'completer ' , completers ( filtr=False , aliasing=False , casing=True ) ) testdata.keywords ( ) + testdata.specials ( ) ) == completions_to_set ( result ) on `` '' '' , suggestions = suggest_type ( 'SELECT FROM tabl ' , 'SELECT ' ) join ( ' '' Users '' U ON U.userid = Users.id ' ) , port=POSTGRES_PORT , assert kw.value == ' ( ' if first_token.lower ( ) in ( `` alter '' , `` create '' , `` drop '' , `` commit '' , `` rollback '' ) : joins.append ( Candidate ( join , prio , 'join ' , synonyms=synonyms ) ) parametrize , assert completions_to_set ( result ) == completions_to_set ( [ keyword ( `` SELECT '' , -3 ) ] ) case_sensitive=True , return ( Column ( table_refs=tables , local_tables=stmt.local_tables ) , completer = testdata.get_completer ( { `` keyword_casing '' : keyword_casing } ) '| bigint_array | nested_numeric_array | 配列 | ' , Table ( schema='t1 ' ) , 'SELECT * FROM `` Users '' u JOIN id ' , assert '\n'.join ( expanded_results ) == '\n'.join ( expanded ) self.completer.set_search_path ( self.pgexecute.search_path ( ) ) function ( f ) for f in ( 'Custom_Fun ( ) ' , '_custom_fun ( ) ' , 'Custom_Func1 ( ) ' , 'custom_func2 ( ) ' ) 'select a.x , b.y from abc a join bcd b on a.id = b.id AND a.id2 = ' , `` | bigint_array | nested_numeric_array | 配列 | '' , assert set ( suggestions ) == cols_etc ( `` a '' , last_keyword= '' SELECT '' ) if prev_prev_tok and prev_prev_tok.normalized == `` INTO '' : start_pos = len ( `` ' -- blah blah blah username_opt , `` SELECT * FROM users u1 JOIN user_emails ue USING ( ) JOIN users u2 ue USING ( first_name , last_name ) '' , cur.execute ( sql , ( spec , ) ) `` -h '' , normalize_ref = lambda ref : ref if ref [ 0 ] == ' '' ' else ' '' ' + ref.lower ( ) + ' '' ' assert result > completions_to_set ( y AS ( SELECT ghi , jkl FROM y ) ' '' ) 'SELECT * FROM ' , 'dsn ' : new_params [ 'dsn ' ] , name_join ( `` orders.id = users.id '' ) , ] 'orders ' , for fk in fks ] msg += '\nCurrently set to : % s ' % self.table_format os.path.expanduser.side_effect = IOError ( `` test '' ) arg_defaults sql = `` ' -- blah blah blah `` select * from foo where bar = 1 and baz or `` , text = `` SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON x.id = `` ( 10 , 10 , `` - '' * 10 ) , `` cli_helpers [ styles ] > = 1.2.0 '' , pgclirc_file=pgclirc , print ( 'reading fixture data : { } '.format ( fixture_dir ) ) result.append ( 'select * from `` abc '' . `` def '' ' , assert tables == ( ( None , `` abc '' , `` abc '' , False ) , ) `` natural join '' , `` query '' , # The entire text of the command all_success , run_step ( 'git ' , 'push ' , ' -- tags ' , 'origin ' ) sql = `` WITH a AS ( SELECT abc FROM xxx ) SELECT * FROM a '' with patch.object ( executor , 'host ' , 'localhost.example.org ' ) : 'total_time ' , # Time elapsed executing the query and formatting results assert ( column ( 'id ' ) in result ) for sch , funcs in metadata [ 'functions ' ] .items ( ) `` SELECT * FROM foo WHERE bar AND NOT EXISTS ( S '' , assert funcs > = set ( tables = ( ( None , 'foo ' , None , False ) , ) string = string.replace ( '\\ # ' , `` # '' if ( self.pgexecute.superuser ) else `` > '' ) self.write_to_file , elif token_v in ( 'select ' , 'where ' , 'having ' , 'order by ' , 'distinct ' ) : sql = `` SELECT abc , def FROM xxx '' 'You are connected to database `` % s '' as user ' collist = sep.join ( self.case ( c.completion ) 'meta_changed ' , # True if any subquery executed create/alter/drop assert completions_to_set ( result ) == completions_to_set ( [ alias ( `` u '' ) , alias ( `` o '' ) ] ) text = `` \\dT `` context.cli.sendline ( `` '' '' insert into a ( x ) values ( 'xxx ' ) ; '' '' '' ) print ( `` -- - Skipping ... '' ) return [ ( None , None , None , reverse=True ) `` `` '' INSERT INTO public.orders ( orderid ) `` most_punctuations '' : re.compile ( r '' ( [ ^\ . ( ) : ,\s ] + ) $ '' ) , | _build : : table ( ' '' select '' s ' ) , logger.error ( `` Unhandled style / class name : % s '' , token ) execution , qual = [ `` if_more_than_one_table '' , `` always '' ] string = string.replace ( `` \\dsn_alias '' , self.dsn_alias or `` '' ) description = `` CLI for Postgres Database . With auto-completion and syntax highlighting . '' assert set ( suggestions ) == cols_etc ( ' b ' , last_keyword='SELECT ' ) 'mutated ' , # True if any subquery executed insert/update/delete table , context.response = { `` database_name '' : context.conf [ `` dbname_tmp '' ] } 'click > = 4.1 ' , self.completer.search_path ) arg_type=NO_QUERY , assert set ( executor.table_columns ( ) ) > = set ( [ ] ' '' ) , function ( Function , txt = named_query_regex.sub ( `` , txt ) suggestions = suggest_type ( `` \d xxx '' , `` \d xxx '' ) `` SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = `` , __version__ = `` 2.1.0 '' schema = partial ( completion , 'schema ' ) suggestions = suggest_type ( 'select * from a ; select from b ' , k : unicode2utf8 ( v ) for k , v in new_params.items ( ) if v join=True , expanded=expanded ) os.environ [ `` COVERAGE_PROCESS_START '' ] = os.path.join ( context.package_root , func_name= '' func4 '' , search_path_query = `` ' `` confirmed , it will be skipped . '' ) `` missing_value '' : settings.missingval , if pgcli.multiline_mode == `` safe '' : and len ( prompt ) > self.max_len_prompt settings=settings ) TableMetadata = namedtuple ( `` TableMetadata '' , `` name columns '' ) Database = namedtuple ( `` Database '' , [ ] ) '\\conninfo ' , 'Get connection details ' ) pgexecute = PGExecute ( database , user , passwd , host , port , dsn , * * kwargs ) name_join ( `` o.email = u.email '' ) , 'License : : OSI Approved : : BSD License ' , [ l for l , prev in zip ( tbl , ' _ ' + tbl ) if prev == ' _ ' and l ! = ' _ ' ] ) is_aggregate , is_window , is_set_returning , is_extension , arg_defaults _Candidate = namedtuple ( os.environ [ `` XDG_CONFIG_HOME '' ] = context.env_config_home @ parametrize ( 'completer ' , completers ( casing=False , filtr=False , aliasing=False ) ) if token_v == `` from '' or is_join : [ Column ( table_refs= ( ( None , `` tbl '' , None , False ) , ) , qualifiable=True ) ] 'INSERT INTO users ( ) SELECT * FROM orders ; ' , wrappers.expect_exact ( context , `` : '' , timeout=2 ) if arg == `` -- password '' : table_refs=tables , parent=None ) ) 'SELECT U . FROM `` custom '' .USERS U ' , databases_query = `` ' `` integer '' , tables = extract_tables ( `` select a , from abc '' ) self.qualify_columns = settings.get ( `` qualify_columns '' , `` if_more_than_one_table '' ) suggestions = suggest_type ( '\\dn ' , '\\dn ' ) _logger.debug ( `` View Definition Query . sql : % r\nspec : % r '' , sql , spec ) def views ( self , parent='public ' , pos=0 ) : Path , arg_modes=None , return_type=None , is_aggregate=False , is_window=False , [ Datatype ( schema= '' bar '' ) , Table ( schema= '' bar '' ) ] assert set ( suggestions ) == cols_etc ( `` func '' , is_function=True , last_keyword= '' SELECT '' ) assert tables == ( ( 'foo ' , 'bar ' , None , True ) , ) alias , c ( left.col ) , rtbl.ref , c ( right.col ) join=True , as $ $ select 1 , 2 from generate_series ( 1,5 ) $ $ ; ' '' ) `` User_Emails '' , default=False , assert result [ :2 ] == [ table ( 'Entries E2 ' , -1 ) , join ( `` users '' , lastword = last_word ( word_before_cursor , include='most_punctuations ' ) 'Programming Language : : Python : : 3.5 ' , 'Programming Language : : Python : : 2 ' , table ( t ) for t in ( 'users u ' , ' '' Users '' U ' , 'orders o ' , ' '' select '' s ' ) for func in ( functions or [ ] ) : re.compile ( pattern ) for k , v in iteritems ( self.completer.pgspecial.commands ) list_dsn , warn ) : `` ALTER TABLE foo ALTER COLUMN bar '' , return arg.decode ( 'utf-8 ' ) help= '' list of DSN configured into the [ alias_dsn ] section of pgclirc file . `` , `` FROM '' , def cli ( dbname , username_opt , host , port , prompt_passwd , never_prompt , for sch , datatypes in metadata [ 'datatypes ' ] .items ( ) prev_keyword , self.text_before_cursor = \ ( u '' -\u001b ] 23\u0007- '' , 2 ) , ' '' ) + context.conf [ 'pager_boundary ' ] , ' % ( asctime ) s ( % ( process ) d/ % ( threadName ) s ) ' result = get_result ( completer , `` '' ) return float ( 'Infinity ' ) , -1 password=password , port=port ) FromClauseItem ( schema='sch ' , table_refs=tbls ) , if hasattr ( cur , `` description '' ) : if editor_command == '\\ev ' : fixture_dir = os.path.join ( testdata.schemas ( ) @ then ( 'we see the named query deleted ' ) if arg_mode == 'call ' : Column ( table_refs= ( ( None , `` tabl '' , `` t '' , False ) , ) ) , assert run ( executor , `` SELECT ( CAST ( '4713-01-01 BC ' AS date ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ lines = text.split ( '\n ' ) os.path.dirname ( os.path.dirname ( os.path.dirname ( __file__ ) ) ) ) PROMPT_STYLE_TO_TOKEN = { casing_prefs = `` \n '' .join ( executor.casing ( ) ) `` + -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- + '' , arg_defaults=None , ' $ a $ $ $ $ a $ ' , } 'SELECT U . FROM `` custom '' .USERS U ' , context.response = { tables = tuple ( [ ( None , `` foo '' , None , False ) , ( None , `` bar '' , None , False ) ] ) ( fk , rtbl , rcol ) `` types '' , git+https : //github.com/hayd/pep8radius.git assert result [ 0 ] == table ( `` Entries '' , -1 ) database = 'postgres ' 'SELECT U . FROM custom.USERS U ' , Column ( table_refs=stmt.get_tables ( 'insert ' ) , context='insert ' ) , @ then ( 'we see record inserted ' ) print ( 'Time : % 0.03fs ( % s ) , executed in : % 0.03fs ( % s ) ' % ( query.total_time , table ( ' '' Users '' U ' ) , context.config.userdata.get ( `` pg_cli_command '' , None ) 'alphanum_underscore ' : re.compile ( r ' ( \w+ ) $ ' ) , `` blog '' : [ ipython.register_magic_function ( pgcli_line_magic , 'line ' , 'pgcli ' ) pep8radius master -- docformatter -- diff -- error-status ( JoinCondition ( table_refs=tables , parent=None ) , Alias ( aliases= ( `` a '' , `` b '' ) ) ) `` custom_func2 ( ) '' , 'Quit pgcli . ' , arg_type=NO_QUERY , case_sensitive=False , assert run ( executor_copy , `` '' '' select * from test '' '' '' , join=True ) == dedent ( self.pgspecial.register ( self.execute_from_file , '\\i ' , '\\i filename ' , function ( 'custom_func2 ( ) ' , -2 ) ] ) return sql.endswith ( `` ; '' ) and not is_open_quote ( sql ) True , sslcert='my.pem ' , passwd = click.prompt ( 'Password for % s ' % user , `` never_prompt '' , word_before_cursor , NamedQueries.instance.list ( ) , meta= '' named query '' } , assert tables == ( ( `` abc '' , `` def '' , ' '' def '' ' , False ) , ) 'SELECT * FROM foo JOIN bar USING ( barid ) JOIN ' def find_matches ( self , text , collection , mode='fuzzy ' , meta=None ) : 'SELECT * FROM foo WHERE bar AND NOT EXISTS ( ' , qualifiable=True ) completer , 'SELECT * FROM Functions WHERE function : text ' [ : l ] or status == ext.TRANSACTION_STATUS_INTRANS assert tables == ( ( None , `` my_table '' , `` m '' , False ) , ) style = pygments.styles.get_style_by_name ( 'native ' ) suggestions = suggest_type ( '\\d ' , '\\d ' ) testdata.columns_functions_and_keywords ( `` products '' , `` custom '' ) start2 = len ( start1 = len ( in enumerate ( suggestion.table_refs ) ) if item.ttype is DML and item.value.upper ( ) in ( 'SELECT ' , 'INSERT ' , for match in `` select * from abc '' .split ( `` `` ) : function ( '_custom_fun ( ) cf ' ) , [ 'integer ' , 'text ' ] , [ ' i ' , ' o ' ] , `` , False , False , True , False ] , `` SELECT * FROM ( S '' , 'select * from foo where bar ' , `` `` '' commit_for_release ( `` pgcli/__init__.py '' , ver ) @ then ( 'we see list of databases ' ) result = run ( executor , `` invalid syntax ! `` , exception_formatter=exception_formatter ) os.environ [ `` PGDATABASE '' ] = context.conf [ `` dbname '' ] [ keyword ( 'SELECT ' , -3 ) ] ) position = len ( 'SELECT p. * ' ) select * from abc inner join def using ( col1 , `` ' , tables = extract_tables ( 'select a , from abc ' ) `` childcolumn '' , run ( executor , 'create schema schema1 ' ) arg_type=NO_QUERY , case_sensitive=True , aliases= ( ' : q ' , ) ) is_set_returning=True , v : k for k , v in TOKEN_TO_PROMPT_STYLE.items ( ) if name and ( port= '' 2543,2543,2543 '' , InputMode.INSERT : `` I '' , assert set ( suggestions ) == set ( `` insert into hij select * from abc inner join def using ( `` , arg_names , for c in cols humanize.time.naturaldelta ( tables = extract_tables ( `` SELECT * FROM my_table AS m WHERE m.a > 5 '' ) run ( executor , `` 'create table test ( a text ) ' '' ) JSON_AVAILABLE = `` json '' in json_types username , display=display ( `` public '' , `` a '' , `` x '' , `` text '' , False , None ) , table ( `` users u '' ) , return ( Function ( schema=schema , usage= '' special '' ) , ) for x in self.metadata.get ( `` tables '' , { } ) .get ( parent , [ ] ) dest= '' dry_run '' , `` foo bar $ $ baz $ $ '' , arg = ' -- port= { } '.format ( context.conf [ 'port ' ] ) `` WITH cte AS ( SELECT foo FROM bar ) SELECT * FROM cte c WHERE c. '' , 'keyword_casing ' : keyword_casing , tbl_cols.extend ( [ self._make_col ( sch , tbl , col ) `` Custom '' : [ [ `` func4 '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] ] , return None , `` '' completer , `` SELECT u.id , u. from users u '' , len ( `` SELECT u.id , u . '' ) assert tables == ( ( None , `` Abc '' , None , False ) , ) for sch , tbls in metadata.get ( `` views '' , { } ) .items ( ) : start_pos = len ( user=None , pgspecial.register ( extras_require= { `` keyring '' : [ `` keyring > = 12.2.0 '' ] } , context.cli.sendline ( '\o { 0 } '.format ( configured_pager = config [ `` main '' ] .get ( `` pager '' ) if item.lower ( ) [ : len ( text ) + 1 ] in ( text , text + `` `` ) : synonyms = [ @ when ( u'we query `` select 123456 '' ' ) result = executor.view_definition ( `` there_is_no_such_view '' ) with mock.patch.object ( cli.pgspecial , 'pager_config ' , PAGER_ALWAYS ) : full_text = full_text [ cte.start : cte.stop ] 'select * from `` abc '' .def ' , ORDER BY 1 `` ' self.call_arg_oneliner_max = settings.get ( 'call_arg_oneliner_max ' , 2 ) os.environ [ 'PGUSER ' ] = context.conf [ 'user ' ] meta_changed , elif token_v == 'as ' : self.full_text if scope == 'full ' else self.text_before_cursor ) context.cli.sendline ( '\ ? ' ) if mode in ( ' i ' , ' b ' , ' v ' ) # IN , INOUT , VARIADIC 'SELECT * FROM abc a JOIN def d ON a.id = d.id AND a . ' , if prompt is not None if log_file == 'default ' : `` humanize > = 0.5.1 '' , collection = [ 'user_action ' , ' '' user '' ' ] completer.extend_relations ( executor.tables ( ) , kind='tables ' ) `` - [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- - '' , return [ ( None , None , None , 'Auto-completion refresh restarted . ' ) ] `` user '' : context.config.userdata.get ( install_requirements.append ( `` setproctitle > = 1.1.9 '' ) [ schema ( 'PUBLIC ' ) ] + cased_aliased_rels ) with patch.object ( executor , 'host ' , 'localhost1.example.org , localhost2.example.org ' ) : } , assert set ( tables ) == set ( [ ( None , `` Abc '' , `` a '' , False ) , ( None , `` Def '' , `` d '' , False ) ] ) comp.extend_relations ( views , kind= '' views '' ) `` SELECT * FROM foo WHERE EXISTS ( S '' , ' [ F2 ] Smart Completion : ON ' ) ) `` SELECT * FROM ( SELECT t. FROM tabl t '' , `` SELECT * FROM ( SELECT t . '' version = str ( ast.literal_eval ( _version_re.search ( alias = partial ( completion , `` table alias '' ) _logger.debug ( `` Dangerous query detected -- ignoring '' ) @ then ( 'we see the sql in prompt ' ) dsn_config = cfg [ 'alias_dsn ' ] [ dsn ] @ parametrize ( 'completer ' , completers ( filtr=True , casing=True , qualify=no_qual ) ) completer , 'SELECT from custom.products ' , len ( 'SELECT ' ) 'SELECT * FROM abc a JOIN def d ON a . ' , help= '' Use DSN configured into the [ alias_dsn ] section of pgclirc file . `` , run ( executor , `` 'create table test ( a boolean ) ' '' ) arg_mode = { for func_meta in funcs tables = extract_tables ( 'SELECT * FROM abc.def x JOIN ghi.jkl y ON x.id = y.num ' ) text.startswith ( `` \\ '' ) ipython.register_magic_function ( pgcli_line_magic , `` line '' , `` pgcli '' ) context.cli.sendcontrol ( `` d '' ) self.functions_and_keywords ( pos=pos ) elif token_v == `` as '' : `` INSERT INTO users ( ) '' , `` column '' , 'port ' : context.config.userdata.get ( elif token_v in ( `` table '' , `` view '' ) : func_name , function ( `` Custom_Func1 ( ) CF '' ) , name_join ( ' o.email = u.email ' ) , if editor_command == '\\e ' : wrappers.expect_exact ( context , ' : ' , timeout=2 ) white_space_regex = re.compile ( `` \\s+ '' , re.MULTILINE ) actual = re.sub ( r '' \x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? `` , `` '' , context.cli.before ) View ( schema=None ) , Column ( table_refs= ( ( None , 'def ' , 'd ' , False ) , ) ) , 'SELECT * FROM foo JOIN bar on bar.barid = foo.barid JOIN ' , `` head2 | def '' , sugs = [ if self.asterisk_column_order == `` alphabetic '' : passwd = os.environ.get ( `` PGPASSWORD '' , `` '' ) message = str ( e ) + `` \nFile output disabled '' @ click.option ( '-U ' , ' -- username ' , 'username_opt ' , help='Username to connect to the postgres database . ' ) def schemas_and_from_clause_items ( self , parent='public ' , pos=0 ) : 'dbname_tmp ' : db_name_full + '_tmp ' , result = get_result ( completer , text , position=text.find ( ' ' ) + 1 ) cased_users_col_names ( `` users '' , ' '' users '' ' , `` Users '' ) , Keyword ( `` DISTINCT '' ) , table = partial ( completion , 'table ' ) .format ( timing ) ) result = executor.function_definition ( `` the_number_three '' ) `` You 're about to run a destructive command.\r\nDo you want to proceed ? ( y/n ) : '' , 'Custom ' : [ `` Topic : : Software Development : : Libraries : : Python Modules '' , default=False , help='Never prompt for password . ' ) 1 , FromClauseItem ( schema=None , table_refs=tbls ) , sql = `` select 1 ; error ; select 1 ; '' ( 'blog ' , 'entries ' , 'entryid ' , 'blog ' , 'entrytags ' , 'entryid ' ) , @ then ( 'we see the named query executed ' ) `` SELECT users.name , orders.id FROM users JOIN orders ON JOIN orders orders2 ON '' , Alias = namedtuple ( `` Alias '' , [ `` aliases '' ] ) Schema , click.secho ( str ( e ) , err=True , fg='red ' ) Column ( table_refs= ( ( None , 'tabl2 ' , 't2 ' , False ) , ) ) , Function ( schema= '' d '' ) , wrappers.expect_exact ( context , `` SELECT 1 '' , timeout=1 ) return set ( [ 'UPDATE users SET ' , assert set ( tables ) == set ( [ ( 'foo ' , 'bar ' , 'baz ' , False ) , Function ( schema=parent ) , style_output=self.style_output pgclirc_file=None , wrappers.expect_pager ( `` blog '' : { self.pgexecute.user , self.keywords ( pos ) return [ ( None , None , None , message , `` '' , True , True ) ] vi = ' _'.join ( [ str ( x ) for x in sys.version_info [ :3 ] ] ) @ patch ( 'pgcli.main.os ' ) Completion ( 'foo ' , 0 , display_meta='column ' ) , print ( 'Connected : { } '.format ( conn.name ) ) help='Warn before running a destructive query . ' ) pgexecute = PGExecute ( database , user , passwd , host , port , dsn , context.cli.sendline ( '\\ ' + ' x { } '.format ( mode ) ) position = len ( 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON ' ) schema ( u '' 'custom ' '' ) , 'CREATE TABLE foo ( bar custom . ' , cond = prefix + case ( lcol ) + ' = ' + rref + ' . ' + case ( rcol ) self.multiline_continuation_char = c [ `` main '' ] [ `` multiline_continuation_char '' ] `` SELECT * FROM foo WHERE EXISTS ( SELECT * FROM `` , click.secho ( default_config = os.path.join ( package_root , `` pgclirc '' ) for pattern in settings.get ( assert result [ 0 ] == join ( type=str ) over_default_cursor.configure_mock ( rowcount=DEFAULT + 10 ) elif arg_mode == 'signature ' : self.arg_defaults [ num - num_args + num_defaults ] if has_default if suggestion.usage == `` from '' : False , `` is_window= % r , is_set_returning= % r , is_extension= % r , arg_defaults= % r ) '' aliased_rels = [ _logger.debug ( 'Regular sql statement . sql : % r ' , split_sql ) def drop_db ( hostname= '' localhost '' , username=None , password=None , dbname=None , port=None ) : full_text = full_text [ ctes [ -1 ] .stop : ] 'select a.x , b.y from abc a join bcd b on a.id = b.id OR ' , os.path.basename ( context.tee_file_name ) ) ) context , `` Auto-completion refresh started in the background.\r\n '' , timeout=2 matches = self.find_matches ( word_before_cursor , self.all_completions , func_name , schema_name='public ' , arg_names=None , arg_types=None , `` text , expected_length '' , self.full_text if scope == `` full '' else self.text_before_cursor function ( f ) if hasattr ( context , 'cli ' ) and context.cli and not context.exit_sent : 'SELECT * FROM tabl WHERE foo = 1 AND ' , 'SELECT u.name , o.id FROM users u JOIN orders o ON JOIN orders o2 ON ' INNER JOIN `` ' , for col in cols ] ) entry_points= '' ' Keyword ( 'SELECT ' ) , def _relations ( self , kinds= ( ' r ' , ' v ' , 'm ' ) ) : assert set ( executor.tables ( ) ) > = set ( [ port=port , suggestions = suggest_type ( 'select from a ; select * from b ' , cols + testdata.functions_and_keywords ( ) alias , c ( left.col ) , rtbl.ref , c ( right.col ) ) ] `` PGPORT '' : os.environ.get ( `` PGPORT '' , None ) , @ click.option ( '-l ' , ' -- list ' , 'list_databases ' , is_flag=True , help='list ' default=False , result = get_result ( completer , `` SELECT * FROM u '' ) print ( context.cli.sendline ( '\\n foo ' ) suggestions = suggest_type ( '\d xxx ' , '\d xxx ' ) context.cli.sendline ( '\o ' ) textwrap.dedent ( result = run ( executor , `` SELECT d FROM jsonbtest LIMIT 1 '' , `` Output shorter than terminal width '' , assert '_test_db ' in databases ColumnMetadata ( name , typ , [ ] ) == `` | 4713-01-01 BC | '' ipython.run_line_magic ( 'load_ext ' , 'sql ' ) assert tables == ( ( None , 'foo ' , 'bar ' , True ) , ) def from_clause_items ( self , parent='public ' , pos=0 ) : Token.Menu.Completions.Meta : `` completion-menu.meta.completion '' , style_from_pygments_cls ( style ) , `` UPDATE '' , assert tables == ( ( None , 'foo ' , None , True ) , ) [ `` integer '' ] , 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = ' assert set ( tables ) == set ( [ ( None , 'foo ' , None , False ) , SELECT * FROM a '' ' context.package_root , `` tee_file_ { 0 } .sql '' .format ( context.conf [ `` vi '' ] ) `` select * from a ; select from b '' , `` select * from a ; select `` if ( Alias ( aliases= ( ' a ' , ' b ' , ) ) , ) ) [ 'extract_entry_symbols ' , [ '_entryid ' , 'symbol ' ] , host=host , not JSON_AVAILABLE , ) wrappers.expect_pager ( context , `` DROP DATABASE\r\n '' , timeout=2 ) cols = ( ' '' select '' .id , `` select '' . `` localtime '' , `` select '' . `` ABC '' , ' elif token_v in ( `` select '' , `` where '' , `` having '' , `` order by '' , `` distinct '' ) : assert result [ 0 ] == join ( `` EntryTags ON EntryTags.EntryID = Entries.EntryID '' , -2 ) assert ( callbacks [ 0 ] .call_count == 1 ) fk_join ( `` shipments.user_id = users.id '' ) , if casing == `` upper '' : `` Output longer than terminal width '' , 'SELECT * FROM tabl WHERE foo BETWEEN foo AND ' , run ( executor , `` SELECT ( CAST ( '00:00:00+14:59 ' AS timetz ) ) '' , join=True ) .split ( Function ( schema= '' t1 '' ) , display='set_returning_func ( x , y ) srf ' 'types ' , 'databases ' , 'casing ' , 'functions ' ] return os.getenv ( 'USERPROFILE ' ) + '\\AppData\\Local\\dbcli\\pgcli\\ ' self , database= '' '' , host= '' '' , user= '' '' , port= '' '' , passwd= '' '' , dsn= '' '' , * * kwargs context.currentdb = `` postgres '' style = pygments.styles.get_style_by_name ( 'native ' ) .styles Token.Toolbar.Transaction.Valid : `` bottom-toolbar.transaction.valid '' , `` -p '' , return `` set search_path '' in sql.lower ( ) 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON JOIN public.orders z ON z.id > y.id ' wildcard_expansion , os.environ [ 'XDG_CONFIG_HOME ' ] = context.env_config_home 'create table a ( x integer , y real , z numeric ( 10 , 4 ) ) ; ' ) Alias = namedtuple ( 'Alias ' , [ 'aliases ' ] ) print ( 'Closed connection : { 0 } . '.format ( cn.dsn ) ) dedent ( Token.Output.Header : 'output.header ' , 'dbname ' : db_name_full , Completion ( 'cte1 ' , 0 , display_meta='table ' ) , type=click.INT , 'port ' : port , expected_handlers = [ position = len ( 'SELECT * ' ) `` Programming Language : : Python : : 2 '' , context.conf [ `` dbname '' ] , ( text == `` ) # Just a plain enter without any text Special = namedtuple ( `` Special '' , [ ] ) `` SELECT * FROM abc a JOIN def d ON a.id = d.id AND a.id2 = d. '' , result.append ( ( `` class : bottom-toolbar.on '' , `` [ F3 ] Multiline : ON `` ) ) databases_query = `` '' '' 'SELECT * FROM `` Users '' u JOIN userid ' , default=False , or ( text == `` quit '' ) # Exit does n't need semi-colon completer , 'select from set_returning_func ( ) ' , len ( 'select ' ) View ( schema= '' t '' ) , os.environ [ `` PGHOST '' ] = context.conf [ `` host '' ] cursor.execute ( `` SELECT NULL : :timestamp '' ) d [ 1 ] in psycopg2.extensions.DECIMAL.values 'Auto-completion refresh started in the background . ' ) ] testdata.columns_functions_and_keywords ( `` users '' ) print ( 'Server : PostgreSQL ' , self.pgexecute.server_version ) `` `` '' \ server_version = `` assert extract_column_names ( sql ) == ( 'def ' , 'jkl ' ) 'SELECT * FROM `` Users '' u JOIN u ' , _logger.debug ( 'Function Definition Query . sql : % r\nspec : % r ' , `` import coverage '' , Schema = namedtuple ( 'Schema ' , [ 'quoted ' ] ) text = `` DROP TABLE schema_name.table_name '' language sql as $ $ select 2 $ $ '' '' '' , expected_handlers = [ 'schemata ' , 'tables ' , 'views ' , suggestions = [ Datatype ( schema=schema ) , qualifys = qualify or [ 'always ' , 'if_more_than_one_table ' , 'never ' ] if keyword_casing not in ( `` upper '' , `` lower '' , `` auto '' ) : @ when ( 'we execute a large query ' ) name= '' pgcli '' , suggestions = suggest_type ( 'SELECT FROM sch.tabl ' , 'SELECT ' ) assert `` MATERIALIZED VIEW '' in result context.cli.sendline ( ' . ' ) context.currentdb = 'postgres ' suggestions = suggest_type ( '\\df xxx ' , '\\df xxx ' ) elif char == `` , '' and not in_quote : schema_name='public ' , sql = 'select 1 ; error ; select 1 ; ' 'Custom_Fun ' , '_custom_fun ' , 'Custom_Func1 ' , 'custom_func2 ' , 'set_returning_func ' 'SELECT * FROM ( S ' , assert completions_to_set ( result ) == completions_to_set ( testdata.schemas ( ) + aliased_rels + [ assert remainder.strip ( ) == `` SELECT * FROM a '' click.secho ( `` cancelled query '' , err=True , fg= '' red '' ) r'__version__\s+=\s+ ( ? P < quote > [ \ ' '' ] ) ( ? P < version > . * ) ( ? P=quote ) ' ) tables = extract_tables ( 'select * from abc , def ' ) `` License : : OSI Approved : : BSD License '' , on a.id = `` '' '' _version_re = re.compile ( r '' __version__\s+=\s+ ( . * ) '' ) full_databases_query = `` '' '' Alias ( aliases= ( 'abc ' , 'bcd ' , ) ) , ) ) @ parametrize ( 'completer ' , completers ( aliasing=False , casing=True , filtr=True ) ) arg_types= ( `` integer '' , ) , elif char == ' , ' and not in_quote : assert set ( suggestions ) == set ( [ FromClauseItem ( schema= '' sch '' ) ] ) 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] , expected = ( name_join ( 'orders.email = users.email ' ) , self.decimal_format = c [ `` data_formats '' ] [ `` decimal '' ] RuntimeError , `` datatypes '' : { `` public '' : [ `` typ1 '' , `` typ2 '' ] , `` custom '' : [ `` typ3 '' , `` typ4 '' ] } , Table , `` SELECT * FROM Custom.Set_Returning_Func ( ) '' , text = `` select * from foo f left join bar b , '' 'set_returning_func ( x : = , y : = ) ' , table ( 'Orders O ' if text == 'SELECT * FROM ' else 'Orders O2 ' ) , result = executor.view_definition ( 'there_is_no_such_view ' ) Token.Toolbar.On : `` bottom-toolbar.on '' , 'SELECT * FROM public . `` Users '' RIGHT OUTER JOIN ' , package_data= { `` pgcli '' : [ `` pgclirc '' , `` packages/pgliterals/pgliterals.json '' ] } , database= '' testdb '' , 'Have you updated the ` Usage ` section of the README ? ' , __version__ = ' 2.1.0 ' click.secho ( 'Your call ! ' ) `` `` '' insert into hij ( a , b , c ) fks = ( 'Programming Language : : Python ' , arg_type=NO_QUERY , tables = extract_tables ( 'SELECT * FROM foo ( { 0 } ) '.format ( arg_list ) ) ( `` public '' , `` users '' , `` id '' , `` public '' , `` users '' , `` parentid '' ) , [ Completion ( text= '' CREATE '' , display_meta= '' keyword '' ) ] ) not in result assert extract_column_names ( sql ) == ( `` abc '' , ) def refresh_completions ( self , history=None , persist_priorities= '' all '' ) : `` text , expected '' , Keyword ( 'DISTINCT ' ) 'SELECT from custom.users ' , 'SELECT * FROM ( SELECT ' ) return ' % s/pgcli/ ' % expanduser ( os.environ [ 'XDG_CONFIG_HOME ' ] ) def list_dict ( pairs ) : # Turns [ ( a , b ) , ( a , c ) ] into { a : [ b , c ] } join=True , expanded=expanded ) 'SELECT * FROM foo ( ) AS bar ( baz ' , 'Programming Language : : Python : : 3 ' , tables = extract_tables ( `` select a , b from abc.def '' ) ( 'upper ' , 'SELECT ' , ( `` , 's ' , 'S ' , 'Sel ' ) ) , 'INSERT INTO public.users SELECT u . * FROM users u ' , 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' , 'email ' ] , not in result sugs.append ( JoinCondition ( table_refs=tables , wrappers.expect_exact ( context , `` Password for '' , timeout=5 ) as $ $ select generate_series ( 1,5 ) $ $ ; '' '' '' , `` total_time '' , # Time elapsed executing the query and formatting results type_priority , ( 'ghi ' , 'jkl ' , ' y ' , False ) ] ) settings.table_format ) `` text , text_before '' , assert result [ 0 ] == join ( `` EntryTags ET ON ET.EntryID = E.EntryID '' , -2 ) template = `` CREATE OR REPLACE { 6 } VIEW { 0 } . { 1 } AS \n { 3 } '' version = str ( `` sql '' , [ 'select * from `` abc '' . `` def '' ' , 'select * from abc . `` def '' ' ] expected = cols_etc ( 'tabl ' , alias= ' '' tabl '' ' , last_keyword='WHERE ' ) ( `` SELECT DISTINCT x . FROM tbl x JOIN tbl1 y '' , `` SELECT DISTINCT x . `` ) , ( 'public ' , 'users ' , 'id ' , 'public ' , 'Users ' , 'userid ' ) testdata.columns ( 'orders ' ) ) Token.Toolbar.Transaction.Valid : 'bottom-toolbar.transaction.valid ' , self.tables ( parent , pos ) and last_tok.value.lower ( ) not in ( 'cross join ' , 'natural join ' ) ) _logger.debug ( `` Databases Query . sql : % r '' , self.databases_query ) if word_before_cursor [ -1 ] == ' ( ' or word_before_cursor [ 0 ] == '\\ ' : 'cli_helpers [ styles ] > = 1.2.0 ' , ] assert set ( suggestion ) == set ( [ Table ( schema=None ) , View ( schema=None ) , Schema ( ) ] ) assert set ( suggestion ) == set ( [ FromClauseItem ( schema=None ) , Schema ( ) ] ) @ pytest.mark.parametrize ( 'text ' , [ TableMetadata = namedtuple ( 'TableMetadata ' , 'name columns ' ) `` public '' , `` database '' : database , ) % ( ( self.__class__.__name__ , ) + self._signature ( ) ) self.auto_expand = auto_vertical_output or c [ `` main '' ] .as_bool ( `` auto_expand '' ) keyring.set_password ( `` pgcli '' , key , passwd ) add_cond ( c.name , c.name , rtbl.ref , prio , `` name join '' ) ' '' select '' .id , `` select '' .insert , `` select '' . `` ABC '' , ' 'INSERT INTO Orders ( * ' , function ( f ) for f in ( cols = ( `` EntryText '' , `` EntryTitle '' , `` EntryID '' ) auto_vertical_output=False , default=False , help= ( `` Confirm every step . If the step is not `` `` prompt_toolkit > =2.0.6 , < 2.1.0 '' , format_numbers ) Keyword = namedtuple ( `` Keyword '' , [ `` last_token '' ] ) @ parametrize ( 'completer ' , completers ( filtr=True , casing=False , aliasing=False ) ) actual = re.sub ( r'\x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? ' , `` meta_changed '' , # True if any subquery executed create/alter/drop self.search_path_filter = settings.get ( 'search_path_filter ' ) for x in self.metadata.get ( `` functions '' , { } ) .get ( parent , [ ] ) completer.extend_columns ( executor.table_columns ( ) , kind= '' tables '' ) password=POSTGRES_PASSWORD , for row in self._columns ( kinds= [ `` v '' , `` m '' ] ) : rel_type = { `` table '' : Table , `` view '' : View , `` function '' : Function } [ token_v ] suggestions = [ Datatype ( schema=schema ) , Table ( schema=schema ) ] with patch ( 'pgcli.completion_refresher.PGExecute ' , pgexecute_class ) : name='pgcli ' , string = string.replace ( `` \\i '' , str ( self.pgexecute.pid ) or `` ( none ) '' ) `` SELECT * FROM abc a JOIN def d ON a.id = d. '' , [ `` signature '' : self.signature_arg_style , assert u'日本語 ' in run ( executor , u '' SELECT '日本語 ' AS japanese ; '' , join=True ) self.on_error = c [ `` main '' ] [ `` on_error '' ] .upper ( ) context.tmpfile_sql_help.write ( b'\ ? ' ) Token.Toolbar.Search : 'search-toolbar ' , Token.Menu.Completions.Completion.Current : 'completion-menu.completion.current ' , | \.pytest_cache completer , `` SELECT MAX ( from custom.products '' , len ( `` SELECT MAX ( `` ) `` $ $ 'foo ' $ $ '' , assert completions_to_set ( result ) == completions_to_set ( [ if ( return expanduser ( `` ~/.config/pgcli/ '' ) When you submit a PR , the changeset is checked for pep8 compliance using text = `` SELECT p. * FROM custom.products p '' wrappers.expect_pager ( context , 'foo : Deleted\r\n ' , timeout=1 ) _logger.debug ( `` Datatypes Query . sql : % r '' , query ) assert tuple ( ctes ) == ( ( `` a '' , ( `` def '' , ) , start_pos , stop_pos ) , ) assert completions_to_set ( result ) == completions_to_set ( testdata.columns ( `` select '' ) ) chars= ' [ ] ( ) { } ' ) , return sql.endswith ( ' ; ' ) and not is_open_quote ( sql ) assert counter.keyword_count ( 'NOSUCHKEYWORD ' ) == 0 ( schema , relname , colname ) = self.escaped_names ( `` INSERT INTO users ( ) SELECT * FROM users u cross join orders o '' , | \.hg views = self.populate_schema_objects ( suggestion.schema , `` views '' ) context.cli.sendline ( `` '' '' insert into a ( x , y , z ) values ( 1 , 1.0 , 1.0 ) ; '' '' '' ) 'INSERT INTO users ( ) ' , context.cli.sendcontrol ( `` d '' ) continuation = self.multiline_continuation_char * ( width - 1 ) + ' ' query = special.get_editor_query ( text ) or self.get_last_query ( ) if not click.confirm ( `` Do you want to continue ? `` ) : click.secho ( `` Aborted ! `` , err=True , fg='red ' ) assert executor.search_path ( ) == [ `` pg_catalog '' , `` public '' ] ' '' % s '' on % s at port `` % s '' . ' % ( self.pgexecute.dbname , return pgcli.pgexecute.PGExecute ( result = run ( executor , 'select invalid command ' , ( tbl + ' . ' + self.case ( col ) ) if do_qualify else self.case ( col ) ) result = run ( executor , u '' select 'fooé ' ; invalid syntax é '' , PEP8 checks ( lint ) ) defaults = self.metadata.get ( `` defaults '' , { } ) .get ( sch , { } ) ( 'public ' , ' b ' , ' z ' , 'text ' , False , None ) , assert Keyword ( `` ALTER '' ) in set ( suggest_type ( sql , sql ) ) completer , text , text.find ( ' ' ) + 1 ) ) 'SELECT * FROM foo WHERE EXISTS ( ' , suggestions = suggest_type ( text , text [ : text.find ( `` ; `` ) + 1 ] ) db_name = getattr ( context , `` currentdb '' , context.conf [ `` dbname '' ] ) wrappers.expect_pager ( context , 'DELETE 1\r\n ' , timeout=2 ) lexical_priority , if dsn is not `` '' : `` Have you updated the AUTHORS file ? `` , self.completion_refresher.refresh ( @ when ( u'we send source command ' ) 'SELECT foo ' , 'CREATE TABLE foo ( bar DOU ' , 'functions ' : [ 'function ' ] , elif token_v == 'column ' : target-version = [ 'py27 ' ] run_step ( 'git ' , 'push ' , 'origin ' , 'master ' ) view ( escape ( x ) , pos ) for x in self.metadata.get ( `` views '' , { } ) .get ( parent , [ ] ) `` INSERT INTO public.orders ( `` , elif platform.system ( ) == 'Windows ' : table ( `` Entries E2 '' , -1 ) , INNER JOIN `` ' `` { 0 } \r\n { 1 } { 0 } \r\n '' .format ( context.conf [ `` pager_boundary '' ] , expected ) , Token.Menu.Completions.Completion : `` completion-menu.completion '' , Token.Menu.Completions.MultiColumnMeta : 'completion-menu.multi-column-meta ' , tbls = tuple ( [ ( None , `` foo '' , `` f '' , False ) ] ) Match ( if hasattr ( sql.connection.Connection , 'get ' ) : return self.find_matches ( word_before_cursor , flat_cols ( ) , @ click.option ( '-p ' , ' -- port ' , default=5432 , help='Port number at which the ' assert kw.value == `` ( `` settings = OutputSettings ( table_format= '' ascii '' , missingval= '' < null > '' ) View ( schema=parent ) , [ schema ( 'PUBLIC ' ) ] + [ function ( f ) for f in cased_func_names ] ( `` SELECT * FROM users JOIN NonTable on `` , `` NonTable '' ) , assert u '' Description '' in result [ 2 ] function ( '_custom_fun ( ) ' , -2 ) , reason= '' Need a postgres instance at localhost accessible by user 'postgres ' '' , text = `` ALTER `` return click.style ( utf8tounicode ( str ( e ) ) , fg= '' red '' ) sql = 'SELECT abc , def FROM xxx ' 'INSERT INTO Orders SELECT from users U NATURAL JOIN `` Users '' ' , @ pytest.mark.parametrize ( 'text ' , ( ' , ' , ' , ' , 'sel , ' , ) ) `` generate_aliases '' : c [ `` main '' ] .as_bool ( `` generate_aliases '' ) , self.pgexecute , suggestions = suggest_type ( text , 'INSERT INTO abc ( ' ) return merge_styles ( [ assert run ( executor_copy , `` 'select * from test '' ' , join=True ) == dedent ( `` '' '' \ result = run ( executor , `` \\ ? `` , pgspecial=pgspecial ) [ 1 ] .split ( `` | '' ) query = r '' ' @ parametrize ( 'completer ' , completers ( filtr=True , casing=False , qualify=no_qual ) ) arg_default = arg_default_type_strip_regex.sub ( `` , arg_default ) ' % s ( schema_name= % r , func_name= % r , arg_names= % r , ' synonyms = [ join , ' { 0 } ON { 0 } . { 1 } = { 2 } . { 3 } '.format ( 'PGSERVICEFILE ' : os.environ.get ( 'PGSERVICEFILE ' , None ) , _logger.debug ( `` Regular sql statement . sql : % r '' , split_sql ) 'select * from abc inner join def using ( col1 , ' , tables = extract_tables ( `` select * from abc '' ) elif editor_command == `` \\ef '' : `` table '' , 'asterisk_column_order ' , 'table_order ' ) schema= ( self._maybe_schema ( schema=sch , parent=schema ) ) `` bigint_array | { } '' , function_body_pattern = re.compile ( r '' ( \ $ . * ? \ $ ) ( [ \s\S ] * ? ) \1 '' , re.M ) testdata.from_clause_items ( 'custom ' , start_position ) ) [ `` func3 '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , tables = extract_tables ( configured_pager = config [ 'main ' ] .get ( 'pager ' ) run ( executor , `` 'insert into test values ( True ) ' '' ) create_db , suggestions = suggest_type ( 'SELECT * FROM ( SELECT a , FROM abc ' , table_format= '' psql '' , dcmlfmt= '' d '' , floatfmt= '' g '' , expanded=expanded `` pg_test_pass '' , os.getenv ( `` PGPASSWORD '' , None ) click.secho ( 'The result set has more than % s rows . ' `` Invalid DSNs found in the config file. `` `` arg_types= % r , arg_modes= % r , return_type= % r , is_aggregate= % r , `` statement = `` '' '' identifier.get_alias ( ) , is_function ) ( None , None , None , `` Auto-completion refresh started in the background . '' ) with mock.patch.object ( PGExecute , '__init__ ' ) as mock_pgexecute : db_name_full = ' { 0 } _ { 1 } '.format ( db_name , vi ) word_before_cursor , self.functions , mode= '' strict '' , meta= '' function '' @ parametrize ( 'completer ' , completers ( aliasing=False ) ) lambda x : x , @ refresher ( 'tables ' ) run ( executor , `` 'insert into test values ( 'abc ' ) ' '' ) position = len ( `` SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = `` ) help= '' Port number at which the `` `` postgres instance is listening . `` , host , or ' { python } -c `` { startup } '' '.format ( `` successful '' , # True If all subqueries were successful @ click.option ( ' -- auto-vertical-output ' , is_flag=True , @ then ( 'we see database dropped ' ) if name and ( ( not self.name_pattern.match ( name ) ) @ pytest.mark.skipif ( platform.system ( ) == 'Windows ' , assert set ( tables ) == set ( [ ( 'abc ' , 'def ' , None , False ) , tables = extract_tables ( 'select a , b from abc.def ' ) 'INSERT INTO public.orders ( * ) ' , run ( executor , `` ' `` SELECT * FROM tabl WHERE foo BETWEEN foo AND `` , of these checks , install pep8radius and apply style fixes : assert tables == ( ( 'abc ' , 'def ' , ' '' def '' ' , False ) , ) 'dv ' : View , `` Tags '' , context.cli.sendline ( `` x '' ) _logger.debug ( 'Columns Query . sql : % r ' , sql ) sql = `` SELECT abc.def , ghi.jkl FROM xxx '' assert completions [ 0 ] .text == 'VIEW ' 'UPDATE ' , elif not tok_val == `` select '' : sslrootcert= '' ca.pem '' , Table = namedtuple ( `` Table '' , [ `` schema '' , `` table_refs '' , `` local_tables '' ] ) ] , 'int ' , False , False , False , False , None for usage in ( `` call '' , `` call_display '' , `` signature '' ) for rtbl , rcols in cols.items ( ) $ pep8radius master -- docformatter -- diff # view a diff of proposed fixes completer , 'SELECT MAX ( from users ' , len ( 'SELECT MAX ( ' ) mock_connect.assert_called_with ( database='testdb [ ' , cols = ( 'EntryText ' , 'EntryTitle ' , 'EntryID ' ) @ pytest.mark.parametrize ( 'command ' , [ '\\c ' , '\\connect ' ] ) View ( schema= '' a '' ) , def refresh ( self , executor , special , callbacks , history=None , `` SELECT * FROM tbl x JOIN tbl1 y ORDER BY `` , ] , _logger.debug ( 'Detected enter key . ' ) JOIN v ON ( c.oid = v.v_oid ) '' '' '' tables = stmt.get_tables ( 'before ' ) if ( prompt_format == self.default_prompt and `` SELECT '' , ) TableReference = namedtuple ( @ parametrize ( 'completer ' , completers ( aliasing=True , casing=True , filtr=True ) ) `` bigint_array | { 1,2,3 } '' , `` + -- -- -- -- -+ -- -- -- -- -+ '' , quoted = prev_keyword and prev_keyword.value.lower ( ) == `` set '' get_config , position = text.index ( ' * ' ) + 1 fg= '' red '' , context.cli.sendline ( `` 'update a set x = 'yyy ' where x = 'xxx ' ; ' '' ) [ function ( x ) for x in ( 'func2 ( ) f ' , ) ] self , tbl , parent='public ' , typ='tables ' , pos=0 drop_tables , context.cli.sendline ( '\\connect postgres ' ) self.arg_names , self.arg_types , self.arg_modes ) 'SELECT * FROM users u1 JOIN user_emails ue USING ( ) JOIN users u2 ue USING ( first_name , last_name ) ' , list_databases , return arg.encode ( `` utf-8 '' ) if token2 and token2.value.upper ( ) == 'FUNCTION ' : return ( Alias ( aliases=aliases ) , JoinCondition ( Column ( table_refs= ( ( None , 'tabl1 ' , 't1 ' , False ) , ) ) , if statement.get_type ( ) in ( `` CREATE '' , `` CREATE OR REPLACE '' ) : HighlightMatchingBracketProcessor , assert set ( suggestions ) == set ( [ Schema ( ) , Table ( schema=None ) , View ( schema=None ) ] ) with mock.patch.object ( cli.pgspecial , `` pager_config '' , PAGER_ALWAYS ) : `` view '' , assert tables == ( ( None , 'abc ' , ' a ' , False ) , not word_before_cursor.startswith ( 'pg_ ' ) ) : text ) or self.get_last_query ( ) schema_name='schema1 ' , run_step ( `` twine '' , `` upload '' , `` dist/ * '' ) schema_name= '' schema1 '' , func_name= '' func2 '' , return_type= '' integer '' assert completions_to_set ( result ) == completions_to_set ( `` SELECT ( CAST ( '4713-01-01 00:00:00+00 BC ' AS timestamptz ) ) '' , `` SELECT * FROM foo AS bar `` , Table ( schema= '' t1 '' ) , connection = db_connection ( `` _test_db '' ) 'integer_format ' : settings.dcmlfmt , title = `` '' [ [ `` user_action '' , `` user '' ] , [ `` user_group '' , `` user '' ] , [ `` user_group '' , `` user_action '' ] ] , x AS ( SELECT abc , def FROM x ) ' '' ) assert run ( executor , `` SELECT ( CAST ( '4713-01-01 00:00:00+00 BC ' AS timestamptz ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ == `` | 4713-01-01 BC | '' ) ) help='Skip intro on startup and goodbye on exit . ' ) `` schemata '' , `` single_connection '' : single_connection , assert set ( executor.views ( ) ) > = set ( [ 'datatypes ' : { print ( ' -- - after_scenario { } : kill cli'.format ( scenario.name ) ) settings = OutputSettings ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' ) views = [ v for v in views if not v.name.startswith ( `` pg_ '' ) ] termsize = namedtuple ( `` termsize '' , [ `` rows '' , `` columns '' ] ) wrappers.expect_exact ( context , 'Password for ' , timeout=5 ) never_prompt , `` DELETE '' , help= '' Force password prompt . `` , LEFT JOIN `` '' '' , qual , @ then ( 'we see completions refresh started ' ) completion=Completion ( complete_event , query.execution_time , with mock.patch ( 'pgcli.main.click.echo ' ) as mock_echo , \ assert token_start_pos ( p.tokens , idx ) == len ( `` SELECT * FROM \n '' ) dbname=None , port=None ) : self.multi_line = c [ `` main '' ] .as_bool ( `` multi_line '' ) table ( `` Orders O2 '' ) , if char == ' '' ' or char == '\ '' : childcolmeta = meta [ childschema ] [ childtable ] [ childcol ] 'INSERT INTO users ( ' , `` pg_test_user '' , os.getenv ( `` PGUSER '' , `` postgres '' ) assert set ( suggest_type ( q , q ) ) == set ( Function ( schema=parent ) , drop_tables ) def _bg_refresh ( self , pgexecute , special , callbacks , history=None , coldict = list_dict ( cols , start_position=pos , display_meta='columns ' , display= ' * ' ) 'INSERT INTO Orders ( * ) ' prompt_dsn=prompt_dsn , completer.extend_relations ( executor.views ( ) , kind='views ' ) Function ( schema='t1 ' ) , `` users '' : [ `` id '' , `` email '' , `` first_name '' , `` last_name '' ] , action= '' store_true '' , context.cli.sendline ( `` create database { 0 } ; '' .format ( context.conf [ `` dbname_tmp '' ] ) ) pgcli.logger.debug ( click.secho ( str ( e ) , err=True , fg= '' red '' ) if not suggestion.schema and ( result = run ( casing_file = config_location ( ) + `` casing '' `` XDG_CONFIG_HOME '' : os.environ.get ( `` XDG_CONFIG_HOME '' , None ) , 'SELECT * FROM sch . `` ' , def find_matches ( self , text , collection , mode= '' fuzzy '' , meta=None ) : suggest_type , Token.Toolbar : 'bottom-toolbar ' , literal_file = os.path.join ( root , `` pgliterals.json '' ) keyword ( `` MATERIALIZED VIEW '' , -2 ) , elif token_v == 'function ' : if new_params [ 'password ' ] : dsn_config = cfg [ `` alias_dsn '' ] [ dsn ] function ( 'func2 ( ) f ' ) ] ) | tests/data '.coveragerc ' ) pgcli = PGCli ( prompt_passwd , never_prompt , pgclirc_file=pgclirc , add_cond ( left.col , right.col , rtbl.ref , 2000 , 'fk join ' ) assert actual2 [ 0 ] [ 3 ] == 'Auto-completion refresh restarted . ' `` `` '' insert into hij ( x , y , z ) level_map = { View ( schema='t ' ) , coltyp = namedtuple ( `` coltyp '' , `` name datatype '' ) suggestions = suggest_type ( 'TRUNCATE sch . ' , 'TRUNCATE sch . ' ) `` Column '' , ( `` blog '' , `` entries '' , `` entryid '' , `` blog '' , `` entrytags '' , `` entryid '' ) , ( f.is_public or f.schema_name == suggestion.schema ) ) `` expression '' , [ `` INSERT INTO `` , `` COPY `` , `` UPDATE `` , `` DESCRIBE `` ] click.secho ( 'Not Yet Implemented . ' , fg= '' yellow '' ) 'dsn ' : dsn , cased_aliased_rels = [ join = left.schema + ' . ' + join 'SELECT * FROM `` tabl1 '' t1 , tabl2 t2 WHERE t1 . ' , suggestions = suggest_type ( `` select from a ; select * from b '' , `` select `` ) `` less_chatty '' , string = string.replace ( '\\H ' , self.pgexecute.host or ' ( none ) ' ) ( testdata.columns_functions_and_keywords ( 'users ' ) ) ) lambda self : self.alias is_window=False , schema_name= '' public '' , c ( left.tbl ) , c ( left.col ) , rtbl.ref , c ( right.col ) ) print ( `` Config file ( ~/.pgclirc ) moved to new location '' , config_full_path ) prompt=None , ) , _logger.debug ( `` Detected enter key . '' ) ) # Just a plain enter without any text def refresh ( self , executor , special , callbacks , history=None , settings=None ) : Column ( table_refs= ( ( None , `` abc '' , None , False ) , ) , qualifiable=True ) , self.pgspecial.register ( self.change_table_format , '\\T ' , '\\T [ format ] ' , ( 10 , 10 , `` \n '' .join ( [ test_line ] * 5 ) ) , return [ get_comp ( * * c ) for c in _cfgs ( casing , filtr , aliasing , qualify ) ] 'SELECT DISTINCT x . FROM tbl x JOIN tbl1 y ' , casing = 'upper ' format_output , Function ( schema=parent ) , ) `` DEBUG '' : logging.DEBUG , InputMode.INSERT : ' I ' , `` UPDATE '' , `` path_changed '' , # True if any subquery changed the search path arg = `` -- password '' cols = [ column ( ' U . ' + c.lower ( ) ) for c in cased_users_col_names ] casing_prefs = '\n'.join ( executor.casing ( ) ) return float ( `` Infinity '' ) , -1 logger.error ( 'Unhandled style / class name : % s ' , token ) `` configobj > = 5.0.6 '' , stdin = click.get_text_stream ( `` stdin '' ) token , style , cli_style ) function ( 'custom_func1 ( ) ' , -2 ) , function ( 'MAX ' , -2 ) , click.secho ( str ( e ) , err=True , fg='red ' ) if scenario.name == 'list databases ' : prefix = `` if suggestion.parent else ltbl.ref + ' . ' if token2 and token2.value.upper ( ) == `` FUNCTION '' : missingval= ' < null > ' string = string.replace ( `` \\H '' , self.pgexecute.host or `` ( none ) '' ) for reltype in ( 'tables ' , 'views ' ) : completion , prio , meta , synonyms or [ completion ] , prio2 , confirm_destructive_query ( query ) is False ) : `` set_returning_func ( x : = , y : = ) srf '' , [ column ( `` id '' ) , column ( `` email '' ) ] def ColumnMetadata ( name , datatype , foreignkeys=None , default=None , has_default=False ) : assert completions_to_set ( result ) == completions_to_set ( [ Completion ( with patch.object ( executor , `` host '' , `` localhost.example.org '' ) : Keyword ( `` SELECT '' ) , suggest_type , Special , Database , Schema , Table , View , Function , Datatype ) self.logger.info ( 'Default pager found in PAGER environment variable : `` { } '' '.format ( assert tables == ( ( 'abc ' , 'def ' , None , False ) , ) 'CREATE FUNCTION foo ( bar INT , baz ' , ( 'copy ' , 'from ' , 'update ' , 'into ' , 'describe ' , 'truncate ' ) ) : `` Intended Audience : : Developers '' , return Candidate ( qualify ( name , ref ) , 0 , 'column ' , synonyms ) function_definition_query = `` ' [ style_from_pygments_cls ( style ) , override_style , Style ( prompt_styles ) ] return set ( len ( 'SELECT * FROM Functions WHERE function : ' ) , 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' SELECT 1 '' '' '' ) join ( ' '' Users '' ON `` Users '' .UserID = Users.ID ' ) , 'INSERT INTO public.Orders ( * ) ' , BY baz '' ' self.refresh_completions ( history=history , persist_priorities= '' none '' ) INNER JOIN set_returning_func ( ) f2 USING ( `` ' for name in [ `` json '' , `` jsonb '' ] : join ( 'users u ON u.parentid = Users.id ' ) , print ( 'Releasing Version : ' , ver ) 'DEBUG ' : logging.DEBUG , current = `` '' tables = ( ( None , `` foo '' , None , False ) , ) elif not tok_val == 'select ' : shutil.move ( os.path.expanduser ( `` ~/.pgclirc '' ) , config_full_path ) self.generate_aliases = settings.get ( 'generate_aliases ' ) str ( e ) self.refresh_completions ( persist_priorities='all ' ) get_casing_file , require_last_table=True , 'sep_character ' : '- ' , len ( 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT ' ) `` SELECT * FROM custom.set_returning_func ( ) '' , Datatype = namedtuple ( `` Datatype '' , [ `` schema '' ] ) suggestions = suggest_type ( `` \d myschema.xxx '' , `` \d myschema.xxx '' ) position = text.index ( `` ( ) '' ) + 1 elif arg_mode == `` signature '' : result.append ( ( `` class : bottom-toolbar.on '' , `` [ F2 ] Smart Completion : ON `` ) ) level_map = { 'CRITICAL ' : logging.CRITICAL , ( 'class : bottom-toolbar ' , ' Refreshing completions ... ' ) ) display= '' set_returning_func ( x , y ) srf '' , ( ) , return [ ( None , None , None , [ `` func1 '' , [ ] , [ ] , [ ] , `` '' , False , False , False , False ] , @ kb.add ( 'escape ' , filter=has_completions ) prompt = self.get_prompt ( '\\d > ' ) with open ( self.output_file , `` a '' , encoding= '' utf-8 '' ) as f : database = dbname_opt or dbname or `` ' ; ; ; $ $ ' , assert callbacks [ 0 ] .call_count == 1 'Default pager found in config file : `` { } '' '.format ( configured_pager ) ) suggestions = suggest_type ( '\d ' , '\d ' ) `` SELECT * FROM tabl WHERE foo = `` , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . ' assert set ( suggestions ) == \ POSTGRES_PASSWORD = getenv ( 'PGPASSWORD ' , `` ) if cmd in ( '\\c ' , '\\connect ' ) : @ parametrize ( 'text , expected ' , [ 'SELECT t1 . FROM `` tabl1 '' t1 , `` tabl2 '' t2 ' , 'if_more_than_one_table ' : len ( tables ) > 1 } [ self.qualify_columns ] ORDER BY 1 , 2 , att.attnum '' '' '' for s in schema_names 'password ' : password , help= '' Location of pgclirc file . `` , InputMode.REPLACE : ' R ' , help= '' Set threshold for row limit prompt . Use 0 to disable prompt . `` , [ table ( t ) for t in ( `` users u '' , ' '' Users '' U ' , `` orders o '' , ' '' select '' s ' ) ] string = string.replace ( '\\n ' , `` \n '' ) `` Output longer than terminal height '' , print ( `` package root : '' , context.package_root ) open ( filename , ' w ' ) .close ( ) context.tmpfile_sql_help = tempfile.NamedTemporaryFile ( prefix= '' pgcli_ '' ) `` Refresh auto-completions . `` , return self.find_matches ( word_before_cursor , schema_names , meta='schema ' ) settings = OutputSettings ( database= '' testdb [ `` , host= '' baz.com '' , user= '' bar^ '' , passwd= '' ] foo '' if arg_mode in ( ' b ' , ' i ' ) mutating = set ( [ 'insert ' , 'update ' , 'delete ' ] ) text = 'foo ' 'SELECT * FROM users INNER JOIN orders USING ( ' , self.is_public = ( self.schema_name and self.schema_name == 'public ' ) if platform.system ( ) ! = 'Windows ' and not platform.system ( ) .startswith ( `` CYGWIN '' ) : 'is_window= % r , is_set_returning= % r , is_extension= % r , arg_defaults= % r ) ' position = text.find ( `` * '' ) + 1 'ALTER TABLE foo ALTER COLUMN bar ' , table ( ' '' select '' ' ) , context.cli.sendline ( `` \o '' ) _is_complete ( text ) or # A complete SQL command def run ( self , statement , pgspecial=None , exception_formatter=None , 'Refresh auto-completions . ' , arg_type=NO_QUERY ) assert kw.value == `` ( `` and q2 == `` select * from tbl1 inner join tbl2 using ( `` cr.execute ( 'create database % s ' , ( AsIs ( dbname ) , ) ) prompt_dsn=None , and prev_tok.value.lower ( ) .split ( ' ' ) [ -1 ] == 'using ' ) : == `` | 4713-01-01 00:00:00+00 BC | '' cols = [ column ( `` users . '' + c ) for c in cased_users_col_names ] 'sep_title ' : 'RECORD { n } ' , function , [ schema , relname , colname ] ) key = ' % s @ % s ' % ( user , host ) click.secho ( str ( e ) , err=True , fg= '' red '' ) _logger.debug ( 'Detected F4 key . ' ) Token.Menu.Completions.Meta.Current : 'completion-menu.meta.completion.current ' , context.cli.sendline ( '\pset pager always ' ) context.conf [ 'pager_boundary ' ] + '\r ' + dedent ( `` ' 'EntryID ' , 'EntryTitle ' , 'EntryText ' ) text = '\\ ' JSON_AVAILABLE = 'json ' in json_types ' $ $ `` foo '' $ $ ' , click.echo ( `` , file=f ) # extra newline assert suggestion == ( Keyword ( ) , ) for sch in self._get_schemas ( 'functions ' , schema ) string = string.replace ( `` \\t '' , self.now.strftime ( `` % x % X '' ) ) comp.set_search_path ( [ 'public ' ] ) ' $ $ `` foo '' ' , if scenario.name == `` list databases '' : _logger.debug ( 'Detected < Tab > key . ' ) display_meta= '' Toggle timing of commands . `` , ver = _version_re.search ( f.read ( ) ) .group ( 'version ' ) history_file = config_location ( ) + `` history '' if lastword == ' * ' : `` select abc.x , bcd.y from abc join bcd on abc.id = bcd.id AND `` , run ( executor_copy , `` 'create table test ( a text ) ' '' ) `` many_punctuations '' : re.compile ( r '' ( [ ^ ( ) : ,\s ] + ) $ '' ) , @ when ( 'we delete a named query ' ) author_email='pgcli-dev @ googlegroups.com ' , matches.extend ( testdata.from_clause_items ( 'Custom ' , start_position ) ) config_full_path , `` CREATE TABLE foo ( bar custom . `` , self.arg_defaults , return self.find_matches ( word_before_cursor , conds , meta= '' join '' ) position = len ( 'SELECT ' ) print ( `` Time : % 0.03fs '' % query.total_time ) expected = [ Completion ( 'foo ' , 0 , display_meta='column ' ) ] other_tbls = set ( ( t.schema , t.name ) for t in list ( cols ) [ : -1 ] ) self.last_token = parsed and parsed.token_prev ( len ( parsed.tokens ) ) [ 1 ] or `` '' full_databases_query = `` ' create_db ( '_test_db ' ) if arg == ' -- username ' : return Completion ( tables_query = `` ' expanded=expanded ) 'SELECT from users ' , suggestion = suggest_type ( 'SELECT MAX ( FROM tbl ' , 'SELECT MAX ( ' ) 'select a.x , b.y from abc a join bcd b on ' , cn = create_cn ( hostname , password , username , `` postgres '' , port ) `` `` '' INSERT INTO users ( id , parentid , email , first_name , last_name ) def refresh_completions ( self , history=None , persist_priorities='all ' ) : cmd = ' '.join ( cmd_parts ) [ table ( x ) for x in ( 'orders ' , ' '' select '' ' , 'custom.shipments ' ) ]","['.github/PULL_REQUEST_TEMPLATE.md', '.pre-commit-config.yaml', '.travis.yml', 'DEVELOP.rst', 'changelog.rst', 'pgcli/__init__.py', 'pgcli/completion_refresher.py', 'pgcli/config.py', 'pgcli/encodingutils.py', 'pgcli/key_bindings.py', 'pgcli/magic.py', 'pgcli/main.py', 'pgcli/packages/parseutils/__init__.py', 'pgcli/packages/parseutils/ctes.py', 'pgcli/packages/parseutils/meta.py', 'pgcli/packages/parseutils/tables.py', 'pgcli/packages/parseutils/utils.py', 'pgcli/packages/pgliterals/main.py', 'pgcli/packages/prioritization.py', 'pgcli/packages/prompt_utils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgbuffer.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'pgcli/pgstyle.py', 'pgcli/pgtoolbar.py', 'pyproject.toml', 'release.py', 'requirements-dev.txt', 'setup.py', 'tests/conftest.py', 'tests/features/db_utils.py', 'tests/features/environment.py', 'tests/features/fixture_utils.py', 'tests/features/steps/auto_vertical.py', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/crud_table.py', 'tests/features/steps/expanded.py', 'tests/features/steps/iocommands.py', 'tests/features/steps/named_queries.py', 'tests/features/steps/specials.py', 'tests/features/steps/wrappers.py', 'tests/features/wrappager.py', 'tests/metadata.py', 'tests/parseutils/test_ctes.py', 'tests/parseutils/test_function_metadata.py', 'tests/parseutils/test_parseutils.py', 'tests/test_completion_refresher.py', 'tests/test_fuzzy_completion.py', 'tests/test_main.py', 'tests/test_naive_completion.py', 'tests/test_pgexecute.py', 'tests/test_pgspecial.py', 'tests/test_prioritization.py', 'tests/test_prompt_utils.py', 'tests/test_rowlimit.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py', 'tests/utils.py']",black all the things . ( # 1049 )
52,a5e607b6fc889afd3f8960ca3903ae16b641c304,2019-05-21 21:27:47-07:00,"def step_run_cli_using_arg ( context , arg ) : When we launch dbcli using -- username then we send password and we see dbcli prompt @ wip Scenario : run the cli with -- password Scenario : run the cli with -- port wrappers.expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) new_params [ 'dsn ' ] , password=new_params.pop ( 'password ' ) ) host=localhost new_params [ 'dsn ' ] = `` { 0 } password= { 1 } '' .format ( def connect_dsn ( self , dsn , * * kwargs ) : if arg == ' -- user ' : then we see help output db_name = getattr ( context , `` currentdb '' , context.conf [ 'dbname ' ] ) wrappers.run_cli ( context , run_args= [ def step_send_password ( context ) : [ mock_postgres ] arg = ' -- password ' def run_cli ( context , run_args=None ) : if arg == ' -- password ' : arg = 'service=mock_postgres -- password ' arg = ' -- port= { } '.format ( context.conf [ 'port ' ] ) new_params [ 'dsn ' ] , new_params.pop ( 'password ' ) currentdb = None # This uses the mock_pg_service.conf file in fixtures folder . when we send `` \ ? '' command dbname=postgres user=postgres Scenario : run the cli with dsn and password arg = ' -- username= { } '.format ( context.conf [ 'user ' ] ) def connect_dsn ( self , dsn ) : def run_cli ( context , run_args=None , prompt_check=True , currentdb=None ) : self.connect ( dsn=dsn , * * kwargs ) wait_prompt ( context ) arg = ' -- user= { } '.format ( context.conf [ 'user ' ] ) context.currentdb = context.conf [ 'dbname ' ] Scenario : run the cli with -- username new_params [ 'dsn ' ] = make_dsn ( wrappers.expect_exact ( context , ' { 0 } > '.format ( db_name ) , timeout=5 ) When we launch dbcli using -- user ) currentdb = `` postgres '' fixture_dir , 'mock_pg_service.conf ' ) When we launch dbcli using -- port When we launch dbcli using -- password context.cli.sendline ( context.conf [ 'pass ' ] or 'DOES NOT MATTER ' ) os.environ [ 'PGSERVICEFILE ' ] = os.path.join ( and we send `` \ ? '' command if arg == ' -- port ' : self.connect ( dsn=dsn ) When we launch dbcli using dsn_password if arg == 'dsn_password ' : wrappers.expect_exact ( context , 'Password for ' , timeout=5 ) prompt_check = False if prompt_check : pgcli.connect_dsn ( database , user=user ) Scenario : run the cli with -- user 'PGSERVICEFILE ' : os.environ.get ( 'PGSERVICEFILE ' , None ) , prompt_check = False if arg == ' -- username ' : arg ] , prompt_check=prompt_check , currentdb=currentdb ) pgcli.connect_dsn ( database ) wait_prompt ( context ) context.currentdb = currentdb or context.conf [ 'dbname ' ]","['pgcli/main.py', 'pgcli/pgexecute.py', 'tests/features/basic_commands.feature', 'tests/features/environment.py', 'tests/features/fixture_data/mock_pg_service.conf', 'tests/features/specials.feature', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/wrappers.py']",Merge pull request # 1056 from dbcli/handle_password_spaces
53,300febccdd9f6ac36dd2124d35bf974cf950a703,2019-05-11 07:57:45+02:00,self.dbname = dsn_parameters.get ( 'dbname ' ) self.host = dsn_parameters.get ( 'host ' ) self.user = dsn_parameters [ 'user ' ] self.user = dsn_parameters.get ( 'user ' ) * Connecting using socket is broken in current master . ( # 1053 ) . ( Thanks : ` Irina Truong ` _ ) self.port = dsn_parameters.get ( 'port ' ) self.port = dsn_parameters [ 'port ' ] self.host = dsn_parameters [ 'host ' ] self.dbname = dsn_parameters [ 'dbname ' ],"['changelog.rst', 'pgcli/pgexecute.py']",Dsn parameters not always present . ( # 1054 )
54,580639904c07c4b29376a144d15fa00f4cd39b9e,2019-05-06 11:11:57-07:00,"if tok1 and tok1.value.startswith ( '\\ ' ) : 'sqlparse > =0.3.0 , < 0.4 ' , 'sqlparse > =0.2.2 , < 0.3.0 ' , .. _ ` VVelox ` : https : //github.com/VVelox if tok1 and tok1.value == '\\ ' : 'BY ' , elif token_v in ( 'select ' , 'where ' , 'having ' , 'order by ' , 'distinct ' ) : elif token_v in ( 'select ' , 'where ' , 'having ' , 'by ' , 'distinct ' ) : 'ORDER BY ' , * Zane C. Bowers-Hadley * No longer depend on sqlparse as being less than 0.3.0 with the release of sqlparse 0.3.0 . ( Thanks : ` VVelox ` _ )","['AUTHORS', 'changelog.rst', 'pgcli/packages/sqlcompletion.py', 'setup.py', 'tests/test_sqlcompletion.py']",Merge pull request # 1052 from dbcli/pr1047
55,9f2d61bc234cff3d33be9c526d8cc38c9e475063,2019-05-06 11:09:50-07:00,"'dsn ' : new_params [ 'dsn ' ] , conn_params [ 'dsn ' ] = make_dsn ( new_params = { } k : unicode2utf8 ( v ) for k , v in new_params.items ( ) if v new_params [ 'dsn ' ] = `` { 0 } password= { 1 } '' .format ( 'password ' : new_params [ 'password ' ] ) if new_params [ 'password ' ] : if new_params [ 'dsn ' ] : .. _ ` Xavier Francisco ` : https : //github.com/Qu4tro conn_params [ 'dsn ' ] , password=conn_params.pop ( 'password ' ) ) new_params [ 'dsn ' ] , new_params.pop ( 'password ' ) * Fix the broken support for pgservice . ( Thanks : ` Xavier Francisco ` _ ) k : unicode2utf8 ( v ) for k , v in new_params.items ( ) if v is not None if 'password ' in conn_params and 'dsn ' in conn_params :","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 1051 from dbcli/pr1035
56,30c788917bf083aae6c4331ee102f8785c69432a,2019-05-04 11:30:15-07:00,"`` 3.7 '' deps = pytest > =2.7.0 , < =3.0.7 'Programming Language : : Python : : 3.7 ' , mock postgresql : `` 9.6 '' pgspecial envlist = py27 , py34 , py35 , py36 mock > =1.0.1 sudo : required envlist = py27 , py34 , py35 , py36 , py37 postgresql : `` 9.3 '' behave > =1.2.4 psycopg2 dist : xenial deps = pytest pexpect==3.3 humanize * Add python 3.7 to travis build matrix . ( Thanks : ` Irina Truong ` _ ) Internal :","['.travis.yml', 'changelog.rst', 'setup.py', 'tox.ini']",Merge pull request # 1026 from dbcli/j-bennet/python37
57,6d1b653e24278111d82b761c2ea1e66a0621a27d,2019-05-01 08:53:55-07:00,"try : * Zhaolong Zhu if not passwd and keyring and self.keyring_enabled : self.keyring_enabled = c [ `` main '' ] .as_bool ( `` keyring '' ) global keyring .. _ ` Zhaolong Zhu ` : https : //github.com/zzl0 except : self.initialize_keyring ( ) # Try best to load keyring ( issue # 1041 ) . self.logger.warning ( 'import keyring failed : % r . ' , e ) if keyring_enabled : def initialize_keyring ( self ) : if passwd and keyring : keyring = None import keyring * Load keyring only when keyring is enabled in the config file ( # 1041 ) . ( Thanks : ` Zhaolong Zhu ` _ ) keyring = None # keyring will be loaded later keyring = importlib.import_module ( 'keyring ' ) except Exception as e : # ImportError for Python 2 , ModuleNotFoundError for Python 3 # pep8 will be unhappy about this . But keyring is optional , and we better disable it if it wo n't load . keyring_enabled = self.config [ `` main '' ] .as_bool ( `` keyring '' ) try : if passwd and keyring and self.keyring_enabled : import importlib if not passwd and keyring :","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",lazy load keyring . ( # 1046 )
58,3fd91012f20faef6f823cae3b0ba970181e30c75,2019-04-28 15:06:01-07:00,"from psycopg2.extensions import POLL_OK , POLL_READ , POLL_WRITE from psycopg2.extensions import POLL_OK , POLL_READ , POLL_WRITE , make_dsn conn_params [ 'dsn ' ] = make_dsn ( .. _ ` raylu ` : https : //github.com/benchling .. _ ` raylu ` : https : //github.com/raylu conn_params [ 'dsn ' ] , conn_params.pop ( 'password ' ) ) conn_params [ 'dsn ' ] = `` { 0 } password= { 1 } '' .format ( * Pgcli no longer works with password containing spaces ( # 1043 ) . ( Thanks : ` Irina Truong ` _ ) conn_params [ 'dsn ' ] , password=conn_params.pop ( 'password ' ) )","['changelog.rst', 'pgcli/pgexecute.py']",More intelligent dsn format ( # 1045 )
59,9a53fe859acbbf833c05f14e673d5cc76e5fe135,2019-04-28 08:00:40+02:00,"* Fix for `` no attribute KeyringLocked '' ( # 1040 ) . ( Thanks : ` Irina Truong ` _ ) keyring.errors.KeyringError , keyring.errors.InitError , # pep8 will be unhappy about this . But keyring is optional , and we better disable it if it wo n't load . except ImportError : keyring.errors.KeyringLocked except :","['changelog.rst', 'pgcli/main.py']",Possibly fix # 1040 . ( # 1042 )
60,eef0e0d65c01159c1754e72a060a557cacdecfdb,2019-04-27 21:25:19-06:00,".. _ ` raylu ` : https : //github.com/benchling * Allow application_name to be overridden . ( Thanks : ` raylu ` _ ) port=port , application_name='pgcli ' ) application_name='cow ' ) from pgcli.pgexecute import PGExecute port=port , * * self.pgexecute.extra_args ) mock_pgexecute.assert_called_with ( 'bar ' , 'bar ' , `` , 'baz.com ' , `` , `` , self.extra_args = None dsn , * * kwargs ) * * kwargs ) mock_pgexecute.return_value = None dsn , application_name='pgcli ' , kwargs.setdefault ( 'application_name ' , 'pgcli ' ) def test_application_name_db_uri ( tmpdir ) : * * kwargs ) * raylu cli = PGCli ( pgclirc_file=str ( tmpdir.join ( `` rcfile '' ) ) ) with mock.patch.object ( PGExecute , '__init__ ' ) as mock_pgexecute : application_name='pgcli ' , * * kwargs )","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgexecute.py', 'tests/test_main.py']",Allow application_name to be overridden ( # 1044 )
61,4af4e33e31dc800a8ebaed517e0a781fa3dbb437,2019-04-13 13:22:03-07:00,".. _ ` Nathan Verzemnieks ` : https : //github.com/njvrzm * Nathan Verzemnieks ========= from prompt_toolkit.filters import completion_is_selected , has_completions @ kb.add ( 'escape ' ) from prompt_toolkit.filters import completion_is_selected * Escape switches to VI navigation mode when not canceling completion popup . ( Thanks : ` Nathan Verzemnieks ` _ ) Upcoming : Bug fixes :","['AUTHORS', 'changelog.rst', 'pgcli/key_bindings.py']",Allow escape to switch to vi navigation mode ( # 1039 )
62,ab18b08903a3caa14025c9917923aaf20c0b048d,2019-04-05 17:24:10-07:00,"'cli_helpers [ styles ] > = 1.2.0 ' , ========= ===== 'cli_helpers [ styles ] > = 1.0.1 ' , Upcoming : 2.1.0","['changelog.rst', 'setup.py']",Changelog update before release . Bump cli_helpers . ( # 1030 )
63,a7632361c42b33e4474a4ca5363bddbf57484daa,2019-03-23 10:12:12-07:00,"# fails . Do n't prompt if the -w flag is supplied # fails . Do n't prompt if the -w flag is supplied auto_passwd_prompt = not passwd and not self.never_passwd_prompt if `` password authentication failed '' in error_msg : return False # prompt for a password ( no -w flag ) , prompt for a passwd and try again . return False # fails because of a missing password , but we 're allowed to prompt for # a password ( no -w flag ) , prompt for a passwd and try again . # fails because of a missing or incorrect password , but we 're allowed to return True error_msg = utf8tounicode ( exc.args [ 0 ] ) # Prompt for a password after 1st attempt to connect if should_ask_for_password ( e ) : # Prompt for a password after 1st attempt to connect without a password if self.never_passwd_prompt : auto_passwd_prompt ) : if ( 'no password supplied ' in utf8tounicode ( e.args [ 0 ] ) and def should_ask_for_password ( exc ) : * Password authentication failed for user `` postgres '' when using non-default password ( # 1020 ) . ( Thanks : ` Irina Truong ` _ ) if `` no password supplied '' in error_msg :","['changelog.rst', 'pgcli/main.py']",Merge pull request # 1028 from dbcli/j-bennet/update-keyring-password
64,d8df2cc03b8b83061786027c1def3a0edd02f05c,2019-03-18 09:47:12-07:00,"raise psycopg2.InterfaceError ( `` I 'm broken ! '' ) * Can not quit application without reconnecting to database ( # 1014 ) . ( Thanks : ` Irina Truong ` _ ) cur = self.conn.cursor ( ) def cursor ( self ) : pgspecial.register ( quit_handler , '\\q ' , '\\q ' , 'Quit pgcli . ' , with pytest.raises ( psycopg2.InterfaceError ) : pgspecial = PGSpecial ( ) class BrokenConnection ( object ) : from mock import patch , MagicMock with patch.object ( executor , `` conn '' , BrokenConnection ( ) ) : # See https : //github.com/dbcli/pgcli/issues/1014 . try : # we should be able to quit the app , even without active connection cur = self.conn.cursor ( ) import psycopg2 from pgspecial.main import PGSpecial , NO_QUERY arg_type=NO_QUERY , case_sensitive=True , aliases= ( ' : q ' , ) ) from mock import patch except psycopg2.InterfaceError : from pgcli.packages.parseutils.meta import FunctionMetadata # an exception should be raised when running a query without active connection quit_handler.assert_called_once ( ) from textwrap import dedent from textwrap import dedent quit_handler = MagicMock ( ) from pgcli.packages.parseutils.meta import FunctionMetadata cur = None `` `` '' Mock a connection that failed . '' '' '' # edge case when connection is already closed , but we # do n't need cursor for special_cmd.arg_type == NO_QUERY . run ( executor , `` select 1 '' , pgspecial=pgspecial ) import psycopg2 run ( executor , `` \\q '' , pgspecial=pgspecial ) def test_exit_without_active_connection ( executor ) :","['changelog.rst', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 1017 from dbcli/j-bennet/bugfix-should-exit-even-with-connection-closed
65,72f6b6a5611c08ae22ee72d320995a35b6e45998,2019-03-17 07:04:29+01:00,"pg_catalog.pg_get_viewdef ( c.oid , true ) , SELECT nspname , relname , relkind , WHEN 'check_option=local ' = ANY ( c.reloptions ) THEN 'LOCAL ' : :text except select.error as e : END AS checkoption FROM pg_catalog.pg_class c WHEN 'check_option=cascaded ' = ANY ( c.reloptions ) THEN 'CASCADED ' : :text WHEN 'check_option=cascaded ' = ANY ( c.reloptions ) THEN 'CASCADED ' : :text pg_catalog.pg_get_viewdef ( c.oid , true ) , WHEN 'check_option=local ' = ANY ( c.reloptions ) THEN 'LOCAL ' : :text raise errno = e.args [ 0 ] ELSE NULL CASE FROM pg_catalog.pg_class c CASE 'check_option=cascaded ' ) AS reloptions , SELECT nspname , relname , relkind , WITH f AS 'check_option=cascaded ' ) AS reloptions , WITH f AS if errno ! = 4 : ELSE NULL END AS checkoption * Resizing pgcli terminal kills the connection to postgres in python 2.7 ( Thanks : ` Amjith Ramanujam ` _ )","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 1022 from dbcli/system-error
66,80f440e91c1276f98463dd66007bfd9a7a59a878,2019-03-16 17:50:11-07:00,"# When the < Tab > key is pressed on an empty line , use 4 spaces instead of \t tab_insert_text = ' ' * 4 expand_tab = False expand_tab = pgcli.config [ 'main ' ] .as_bool ( 'expand_tab ' ) tab_insert_text = ' ' * 4 if expand_tab else '\t '","['pgcli/key_bindings.py', 'pgcli/pgclirc']",Merge pull request # 1023 from dbcli/remove_expand_tab_option
67,b8f6974f14e9eb37023e944a943015ca932bff72,2019-03-16 14:07:39-07:00,"* Tab press on an empty line increases the indentation instead of triggering doc = buff.document tab_insert_text = ' ' * 4 if expand_tab else '\t ' buff.start_completion ( select_first=True ) expand_tab = pgcli.config [ 'main ' ] .as_bool ( 'expand_tab ' ) if b.complete_state : buff.insert_text ( tab_insert_text , fire_event=False ) expand_tab = False buff.complete_next ( ) b = event.app.current_buffer `` `` '' Force autocompletion at cursor on non-empty lines . '' '' '' else : b.complete_next ( ) the auto-complete pop-up . ( Thanks : ` Artur Balabanov ` _ ) if buff.complete_state : buff = event.app.current_buffer `` `` '' Force autocompletion at cursor . '' '' '' if doc.on_first_line or doc.current_line.strip ( ) : b.start_completion ( select_first=True ) # When the < Tab > key is pressed on an empty line , use 4 spaces instead of \t","['changelog.rst', 'pgcli/key_bindings.py', 'pgcli/pgclirc']",Merge pull request # 928 from arturbalabanov/tab-on-line-start
68,7d6523e18b2c752e0a404746018df77cbad5bcdb,2019-03-16 13:44:40-07:00,".. _ ` Scott Brenstuhl ` : https : //github.com/808sAndBR # PostgreSQL 10.3 on x86_64-apple-darwin17.3.0 , compiled by Apple LLVM version 9.0.0 ( clang-900.0.39.2 ) , 64-bit # noqa else : cur.execute ( self.version_query ) # let 's only retrieve version number self.server_version = self.get_server_version ( cursor ) self.server_version = version_parts [ 1 ] def get_server_version ( self ) : result = cursor.fetchone ( ) * Fix crash retrieving server version with `` -- single-connection `` . ( Thanks : ` Irina Truong ` _ ) * easteregg result = cur.fetchone ( ) if self.server_version : * reconnect automatically when server closes connection print ( 'Server : PostgreSQL ' , self.pgexecute.server_version ) # full version string looks like this : self.server_version = `` # Create a new pgexecute method to populate the completions . except ( PgCliQuitError , EOFError ) as e : def get_server_version ( self , cursor ) : with self.conn.cursor ( ) as cur : if result : * Reconnect automatically when server closes connection . ( Thanks : ` Scott Brenstuhl ` _ ) version_parts = result [ 0 ] .split ( ) * easteregg ( verfriemelt-dot-org ) .. _ ` easteregg ` : https : //github.com/verfriemelt-dot-org server_version = version_parts [ 1 ] print ( 'Server : PostgreSQL ' , self.pgexecute.get_server_version ( ) ) # Create a new pgexecute method to popoulate the completions . except PgCliQuitError as e : # full version string looks like this : * keybindings for closing the autocomplete list return self.server_version version_parts = result [ 0 ] .split ( ) _logger.debug ( 'Version Query . sql : % r ' , self.version_query ) cursor.execute ( self.version_query ) # PostgreSQL 10.3 on x86_64-apple-darwin17.3.0 , compiled by Apple LLVM version 9.0.0 ( clang-900.0.39.2 ) , 64-bit # noqa _logger.debug ( 'Version Query . sql : % r ' , self.version_query ) return server_version # let 's only retrieve version number server_version = `` * Keybindings for closing the autocomplete list . ( Thanks : ` easteregg ` _ ) if result :","['AUTHORS', 'changelog.rst', 'pgcli/completion_refresher.py', 'pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 1016 from dbcli/j-bennet/bugfix-server-version-single-connection
69,1c66dece59d4595eee3fb33d2609e2e288a28ff4,2019-02-23 16:37:26-08:00,"click.secho ( 'Reconnect Failed ' , fg='red ' ) click.secho ( str ( e ) , err=True , fg='red ' ) def _handle_server_closed_connection ( self ) : self.pgexecute.connect ( ) click.secho ( str ( e ) , err=True , fg='red ' ) self._handle_server_closed_connection ( ) except OperationalError as e : click.secho ( 'Reconnecting ... ' , fg='green ' ) self.pgexecute.connect ( ) click.secho ( 'Reconnected ! ' , fg='green ' ) if reconnect : def _handle_server_closed_connection ( self , text ) : try : except OperationalError as e : show_default=False , type=bool , default=True ) try : 'Connection reset . Reconnect ( Y/n ) ' , `` `` '' Used during CLI execution . '' '' '' click.secho ( 'Reconnected ! \nTry the command again . ' , fg='green ' ) * reconnect automatically when server closes connection self.execute_command ( text ) * Scott Brenstuhl ( 808sAndBR ) self._handle_server_closed_connection ( text ) reconnect = click.prompt ( `` `` '' Used during CLI execution '' '' ''","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Add reconnect automatically enhancement ( # 1009 )
70,bd0aaefdd277b7328ff5948d8621d34fb8f87dfd,2019-02-12 16:18:32-08:00,_logger.debug ( 'Detected < Esc > key . ' ) Features : `` `` '' Force closing of autocompletion . '' '' '' event.app.current_buffer.complete_state = None b = event.app.current_buffer def _ ( event ) : * easteregg * keybindings for closing the autocomplete list event.current_buffer.complete_state = None b.complete_state = None,"['AUTHORS', 'changelog.rst', 'pgcli/key_bindings.py']",keybinding for dismissing autocompletelist ( # 1007 )
71,484abb6530b4d271b88d3b38b44f26e7ccd67650,2019-02-08 21:25:03+01:00,"assert completions_to_set ( result ) == completions_to_set ( cased_funcs + cased_users_cols return set ( ( completion.display_text , completion.display_meta_text ) for completion in completions ) result = get_result ( completer , r'\df ' ) assert result == set ( testdata.columns ( 'Users ' , 'custom ' ) ) assert result == set ( [ alias ( 'users ' ) , alias ( 'orders ' ) ] ) assert result == set ( testdata.from_clause_items ( 'custom ' , start_position ) ) assert completions_to_set ( expected ) == completions_to_set ( result ) completions = result_set ( completer , text ) result = result_set ( completer , 'SELECT om ' ) result = result_set ( completer , query.format ( tbl ) ) [ alias ( 'users ' ) , alias ( 'orders ' ) ] ) assert result == set ( [ Completion ( text='SELECT ' , start_position=-3 ) ] ) result = get_result ( completer , '\\t ' ) testdata.from_clause_items ( 'Custom ' , start_position ) ) assert first.display == 'enter_entry ( _title , _text ) ' assert completions_to_set ( result ) == completions_to_set ( cased_schemas + [ assert Completion ( text= '' CREATE '' , display_meta= '' keyword '' ) not in result testdata.columns ( 'Users ' , 'custom ' ) ) [ Completion ( text= '' CREATE '' , display_meta= '' keyword '' ) ] ) not in result assert result == set ( [ alias ( 'users ' ) , alias ( ref ) ] ) result = set ( completer.get_completions ( testdata.columns ( 'Users ' ) ) assert completions_to_set ( result ) == completions_to_set ( cased_funcs + cols result = get_result ( completer , text , position ) assert result == set ( testdata.columns ( 'products ' , 'custom ' ) ) result = result_set ( completer , 'SEL ' ) assert result == set ( [ * Fix unit tests , unhashable formatted text since new python prompttoolkit version . ( Thanks : ` Dick Marinus ` _ ) result = completions_to_set ( get_result ( assert completions_to_set ( result ) == completions_to_set ( [ schema ( 'PUBLIC ' ) ] + cased_rels + [ assert first.display_text == 'enter_entry ( _title , _text ) ' assert set ( expected ) == result testdata.columns_functions_and_keywords ( 'users ' ) ) testdata.columns ( 'users ' ) ) testdata.schemas ( ) + aliased_rels ) assert result == set ( testdata.columns ( 'users ' ) ) result = result_set ( completer , 'SELECT cu ' ) expected = set ( [ schema ( u '' 'public ' '' ) ] ) result = result_set ( completer , 'select * from `` select '' s where s . ' ) result = completions_to_set ( completer.get_completions ( assert result == set ( cased_users_cols ) [ Completion ( text='SELECT ' , start_position=-3 ) ] ) assert completions_to_set ( result ) == completions_to_set ( cased_users_cols ) result = get_result ( completer , 'SELECT from `` select '' ' , len ( 'SELECT ' ) ) testdata.keywords ( ) + testdata.specials ( ) ) == completions_to_set ( result ) assert result == set ( testdata.from_clause_items ( 'Custom ' , start_position ) ) assert completions_to_set ( assert result == set ( testdata.columns ( 'select ' ) ) completions = get_result ( completer , text ) assert result == set ( [ schema ( 'PUBLIC ' ) ] + cased_aliased_rels ) result = get_result ( completer , text ) Document ( text=text , cursor_position=position ) , assert completions_to_set ( result ) > = completions_to_set ( assert result == set ( cols + testdata.functions_and_keywords ( ) ) assert expected < = completions_to_set ( result ) result = get_result ( completer , 'select * from `` select '' s where s . ' ) assert set ( result ) == set ( testdata.schemas_and_from_clause_items ( ) ) [ alias ( ' x ' ) , alias ( ' y ' ) ] ) result = result_set ( completer , 'SELECT from `` select '' ' , len ( 'SELECT ' ) ) expected = set ( [ assert result == set ( testdata.schemas_and_from_clause_items ( ) ) assert completions_to_set ( result ) == completions_to_set ( testdata.schemas ( ) + [ result = result_set ( completer , 'SELECT MA ' ) result = get_result ( completer , 'SELECT from users ' , len ( 'SELECT ' ) ) assert result > completions_to_set ( [ cols + testdata.functions_and_keywords ( ) ) result = get_result ( completer , query.format ( tbl ) ) assert result == set ( testdata.schemas ( ) + aliased_rels ) 'SELECT * FROM Orders o CROSS JOIN ' ] ) testdata.builtin_functions ( ) + testdata.keywords ( ) ) assert expected in completions result = get_result ( completer , 'SELECT * from `` sele ' ) testdata.columns ( 'users ' , 'custom ' ) ) testdata.from_clause_items ( 'custom ' , start_position ) ) 'SELECT * FROM Orders o CROSS JOIN ' ] ) map ( Completion , completer.all_completions ) ) assert expected < = result assert result == set ( testdata.columns_functions_and_keywords ( 'users ' ) ) assert result == completions_to_set ( [ assert completions_to_set ( result ) == expected [ keyword ( 'SELECT ' , -3 ) ] ) result = get_result ( assert first.display == 'extract_entry_symbols ( _entryid ) ' assert completions_to_set ( result ) == completions_to_set ( testdata.schemas ( ) + aliased_rels + [ testdata.columns ( 'products ' , 'custom ' ) ) assert result == set ( [ alias ( ' u ' ) , alias ( ' o ' ) ] ) assert result > set ( [ assert result == set ( [ alias ( ' x ' ) , alias ( ' y ' ) ] ) result = result_set ( completer , 'SELECT FROM ' + table , len ( 'SELECT ' ) ) assert set ( testdata.keywords ( ) + testdata.specials ( ) ) == result result = get_result ( completer , 'SEL ' ) result = result_set ( completer , 'SELECT from users ' , len ( 'SELECT ' ) ) assert result == set ( [ column ( 'foo ' ) ] + testdata.functions_and_keywords ( ) ) result = result_set ( completer , r'\df ' ) assert completions_to_set ( result ) == completions_to_set ( [ assert result == set ( [ column ( 'id ' ) , column ( 'email ' ) ] ) testdata.columns ( 'select ' ) ) assert result == set ( cased_funcs + cased_users_cols expected = completions_to_set ( [ testdata.columns ( 'orders ' ) ) assert expected in set ( completions ) result = get_result ( completer , 'SELECT om ' ) result = result_set ( completer , text , position ) result = get_result ( completer , 'SELECT MA ' ) assert result == set ( testdata.columns_functions_and_keywords ( 'select ' ) ) assert result == set ( testdata.columns ( 'users ' , 'custom ' ) ) testdata.builtin_functions ( ) + testdata.keywords ( ) ) testdata.schemas_and_from_clause_items ( ) ) assert result == set ( assert completions_to_set ( result ) == completions_to_set ( assert result == expected assert result == set ( ) def test_paths_completion ( completer , complete_event ) : [ column ( 'foo ' ) ] + testdata.functions_and_keywords ( ) ) result = result_set ( completer , text ) assert completions_to_set ( get_result ( completer , text ) ) == completions_to_set ( assert result == set ( cased_funcs + cols ( testdata.columns_functions_and_keywords ( 'users ' ) ) ) assert result == set ( cased_schemas + [ result = result_set ( completer , '\\t ' ) result = result_set ( result = get_result ( completer , `` ) [ alias ( ' u ' ) , alias ( ' o ' ) ] ) expected = completions_to_set ( [ schema ( u '' 'public ' '' ) ] ) assert result == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels ) assert result == set ( testdata.schemas ( ) + aliased_rels + [ result = result_set ( completer , text , text.find ( ' ' ) + 1 ) result = result_set ( completer , text , position = text.find ( ' ' ) + 1 ) result = get_result ( completer , text , position=text.find ( ' ' ) + 1 ) result = get_result ( completer , 'SELECT u. from users u ' , len ( 'SELECT u . ' ) ) assert result == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels + [ completer , text , text.find ( ' ' ) + 1 ) ) assert completions_to_set ( result ) == completions_to_set ( [ Completion ( assert result == set ( cols ) position = len ( text ) def completions_to_set ( completions ) : complete_event , assert first.display_text == 'extract_entry_symbols ( _entryid ) ' smart_completion=True ) ) assert result > = set ( testdata.types ( 'custom ' ) ) assert result == set ( testdata.types ( 'custom ' ) ) result = get_result ( completer , 'SELECT FROM ' + table , len ( 'SELECT ' ) ) assert result == set ( testdata.schemas ( ) + [ assert result == set ( testdata.columns_functions_and_keywords ( result = result_set ( completer , 'SELECT * from `` sele ' ) result = result_set ( completer , `` ) text = '\i ' assert completions_to_set ( result ) == completions_to_set ( cols ) result = result_set ( completer , 'SELECT u. from users u ' , len ( 'SELECT u . ' ) ) assert completions_to_set ( result ) == completions_to_set ( testdata.columns_functions_and_keywords ( assert result_set ( completer , text ) == set ( testdata.columns ( 'orders ' ) ) from utils import completions_to_set [ column ( 'id ' ) , column ( 'email ' ) ] ) assert result == set ( [ Completion ( assert result == set ( map ( Completion , completer.all_completions ) ) assert result == completions_to_set ( [ schema ( 'PUBLIC ' ) ] + cased_rels ) assert result == completions_to_set ( [ ] ) assert result == set ( testdata.columns ( 'Users ' ) ) result = get_result ( completer , 'SELECT cu ' ) assert result == [ ] testdata.columns_functions_and_keywords ( 'select ' ) ) assert result == set ( [ keyword ( 'SELECT ' , -3 ) ] ) assert result > set ( [ Completion ( text= '' setup.py '' , start_position=0 ) ] ) [ schema ( 'PUBLIC ' ) ] + cased_aliased_rels ) [ alias ( 'users ' ) , alias ( ref ) ] )","['changelog.rst', 'tests/test_naive_completion.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/utils.py']",Merge pull request # 1006 from dbcli/internal/fix_unhashable_formatted_text
72,3eff3bbebd477a95c3a78fa54e876e1ca56805f0,2019-01-22 10:46:31-08:00,"context.logfile = StringIO ( ) Internal : * Override VISUAL environment variable for behave tests . ( Thanks : ` Marcin Cieślak ` _ ) context.cli.logfile = context.logfile * ( Fixup ) Clean up and add behave logging . ( Thanks : ` Marcin Cieślak ` _ , ` Dick Marinus ` _ )","['changelog.rst', 'tests/features/steps/wrappers.py']",Merge pull request # 1001 from dbcli/internal/add_behave_logging
73,a88c693c49feb9c9b9fe253e1e35adb10af2efa5,2019-01-22 19:18:39+01:00,"context.logfile = StringIO ( ) Internal : * Override VISUAL environment variable for behave tests . ( Thanks : ` Marcin Cieślak ` _ ) context.cli.logfile = context.logfile * ( Fixup ) Clean up and add behave logging . ( Thanks : ` Marcin Cieślak ` _ , ` Dick Marinus ` _ )","['changelog.rst', 'tests/features/steps/wrappers.py']",fixup ! Clean up and add behave logging ( # 956 )
74,ef8aac61c476bd46747d3d4910a4d494a59fa375,2019-01-21 16:00:25-08:00,cur.execute ( * Avoid error message on the server side if hstore extension is not installed in the current database ( # 991 ) . ( Thanks : ` Marcin Cieślak ` _ ) .. _ ` Mikhail Elovskikh ` : https : //github.com/wronglink * Marcin Cieślak ( saper ) TODO .. _ ` Mikhail Elovskikh ` : https : //github.com/wronglink `` select t.oid FROM pg_type t WHERE t.typname = 'hstore ' and t.typisdefined '' ) cur.execute ( `` SELECT 'hstore ' : :regtype : :oid '' ) .. _ ` Marcin Cieślak ` : https : //github.com/saper Bug fixes :,"['AUTHORS', 'changelog.rst', 'pgcli/pgexecute.py']",Determine hstore OID from the system view ( # 992 )
75,f614cef7ed63fd7f2a9c44600f4d3c84f96c59d2,2019-01-03 14:27:47-08:00,"cursor = conn.cursor ( ) * * arguments ) * * kwargs ) .. _ ` Mikhail Elovskikh ` : https : //github.com/wronglink self.host = host database = uri.path [ 1 : ] # ignore the leading fwd slash pid = -1 psycopg2 self.dbname = dsn_parameters [ 'dbname ' ] user = dsn_parameters [ 'user ' ] self.port = port # TODO : use actual connection info from psycopg2.extensions.Connection.info as psycopg > 2.8 is available and required dependency # noqa host=POSTGRES_HOST , password=POSTGRES_PASSWORD , port=None , dsn=None ) with mock.patch.object ( PGCli , 'connect ' ) as mock_connect : conn = psycopg2.connect ( dsn=unicode2utf8 ( dsn ) ) # user , etc . we connected to . Let 's read it . self.extra_args = { k : unicode2utf8 ( v ) for k , v in kwargs.items ( ) } self.extra_args = kwargs conn_params [ 'dsn ' ] = `` { 0 } password= { 1 } '' .format ( * * e.extra_args ) self.dbname = database port=unicode2utf8 ( port ) , # When we connect using a DSN , we do n't really know what db , database=dbname ) assert executor.short_host == 'localhost1 ' short_host , _ , _ = host.partition ( ' . ' ) | abc | if uri.query : `` `` '' Returns a clone of the current executor . '' '' '' dsn_parameters = conn.get_dsn_parameters ( ) user = ( user or self.user ) e.dbname , e.user , e.password , e.host , e.port , e.dsn , { k : v for k , ( v , ) in parse_qs ( uri.query ) .items ( ) } , def test_copy ( executor ) : if self.conn : self.connect ( database , user , password , host , port , dsn , * * kwargs ) e = pgexecute def __init__ ( self , database=None , user=None , password=None , host=None , 'port ' : port , self.connect ( * * arguments ) kwargs = { remap.get ( k , k ) : v for k , v in kwargs.items ( ) } conn.set_client_encoding ( 'utf8 ' ) db = ( database or self.dbname ) PGPORT host = ( host or self.host ) 'password ' : 'passwd ' , assert run ( executor_copy , `` 'select * from test '' ' , join=True ) == dedent ( `` '' '' \ } SELECT 1 '' '' '' ) if hasattr ( self , 'conn ' ) : ) dsn = ( dsn or self.dsn ) port=fixup_possible_percent_encoding ( uri.port ) , # Note : moved this after setting autocommit because of # 664 . port=None , cli.connect_uri ( database=unicode2utf8 ( db ) , self._conn_params = conn_params kwargs = psycopg2.extensions.parse_dsn ( uri ) port = dsn_parameters [ 'port ' ] return short_host self.dbname = None conn.set_client_encoding ( 'utf8 ' ) def test_multihost_db_uri ( tmpdir ) : self.password = None host = self.host port=POSTGRES_PORT , | -- -- -| self.user = user self.port = dsn_parameters [ 'port ' ] executor = PGExecute ( short_host , _ , _ = host.partition ( ' . ' ) # user , etc . we connected to . Let 's read it . string = string.replace ( '\\h ' , self.pgexecute.short_host or ' ( none ) ' ) run ( executor_copy , `` 'insert into test values ( 'abc ' ) ' '' ) conn = psycopg2.connect ( * * conn_params ) passwd=fixup_possible_percent_encoding ( uri.password ) ) port=None , dsn=None , * * kwargs ) : return unquote ( str ( s ) ) if s else s arguments = dict ( database=fixup_possible_percent_encoding ( database ) , self.password = password assert executor.short_host == 'localhost ' if password : def fixup_possible_percent_encoding ( s ) : 'database ' : database , host , _ , _ = self.host.partition ( ' , ' ) remap = { from utils import ( POSTGRES_HOST , POSTGRES_PORT , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , user=fixup_possible_percent_encoding ( uri.username ) , def short_host ( self ) : k : unicode2utf8 ( v ) for k , v in new_params.items ( ) if v is not None password=POSTGRES_PASSWORD , port=POSTGRES_PORT , dsn=None ) host=unicode2utf8 ( host ) , conn = psycopg2.connect ( user=POSTGRES_USER , host=POSTGRES_HOST , database=dbname ) self.user = dsn_parameters [ 'user ' ] self.connect ( ) run ( executor_copy , `` 'create table test ( a text ) ' '' ) # Deal with extra params e.g . ? sslmode=verify-ca & sslrootcert=/myrootcert new_params.update ( kwargs ) 'dsn ' : dsn , self.port = None user='bar ' , conn = psycopg2.connect ( user=POSTGRES_USER , from utils import ( POSTGRES_HOST , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , user=unicode2utf8 ( user ) , string = string.replace ( '\\H ' , host ) return pgcli.pgexecute.PGExecute ( database='_test_db ' , user=POSTGRES_USER , host=POSTGRES_HOST , conn_params.update ( { port='2543,2543,2543 ' ) host=POSTGRES_HOST , self.connect ( * * kwargs ) arguments = dict ( def __init__ ( self , database , user , password , host , port , dsn , * * kwargs ) : dsn_parameters = conn.get_dsn_parameters ( ) # Note : moved this after setting autocommit because of # 664 . * Support for multihost connection string that is convenient if you have postgres cluster . ( Thanks : ` Mikhail Elovskikh ` _ ) self.conn = None self.dbname = db 'password ' : password , conn_params = self._conn_params.copy ( ) } ) passwd='foo ' , with patch.object ( executor , 'host ' , 'localhost1.example.org , localhost2.example.org ' ) : else : host = dsn_parameters [ 'host ' ] if 'password ' in conn_params and 'dsn ' in conn_params : def test_short_host ( executor ) : mock_connect.assert_called_with ( database='testdb ' , dsn = `` { 0 } password= { 1 } '' .format ( dsn , password ) return pgcli.pgexecute.PGExecute ( database='_test_db ' , user=POSTGRES_USER , host = self.pgexecute.host or ' ( none ) ' with patch.object ( executor , 'host ' , 'localhost ' ) : POSTGRES_PORT = getenv ( 'PGPORT ' , 5432 ) port = ( port or self.port ) string = string.replace ( '\\H ' , self.pgexecute.host or ' ( none ) ' ) # unquote str ( each URI part ( they may be percent encoded ) string = string.replace ( '\\h ' , short_host ) if dsn : kwargs = ( kwargs or self.extra_args ) 'host ' : host , def copy ( self ) : return self.__class__ ( * * self._conn_params ) password=POSTGRES_PASSWORD , | a | db = dsn_parameters [ 'dbname ' ] self.user = None executor_copy = executor.copy ( ) # When we connect using a DSN , we do n't really know what db , 'dbname ' : 'database ' , with patch.object ( executor , 'host ' , 'localhost.example.org ' ) : password = ( password or self.password ) conn = psycopg2.connect ( self.dsn = dsn self.host = dsn_parameters [ 'host ' ] new_params = { uri = urlparse ( uri ) password=unicode2utf8 ( password ) , executor = pgexecute.copy ( ) cursor = conn.cursor ( ) * Mikhail Elovskikh ( wronglink ) else : host='baz1.com , baz2.com , baz3.com ' , 'user ' : user , self.host = None self._conn_params = { } if ' , ' in self.host : conn_params [ 'dsn ' ] , conn_params.pop ( 'password ' ) cli = PGCli ( pgclirc_file=str ( tmpdir.join ( `` rcfile '' ) ) ) host=fixup_possible_percent_encoding ( uri.hostname ) ,","['AUTHORS', 'changelog.rst', 'pgcli/completion_refresher.py', 'pgcli/main.py', 'pgcli/pgexecute.py', 'tests/conftest.py', 'tests/test_main.py', 'tests/test_pgexecute.py', 'tests/utils.py', 'tox.ini']",Support multihost connection string ( # 978 )
76,b3bf7ec188b7f924a7df1b2884440444be7e1e08,2019-01-02 16:31:05-08:00,====== 2.0.2 : TODO,['changelog.rst'],Changelog update for bugfix release . ( # 984 )
77,0cae7e20361dbee41fb8f79d7ee9c763d17d51e1,2019-01-02 16:15:59-08:00,"is_aggregate , is_window , is_set_returning , is_extension , arg_defaults def filt ( f ) : return not f.is_aggregate and not f.is_window [ '_custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , self.arg_types , self.arg_modes , self.return_type , self.is_aggregate , self.schema_name , self.func_name , self.arg_names , self.arg_types , [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] ] , return ( not f.is_extension and return_type , is_aggregate , is_window , is_set_returning , arg_defaults [ 'func2 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] , return_type , is_aggregate , is_window , is_set_returning , is_extension , is_aggregate , is_window , is_set_returning , arg_defaults is_set_returning=False , arg_defaults=None def filt ( f ) : return True not f.is_window and for f in all_functions not f.is_extension and [ 'func1 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , '' , False , False , False ] ] , arg_defaults [ ' b ' , ' b ' ] , `` , False , False , True ] ] , def filt ( f ) : 's ' , ' g ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , False , False , None [ 'func2 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] ] , 's ' , ' g ' , [ ' x ' ] , [ 'integer ' ] , [ LEFT JOIN pg_depend d ON d.objid = p.oid and d.deptype = ' e ' [ 'custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False ] , [ 'func1 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , [ 'custom_func1 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , [ 'integer ' , 'text ' ] , [ ' i ' , ' o ' ] , `` , False , False , True ] , ( f.is_public or f.schema_name == suggestion.schema ) ) [ '_custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False ] , '' , False , False , False , False ] ] , all_functions = self.populate_functions ( suggestion.schema , filt ) INNER JOIN pg_catalog.pg_namespace n 'integer ' , False , False , True , False ] ] , [ function ( x+ ' ( ) ' ) for x in ( 'func2 ' , 'CUSTOM.func3 ' ) ] [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] , self.is_window , self.is_set_returning , self.arg_defaults d.deptype = ' e ' is_extension , 'integer ' , False , False , True ] ] , is_set_returning=False , is_extension=False , arg_defaults=None self.schema_name , self.func_name , self.arg_names , [ function ( x + ' ( ) ' ) for x in ( 'func2 ' , ) ] 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ [ function ( x ) for x in ( 'func2 ( ) f ' , ) ] [ 'custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , [ 'func3 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , self.is_public = ( self.schema_name and self.schema_name == 'public ' ) [ 'custom_func2 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , ] , 'int ' , False , False , False , False , None * Fix for lag in v2 ( # 979 ) . ( Thanks : ` Irina Truong ` _ ) [ function ( x ) for x in ( 'func2 ( ) f ' , 'custom.func3 ( ) f ' ) ] [ 'custom_func1 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , [ 'func3 ' , [ ] , [ ] , [ ] , `` , False , False , False , False ] , self.is_extension = bool ( is_extension ) ON n.oid = p.pronamespace INNER JOIN pg_catalog.pg_namespace n self.is_window , self.is_set_returning , self.is_extension , self.arg_defaults 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , False , False , None ) % ( ( self.__class__.__name__ , ) + self._signature ( ) ) for f in self.populate_functions ( suggestion.schema , filt ) 'is_window= % r , is_set_returning= % r , is_extension= % r , arg_defaults= % r ) ' [ 'integer ' , 'text ' ] , [ ' i ' , ' o ' ] , `` , False , False , True , False ] , 'is_window= % r , is_set_returning= % r , arg_defaults= % r ) ' [ function ( x+ ' ( ) ' ) for x in ( 'func2 ' , 'custom.func3 ' ) ] ON n.oid = p.pronamespace ) % ( self.__class__.__name__ , ) + self._signature ( ) [ ' b ' , ' b ' ] , `` , False , False , True , False ] ] , [ 'custom_func2 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , return ( not f.is_aggregate and self.arg_modes , self.return_type , self.is_aggregate ,","['changelog.rst', 'pgcli/packages/parseutils/meta.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/parseutils/test_function_metadata.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Remove some functions completions ( # 982 )
78,2a1de91292e1996f0fff0407ca147c5894be8042,2018-12-27 17:36:58-08:00,"from prompt_toolkit.completion import DynamicCompleter completer=DynamicCompleter ( lambda : self.completer ) , DynamicCompleter ( lambda : self.completer ) ) , from prompt_toolkit.completion import DynamicCompleter , ThreadedCompleter completer=ThreadedCompleter (",['pgcli/main.py'],Merge pull request # 983 from dbcli/j-bennet/threaded-completer
79,9494ef705003a99b2053f2b4084e9346b6c279a0,2018-12-07 10:39:07-08:00,"execution = time ( ) - start humanize.time.naturaldelta ( query.total_time ) ) ) print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , MetaQuery.__new__.__defaults__ = ( `` , False , 0 , False , False , False , False ) 'total_time ' , # Time elapsed executing the query and formatting results MetaQuery.__new__.__defaults__ = ( `` , False , 0 , 0 , False , False , False , False ) meta_query = MetaQuery ( text , all_success , total , meta_changed , humanize.time.naturaldelta ( humanize.time.naturaldelta ( query.execution_time ) ) ) print ( 'Time : % 0.03fs ( % s ) , executed in : % 0.03fs ( % s ) ' % ( query.total_time , query.total_time ) , meta_query = MetaQuery ( text , all_success , total , execution , meta_changed , query.execution_time , 'total_time ' , # Time elapsed executing the query 'execution_time ' , # Time elapsed executing the query execution = 0",['pgcli/main.py'],Merge pull request # 977 from dbcli/j-bennet/execution-time
80,7b03f8e2043682aa2d1c06e0f7e8258b2f9c43c5,2018-11-30 15:21:12-08:00,"* Improve development guide ( Thanks : ` Ignacio Campabadal ` _ ) Features : * Improve development guide . ( Thanks : ` Ignacio Campabadal ` _ ) @ click.option ( ' -- user ' , 'username_opt ' , help='Username to connect to the postgres database . ' ) * Ignacio Campabadal * Allows passing the `` -u `` flag to specify a username . ( Thanks : ` Ignacio Campabadal ` _ )","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",allow passing -u flag ( lowercase ) to specify username ( # 975 )
81,3b9041fe36798639b4316fb3e413ac7a04c43da3,2018-11-27 07:49:54-08:00,"assert result == set ( ) result = set ( completer.get_completions ( def test_special_name_completion ( completer ) : text = '\\ ' Document ( text=text , cursor_position=position ) , return [ Completion ( text=k , start_position=pos , display_meta=v.description ) for k , v in iteritems ( self.completer.pgspecial.commands ) ] comp = PGCompleter ( smart_completion=True , comp = PGCompleter ( smart_completion=True , settings=settings ) assert set ( testdata.keywords ( ) + testdata.specials ( ) ) == result # Special commands will NOT be suggested during naive completion mode . text='\\timing ' , start_position=-2 , display_meta='Toggle timing of commands . ' ) ] ) TODO position = len ( '\\ ' ) assert set ( testdata.keywords ( ) ) == result def test_special_name_completion ( completer , complete_event ) : from pgspecial import PGSpecial complete_event ) ) * Added tests for special command completion . ( Thanks : ` Amjith Ramanujam ` _ ) from six import iteritems Internal : settings=settings , pgspecial=PGSpecial ( ) ) def specials ( self , pos=0 ) : assert result == set ( [ Completion ( result = result_set ( completer , '\\t ' )","['changelog.rst', 'tests/metadata.py', 'tests/test_naive_completion.py', 'tests/test_smart_completion_public_schema_only.py']",Fix special commands ( # 973 )
82,580ff415c8f611a9651878e1135922b62673535c,2018-11-18 20:16:29-08:00,====== TODO 2.0.1 :,['changelog.rst'],going to release . ( # 972 )
83,25a66ecfb3dee049b4094d5113bbd178dc190bef,2018-11-18 20:11:15-08:00,"schema_name , real_name , alias = parse_identifier ( item ) is_function = ( allow_functions and for identifier in item.get_identifiers ( ) : elif isinstance ( item , Function ) : continue for item in token_stream : continue if real_name : _identifier_is_function ( identifier ) ) # ` return ` . So we need to ignore the keyword if the keyword raise StopIteration try : is_function = allow_functions and _identifier_is_function ( item ) # Sometimes Keywords ( such as FROM ) are classified as schema_name , real_name , alias = parse_identifier ( item ) yield TableReference ( None , real_name , alias , allow_functions ) yield TableReference ( schema_name , real_name , alias , is_function ) elif isinstance ( item , Identifier ) : schema_name = identifier.get_parent_name ( ) return yield TableReference ( schema_name , real_name , return # identifiers which do n't have the get_real_name ( ) method . # identifiers which do n't have the get_real_name ( ) method . yield TableReference ( schema_name , real_name , elif isinstance ( item , Identifier ) : if real_name : # StopIteration . So we need to ignore the keyword if the keyword yield TableReference ( None , real_name , alias , allow_functions ) if isinstance ( item , IdentifierList ) : real_name = identifier.get_real_name ( ) elif isinstance ( item , Function ) : yield TableReference ( schema_name , real_name , alias , is_function ) _identifier_is_function ( identifier ) ) is_function = allow_functions and _identifier_is_function ( item ) except AttributeError : schema_name = identifier.get_parent_name ( ) * Fix StopIteration exception raised at runtime for Python 3.7 ( Thanks : ` Amjith Ramanujam ` _ ) . is_function = ( allow_functions and real_name = identifier.get_real_name ( ) for identifier in item.get_identifiers ( ) : # Sometimes Keywords ( such as FROM ) are classified as if isinstance ( item , IdentifierList ) : except AttributeError : identifier.get_alias ( ) , is_function ) try : try : for item in token_stream : identifier.get_alias ( ) , is_function ) except StopIteration :","['changelog.rst', 'pgcli/packages/parseutils/tables.py']",Fix the StopIteration issue in Python 3.7 ( # 971 )
84,923f2d64417ed8ab3b778b87a517e64c0534b6ec,2018-11-17 19:41:34-08:00,".. _ ` Amjith Ramanujam ` : https : //github.com/amjith * Enable Ctrl-Z to suspend the app ( Thanks : ` Amjith Ramanujam ` _ ) . enable_suspend=True , .. _ ` Amjith Ramanujam ` : https : //blog.amjith.com","['changelog.rst', 'pgcli/main.py']",Enable suspend using C-Z . ( # 970 )
85,0f0be9deab501b85f9d77d5233886505ba17abc5,2018-11-17 11:26:05-08:00,Set default port in ` connect_uri ` when none is given . ( Thanks : ` DanEEStar ` _ ) * Set default port in ` connect_uri ` when none is given . ( Thanks : ` Daniel Egger ` _ ) * Daniel Egger NamedQueries.instance = NamedQueries.from_config ( from pgspecial.namedqueries import NamedQueries load_config ( config_location ( ) + 'config ' ) ) .. _ ` Daniel Egger ` : https : //github.com/DanEEStar NamedQueries.instance = NamedQueries.from_config ( self.config ) * Fix for loading/saving named queries from provided config file ( # 938 ) . ( Thanks : ` Daniel Egger ` _ ) * DanEEStar .. _ ` DanEEStar ` : https : //github.com/DanEEStar,"['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgcompleter.py']",Merge pull request # 962 from DanEEStar/bugfix/named-queries-from-config
86,462443a2d1d34d686eb11dd1b9b490c062e688a4,2018-11-17 11:15:13-08:00,"username = dbname # work as psql : when database is given as option and argument use the argument as user help='Do not use a separate connection for completions . ' ) help='Username to connect to the postgres database . ' ) help='Force password prompt . ' ) help='Do not use a separate connection for completions . ' ) database = dbname_opt or dbname or `` default=False , if dbname_opt and dbname : single_connection , dbname , username , version , pgclirc , dsn , row_limit , @ click.option ( '-U ' , ' -- username ' , 'username_opt ' , envvar='PGUSER ' , @ click.option ( ' -- user ' , 'username_opt ' , envvar='PGUSER ' , default=False , help='Never prompt for password . ' ) help='Force password prompt . ' ) single_connection , dbname_opt , username , version , pgclirc , dsn , row_limit , def cli ( database , username_opt , host , port , prompt_passwd , never_prompt , help='Username to connect to the postgres database . ' ) from __future__ import print_function from __future__ import print_function @ click.option ( '-d ' , ' -- dbname ' , default= '' , envvar='PGDATABASE ' , help='database name to connect to . ' ) @ click.argument ( 'database ' , default=lambda : None , envvar='PGDATABASE ' , nargs=1 ) def cli ( dbname , username_opt , host , port , prompt_passwd , never_prompt , default=False , help='Never prompt for password . ' ) default=False , database = database or dbname",['pgcli/main.py'],Merge pull request # 961 from DanEEStar/feature/dbname-username-options
87,819f66e5b550e8881f2a650c0d70bcaa01af8ecb,2018-11-13 14:01:47-08:00,"_ explanation of this process . effects of your change . what a virtualenv is , ` this guide < http : //docs.python-guide.org/en/latest/dev/virtualenvs/ # virtual-environments > ` _ : : $ sudo service postgresql restart # on directory /pgcli/tests to the code are immediately available in the installed version of pgcli . This After that , tests in the `` /pgcli/tests `` directory can be run with : Check Github 's ` Understanding the GitHub flow guide at `` localhost `` . Make sure the authentication method is set to `` trust `` . If having to go through the install cycle every time you change the code . Check your `` pg_hba.conf `` file to verify local connections are enabled After that , tests can be run with : The database user has to have effects of your changes . .. _ ` Ignacio Campabadal ` : https : //github.com/igncampa And on the `` /pgcli `` directory : by checking your `` pg_hba.conf `` file . The default user should be `` postgres `` at `` localhost `` , without the password ( authentication mode trust ) . $ cd tests Ensure that the database user has permissions to create and drop test databases permissions to create and drop test databases . Default user is `` postgres `` we 've linked the pgcli installation with the working copy . Any changes made thanks . ` Fork the project < https : //github.com/dbcli/pgcli > ` _ on github . Then Contact us on ` gitter < https : //gitter.im/dbcli/pgcli/ > ` _ or ` file an issue < https : //github.com/dbcli/pgcli/issues/new > ` _ . what a virtualenv is , this ` guide < http : //docs.python-guide.org/en/latest/dev/virtualenvs/ # virtual-environments > ` _ # on directory /pgcli service for the changes to take effect . # ONLY IF YOU MADE CHANGES TO YOUR pg_hba.conf FILE Troubleshooting the integration tests < https : //guides.github.com/introduction/flow/ > ` _ for a more detailed Make sure postgres instance on localhost is running we 've linked the pgcli installation with the working copy . So any changes made * Improve development guide ( Thanks : ` Ignacio Campabadal ` _ ) to the code is immediately available in the installed version of pgcli . This you made any changes to your `` pg_hba.conf `` make sure to restart the postgres having to go through the install cycle everytime you change the code . thanks . ` Fork the project < https : //github.com/dbcli/pgcli > ` _ in github . Then Check ` this issue < https : //github.com/dbcli/pgcli/issues/945 > ` _ for relevant information .","['DEVELOP.rst', 'changelog.rst']",Contrib guide improv ( # 946 )
88,b92743368bfc357f72a4046e899faef899ee9972,2018-10-31 18:46:04+01:00,Set default port in ` connect_uri ` when none is given . ( Thanks : ` DanEEStar ` _ ) * Set default port in ` connect_uri ` when none is given . ( Thanks : ` Daniel Egger ` _ ) * Daniel Egger NamedQueries.instance = NamedQueries.from_config ( from pgspecial.namedqueries import NamedQueries load_config ( config_location ( ) + 'config ' ) ) .. _ ` Daniel Egger ` : https : //github.com/DanEEStar NamedQueries.instance = NamedQueries.from_config ( self.config ) * Fix for loading/saving named queries from provided config file ( # 938 ) . ( Thanks : ` Daniel Egger ` _ ) from __future__ import print_function from __future__ import print_function * DanEEStar .. _ ` DanEEStar ` : https : //github.com/DanEEStar,"['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgcompleter.py']",Bugfix for # 938 : load named queries from provided config file
89,589c2abdfb329d343f5fcc41f674993677f01607,2018-10-30 07:41:38-07:00,* DanEEStar .. _ ` DanEEStar ` : https : //github.com/DanEEStar Set default port in ` connect_uri ` when none is given . ( Thanks : ` DanEEStar ` _ ),"['AUTHORS', 'changelog.rst']",Missed changelog update . ( # 960 )
90,12ad10f6975d9651d0c696a021fc982c2c5de861,2018-10-14 13:53:19-07:00,"actual = COLOR_CODE_REGEX.sub ( `` , context.cli.before ) timedout = False if timedout : expected , ) except ImportError : * Clean up and add behave logging . ( Thanks : ` Dick Marinus ` _ ) { 2 ! r } timedout = True { 0 ! r } Bug fixes : textwrap.dedent ( `` '\ try : '' , context.cli.before ) except : actual , ) actual ) ) { 1 ! r } Expected : ' '' ) .format ( from io import StringIO context.logfile.getvalue ( ) expected , Actual : actual = re.sub ( r'\x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? ' , raise Exception ( 'Expected : \n -- -\n { 0 ! r } \n -- -\n\nActual : \n -- -\n { 1 ! r } \n -- -'.format ( Full log : Internal : from StringIO import StringIO except pexpect.exceptions.TIMEOUT : import textwrap raise Exception (","['changelog.rst', 'tests/features/steps/wrappers.py']",Clean up and add behave logging ( # 956 )
91,fcf0eb022ee81cc8e961c08c4a89742a9714cd63,2018-10-02 17:10:43-07:00,"if hasattr ( context , 'cli ' ) and not context.exit_sent : def is_too_wide ( self , line ) : context.cli.expect_exact ( pexpect.EOF , timeout=10 ) # not using the cli for that context.cmd_output = subprocess.check_output ( cmd , cwd=context.package_root ) context.atprompt = True context.cli.expect_exact ( pexpect.EOF , timeout=15 ) assert b'postgres ' in context.cmd_output def is_too_tall ( self , lines ) : except pexpect.TIMEOUT : def step_list_databases ( context ) : import subprocess return False Scenario : list databases return len ( lines ) > = ( self.prompt_app.output.get_size ( ) .rows - 4 ) TODO try : context.cli.expect_exact ( ' { 0 } > '.format ( dbname ) , timeout=15 ) if scenario.name == 'list databases ' : When we list databases print ( ' -- - after_scenario { } : kill cli'.format ( scenario.name ) ) if self.is_too_tall ( lines ) or any ( self.is_too_wide ( l ) for l in lines ) : return import pexpect def before_scenario ( context , _ ) : def is_wide_line ( self , line ) : ' { 0 } > '.format ( dbname ) , def after_scenario ( context , _ ) : def step_see_list_databases ( context ) : assert b'List of databases ' in context.cmd_output ) timeout=5 context.cmd_output = None context.cli.kill ( signal.SIGKILL ) context.cli.expect_exact ( def after_scenario ( context , scenario ) : if not self.prompt_app : def before_scenario ( context , scenario ) : context.cli.expect_exact ( pexpect.EOF , timeout=15 ) then we see list of databases if hasattr ( context , 'cli ' ) and context.cli and not context.exit_sent : import signal if len ( lines ) > = self.prompt_app.output.get_size ( ) .rows - 4 or any ( self.is_wide_line ( l ) for l in lines ) : `` `` '' Are there too many lines to fit into terminal ? '' '' '' cmd = [ 'pgcli ' , ' -- list ' ] * Fix for error listing databases ( # 951 ) . ( Thanks : ` Irina Truong ` _ )","['changelog.rst', 'pgcli/main.py', 'tests/features/basic_commands.feature', 'tests/features/environment.py', 'tests/features/steps/basic_commands.py', 'tests/features/steps/iocommands.py']",Fix for pgcli -- list . ( # 952 )
92,8428e3fff18a870b881c6b664034af863973974b,2018-09-28 15:57:45-07:00,"====== 2.0.0 : * Update to `` prompt-toolkit `` 2.0 . ( Thanks : ` Jonathan Slenders ` _ , ` Dick Marinus ` _ , ` Irina Truong ` _ )",['changelog.rst'],Merge pull request # 948 from dbcli/j-bennet/release-2.0.0
93,392491a74d2d8abcb2c0db5230fc7f11502c6ba9,2018-09-28 14:18:40-07:00,"message=get_message , def get_message ( ) : Token.Toolbar.Arg : 'arg-toolbar ' , _logger.debug ( 'Detected enter key . ' ) # TODO : uncomment to debug a failure multiline=pg_is_multiline ( self ) , ' [ F2 ] Smart Completion : OFF ' ) ) cli.application.pre_run_callables = saved_callables prompt_app = PromptSession ( max_width = self.prompt_app.output.get_size ( ) .columns Style ( prompt_styles ) document = cli.run ( ) Token.Menu.Completions.Meta = 'bg : # 448888 # ffffff ' from prompt_toolkit.key_binding.manager import KeyBindingManager logger.error ( 'Unhandled style / class name : % s ' , token ) return [ ( 'class : continuation ' , continuation ) ] if self.cli : cli.application.pre_run_callables = [ ] from prompt_toolkit.enums import DEFAULT_BUFFER self.prompt_app.app.invalidate ( ) return [ ( Token.Continuation , continuation ) ] chars= ' [ ] ( ) { } ' ) , event.app.editing_mode = EditingMode.VI if pgcli.vi_mode else EditingMode.EMACS Token.Toolbar.Search : 'search-toolbar ' , completer=self.completer , eventloop=self.eventloop ) complete_state = cli.current_buffer.complete_state Token.Toolbar.System : 'system-toolbar ' , vi_mode=self.vi_mode document = self.handle_editor_command ( self.cli , document ) if pgcli.vi_mode : get_vi_mode_enabled=lambda : self.vi_mode , return [ ( 'class : prompt ' , prompt ) ] if failed_transaction ( ) : continuation=self.multiline_continuation_char * ( width - 1 ) + ' ' `` `` '' Will this line be too wide to fit into terminal ? '' '' '' result.append ( ( token.On , ' [ F2 ] Smart Completion : ON ' ) ) get_prompt_tokens=prompt_tokens , result.append ( layout=layout , def handle_editor_command ( self , text ) : if ( not expanded and max_width and len ( first_line ) > max_width and headers ) : Token.Toolbar.On : 'bottom-toolbar.on ' , self.get_last_query ( ) ) result.append ( ( token , ' ( Semi-colon [ ; ] will end the line ) ' ) ) lexer=PygmentsLexer ( PostgresLexer ) , Token.Toolbar.Search = 'noinherit bold ' 'prompt_toolkit > =1.0.10 , < 1.1.0 ' , Token.Output.OddRow : 'output.odd-row ' , if len ( lines ) > = self.cli.output.get_size ( ) .rows - 4 \ accept_action=AcceptAction.RETURN_DOCUMENT ) search = ' # ffffff bg : # 4444aa ' def is_wide_line ( self , line ) : Token.Menu.Completions.ProgressBar : 'scrollbar ' , # best guess editing_mode=editing_mode ) Enable/Disable Multiline Mode . arg-toolbar.text = 'nobold ' filename , sql=query ) 'all ' - The new prioritizer is updated to exactly reflect : param token_name : str name of Pygments token . Example : `` Token.String '' import logging query = self.pgexecute.function_definition ( spec ) style.update ( { string_to_tokentype ( if cli.buffers [ DEFAULT_BUFFER ] .multiline_mode == 'safe ' : event.cli.editing_mode = EditingMode.VI if vi_mode else EditingMode.EMACS raise RuntimeError ( message ) # map Pygments tokens ( ptk 1.0 ) to class names ( ptk 2.0 ) . Token.Toolbar.Arg.Text = 'nobold ' ( 'class : bottom-toolbar ' , ' [ F4 ] Vi-mode ( ' + _get_vi_mode ( ) + ' ) ' ) ) # exists before trying the replace the completer object in cli . text = self.handle_editor_command ( text ) : param document : Document # It 's internal api of prompt_toolkit that may change . This was added to fix # 668 . if pgcli.pgexecute.failed_transaction ( ) : return cli result.append ( ( token , ' ' ) ) system-toolbar = 'noinherit bold ' scrollbar = 'bg : # 00aaaa ' # We may find a better way to do it in the future . # Highlight matching brackets while editing . search-toolbar.text = 'nobold ' : param text : Document or any ( len ( COLOR_CODE_REGEX.sub ( `` , l ) ) > self.cli.output.get_size ( ) .columns for l in lines ) : completion-menu.completion.current = 'bg : # ffffff # 000000 ' search_ignore_case=True ) `` `` '' Swap the completer object with the newly created completer . @ key_binding_manager.registry.add_binding ( Keys.ControlJ , filter=HasSelectedCompletion ( ) ) def get_continuation ( width , line_number , is_soft_wrap ) : ( accept current selection ) . bottom-toolbar.transaction.valid = 'bg : # 222222 # 00ff5f bold ' from prompt_toolkit.enums import DEFAULT_BUFFER result.append ( ( token.Off , ' [ F2 ] Smart Completion : OFF ' ) ) from prompt_toolkit.buffer import AcceptAction for recent in history [ -n_recent : ] : if cli.buffers [ DEFAULT_BUFFER ] .always_multiline : token ) : style [ string_to_tokentype ( cli_style [ token ] ) ] , } ) processor=HighlightMatchingBracketProcessor ( doc = get_app ( ) .layout.get_buffer_by_name ( DEFAULT_BUFFER ) .document enable_system_prompt=True , while True : raise RuntimeError ( message ) def __repr__ ( self ) : from prompt_toolkit import CommandLineInterface , Application , AbortAction from __future__ import unicode_literals self.completer.extend_query_history ( document.text ) if editor_command == '\\e ' : lambda : self.vi_mode , self.completion_refresher.is_refreshing , from prompt_toolkit.contrib.completers import PathCompleter from prompt_toolkit.lexers import PygmentsLexer result.append ( ( 'class : bottom-toolbar ' , ' [ F4 ] Emacs-mode ' ) ) key_binding_manager = pgcli_bindings ( Return a function that generates the toolbar tokens . style_from_pygments_cls ( style ) , result.append ( ( token.On , ' [ F3 ] Multiline : ON ' ) ) # treat as prompt style name ( 2.0 ) . See default style names here : Token.Toolbar.Transaction.Valid = 'bg : # 222222 # 00ff5f bold ' if not expanded and max_width and len ( first_line ) > max_width and headers : return False self.completer.extend_query_history ( text ) # Something went wrong . Raise an exception and bail . key_bindings = pgcli_bindings ( self ) prompt_continuation=get_continuation , @ key_binding_manager.registry.add_binding ( Keys.F4 ) editor_command = special.editor_command ( document.text ) Token.Menu.Completions.Completion.Current : 'completion-menu.completion.current ' , from prompt_toolkit.shortcuts import PromptSession , CompleteStyle @ key_binding_manager.registry.add_binding ( Keys.Tab ) on_exit=AbortAction.RAISE_EXCEPTION , self.pgexecute.failed_transaction , result.append ( ( token , ' ( [ Esc ] [ Enter ] to execute ] ) ' ) ) sql , message = special.open_external_editor ( from prompt_toolkit.filters import Filter `` `` '' Parse token type and style string . set_vi_mode_enabled ( vi_mode ) if token_type in TOKEN_TO_PROMPT_STYLE : learned prioritizer should be transferred to the new completer . complete_style = CompleteStyle.COLUMN max_width = self.cli.output.get_size ( ) .columns `` `` '' completer=DynamicCompleter ( lambda : self.completer ) , return kb self.always_multiline = always_multiline query = special.get_editor_query ( from pygments.token import string_to_tokentype , Token Token.SearchMatch : 'search ' , def _get_vi_mode ( cli ) : override_style , output.header = `` # 00ff5f bold '' return not _multiline_exception ( doc.text ) complete_style=complete_style , ' [ F2 ] Smart Completion : ON ' ) ) from __future__ import print_function , unicode_literals 'none ' - The new prioritizer is left in a new/clean state bottom_toolbar=get_toolbar_tokens , layout = create_prompt_layout ( spec = document.text.split ( ) [ 1 ] tempfile_suffix='.sql ' , * * kwargs ) continuation = self.multiline_continuation_char * ( width - 1 ) + ' ' prompt_style = TOKEN_TO_PROMPT_STYLE [ token_type ] ( 'class : bottom-toolbar ' , ' Refreshing completions ... ' ) ) } [ cli.vi_state.input_mode ] # TODO : cli helpers will have to switch to ptk.Style return document wrappers.expect_exact ( context , expected_line , timeout=1 ) query = self.pgexecute.view_definition ( spec ) query = ( special.get_editor_query ( document.text ) or persist_priorities is a string specifying how the old completer 's Token.Output.EvenRow = `` '' logger = logging.getLogger ( __name__ ) return cond def __init__ ( self , always_multiline , multiline_mode , * args , * * kwargs ) : editor_command = special.editor_command ( document.text ) Token.Menu.Completions.Completion : 'completion-menu.completion ' , finally : while editor_command : def get_toolbar_tokens ( ) : @ key_binding_manager.registry.add_binding ( Keys.F2 ) def pgcli_bindings ( get_vi_mode_enabled , set_vi_mode_enabled ) : # treat as pygments token ( 1.0 ) try : priorities , but not any other . Token.Toolbar.System = 'noinherit bold ' failed_transaction , valid_transaction ) : scrollbar.arrow = 'bg : # 003333 ' the completion dropdown menu , instead close the dropdown menu Token.Menu.Completions.Completion = 'bg : # 008888 # ffffff ' from prompt_toolkit.completion import Completer , Completion , PathCompleter Token.Output.EvenRow : 'output.even-row ' , # reverse dict for cli_helpers , because they still expect Pygments tokens . Token.Toolbar.Arg.Text : 'arg-toolbar.text ' , 'prompt_toolkit > =2.0.0 , < 2.1.0 ' , enable_abort_and_exit_bindings=True ) def get_continuation_tokens ( cli , width ) : style.update ( { token_type : cli_style [ token ] } ) get_toolbar_tokens = create_toolbar_tokens_func ( continue Token.Toolbar : 'bottom-toolbar ' , @ key_binding_manager.registry.add_binding ( Keys.F3 ) if get_is_refreshing ( ) : text ) or self.get_last_query ( ) # import pdb ; pdb.set_trace ( ) Token.Output.OddRow = `` '' class HasSelectedCompletion ( Filter ) : bottom-toolbar.on = 'bg : # 222222 # ffffff ' yield cli , mock_echo , mock_echo_via_pager , mock_app Token.Toolbar.Transaction.Valid : 'bottom-toolbar.transaction.valid ' , token , style , cli_style ) logger.error ( `` sql : % r , error : % r '' , text , e ) filename = special.get_filename ( document.text ) # we do n't want to support tokens anymore TOKEN_TO_PROMPT_STYLE = { # Render \t as 4 spaces instead of `` ^I '' self.prompt_app = self._build_cli ( history ) Force autocompletion at cursor . from prompt_toolkit.filters import HasFocus , IsDone event.cli.start_completion ( select_first=True ) `` `` '' tempfile_suffix='.sql ' , def is_multiline ( ) : completion-menu.meta.completion.current = 'bg : # 44aaaa # 000000 ' except AttributeError as err : result.append ( ( token.Off , ' [ F3 ] Multiline : OFF ' ) ) lexer=PygmentsLexer ( PostgresLexer ) , b.start_completion ( select_first=True ) `` `` '' Return a function that generates the toolbar tokens . '' '' '' from pygments.token import Token include_default_pygments_style=False , enable_auto_suggest_bindings=True , sql , cursor_position=len ( sql ) ) if message : doc = self.document sql , message = special.open_external_editor ( Token.Toolbar.On = 'bg : # 222222 # ffffff ' while editor_command : @ Condition def handle_editor_command ( self , cli , document ) : get_bottom_toolbar_tokens=get_toolbar_tokens , kb = KeyBindings ( ) self.vi_mode = value selected = ' # ffffff bg : # 6666aa ' return ( complete_state is not None and wrappers.expect_exact ( context , expected_line , timeout=2 ) wrappers.expect_exact ( context , 'Saved . ' , timeout=2 ) ) def cond ( ) : cli.current_buffer.document = Document ( completion-menu.meta.completion = 'bg : # 448888 # ffffff ' : param style_object : pygments.style.Style instance to use as base elif editor_command == '\\ef ' : Token.Menu.Completions.Completion.Current = 'bg : # ffffff # 000000 ' assert callable ( get_vi_mode_enabled ) filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , application = Application ( `` `` '' from .pgbuffer import pg_is_multiline Token.Toolbar.Search.Text = 'nobold ' query = self.pgexecute.view_definition ( spec ) event.cli.start_completion ( select_first=False ) Token.SelectedText = ' # ffffff bg : # 6666aa ' query = self.execute_command ( text ) ' Failed transaction ' ) ) return token_type , style_object.styles [ other_token_type ] b = event.app.current_buffer bottom-toolbar = 'bg : # 222222 # aaaaaa ' multiline=True , ( 'class : bottom-toolbar.transaction.valid ' , ' Transaction ' ) ) Token.Toolbar.Search.Text : 'search-toolbar.text ' , from __future__ import print_function style.update ( # FIXME : using application.pre_run_callables like this here is not the best solution . ( 'class : bottom-toolbar ' , ' ( [ Esc ] [ Enter ] to execute ] ) ' ) ) custom_styles [ string_to_tokentype ( token ) ] = cli_style [ token ] if len ( lines ) > = self.prompt_app.output.get_size ( ) .rows - 4 or any ( self.is_wide_line ( l ) for l in lines ) : other_token_type = string_to_tokentype ( style_dict [ token_name ] ) try : processor=HighlightMatchingBracketProcessor ( # names in 2.0 . Convert old token types to new style names , for backwards compatibility . class PGBuffer ( Buffer ) : multiline_mode=self.multiline_mode , import pygments.styles if cli.buffers [ DEFAULT_BUFFER ] .completer.smart_completion : # you can use token or custom colors search.current = ' # ffffff bg : # 44aa44 ' style.update ( { token_type : style_value } ) prompt_styles = [ ] `` `` '' Custom key bindings for pgcli . '' '' '' TabsProcessor ( char1= ' ' , char2= ' ' ) ] , if pgcli.multiline_mode == 'safe ' : # color of table from prompt_toolkit.filters import completion_is_selected from prompt_toolkit.key_binding import KeyBindings `` `` '' Force autocompletion at cursor . '' '' '' def prompt_tokens ( _ ) : 'keywords ' - The new prioritizer is updated with old keyword if pgcli.completion_refresher.is_refreshing ( ) : : param style_dict : dict of token names and their styles , customized to this cli Token.SearchMatch = ' # ffffff bg : # 4444aa ' Token.Toolbar.Transaction.Failed = 'bg : # 222222 # ff005f bold ' ignore_case=True , always_multiline=self.multi_line , learned prioritizer should be transferred to the new completer . result.append ( ( token.On , ' [ F4 ] Vi-mode ( ' + _get_vi_mode ( cli ) + ' ) ' ) ) Token.Menu.Completions.Meta.Current = 'bg : # 44aaaa # 000000 ' persist_priorities is a string specifying how the old completer 's if self.prompt_app : from prompt_toolkit.filters import Condition if not self.always_multiline : def get_toolbar_tokens ( cli ) : reserve_space_for_menu=self.min_num_menu_lines , def __call__ ( self , cli ) : return PygmentsStyle.from_defaults ( style_dict=custom_styles , else : { string_to_tokentype ( token ) : cli_style [ token ] , } ) result.append ( ( token.Transaction.Failed , ' Failed transaction ' ) ) else : # \ev or \ef class OutputStyle ( pygments.style.Style ) : the old one pgcli.completer.smart_completion = not pgcli.completer.smart_completion return self.row_limit > 0 and cur and cur.rowcount > self.row_limit return prompt_app if valid_transaction ( ) : if editor_command == '\\ev ' : from .pgbuffer import PGBuffer Token.Menu.Completions.Meta.Current : 'completion-menu.meta.completion.current ' , complete_style = CompleteStyle.MULTI_COLUMN 'all ' - The new prioritizer is updated to exactly reflect self.pgexecute.valid_transaction ) def create_toolbar_tokens_func ( get_vi_mode_enabled , get_is_refreshing , get_continuation_tokens=get_continuation_tokens , Token.Menu.Completions.ProgressBar = 'bg : # 00aaaa ' if pgcli.multi_line : def set_vi_mode ( value ) : if pgcli.multiline_mode == 'safe ' : enable_open_in_editor=True , return token_type , style_dict [ token_name ] b = event.cli.current_buffer `` `` '' Swap the completer object in cli with the newly created completer . except AttributeError as err : token_type = string_to_tokentype ( token_name ) completion-menu.multi-column-meta = 'bg : # aaffff # 000000 ' get_char2=lambda _ : ' ' ) , assert callable ( set_vi_mode_enabled ) return True get_toolbar_tokens = create_toolbar_tokens_func ( self ) except KeyboardInterrupt : return [ ( Token.Prompt , prompt ) ] from pygments.token import string_to_tokentype } for recent in history.get_strings ( ) [ -n_recent : ] : # Render \t as 4 spaces instead of `` ^I '' return True return self.row_limit > 0 and cur and ( cur.rowcount > self.row_limit ) output.odd-row = `` '' editing_mode = EditingMode.VI if self.vi_mode else EditingMode.EMACS `` `` '' Toggle between Vi and Emacs mode . '' '' '' Token.Output.Header = `` # 00ff5f bold '' if self.multiline_mode == 'safe ' : key_bindings_registry=key_binding_manager.registry , ( 'class : bottom-toolbar ' , ' ( Semi-colon [ ; ] will end the line ) ' ) ) `` `` '' Enable/Disable Multiline Mode . '' '' '' custom_styles [ string_to_tokentype ( default=sql , input_processors= [ search-toolbar = 'noinherit bold ' else : # prompt-toolkit used pygments tokens for styling before , switched to style self.watch_command , timing = special.get_watch_command ( self.completer = new_completer Token.Menu.Completions.ProgressButton = 'bg : # 003333 ' ] ) wrappers.expect_pager ( context , 'Saved.\r\n ' , timeout=1 ) elif editor_command == '\\ef ' : Token.Toolbar.Off : 'bottom-toolbar.off ' , text = self.prompt_app.prompt ( vi_mode=self.vi_mode ) # style classes for colored table output return text filename = None elif token in PROMPT_STYLE_TO_TOKEN : enable_search=True , else : # instantiating the cli object . So it is necessary to check if cli class OutputStyle ( PygmentsStyle ) : Token.Output.Header : 'output.header ' , def parse_pygments_style ( token_name , style_object , style_dict ) : result.append ( ( 'class : bottom-toolbar.on ' , Token.Toolbar.Transaction.Failed : 'bottom-toolbar.transaction.failed ' , if not pgcli.multi_line : yield cli , mock_echo , mock_echo_via_pager , mock_cli self.cli.request_redraw ( ) # Highlight matching brackets while editing . # When pgcli is first launched we call refresh_completions before def _get_vi_mode ( ) : self.watch_command , timing = special.get_watch_command ( text ) if pgcli.pgexecute.valid_transaction ( ) : Token.Toolbar.Off = 'bg : # 222222 # 888888 ' self.prompt_app = None 'keywords ' - The new prioritizer is updated with old keyword # Something went wrong . Raise an exception and bail . result.append ( ( 'class : bottom-toolbar ' , ' ' ) ) bottom-toolbar.transaction.failed = 'bg : # 222222 # ff005f bold ' query = self.execute_command ( document.text ) def pgcli_bindings ( pgcli ) : bottom-toolbar.off = 'bg : # 222222 # 888888 ' complete_state.current_completion is not None ) enable_open_in_editor=True , set_vi_mode_enabled=set_vi_mode ) buf = PGBuffer ( if editor_command == '\\e ' : extra_input_processors= [ } [ get_app ( ) .vi_state.input_mode ] from prompt_toolkit.application import get_app display_completions_in_columns=self.wider_completion_menu , filename , sql=query ) def pg_is_multiline ( pgcli ) : mock.patch.object ( cli , 'cli ' ) as mock_cli : pgcli.multi_line = not pgcli.multi_line key_binding_manager = KeyBindingManager ( spec = text.split ( ) [ 1 ] from prompt_toolkit.styles import merge_styles , Style sql = None on_abort=AbortAction.RETRY , return merge_styles ( [ from prompt_toolkit.keys import Keys from pygments.style import Style as PygmentsStyle from prompt_toolkit.shortcuts import create_prompt_layout , create_eventloop from pygments.style import Style if pgcli.completer.smart_completion : buf.completer.smart_completion = not buf.completer.smart_completion mock.patch.object ( cli , 'prompt_app ' ) as mock_app : Token.Menu.Completions.Meta : 'completion-menu.meta.completion ' , def create_toolbar_tokens_func ( pgcli ) : enable_system_bindings=True , Custom key bindings for pgcli . In other words , do n't execute query when enter is pressed in the old one buffer=buf , ] ) else : # \ev or \ef from prompt_toolkit.filters import Always , HasFocus , IsDone ConditionalProcessor ( 'none ' - The new prioritizer is left in a new/clean state `` `` '' Enable when the current buffer has a selected completion . '' '' '' # Initialize default metaquery in case execution fails self.cli = None arg-toolbar = 'noinherit bold ' if self.cli : complete_while_typing=True , document = self.cli.run ( ) from prompt_toolkit.layout.lexers import PygmentsLexer # # TODO : uncomment to debug a failure Enable/Disable SmartCompletion Mode . self.cli.current_buffer.completer = new_completer `` `` '' Makes the enter key work as the tab key only when showing the menu . Token.SearchMatch.Current : 'search.current ' , ' [ F3 ] Multiline : OFF ' ) ) text = self.prompt_app.prompt ( result.append ( ( 'class : bottom-toolbar.off ' , result.append ( ( token.On , ' [ F4 ] Emacs-mode ' ) ) result.append ( ( token , ' Refreshing completions ... ' ) ) return `` HasSelectedCompletion ( ) '' ConditionalProcessor ( @ key_binding_manager.registry.add_binding ( Keys.ControlSpace ) return not _multiline_exception ( doc.text ) Token.Menu.Completions.ProgressButton : 'scrollbar.arrow ' , # best guess token = Token.Toolbar custom_styles = { } : param cli : CommandLineInterface Token.Toolbar = 'bg : # 222222 # aaaaaa ' buf.always_multiline = not buf.always_multiline Toggle between Vi and Emacs mode . if message : completion-menu.completion = 'bg : # 008888 # ffffff ' self.eventloop = create_eventloop ( ) buf = event.cli.current_buffer Token.SelectedText : 'selected ' , from prompt_toolkit.styles import PygmentsStyle v : k for k , v in TOKEN_TO_PROMPT_STYLE.items ( ) pygments_style_cls=style ) Token.Menu.Completions.MultiColumnMeta : 'completion-menu.multi-column-meta ' , reserve_space_for_menu=self.min_num_menu_lines , result.append ( ( 'class : bottom-toolbar.transaction.failed ' , try : result.append ( ( 'class : bottom-toolbar.on ' , ' [ F3 ] Multiline : ON ' ) ) from prompt_toolkit.styles.pygments import style_from_pygments_cls return False self.multiline_mode = multiline_mode from prompt_toolkit.completion import DynamicCompleter filename = None token ) ] = style.styles [ string_to_tokentype ( cli_style [ token ] ) ] b.start_completion ( select_first=False ) cli = CommandLineInterface ( application=application , editor_command = special.editor_command ( text ) if editor_command == '\\ev ' : result.append ( from prompt_toolkit.buffer import Buffer Token.Menu.Completions.MultiColumnMeta = 'bg : # aaffff # 000000 ' Token.SearchMatch.Current = ' # ffffff bg : # 44aa44 ' saved_callables = cli.application.pre_run_callables # import ipdb ; ipdb.set_trace ( ) complete_while_typing=Always ( ) , filename = special.get_filename ( text ) logger.error ( 'Unhandled style / class name : % s ' , token ) editor_command = special.editor_command ( text ) _logger.debug ( 'Detected < C-J > key . ' ) vi_mode = not get_vi_mode_enabled ( ) document.text ) key_bindings=key_bindings , # https : //github.com/jonathanslenders/python-prompt-toolkit/blob/master/prompt_toolkit/styles/defaults.py return key_binding_manager token_type , style_value = parse_pygments_style ( from prompt_toolkit.completion import Completer , Completion super ( self.__class__ , self ) .__init__ ( * args , is_multiline=is_multiline , pgcli.vi_mode = not pgcli.vi_mode priorities , but not any other . result.append ( ( token.Transaction.Valid , ' Transaction ' ) ) PROMPT_STYLE_TO_TOKEN = { from .filters import HasSelectedCompletion token_type = PROMPT_STYLE_TO_TOKEN [ token ] prompt_styles.append ( ( token , cli_style [ token ] ) ) filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , TabsProcessor ( get_char1=lambda _ : ' ' , import pygments.styles break if self.wider_completion_menu : editing_mode=EditingMode.VI if self.vi_mode else EditingMode.EMACS , `` `` '' Enable/Disable SmartCompletion Mode . '' '' '' chars= ' [ ] ( ) { } ' ) , prompt_styles.append ( ( prompt_style , style_value ) ) Makes the enter key work as the tab key only when showing the menu . override_style = Style ( [ ( 'bottom-toolbar ' , 'noreverse ' ) ] ) query = self.pgexecute.function_definition ( spec ) logger.error ( `` sql : % r , error : % r '' , document.text , e ) self.cli = self._build_cli ( history ) if get_vi_mode_enabled ( ) : if token.startswith ( 'Token . ' ) : return len ( COLOR_CODE_REGEX.sub ( `` , line ) ) > self.prompt_app.output.get_size ( ) .columns Token.Toolbar.Arg = 'noinherit bold ' output.even-row = `` ''","['pgcli/completion_refresher.py', 'pgcli/filters.py', 'pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/packages/parseutils/ctes.py', 'pgcli/packages/parseutils/meta.py', 'pgcli/packages/parseutils/tables.py', 'pgcli/packages/prioritization.py', 'pgcli/packages/prompt_utils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgbuffer.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'pgcli/pgstyle.py', 'pgcli/pgtoolbar.py', 'setup.py', 'tests/features/environment.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/named_queries.py', 'tests/metadata.py', 'tests/test_main.py']",Cherry-picked prompt-toolkit 2.0 changes . ( # 930 )
94,a93ef6f76963a96d6de099656ea336bfea9b7405,2018-09-24 16:24:14-07:00,====== 1.11.0 Upcoming ======== ========= TODO Upcoming :,['changelog.rst'],Merge pull request # 944 from dbcli/j-bennet/release-1.11.0
95,364ee6c33d74ef5b907242cd56f299409e06bcd1,2018-09-23 14:34:58-07:00,"if len ( lines ) > = self.cli.output.get_size ( ) .rows - 4 \ actual = COLOR_CODE_REGEX.sub ( `` , context.cli.before ) with mock.patch.object ( cli.pgspecial , 'pager_config ' , PAGER_OFF ) : cli , mock_echo , mock_echo_via_pager , mock_cli = pset_pager_mocks ( 10 , 10 , '- ' * 9 ) , test_data = [ ( 10 , 10 , '- ' * 10 ) , ( 10 , 10 , '\n'.join ( [ test_line ] * 6 ) ) , # The last 4 lines are reserved for the pgcli menu and padding pytest > =2.7.0 cli.echo_via_pager ( text ) ( 10 , 10 , '- ' * 11 ) , from pgcli.main import COLOR_CODE_REGEX mock_echo_via_pager.assert_not_called ( ) test_ids = [ `` Output longer than terminal height '' , click.echo_via_pager ( text , color=color ) from pgspecial.main import ( PGSpecial , NO_QUERY , PAGER_OFF , PAGER_LONG_OUTPUT ) pager_on_test_data = [ l + ( r , ) for l , r in zip ( test_data , use_pager_when_on ) ] cli.watch_command = None ] ======== obfuscate_process_password , format_output , PGCli , OutputSettings , COLOR_CODE_REGEX * Max Rothman ( u '' -\u001b ] 23\u0007- '' , 2 ) , obfuscate_process_password , format_output , PGCli , OutputSettings def test_pset_pager_off ( term_height , term_width , text , pset_pager_mocks ) : termsize = namedtuple ( 'termsize ' , [ 'rows ' , 'columns ' ] ) Upcoming # Ref : https : //stackoverflow.com/questions/30425105/filter-special-chars-such-as-color-codes-from-shell-output `` Output shorter than terminal width '' ] cli = PGCli ( ) cli = pset_pager_mocks [ 0 ] mock.patch ( 'pgcli.main.click.echo_via_pager ' ) as mock_echo_via_pager , \ else : mock_echo.assert_not_called ( ) yield cli , mock_echo , mock_echo_via_pager , mock_cli `` Output shorter than terminal height '' , ( 10 , 10 , '\n'.join ( [ test_line ] * 7 ) ) , if use_pager : mock_echo.assert_called ( ) # 4 lines are reserved at the bottom of the terminal for pgcli 's prompt .vscode/ True , def pset_pager_mocks ( ) : def test_pset_pager_always ( term_height , term_width , text , pset_pager_mocks ) : actual = re.sub ( r'\x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? ' , `` , context.cli.before ) mock_echo.assert_not_called ( ) `` Output equal to terminal height '' , mock_cli.output.get_size.return_value = termsize ( False ] ] ) venv/ else : `` Output equal to terminal width '' , mock_echo.assert_called ( ) ( u '' =\u001b [ m= '' , 2 ) , from pgspecial.main import ( PGSpecial , NO_QUERY , PAGER_OFF ) click.echo ( text , color=color ) # The maximum version requirement can be removed once Python 3.4 goes EOL mock.patch.object ( cli , 'cli ' ) as mock_cli : def test_color_pattern ( text , expected_length , pset_pager_mocks ) : ( u '' 22200K ....... \u001b [ 0m\u001b [ 91m ... .......... ... \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m ...... ......... \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m \u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m.\u001b [ 0m\u001b [ 91m ...... 50 % 28.6K 12m55s '' , 78 ) , * Respect ` \pset pager on ` and use pager when output is longer than terminal height ( Thanks : ` Max Rothman ` _ ) assert len ( COLOR_CODE_REGEX.sub ( `` , text ) ) == expected_length mock_echo_via_pager.assert_not_called ( ) use_pager_when_on = [ True , with mock.patch.object ( cli.pgspecial , 'pager_config ' , PAGER_LONG_OUTPUT ) : with mock.patch ( 'pgcli.main.click.echo ' ) as mock_echo , \ `` Output longer than terminal width '' , lines = text.split ( '\n ' ) mock_echo_via_pager.assert_called ( ) ( 10 , 10 , '\n'.join ( [ test_line ] * 5 ) ) , elif self.pgspecial.pager_config == PAGER_LONG_OUTPUT : Features : or any ( len ( COLOR_CODE_REGEX.sub ( `` , l ) ) > self.cli.output.get_size ( ) .columns for l in lines ) : # Can be replaced with pytest.param once we can upgrade pytest after Python 3.4 goes EOL False , def test_pset_pager_on ( term_height , term_width , text , use_pager , pset_pager_mocks ) : mock_echo_via_pager.assert_called ( ) pytest > =2.7.0 , < =3.0.7 test_line = '- ' * 10 rows=term_height , columns=term_width ) .. _ ` Max Rothman ` : https : //github.com/maxrothman with mock.patch.object ( cli.pgspecial , 'pager_config ' , PAGER_ALWAYS ) :","['.gitignore', 'AUTHORS', 'changelog.rst', 'pgcli/main.py', 'requirements-dev.txt', 'tests/features/steps/wrappers.py', 'tests/test_main.py']",Merge pull request # 871 from maxrothman/master
96,381869b72712310c05c5643dc89b7fe656e99255,2018-09-22 15:42:45-07:00,"from steps import wrappers `` `` '' Read all files inside fixture_data directory . '' '' '' current_dir = os.path.dirname ( __file__ ) from utils import run , dbtest , requires_json , requires_jsonb def read_fixture_files ( fixture_dir ) : from __future__ import unicode_literals , print_function , absolute_import import db_utils as dbutils Read all files inside fixture_data directory . `` `` '' from tests.utils import run , dbtest , requires_json , requires_jsonb drop_tables ) from metadata import ( MetaData , alias , name_join , fk_join , join , keyword , drop_tables ) def read_fixture_files ( ) : context.fixture_data = fixutils.read_fixture_files ( fixture_dir ) from __future__ import unicode_literals , print_function from __future__ import print_function from tests.utils import dbtest , run from utils import dbtest , run from tests.features.steps import wrappers fixture_dir = os.path.join ( current_dir , 'fixture_data/ ' ) import tests.features.db_utils as dbutils import tests.features.fixture_utils as fixutils from utils import ( POSTGRES_HOST , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , from tests.metadata import ( MetaData , alias , name_join , fk_join , join , from metadata import ( MetaData , alias , name_join , fk_join , join , print ( 'reading fixture data : { } '.format ( fixture_dir ) ) import fixture_utils as fixutils import wrappers from __future__ import print_function , absolute_import from tests.utils import ( POSTGRES_HOST , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , context.fixture_data = fixutils.read_fixture_files ( ) from tests.metadata import ( MetaData , alias , name_join , fk_join , join , keyword ,","['tests/__init__.py', 'tests/conftest.py', 'tests/features/environment.py', 'tests/features/fixture_utils.py', 'tests/features/steps/auto_vertical.py', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/crud_table.py', 'tests/features/steps/expanded.py', 'tests/features/steps/iocommands.py', 'tests/features/steps/named_queries.py', 'tests/features/steps/specials.py', 'tests/test_main.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 942 from dbcli/j-bennet/testing-experiments
97,7889b2838f8890122d0f9c4bc141e03cfc25d003,2018-09-21 21:38:40-07:00,"if not stdin.isatty ( ) : Set env parameters . sql = 'drop database foo ; ' def show_env_changes ( env_old , env_new ) : current_dir = os.path.dirname ( __file__ ) print ( 'package root : ' , context.package_root ) context , context.conf [ 'pager_boundary ' ] + '\r\n ' , timeout=5 ) context.tmpfile_sql_help = None from pgspecial.main import ( PAGER_OFF , PAGER_LONG_OUTPUT , PAGER_ALWAYS ) wait_prompt ( context ) if hasattr ( context , 'tmpfile_sql_help ' ) and context.tmpfile_sql_help : print ( ' { } = '' { } '' '.format ( k , new_value ) ) run_cli ( context ) behave context.cli.sendline ( '\pset pager always ' ) drop_tables ) from steps.wrappers import run_cli , wait_prompt wrappers.wait_prompt ( context ) context.cli.sendline ( '\pset pager off ' ) f.flush ( ) fixture_dir = os.path.join ( current_dir , 'fixture_data/ ' ) context.cli.sendline ( '\i { 0 } '.format ( f.name ) ) from behave import when , then def read_fixture_files ( ) : from __future__ import unicode_literals , print_function , absolute_import from tests.utils import run , dbtest , requires_json , requires_jsonb # turn off pager before exiting from metadata import ( MetaData , alias , name_join , fk_join , join , keyword , `` `` '' Cleans up after each scenario completes . '' '' '' if new_value and old_value ! = new_value : context.cli.sendline ( '\i { 0 } '.format ( context.tmpfile_sql_help.name ) ) import copy wait_prompt ( context ) import wrappers old_value = env_old.get ( k , `` ) def read_fixture_files ( fixture_dir ) : `` `` '' Set env parameters . '' '' '' from collections import namedtuple print ( 'fixture dir : ' , fixture_dir ) context.fixture_data = fixutils.read_fixture_files ( fixture_dir ) from tests.metadata import ( MetaData , alias , name_join , fk_join , join , keyword , for k in sorted ( all_keys ) : from tests.features.steps import wrappers from utils import run , dbtest , requires_json , requires_jsonb `` `` '' Cleans up after each test complete . '' '' '' assert stdin.isatty ( ) is False f.write ( b'\ ? ' ) print ( ' -- - os.environ changed values : -- - ' ) context.tmpfile_sql_help.close ( ) env_old = copy.deepcopy ( dict ( os.environ ) ) sql = 'drop database foo ; ' `` `` '' Print out all test-specific env values . '' '' '' from utils import ( POSTGRES_HOST , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , wrappers.run_cli ( context ) context.tmpfile_sql_help.write ( b'\ ? ' ) import db_utils as dbutils context , context.conf [ 'pager_boundary ' ] + '\r\n ' , timeout=5 ) wrappers.expect_exact ( fixture_dir = os.path.join ( from decimal import Decimal import tests.features.fixture_utils as fixutils import fixture_utils as fixutils from __future__ import print_function , absolute_import from tests.metadata import ( MetaData , alias , name_join , fk_join , join , with tempfile.NamedTemporaryFile ( ) as f : from metadata import ( MetaData , alias , name_join , fk_join , join , show_env_changes ( env_old , dict ( os.environ ) ) from utils import dbtest , run import tests.features.db_utils as dbutils context.package_root , 'tests/features/fixture_data ' ) all_keys = set ( list ( env_old.keys ( ) ) + list ( env_new.keys ( ) ) ) context.fixture_data = fixutils.read_fixture_files ( ) from behave import when wrappers.expect_exact ( `` `` '' new_value = env_new.get ( k , `` ) assert confirm_destructive_query ( sql ) is None print ( '- ' * 20 ) context.tmpfile_sql_help = tempfile.NamedTemporaryFile ( prefix='pgcli_ ' ) from tests.utils import ( POSTGRES_HOST , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , from tests.utils import dbtest , run from __future__ import print_function context.tmpfile_sql_help.flush ( ) drop_tables ) from __future__ import unicode_literals behave -- no-capture assert confirm_destructive_query ( sql ) is None","['.travis.yml', 'tests/__init__.py', 'tests/conftest.py', 'tests/features/environment.py', 'tests/features/fixture_utils.py', 'tests/features/steps/auto_vertical.py', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/crud_table.py', 'tests/features/steps/expanded.py', 'tests/features/steps/iocommands.py', 'tests/features/steps/named_queries.py', 'tests/features/steps/specials.py', 'tests/features/steps/wrappers.py', 'tests/test_main.py', 'tests/test_pgexecute.py', 'tests/test_prompt_utils.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 941 from dbcli/j-bennet/testing-fixes
98,1ddeaf012b58c7d764c2d7a9aaf8531c0ac78ee1,2018-07-27 12:04:18-07:00,1.10.3 ====== Upcoming ======== * Adapt the query used to get functions metadata to PG11 ( # 919 ) . ( Thanks : ` Lele Gaifax ` _ ) . * Adapt the query used to get functions metadata to PG11 ( # 919 ) . ( Thanks : ` Lele Gaifax ` _ ) .,['changelog.rst'],Merge pull request # 929 from dbcli/j-bennet/release-1.10.3
99,f12b472f4935577611d51b1ce14fb8b67886b5ff,2018-07-26 17:17:35-07:00,"if not passwd and keyring and self.keyring_enabled : if passwd and keyring and self.config [ `` main '' ] .get ( `` keyring '' , True ) : self.keyring_enabled = c [ `` main '' ] .as_bool ( `` keyring '' ) * Fix for keyring not disabled properly ( # 920 ) . ( Thanks : ` Irina Truong ` _ ) if passwd and keyring and self.keyring_enabled : if not passwd and keyring and self.config [ `` main '' ] .get ( `` keyring '' , True ) :","['changelog.rst', 'pgcli/main.py']",Merge pull request # 927 from dbcli/j-bennet/keyring-honor-config
100,688f09c0916841d16697bc71b474b878830a83f8,2018-07-25 08:30:34-07:00,"query = `` ' * Fix issue # 603 ( ` \i ` raises a TypeError ) . ( Thanks : ` Emanuele Gaifas ` _ ) . elif self.conn.server_version > 90000 : SELECT n.nspname schema_name , p.proretset is_set_returning , * Use raw strings in regex specifiers . This preemptively fixes a crash in Python 3.6 . ( Thanks ` Lele Gaifax ` _ ) * Use raw strings in regex specifiers . This preemptively fixes a crash in Python 3.6 . ( Thanks ` Emanuele Gaifas ` _ ) * Adapt the query used to get functions metadata to PG11 ( # 919 ) . ( Thanks : ` Lele Gaifax ` _ ) . ORDER BY 1 , 2 .. _ ` Emanuele Gaifas ` : https : //github.com/lelit COALESCE ( proallargtypes : :regtype [ ] , proargtypes : :regtype [ ] ) : :text [ ] , p.prokind = ' w ' is_window , * Fix issue # 603 ( ` \i ` raises a TypeError ) . ( Thanks : ` Lele Gaifax ` _ ) . WHERE p.prorettype : :regtype ! = 'trigger ' : :regtype ' '' p.proname func_name , if self.conn.server_version > 90000 : p.proargnames , INNER JOIN pg_catalog.pg_namespace n FROM pg_catalog.pg_proc p prorettype : :regtype : :text return_type , p.prokind = ' a ' is_aggregate , p.proargmodes , ON n.oid = p.pronamespace if self.conn.server_version > = 110000 : .. _ ` Lele Gaifax ` : https : //github.com/lelit pg_get_expr ( proargdefaults , 0 ) AS arg_defaults","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 921 from lelit/pg11b2
101,9aae5ee34a38167a5eecc028d5bbf1fffa0596ab,2018-07-24 15:23:56-07:00,"* Fix for error retrieving version in Redshift ( # 922 ) . ( Thanks : ` Irina Truong ` _ ) self.server_version = result [ 0 ] if result else `` else : version_parts = result [ 0 ] .split ( ) # full version string looks like this : self.server_version = version_parts [ 1 ] # let 's only retrieve version number TODO # PostgreSQL 10.3 on x86_64-apple-darwin17.3.0 , compiled by Apple LLVM version 9.0.0 ( clang-900.0.39.2 ) , 64-bit # noqa version_query = `` SELECT version ( ) ; '' Bug fixes : if result : version_query = `` SELECT current_setting ( 'server_version ' ) '' self.server_version = ``","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 923 from dbcli/j-bennet/fix-server-version
102,eefe294cc9f338ccaae63d63b07892653c745d77,2018-07-23 17:09:14-07:00,====== TODO 1.10.2,['changelog.rst'],Merge pull request # 918 from dbcli/j-bennet/release-1.10.2
103,97b7d22599deec4b6ddf4bd11a55aff0f93dc6fd,2018-07-23 17:04:55-07:00,"`` Load your password from keyring returned : '' , To remove this message do one of the following : if passwd : try : ) , str ( e ) { } keyring_error_message.format ( RuntimeError , ) as e : pass try : except ( keyring.errors.InitError , RuntimeError ) : keyring.set_password ( 'pgcli ' , key , passwd ) } , err=True , click.secho ( except ImportError : keyring = True pass keyring.errors.InitError , import keyring except ( keyring.errors.InitError , RuntimeError ) : keyring.set_password ( 'pgcli ' , key , passwd ) try : TODO 'keyring ' : [ 'keyring > = 12.2.0 ' ] , keyring_error_message.format ( keyring.errors.KeyringLocked RuntimeError , prepare keyring as described at : https : //keyring.readthedocs.io/en/stable/ from textwrap import dedent keyring = None fg='red ' uninstall keyring : pip uninstall keyring Features : click.secho ( import keyring err=True , fg='red ' ) keyring.errors.InitError ) , keyring.set_password ( 'pgcli ' , key , passwd ) keyring_error_message = dedent ( `` '' '' \ except ( pass * Make ` keyring ` optional ( Thanks : ` Dick Marinus ` _ ) if passwd : try : except ( ) as e : # Use keyring to automatically save and load password in a secure manner if not passwd and keyring and self.config [ `` main '' ] .get ( `` keyring '' , True ) : disable keyring in our configuration : add keyring = False to [ main ] '' '' '' ) if not passwd : str ( e ) extras_require= { `` Set password in keyring returned : '' , ) 'keyring > = 11.0.0 ' except RuntimeError : if passwd and keyring and self.config [ `` main '' ] .get ( `` keyring '' , True ) :","['changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc', 'setup.py']",Merge pull request # 916 from dbcli/feature/optional_keyring
104,abc8d51dd3814cff0b5b015677904fc1939d236b,2018-07-20 17:10:07-07:00,"_logger.debug ( 'Version Query . sql : % r ' , self.version_query ) version_query = `` SELECT current_setting ( 'server_version ' ) '' result = cur.fetchone ( ) return self.server_version self.server_version = result [ 0 ] if result else `` cur.execute ( self.version_query ) print ( 'Server : PostgreSQL ' , self.pgexecute.get_server_version ( ) ) with self.conn.cursor ( ) as cur : if self.server_version : self.server_version = None def get_server_version ( self ) :","['pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 915 from dbcli/j-bennet/add-server-version
105,88e03042a61e0aa4ff32d685353ac9d70c4ada21,2018-07-19 22:21:02-07:00,====== 1.10.1 TODO,['changelog.rst'],Merge pull request # 913 from dbcli/j-bennet/release-1.10.1
106,d2ab7c2353eead864d8d30b6b98005e88e03a3ae,2018-07-19 19:50:13-07:00,which pip which python pip install -U setuptools before_install :,['.travis.yml'],Merge pull request # 912 from dbcli/j-bennet/pip-errors
107,992deefbba7d71b27467e656e88adf37382c8c62,2018-07-19 18:51:21-07:00,self.watch_command = None * Fix for missing keyring . ( Thanks : ` Kenny Do ` _ ) TODO * Fix for `` -l '' Flag Throws Error ( # 909 ) . ( Thanks : ` Irina Truong ` _ ) .. _ ` Kenny Do ` : https : //github.com/kennydo Bug fixes :,"['changelog.rst', 'pgcli/main.py']",Merge pull request # 911 from dbcli/j-bennet/fix-db-list
108,b536c100e84dd27e4e6208dc42737810ed015d44,2018-07-19 18:16:23-07:00,"except keyring.errors.InitError : * Kenny Do * Artur Balabanov * Artur Balabanov except ( keyring.errors.InitError , RuntimeError ) :","['AUTHORS', 'pgcli/main.py']",Merge pull request # 910 from kennydo/kedo-optional-keyring
109,dcd2d039888a4a9e268ac63cb32005d7bc412985,2018-07-14 12:57:26-07:00,"* Add `` application_name `` to help identify pgcli connection to database ( issue # 868 ) ( Thanks : ` François Pietka ` _ ) 1.10.0 ======== * Add `` application_name `` to help identify pgcli connection to database ( issue # 868 ) ( Thanks : ` François Pietka ` _ ) * Add ` -- user ` option , duplicate of ` -- username ` , the same cli option like ` psql ` ( Thanks : ` Alexandr Korsak ` _ ) 'keyring > = 11.0.0 ' 'keyring > = 12.2.0 ' Upcoming : * Support ` \\ev `` , `` \ef `` ( issue # ) ( Thanks : ` Catherine Devlin ` _ ) Upcoming TODO ========= recursive-include tests * * Add ` -- user ` option , duplicate of ` -- username ` , the same cli option like ` psql ` ( Thanks : ` Alexandr Korsak ` _ ) * Support ` \\ev `` , `` \ef `` ( # 754 ) . ( Thanks : ` Catherine Devlin ` _ ) recursive-include tests * .py * .txt * .feature * .ini ======","['MANIFEST.in', 'changelog.rst', 'setup.py']",Merge pull request # 907 from dbcli/meeuw/release-1.10.0
110,5491d288fc7ea3a512a69c1da0b27d0d77c107e4,2018-07-13 13:24:44-07:00,"* Render tab characters as 4 spaces instead of ` ^I ` . ( Thanks : ` Artur Balabanov ` _ ) # Highlight matching brackets while editing . .. _ ` Artur Balabanov ` : https : //github.com/arturbalabanov get_char2=lambda _ : ' ' ) , * Artur Balabanov ConditionalProcessor ( processor=HighlightMatchingBracketProcessor ( chars= ' [ ] ( ) { } ' ) , filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , TabsProcessor ( get_char1=lambda _ : ' ' , ConditionalProcessor ( # Highlight matching brackets while editing . filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , TabsProcessor ) # Render \t as 4 spaces instead of `` ^I '' HighlightMatchingBracketProcessor , processor=HighlightMatchingBracketProcessor ( HighlightMatchingBracketProcessor ) chars= ' [ ] ( ) { } ' ) ,","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 903 from arturbalabanov/render-tabs-with-spaces
111,d5b0b6527bb7d962de7a7494b8335008e15cf23d,2018-07-04 12:36:42-07:00,"( not e.pgcode or * Do n't offer to reconnect when we ca n't change a param in realtime ( # 807 ) . ( Thanks : ` Amjith Ramanujam ` _ and ` Saif Hakim ` _ ) return ( isinstance ( e , psycopg2.OperationalError ) and * Saif Hakim detect that the connection is stil open , we catch the error , as .. _ ` Saif Hakim ` : https : //github.com/saifelse which we should n't catch ; we handle uncaught errors by prompting the reconnecting wo n't solve that problem . ( 'LOCK_NOT_AVAILABLE ' , 'CANT_CHANGE_RUNTIME_PARAM ' ) ) ) `` OperationalError `` s are raised for errors that are not under the user to reconnect . We * do * want to catch OperationalErrors caused by a control of the programmer . Usually that means unexpected disconnects , lock being unavailable , as reconnecting wo n't solve that problem . psycopg2.errorcodes.lookup ( e.pgcode ) not in return self.conn.closed ! = 0 An uncaught error will prompt the user to reconnect ; as long as we * Do n't offer to reconnect when we ca n't change a param in realtime ( # 807 ) . ( Thanks : ` Amjith Ramanujam ` _ )","['AUTHORS', 'changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 901 from benchling/fix-reconnect
112,2e6e0e4acd66d4a29b64c9f3a5a08b5a9527ae80,2018-06-28 12:12:45-07:00,"pass keyring.set_password ( 'pgcli ' , key , passwd ) keyring.set_password ( 'pgcli ' , key , passwd ) except ( keyring.errors.InitError , RuntimeError ) : passwd = keyring.get_password ( 'pgcli ' , key ) try : passwd = keyring.get_password ( 'pgcli ' , key ) pass try : except RuntimeError :",['pgcli/main.py'],Merge pull request # 899 from dbcli/guard-against-missing-backend
113,d403189db7a216093473f9677da7608fc4e8bcb3,2018-06-17 18:55:19-07:00,"_logger.debug ( 'Function Definition Query . sql : % r\nspec : % r ' , # import pytest ; pytest.set_trace ( ) result = executor.function_definition ( 'the_number_three ' ) # 2 : relkind , v or m ( materialized ) sql = self.view_definition_query cli.current_buffer.document = Document ( sql , CASE return result [ 0 ] 'Waiting for { 0 } seconds before repeating ' 'check_option=cascaded ' ) AS reloptions , def view_definition ( self , spec ) : filename = None document.text ) else : # \ev or \ef view_definition_query = `` ' while editor_command : result = cur.fetchone ( ) RETURNS int `` `` '' Returns the SQL defining views described by ` spec ` `` '' '' * Support ` \\ev `` , `` \ef `` ( issue # ) ( Thanks : ` Catherine Devlin ` _ ) # 5 : checkoption : local or cascaded sql , spec ) cursor_position=len ( sql ) ) ' '' ) def test_function_definition ( executor ) : template = 'CREATE OR REPLACE { 6 } VIEW { 0 } . { 1 } AS \n { 3 } ' WHEN 'check_option=local ' = ANY ( c.reloptions ) THEN 'LOCAL ' : :text cur.execute ( sql , ( spec , ) ) filename = special.get_filename ( document.text ) if editor_command == '\\ev ' : with self.conn.cursor ( ) as cur : ( SELECT % s : :pg_catalog.regproc : :pg_catalog.oid AS f_oid ) self.get_last_query ( ) ) except psycopg2.ProgrammingError : def test_nonexistent_function_definition ( executor ) : # 4 : reloptions , null query = self.pgexecute.view_definition ( spec ) _logger.debug ( 'View Definition Query . sql : % r\nspec : % r ' , result = executor.view_definition ( 'mvw1 ' ) .format ( timing ) ) WITH v AS ( SELECT % s : :pg_catalog.regclass : :pg_catalog.oid AS v_oid ) pg_catalog.pg_get_viewdef ( c.oid , true ) , ELSE NULL 'Waiting for { 0 } seconds before repeating ' with pytest.raises ( RuntimeError ) : query = ( special.get_editor_query ( document.text ) or try : sql = self.function_definition_query SELECT pg_catalog.pg_get_functiondef ( f.f_oid ) def test_view_definition ( executor ) : assert 'MATERIALIZED VIEW ' in result FROM pg_catalog.pg_class c AS $ function $ FROM f '' ' cur.execute ( sql , ( spec , ) ) SELECT nspname , relname , relkind , select 3 ; run ( executor , 'create view vw1 AS SELECT * FROM tbl1 ' ) assert 'FROM tbl1 ' in result LEFT JOIN pg_catalog.pg_namespace n ON ( c.relnamespace = n.oid ) query = self.pgexecute.function_definition ( spec ) result = executor.view_definition ( 'there_is_no_such_function ' ) sql , cursor_position=len ( sql ) ) elif editor_command == '\\ef ' : def test_nonexistent_view_definition ( executor ) : run ( executor , 'create table tbl1 ( a text , b numeric ) ' ) WITH f AS LANGUAGE sql CREATE OR REPLACE FUNCTION public.the_number_three ( ) WHEN 'check_option=cascaded ' = ANY ( c.reloptions ) THEN 'CASCADED ' : :text spec = document.text.split ( ) [ 1 ] view_type = 'MATERIALIZED ' if result [ 2 ] == 'm ' else `` while special.editor_command ( document.text ) : query = ( special.get_editor_query ( document.text ) or result = cur.fetchone ( ) editor_command = special.editor_command ( document.text ) raise RuntimeError ( 'Function { } does not exist . '.format ( spec ) ) `` `` '' Returns the SQL defining functions described by ` spec ` `` '' '' editor_command = special.editor_command ( document.text ) JOIN v ON ( c.oid = v.v_oid ) ' '' array_remove ( array_remove ( c.reloptions , 'check_option=local ' ) , run ( executor , `` ' cli.current_buffer.document = Document ( result = executor.view_definition ( 'mvw1 ' ) .format ( timing ) ) filename = special.get_filename ( document.text ) self.get_last_query ( ) ) result = executor.view_definition ( 'vw1 ' ) raise RuntimeError ( 'View { } does not exist . '.format ( spec ) ) document.text ) return template.format ( * result + ( view_type , ) ) function_definition_query = `` ' $ function $ END AS checkoption run ( executor , 'create materialized view mvw1 AS SELECT * FROM tbl1 ' ) result = executor.view_definition ( 'there_is_no_such_view ' ) if editor_command == '\\e ' : def function_definition ( self , spec ) :","['changelog.rst', 'pgcli/main.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 886 from catherinedevlin/ev_command
114,aee99b9a40e17b07a252e388aff7a016691a043c,2018-06-15 14:36:17-07:00,"* Alexandr Korsak .. _ ` Alexandr Korsak ` : https : //github.com/oivoodoo * Add ` -- user ` option , duplicate of ` -- username ` , the same cli option like ` psql ` ( Thanks : ` Alexandr Korsak ` _ ) help='Username to connect to the postgres database . ' )","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 898 from oivoodoo/refactor/add-user-option
115,3fbe8e7cb3ca57fd8656890ea7855da62d2ea03e,2018-06-10 13:07:38+02:00,"* Fix unbound local error when destructive_warning is false . ( Thanks : ` Matthieu Guilbert ` _ ) click.secho ( 'Your call ! ' ) output , query = self._evaluate_command ( text ) if destroy is None : if destroy is False : elif destroy is True : else : elif destroy : output , query = self._evaluate_command ( text ) click.secho ( 'Your call ! ' )","['changelog.rst', 'pgcli/main.py']",Merge pull request # 897 from gma2th/hotfix/output-unbound-local-error
116,9d2f11164c6c3a30c882cc418c69b114cdef6f8a,2018-06-06 12:21:07-07:00,"* Matthieu Guilbert yield ( None , None , None , None , statement , False ) .. _ ` Matthieu Guilbert ` : https : //github.com/gma2th * Fix not enough values to unpack . ( Thanks : ` Matthieu Guilbert ` _ ) yield ( None , None , None , None , statement , False , False )","['AUTHORS', 'changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 895 from gma2th/hotfix/not-enough-values-to-unpack
117,da2c8e542da6ad684e2678f92f06af9cf6c98d82,2018-06-01 20:15:51+02:00,"# `` get '' was renamed to `` set '' in ipython-sql : conn = sql.connection.Connection.set ( parsed [ 'connection ' ] ) if hasattr ( sql.connection.Connection , 'get ' ) : conn = sql.connection.Connection.get ( parsed [ 'connection ' ] ) # https : //github.com/catherinedevlin/ipython-sql/commit/f4283c65aaf68f961e84019e8b939e4a3c501d43 conn = sql.connection.Connection.get ( parsed [ 'connection ' ] ) else : * Fix ipython magic connection ( # 891 ) . ( Thanks : ` Irina Truong ` _ )","['changelog.rst', 'pgcli/magic.py']",Merge pull request # 893 from dbcli/j-bennet/fix-pgcli-magic
118,9e54a9ef5625161f3b7d6ec49b00eda7672ceb5e,2018-06-01 08:18:24-07:00,"# `` get '' was renamed to `` set '' in ipython-sql : conn = sql.connection.Connection.set ( parsed [ 'connection ' ] ) if hasattr ( sql.connection.Connection , 'get ' ) : conn = sql.connection.Connection.get ( parsed [ 'connection ' ] ) # https : //github.com/catherinedevlin/ipython-sql/commit/f4283c65aaf68f961e84019e8b939e4a3c501d43 conn = sql.connection.Connection.get ( parsed [ 'connection ' ] ) else :",['pgcli/magic.py'],Fix for ipython sql connection . Fixes # 891 .
119,908a8ddacf330b593540fc2c8a56ceed0f07f128,2018-05-29 09:10:28+01:00,"* Make keyring optional . ( Thanks : ` Dick Marinus ` _ ) keyring.set_password ( 'pgcli ' , key , passwd ) try : pass keyring.set_password ( 'pgcli ' , key , passwd ) except keyring.errors.InitError :","['changelog.rst', 'pgcli/main.py']",Merge pull request # 888 from dbcli/bugfix/optionalkeyring
120,9a543d05f98a927ea783f2d060c8533d6e7820fe,2018-05-26 12:48:21-07:00,"`` `` '' Confirm destructive command . '' '' '' wrappers.expect_exact ( wrappers.expect_exact ( * Refactor Destructive Warning behave tests ( Thanks : ` Dick Marinus ` _ ) context , 'You\ 're about to run a destructive command.\r\nDo you want to proceed ? ( y/n ) : ' , timeout=2 ) context , 'You\ 're about to run a destructive command.\r\nDo you want to proceed ? ( y/n ) : ' , timeout=2 ) context.cli.sendline ( ' y ' ) context.cli.sendline ( ' y ' ) then we confirm the destructive warning def step_confirm_destructive_command ( context ) :","['changelog.rst', 'tests/features/crud_database.feature', 'tests/features/crud_table.feature', 'tests/features/expanded.feature', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/crud_table.py']",Merge pull request # 889 from dbcli/internal/behave_refactor
121,d01b4eeb6479c951a8b0ee10e29099af9eaf6e5e,2018-05-19 07:20:55+02:00,"wrappers.expect_exact ( context , 'You\ 're about to run a destructive command.\r\nDo you want to proceed ? ( y/n ) : ' , timeout=2 ) context.cli.sendline ( ' y ' )","['tests/features/steps/crud_database.py', 'tests/features/steps/crud_table.py', 'tests/features/steps/expanded.py']",Merge pull request # 885 from dbcli/pr884
122,fc41a5e8daf40baad292b4a4d9a0228d83bc2e35,2018-05-18 21:48:42-07:00,"'is_special ' , # True if the query is a special command `` `` '' \i with an io_error returns an error . '' '' '' query = MetaQuery ( query=text , successful=False ) ( title , rows , headers , status , query , success , is_special ) * Add an is_special command flag to MetaQuery ( Thanks : ` Rishi Ramraj ` _ ) list ( executor.run ( sql , pgspecial=pgspecial ) ) query = self.execute_command ( # Check the result . # Inject an IOError . def test_describe_special ( executor , command , verbose , pattern ) : yield self.execute_normal_sql ( sql ) + ( sql , True , False ) if len ( result ) < 6 : yield None , None , None , exception_formatter ( e ) , sql , False , False for title , cur , headers , status , sql , success in res : return [ ( None , None , None , str ( e ) , `` , False , True ) ] return [ ( None , None , None , str ( e ) , `` , False ) ] self.watch_command , query ) for title , rows , headers , status , sql , success , is_special in results : yield None , None , None , exception_formatter ( e ) , sql , False return [ ( None , None , None , message , `` , False , True ) ] if len ( result ) < 7 : return [ ( None , None , None , message , `` , False ) ] from pgcli.main import PGCli .. _ ` Rishi Ramraj ` : https : //github.com/RishiRamraj .pytest_cache return [ ( None , None , None , message , `` , True , True ) ] def test_describe_special ( executor , command , verbose , pattern , pgspecial ) : status , sql , success , is_special = result [ 0 ] [ 3 : ] from pgspecial.main import PGSpecial os.path.expanduser.side_effect = IOError ( 'test ' ) `` `` '' \i without a filename returns an error . '' '' '' def execute_command ( self , text ) : return [ ( None , None , None , message , `` , False ) ] result = list ( executor.run ( query , pgspecial=pgspecial ) ) def test_not_is_special ( executor , pgspecial ) : yield result + ( sql , True , True ) def test_execute_from_file_io_error ( os , executor , pgspecial ) : success , is_special = result [ 0 ] [ 5 : ] assert 'missing required argument ' in status yield result + ( sql , True ) return [ ( None , None , None , message , `` , True , True ) ] def test_execute_from_file_no_arg ( executor , pgspecial ) : assert success == True for title , cur , headers , status , sql , success , is_special in res : return [ ( None , None , None , message , `` , True ) ] yield self.execute_normal_sql ( sql ) + ( sql , True ) # Initialize default metaquery in case execution fails query = MetaQuery ( query=document.text , successful=False ) return PGSpecial ( ) query = self.execute_command ( document.text , query ) * Rishi Ramraj query = self.execute_command ( document.text ) ( title , rows , headers , status , query , success ) `` `` '' is_special is set to false for database queries . '' '' '' assert is_special == True def execute_command ( self , text , query ) : assert status == 'test ' result = list ( executor.run ( `` \i test '' , pgspecial=pgspecial ) ) assert is_special == False return [ ( None , None , None , message , `` , False , True ) ] .coverage . * return PGCli ( ) .pgspecial query = self.execute_command ( self.watch_command ) return [ ( None , None , None , message , `` , True ) ] query = 'select 1 ' assert success == False result = list ( executor.run ( `` \i '' , pgspecial=pgspecial ) ) from mock import patch db_changed , path_changed , mutated ) for title , rows , headers , status , sql , success in results : db_changed , path_changed , mutated , is_special ) executor.run ( sql )","['.gitignore', 'AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py', 'tests/utils.py']",Merge pull request # 880 from RishiRamraj/feature/get-last-sql-query
123,644ad1a963ee3de3d5aba02b4afb0e9effd4b42d,2018-05-18 21:30:52-07:00,"* True if the query is destructive and the user wants to proceed . from pgcli.packages.prompt_utils import confirm_destructive_query from .packages.prompt_utils import confirm_destructive_query if destroy is None : * Ported Destructive Warning from mycli . def query_starts_with ( query , prefixes ) : def confirm ( * args , * * kwargs ) : return False import sys return prompt ( prompt_text , type=bool ) Returns : def confirm_destructive_query ( queries ) : destroy = confirm = confirm_destructive_query ( text ) prompt_text = ( `` You 're about to run a destructive command.\n '' c_dest_warning = c [ 'main ' ] .as_bool ( 'destructive_warning ' ) * Dan Clark if is_destructive ( queries ) and sys.stdin.isatty ( ) : from .parseutils import is_destructive message = 'Wise choice . Command execution stopped . ' # - * - coding : utf-8 - * def queries_start_with ( queries , prefixes ) : `` `` '' Check if the query starts with any item from * prefixes * . '' '' '' return queries_start_with ( queries , keywords ) list_dsn , warn ) : raise KeyboardInterrupt import click `` `` '' Check if any queries start with any item from * prefixes * . '' '' '' sql = 'drop database foo ; ' except click.Abort : auto_vertical_output=auto_vertical_output , warn=warn ) for query in sqlparse.split ( queries ) : if query and query_starts_with ( query , prefixes ) is True : auto_vertical_output=False ) : stdin = click.get_text_stream ( 'stdin ' ) if ( self.destructive_warning ) : `` `` '' Check if the query is destructive and prompts the user to confirm . assert stdin.isatty ( ) is False formatted_sql = sqlparse.format ( query.lower ( ) , strip_comments=True ) return click.confirm ( * args , * * kwargs ) assert confirm_destructive_query ( sql ) is None click.secho ( 'Your call ! ' ) else : `` `` '' `` Do you want to proceed ? ( y/n ) '' ) # or `` shutdown '' . return True confirm_destructive_query ( query ) is False ) : output , query = self._evaluate_command ( text ) * None if the query is non-destructive or we ca n't prompt the user . output , query = self._evaluate_command ( text ) * False if the query is destructive and the user does n't want to proceed . prefixes = [ prefix.lower ( ) for prefix in prefixes ] auto_vertical_output=False , warn=None ) : keywords = ( 'drop ' , 'shutdown ' , 'delete ' , 'truncate ' , 'alter ' ) # that may cause harm to the database such as `` drop table '' , `` drop database '' # Destructive warning mode will alert you before executing a sql statement return bool ( formatted_sql ) and formatted_sql.split ( ) [ 0 ] in prefixes return click.prompt ( * args , * * kwargs ) if ( self.destructive_warning and return [ ( None , None , None , message ) ] auto_vertical_output=auto_vertical_output ) elif destroy is True : return False click.secho ( 'Wise choice ! ' ) `` `` '' Returns if any of the queries in * queries * is destructive . '' '' '' self.destructive_warning = c_dest_warning if warn is None else warn destructive_warning = True list_dsn ) : `` `` '' Prompt the user for input and handle any abort exceptions . '' '' '' `` `` '' Prompt for confirmation ( yes/no ) and handle any abort exceptions . '' '' '' import sqlparse def test_confirm_destructive_query_notty ( ) : try : help='Warn before running a destructive query . ' ) def prompt ( * args , * * kwargs ) : def is_destructive ( queries ) :","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/packages/parseutils/__init__.py', 'pgcli/packages/prompt_utils.py', 'pgcli/pgclirc', 'tests/test_prompt_utils.py']",Merge pull request # 884 from danclark5/master
124,8e12ea5e0fd32dc5ef3b757d555c9ce1fa5123bf,2018-05-16 17:49:31-07:00,"if passwd : if passwd : pip install keyrings.alt > =3.1 passwd = keyring.get_password ( 'pgcli ' , key ) if not passwd : keyring.set_password ( 'pgcli ' , key , passwd ) 'keyring > = 12.2.0 ' # Find password from store keyring.set_password ( 'pgcli ' , key , passwd ) import keyring","['.travis.yml', 'pgcli/main.py', 'setup.py']",Merge pull request # 873 from cfournie/remember_passwords
125,996a0863b91c688a7761f2684609c5663fb9f4ac,2018-05-15 11:51:35-07:00,$ pep8radius master -- docformatter -- in-place # apply the fixes $ pep8radius -- docformatter -- in-place # apply the fixes $ pep8radius -- docformatter -- diff # view a diff of proposed fixes _ $ pep8radius master -- docformatter -- diff # view a diff of proposed fixes PEP8 checks PEP8 checks ( lint ),['DEVELOP.rst'],Merge pull request # 882 from dbcli/lint-doc
126,0ad1a9a60c5d4d0881ec12321246b0139fcd57f5,2018-05-15 11:58:21-04:00,"( 'LOCK_NOT_AVAILABLE ' , 'CANT_CHANGE_RUNTIME_PARAM ' ) ) ) * Do n't offer to reconnect when we ca n't change a param in realtime ( # 807 ) . ( Thanks : ` Amjith Ramanujam ` _ ) psycopg2.errorcodes.lookup ( e.pgcode ) ! = 'LOCK_NOT_AVAILABLE ' ) ) psycopg2.errorcodes.lookup ( e.pgcode ) not in","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 881 from dbcli/connection-reset
127,f8757c6f59b063786f7ab52479665cccb8ce21c7,2018-05-14 17:33:06-04:00,"self.get_last_query ( ) ) cli.current_buffer.document = Document ( sql , cursor_position=len ( sql ) ) filename , sql=query ) sql , message = special.open_external_editor ( filename , sql=query ) cli.current_buffer.document = Document ( sql , cursor_position=len ( sql ) ) self.get_last_query ( ) ) sql , message = special.open_external_editor (",['pgcli/main.py'],Merge pull request # 879 from dbcli/pr877
128,d971e49993ef3d0308e9f1f4466c87b0e8463bea,2018-05-14 17:32:11-04:00,"continue * Catherine Devlin sql , message = special.open_external_editor ( filename , sql=query ) if message : if message : self.get_last_query ( ) ) document = cli.run ( ) filename = special.get_filename ( document.text ) query = ( special.get_editor_query ( document.text ) or try : # Something went wrong . Raise an exception and bail . sql , message = special.open_external_editor ( filename , sql=query ) # Something went wrong . Raise an exception and bail . cli.current_buffer.document = Document ( sql , cursor_position=len ( sql ) ) filename = special.get_filename ( document.text ) while special.editor_command ( document.text ) : cli.current_buffer.document = Document ( sql , cursor_position=len ( sql ) ) while special.editor_command ( document.text ) : cli.application.pre_run_callables = saved_callables cli.application.pre_run_callables = saved_callables * Avoid losing pre_run_callables on error in editing . ( Thanks : https : //github.com/catherinedevlin ) raise RuntimeError ( message ) raise RuntimeError ( message ) cli.application.pre_run_callables = [ ] document = cli.run ( ) finally : cli.application.pre_run_callables = [ ] query = ( special.get_editor_query ( document.text ) or self.get_last_query ( ) )","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 877 from catherinedevlin/keep_callables
129,16fb504ab9bbdeeb3fe98d94243f9f02a85de8e7,2018-05-14 17:03:08-04:00,"* Add table formats to `` \T `` completion . ( Thanks : ` Jason Ribeiro ` _ ) 'schema ' , 'column ' , 'table alias ' , 'join ' , 'name join ' , 'fk join ' FromClauseItem , suggest_type , Special , Database , Schema , Table , 'schema ' , 'column ' , 'table alias ' , 'join ' , 'name join ' , 'fk join ' , TableFormat : get_table_formats , from .packages.sqlcompletion import ( FromClauseItem , return ( TableFormat ( ) , ) Keyword , NamedQuery , Datatype , Alias , Path , JoinCondition , Join ) TableFormat = namedtuple ( 'TableFormat ' , [ ] ) formats = TabularOutputFormatter ( ) .supported_formats return self.find_matches ( word_before_cursor , formats , meta='table format ' ) Datatype , Alias , Path , JoinCondition , Join ) if cmd == '\\T ' : 'table format ' from .packages.sqlcompletion import ( def get_table_formats ( self , _ , word_before_cursor ) : from cli_helpers.tabular_output import TabularOutputFormatter suggest_type , Special , Database , Schema , Table , Function , Column , View , TableFormat , Function , Column , View , Keyword , NamedQuery ,","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py']",Merge pull request # 878 from jrib/table-format-completion
130,a7fa9cb29f22d62ec189a059142e600e0a1fa75b,2018-05-14 14:55:25-04:00,"query = self.execute_command ( watch_command , query ) if self.watch_command : while watch_command : self.watch_command = None if watch_command : if self.pgspecial.pager_config == PAGER_OFF : watch_command , timing = special.get_watch_command ( document.text ) if self.pgspecial.pager_config == PAGER_OFF or self.watch_command : self.watch_command , timing = special.get_watch_command ( document.text ) while self.watch_command : Bug Fixes : query = self.execute_command ( self.watch_command , query ) * Disable pager when using \watch ( # 837 ) . ( Thanks : ` Jason Ribeiro ` _ ) watch_command = None","['changelog.rst', 'pgcli/main.py']",Merge pull request # 876 from jrib/watch-pager
131,5eb0fd5ddcdf0b77ad30d7aaf051e5fd013e2f7d,2018-05-14 13:04:55-04:00,"# The reason we check here instead of inside the pgexecute is aliases= ( ' : q ' , ) ) raise EOFError raise PgCliQuitError or sql.strip ( ) .lower ( ) == 'quit ' # caught by the try/except block that wraps the pgexecute.run ( ) except PgCliQuitError : return ( sql.strip ( ) .lower ( ) == 'exit ' # because we want to raise the Exit exception which will be class PgCliQuitError ( Exception ) : aliases= ( 'exit ' , ) ) # statement . * Add quit commands to the completion menu . ( Thanks : ` Jason Ribeiro ` _ ) def quit ( self ) : raise .. _ ` Jason Ribeiro ` : https : //github.com/jrib Features : except EOFError : or sql.strip ( ) == ' : q ' ) * Jason Ribeiro 'Quit pgcli . ' , arg_type=NO_QUERY , case_sensitive=False , 'Quit pgcli . ' , arg_type=NO_QUERY , case_sensitive=True , def quit_command ( sql ) : self.pgspecial.register ( self.quit , 'quit ' , 'quit ' , if quit_command ( document.text ) : or sql.strip ( ) == r'\q ' except PgCliQuitError as e : pass self.pgspecial.register ( self.quit , '\\q ' , '\\q ' ,","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 875 from jrib/quit-help
132,f36635f4dc1764fd3b29919e925b7681ddc28ffa,2018-05-14 10:11:16-04:00,# Deal with extra params e.g . ? sslmode=verify-ca & sslrootcert=/myrootcert $ pgcli postgresql : // [ user [ : password ] @ ] [ netloc ] [ : port ] [ /dbname ] $ pgcli postgres : //amjith : pa $ $ w0rd @ example.com:5432/app_db # Deal with extra params e.g . ? sslmode=verify-ca & ssl-cert=/mycert,"['README.rst', 'pgcli/main.py']",Merge pull request # 872 from cfournie/encourage_ssl
133,2f344ca6d27312bc47c2caff35a273590fb7b2ac,2018-04-28 07:31:31+02:00,"| -- -- -- -- -- -- |\r * Add `` application_name `` to help identify pgcli connection to database ( issue # 868 ) ( Thanks : ` François Pietka ` _ ) port=port ) `` SELECT 'found ' FROM pg_stat_activity WHERE application_name = 'pgcli ' HAVING COUNT ( * ) > 0 ; '' context.conf [ 'pager_boundary ' ] + '\r ' + dedent ( `` ' * * kwargs ) | ? column ? |\r * * kwargs ) context.cli.sendline ( then we see found def step_check_application_name ( context ) : | found |\r from textwrap import dedent application_name='pgcli ' , * * kwargs ) dsn , application_name='pgcli ' , dsn , * * kwargs ) Scenario : check our application_name \r port=port , application_name='pgcli ' ) def step_see_found ( context ) : When we run query to check application_name wrappers.expect_exact ( SELECT 1\r ' '' ) + context.conf [ 'pager_boundary ' ] , timeout=5 ) context ,","['changelog.rst', 'pgcli/main.py', 'tests/features/basic_commands.feature', 'tests/features/steps/basic_commands.py']",Merge pull request # 869 from dbcli/fpietka/application_name
134,f81243eb1c86598b020169e01a0738c68a4c74e0,2018-04-05 14:26:30-07:00,* Mark tests requiring a running database server as dbtest ( Thanks : ` Dick Marinus ` _ ) Internal changes : TODO,"['changelog.rst', 'tests/test_main.py']",Merge pull request # 866 from dbcli/mark_dbtest
135,85d087b51eaa1706671b28add8aa86dfc7766a01,2018-04-04 08:56:26-07:00,====== TODO 1.9.1 :,['changelog.rst'],Merge pull request # 864 from dbcli/j-bennet/release-1.9.1
136,0feffcb7789df57b44fd1824d648d73689fe7c1c,2018-03-31 13:20:28-07:00,"token ) ] = style.styles [ string_to_tokentype ( cli_style [ token ] ) ] custom_styles [ string_to_tokentype ( from .pgstyle import style_factory , style_factory_output default_style = `` '' style = pygments.styles.get_style_by_name ( 'native ' ) .styles except ClassNotFound : 'preserve_whitespace ' : True , class OutputStyle ( pygments.style.Style ) : self.syntax_style , c [ 'colors ' ] ) # you can use token or custom colors 'preserve_whitespace ' : True style = pygments.styles.get_style_by_name ( name ) .styles 'style ' : settings.style_output # color of table None , None , None , ' < null > ' , False , None , lambda x : x , None custom_styles = dict ( [ ( string_to_tokentype ( x ) , y ) def style_factory_output ( name , cli_style ) : try : Token.Output.Header = `` # 00ff5f bold '' 'table_format dcmlfmt floatfmt missingval expanded max_width case_function style_output ' Token.Output.OddRow = `` '' Token.Output.EvenRow = `` '' custom_styles = { } for token in cli_style : ) , custom_styles [ string_to_tokentype ( token ) ] = cli_style [ token ] ) except AttributeError as err : token ) : style [ string_to_tokentype ( cli_style [ token ] ) ] , } ) from .pgstyle import style_factory for x , y in cli_style.items ( ) ] ) * Add Color of table by parameter . The color of table is function of syntax style styles = style from pygments.style import Style None , None , None , ' < null > ' , False , None , lambda x : x return OutputStyle self.style_output = style_factory_output ( 'table_format dcmlfmt floatfmt missingval expanded max_width case_function ' style_output=self.style_output { string_to_tokentype ( token ) : cli_style [ token ] , } ) try : style.update ( style.update ( { string_to_tokentype (","['changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgstyle.py']",Merge pull request # 834 from dbcli/fraoustin/colors_of_table
137,e20d4754fab0b4aac7e797ef4e87327093447161,2018-03-28 15:45:01-07:00,"host = self.pgexecute.host or ' ( none ) ' string = string.replace ( '\\H ' , host ) string = string.replace ( '\\h ' , short_host ) string = string.replace ( '\\h ' , self.pgexecute.host or ' ( none ) ' ) Features : short_host , _ , _ = host.partition ( ' . ' ) * Change `` \h `` format string in prompt to only return the first part of the hostname , # \h - Hostname of the server * Andrew Kuchling # \H - Hostname of the server .. _ ` Andrew Kuchling ` : https : //github.com/akuchling # \h - Short hostname of the server ( up to first ' . ' ) ( Thanks : ` Andrew Kuchling ` _ ) up to the first ' . ' character . Add `` \H `` that returns the entire hostname ( # 858 ) .","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 861 from akuchling/akuchling-issue858
138,be246928123ac5c354f4e0ceec067c227451eea6,2018-03-28 11:46:46-07:00,The database user has to have [ behave.userdata ] in the `` tests `` directory . An example : : [ behave ] permissions to create and drop test database . Default user is `` postgres `` Configuration settings for this package are provided via a `` behave.ini `` file Configuration settings for this package are provided via `` behave.ini `` file pg_test_user = dbuser in the `` tests `` directory . pg_test_host = db.example.com permissions to create and drop test databases . Default user is `` postgres `` stderr_capture = false The database user ( `` pg_test_user = postgres `` in .ini file ) has to have pg_test_port = 30000,['DEVELOP.rst'],Merge pull request # 862 from akuchling/akuchling-doc-behave
139,fbf12c3ee3def0a47f040c545f0d3313d9209662,2018-03-28 14:25:48-04:00,"Features : * Change `` \h `` format string in prompt to only return the first part of the hostname , * Andrew Kuchling .. _ ` Andrew Kuchling ` : https : //github.com/akuchling ( Thanks : ` Andrew Kuchling ` _ ) up to the first ' . ' character . Add `` \H `` that returns the entire hostname ( # 858 ) .","['AUTHORS', 'changelog.rst']",# 858 : add changelog item
140,a91afadccfea9fc2063f46989fb1b5028d30b6ee,2018-03-28 08:06:47-04:00,"host = self.pgexecute.host or ' ( none ) ' string = string.replace ( '\\H ' , host ) string = string.replace ( '\\h ' , short_host ) string = string.replace ( '\\h ' , self.pgexecute.host or ' ( none ) ' ) short_host , _ , _ = host.partition ( ' . ' )",['pgcli/main.py'],# 858 : make \h in prompt return the first part of the hostname ; add \H to return whole hostname
141,6fe2c6a06171e6fdc54dfe71e4d649c53c1f0200,2018-03-27 08:42:48-07:00,".. _ ` detailed instructions ` : https : //github.com/dbcli/pgcli # detailed-installation-instructions $ pip install pgcli -- no-binary : all : psycopg2 .. _ ` problems with psycopg2 wheels ` : http : //initd.org/psycopg/articles/2018/02/08/psycopg-274-released/ : : __ https : //github.com/dbcli/pgcli # detailed-installation-instructions 'psycopg2 > = 2.7.4 , < 2.8 ' , If you have ` problems with psycopg2 wheels ` _ , use the following flags to install psycopg2 from 'psycopg2-binary > = 2.7.4 ' , ` detailed instructions ` __ . source : ` detailed instructions ` _ .","['README.rst', 'setup.py']",Merge pull request # 859 from dbcli/j-bennet/revert-to-psycopg2
142,7ea910236a39fc9aa74e64515c3795951ef5d502,2018-03-22 13:24:51+01:00,self.echo_via_pager ( '\n'.join ( formatted ) ) * Fix broken pgcli -- list command line option ( # 850 ) . ( Thanks : ` Dmitry B ` _ ) Bug Fixes : pgcli.echo_via_pager ( '\n'.join ( formatted ) ),"['changelog.rst', 'pgcli/main.py']",Merge pull request # 857 from badanin-dmitry-playrix/patch-1
143,9e46fbab324d887934628104e46472c711dad8b3,2018-03-22 10:58:45+01:00,"ver = str ( ast.literal_eval ( _version_re.search ( run_step ( 'python ' , 'setup.py ' , 'sdist ' , 'upload ' ) run_step ( 'python ' , 'setup.py ' , 'sdist ' ) with open ( version_file , 'rb ' ) as f : r'__version__\s+=\s+ ( ? P < quote > [ \ ' '' ] ) ( ? P < version > . * ) ( ? P=quote ) ' ) _version_re = re.compile ( from optparse import OptionParser choice = raw_input ( `` -- - Confirm step ? ( y/N ) [ y ] `` ) run_step ( 'python ' , 'setup.py ' , 'sdist ' , 'bdist_wheel ' ) if choice.lower ( ) ! = ' y ' : _version_re = re.compile ( r'__version__\s+=\s+ ( . * ) ' ) run_step ( 'git ' , 'commit ' , ' -- message ' , with io.open ( version_file , encoding='utf-8 ' ) as f : ] checklist ( checks ) twine==1.11.0 run_step ( 'git ' , 'tag ' , tag_name ) run_step ( 'git ' , 'tag ' , '-s ' , '-m ' , tag_name , tag_name ) upload_source_tarball ( ) run_step ( 'twine ' , 'upload ' , 'dist/ * ' ) click==6.7 run_step ( 'git ' , 'commit ' , ' -- message ' , 'Releasing version % s ' % ver ) if choice.lower ( ) == ' n ' : 'Releasing version { } '.format ( ver ) ) import ast sys.exit ( 1 ) def upload_source_tarball ( ) : import click if not click.confirm ( 'Are you sure ? ' , default=False ) : 'Have you updated the ` Usage ` section of the README ? ' , f.read ( ) .decode ( 'utf-8 ' ) ) .group ( 1 ) ) ) return not click.confirm ( ' -- - Run this step ? ' , default=True ) if not click.confirm ( ' -- - { } '.format ( question ) , default=False ) : create_git_tag ( ' v % s ' % ver ) choice = raw_input ( 'Are you sure ? ( y/N ) [ n ] ' ) def create_distribution_files ( ) : from optparse import OptionParser return True upload_distribution_files ( ) def upload_distribution_files ( ) : `` `` '' A script to publish a release of pgcli to PyPI . '' '' '' create_git_tag ( ' v { } '.format ( ver ) ) for question in questions : create_distribution_files ( ) create_source_tarball ( ) def checklist ( questions ) : ver = _version_re.search ( f.read ( ) ) .group ( 'version ' ) import io checks = [ 'Have you updated the AUTHORS file ? ' , def create_source_tarball ( ) :","['release.py', 'requirements-dev.txt']",Merge pull request # 856 from dbcli/j-bennet/improved-release-script
144,5f23a764326b8a1edec59f60fe3baebdc7e510da,2018-03-16 10:39:14-07:00,"Internal changes : include LICENSE.txt TODO * Add tests , AUTHORS and changelog.rst to release . ( Thanks : ` Dick Marinus ` _ ) include LICENSE.txt AUTHORS changelog.rst recursive-include tests *","['MANIFEST.in', 'changelog.rst']",Merge pull request # 848 from dbcli/feature/update_manifest
145,6277ffd860bfb682807794f6b83c5e686283b592,2018-03-02 14:35:20-08:00,"Upcoming ======== 1.9.0 ========= ===== 'pgspecial > =1.10.0 ' , 'pgspecial > =1.9.0 ' , TODO Upcoming :","['changelog.rst', 'setup.py']",Merge pull request # 847 from dbcli/j-bennet/release-1.9.0
146,fa248655da620a70e94935541d50cebf440ea946,2018-02-17 13:42:17-08:00,"if list_dsn : except Exception as err : click.secho ( alias + `` : `` + cfg [ 'alias_dsn ' ] [ alias ] ) sys.exit ( 0 ) exit ( 1 ) for alias in cfg [ 'alias_dsn ' ] : less_chatty , prompt , prompt_dsn , list_databases , auto_vertical_output , list_dsn ) : try : * Add option list-dsn ( Thanks : ` Frederic Aoustin ` _ ) . help='list of DSN configured into the [ alias_dsn ] section of pgclirc file . ' ) click.secho ( 'Invalid DSNs found in the config file . ' cfg = load_config ( pgclirc , config_full_path ) less_chatty , prompt , prompt_dsn , list_databases , auto_vertical_output ) : err=True , fg='red ' ) 'Please check the `` [ alias_dsn ] '' section in pgclirc . ' ,","['changelog.rst', 'pgcli/main.py']",Merge pull request # 839 from dbcli/fraoustin/list_dsn
147,9764219f6da245b5febb81b73f48dadd8a699471,2018-02-15 08:54:28-07:00,"autopep8==1.3.3 * Pierre Giraud wrappers.expect_exact ( context , '\r\n : ' , timeout=2 ) wrappers.expect_exact ( context , ' : ' , timeout=2 )","['AUTHORS', 'requirements-dev.txt', 'tests/features/steps/iocommands.py']",Merge pull request # 843 from pgiraud/fix_iocommands_test
148,8138ae8e31ef2139774acf2d16d6a8f7e14f40cb,2018-01-27 14:25:29-08:00,"if self.pgspecial.pager_config == PAGER_OFF : self.echo_via_pager ( '\n'.join ( formatted ) ) click.echo_via_pager ( text , color ) from pgspecial.main import ( PGSpecial , NO_QUERY ) click.echo_via_pager ( '\n'.join ( output ) ) 'enable_pager ' ) and `` on '' or `` off '' ) click.echo_via_pager ( '\n'.join ( formatted ) ) enable_pager = True * manage pager by \pset pager and add enable_pager to the config file ( Thanks : ` Frederic Aoustin ` _ ) . self.pgspecial.pset_pager ( self.config [ 'main ' ] .as_bool ( from pgspecial.main import ( PGSpecial , NO_QUERY , PAGER_OFF ) self.echo_via_pager ( '\n'.join ( output ) ) # manage pager on startup click.echo ( text , color=color ) def echo_via_pager ( self , text , color=None ) : else :","['changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 832 from fraoustin/nopager
149,a6d07e707a1f50b6e1efc20f968570c8bcc0a77d,2018-01-15 20:51:58-08:00,"envlist = py27 , py34 , py35 , py36 Internal changes : 'Programming Language : : Python : : 3.3 ' , `` 3.3 '' * Removed support for Python 3.3 . ( Thanks : ` Irina Truong ` _ ) envlist = py27 , py33 , py34 , py35 , py36","['.travis.yml', 'changelog.rst', 'setup.py', 'tox.ini']",Merge pull request # 836 from dbcli/j-bennet/remove-py33
150,327f15afc3fcbd556b87a5b568b2b6c983519bdd,2018-01-07 13:13:13+01:00,"'postgres instance is listening . ' , envvar='PGPORT ' , type=click.INT ) envvar='PGCLIRC ' , help='Location of pgclirc file . ' , type=click.Path ( dir_okay=False ) ) 'postgres instance is listening . ' , envvar='PGPORT ' ) envvar='PGCLIRC ' , help='Location of pgclirc file . ' )",['pgcli/main.py'],Merge pull request # 831 from dbcli/j-bennet/add-click-types
151,885373496002b0400c1d7ade50330b969ec67ffb,2018-01-04 10:47:12-08:00,"| -- -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- | 'Change the table format used to output results ' ) | \refresh | Refresh auto-completions . | | \c [ onnect ] database_name | Change to a new database . | | \df [ + ] [ pattern ] | List functions . | | -- -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -| self.pgspecial.register ( self.change_table_format , '\\T ' , '\\T [ format ] ' , * Frederic Aoustin Change the table format used to output results self.table_format = pattern msg += `` \n\t { } '' .format ( table_type ) raise ValueError ( ) * Add support for ` \T ` command to change format output . ( Thanks : ` Frederic Aoustin ` _ ) . ======== 'Changed table format to { } '.format ( pattern ) ) if pattern not in TabularOutputFormatter ( ) .supported_formats : | \di [ + ] [ pattern ] | List indexes . | List or describe tables , views and sequences . | | \nd [ name [ query ] ] | Delete a named query . | Upcoming | \ # | Refresh auto-completions . | try : | \e [ file ] | Edit the query with external editor . | msg = 'Table format { } not recognized . Allowed formats : '.format ( | \dn [ + ] [ pattern ] | List schemas . | | \dn [ + ] [ pattern ] | List schemas . | List or describe tables , views and sequences . | \dT [ S+ ] [ pattern ] | List data types | yield ( None , None , None , | \l | List databases . | Set PAGER . Pring the query results via PAGER . | .. _ ` Frederic Aoustin ` : https : //github.com/fraoustin | \du [ + ] [ pattern ] | List roles . | | \ns name query | Save a named query . | | \dt [ + ] [ pattern ] | List tables . | | \x | Toggle expanded output . | pattern ) | \d [ pattern ] | List or describe tables , views and sequences . | def change_table_format ( self , pattern , * * _ ) : | \ns name query | Save a named query . | | \n [ + ] [ name ] | List or execute named queries . | yield ( None , None , None , msg ) | \T [ format ] | Change the table format used to output results | | \ds [ + ] [ pattern ] | List sequences . | | \df [ + ] [ pattern ] | List functions . | | \timing | Toggle timing of commands . | | \du [ + ] [ pattern ] | List roles . | | \refresh | Refresh auto-completions . | msg += '\nCurrently set to : % s ' % self.table_format | \l | List databases . | | \timing | Toggle timing of commands . | | \nd [ name [ query ] ] | Delete a named query . | | \ds [ + ] [ pattern ] | List sequences . | | \d [ pattern ] | List or describe tables , views and sequences . | | \ ? | Show Help . | | \x | Toggle expanded output . | | \dt [ + ] [ pattern ] | List tables . | | \ # | Refresh auto-completions . | \T [ format ] | Command | Description | | \ ? | Show Help . | | Command | Description | except ValueError : | \e [ file ] | Edit the query with external editor . | | \dv [ + ] [ pattern ] | List views . | Features : | \dv [ + ] [ pattern ] | List views . | | \n [ + ] [ name ] | List or execute named queries . | for table_type in TabularOutputFormatter ( ) .supported_formats : | \c [ onnect ] database_name | Change to a new database . | Set PAGER . Pring the query results via PAGER . | \dT [ S+ ] [ pattern ] | List data types | | \di [ + ] [ pattern ] | List indexes . |","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'tests/features/fixture_data/help.txt', 'tests/features/fixture_data/help_commands.txt']",Merge pull request # 830 from fraoustin/change_format_output
152,22773b8b32803b6365874998a291ac8595f16e3d,2017-12-22 10:50:18-08:00,"* Added support of `` \\e `` command . Queries can be edited in an external editor . ( Thanks : ` Irina Truong ` _ ) * Using `` pgspecial `` as a separate module . ( Thanks : ` Irina Truong ` _ ) . * Using `` pgspecial `` as a separate module . ( Thanks : ` Iryna Cherniavska ` _ ) . * Added code coverage to the tests . ( Thanks : ` Iryna Cherniavska ` _ ) .. _ ` Iryna Cherniavska ` : https : //github.com/j-bennet * Add alias completion support to ON keyword . ( Thanks : ` Iryna Cherniavska ` _ ) * Improvements to integration tests to make it more robust . ( Thanks : ` Irina Truong ` _ ) . * Enabled autocompletion in named queries . ( Thanks : ` Irina Truong ` _ ) . * Run behaviorial tests as part of TravisCI ( Thanks : ` Irina Truong ` _ ) postgres database . ( Thanks : ` Irina Truong ` _ ) postgres database . ( Thanks : ` Iryna Cherniavska ` _ ) * Add place holder doc strings for special commands that are planned for implementation . ( Thanks : ` Iryna Cherniavska ` _ ) * Run behaviorial tests as part of TravisCI ( Thanks : ` Iryna Cherniavska ` _ ) * Added code coverage to the tests . ( Thanks : ` Irina Truong ` _ ) * Fixed logging in Windows by switching the location of log and history file based on OS . ( Thanks : Amjith , ` Darik Gamble ` _ , ` Iryna Cherniavska ` _ ) . * Add integration tests using `` behave `` . ( Thanks : ` Irina Truong ` _ ) * Add alias completion support to ON keyword . ( Thanks : ` Irina Truong ` _ ) * Add place holder doc strings for special commands that are planned for implementation . ( Thanks : ` Irina Truong ` _ ) * Improvements to integration tests to make it more robust . ( Thanks : ` Iryna Cherniavska ` _ ) . * Perform auto-completion refresh in background . ( Thanks : Amjith , ` Darik Gamble ` _ , ` Iryna Cherniavska ` _ ) . * Added more behaviorial tests ( Thanks : ` Iryna Cherniavska ` _ ) * Enabled autocompletion in named queries . ( Thanks : ` Iryna Cherniavska ` _ ) . * Added support for pg_service_conf file . ( Thanks : ` Irina Truong ` _ ) . * Added support of `` \\e `` command . Queries can be edited in an external editor . ( Thanks : ` Iryna Cherniavska ` _ ) * Added more behaviorial tests ( Thanks : ` Irina Truong ` _ ) * Perform auto-completion refresh in background . ( Thanks : Amjith , ` Darik Gamble ` _ , ` Irina Truong ` _ ) . * Path to .pgclirc can be specified in command line . ( Thanks : ` Irina Truong ` _ ) . * Fixed logging in Windows by switching the location of log and history file based on OS . ( Thanks : Amjith , ` Darik Gamble ` _ , ` Irina Truong ` _ ) . * Added support for pg_service_conf file . ( Thanks : ` Iryna Cherniavska ` _ ) . * Add integration tests using `` behave `` . ( Thanks : ` Iryna Cherniavska ` _ ) * Path to .pgclirc can be specified in command line . ( Thanks : ` Iryna Cherniavska ` _ ) .",['changelog.rst'],Merge pull request # 827 from dbcli/j-bennet/name-change
153,64f42f211de19b8b80ac15425f863d959e9a23a6,2017-12-20 20:50:22-08:00,Upcoming ======== Features : * Include username into password prompt . ( Thanks : ` Bojan Delić ` _ ) ===== ===== TODO * Use other prompt ( prompt_dsn ) when connecting using -- dsn parameter . ( Thanks : ` Marcin Sztolcman ` _ ) 1.8.2 .. _ ` Bojan Delić ` : https : //github.com/delicb 1.8.2 * Bojan Delić * Use other prompt ( prompt_dsn ) when connecting using -- dsn parameter . ( Thanks : ` Marcin Sztolcman ` _ ),"['AUTHORS', 'changelog.rst']",Merge pull request # 825 from dbcli/j-bennet/more-release-1.8.2
154,460d9a418ecf95e06fe800a37a02a186ba8fc0ae,2017-12-20 15:01:26-08:00,"show_default=False , type=str ) passwd = click.prompt ( 'Password ' , hide_input=True , passwd = click.prompt ( 'Password for % s ' % user , type=str ) passwd = click.prompt ( 'Password for % s ' % user , hide_input=True , hide_input=True , show_default=False , passwd = click.prompt ( 'Password ' , hide_input=True ,",['pgcli/main.py'],Merge pull request # 824 from delicb/feature/username-in-password-prompt
155,8bd7a7a94f4615836de3c431ef5e97da60c77801,2017-12-20 23:58:53+01:00,"show_default=False , type=str ) passwd = click.prompt ( 'Password ' , hide_input=True , passwd = click.prompt ( 'Password for % s ' % user , type=str ) passwd = click.prompt ( 'Password for % s ' % user , hide_input=True , hide_input=True , show_default=False , passwd = click.prompt ( 'Password ' , hide_input=True ,",['pgcli/main.py'],Include username to password prompt . # 823
156,b2e572bf8291c54ea0ced8a6e43444ed6ed2c744,2017-12-16 19:02:45-08:00,.. _ ` Isank ` : https : //github.com/isank if list_databases : * Isank # because option -- list or -l are not supposed to have a db name * Fix the -- list command line option tries to connect to 'personal ' DB ( # 816 ) . ( Thanks : ` Isank ` _ ) database = 'postgres ',"['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 821 from isank/816
157,a3c0d131d7029e3058b4beec8f02fc60a6efc955,2017-12-16 14:14:58-08:00,"# \t - Current date and time prompt = self.get_prompt ( self.prompt_format ) if ( prompt_format == self.default_prompt and self.prompt_dsn_format = prompt_dsn prompt_format = self.prompt_dsn_format less_chatty , prompt , list_databases , auto_vertical_output ) : prompt = self.get_prompt ( prompt_format ) prompt_format = self.prompt_format single_connection=False , less_chatty=None , prompt=None , .. _ ` Marcin Sztolcman ` : https : //github.com/msztolcman # \i - Postgres PID single_connection=False , less_chatty=None , prompt=None , prompt_dsn=None , less_chatty , prompt , prompt_dsn , list_databases , auto_vertical_output ) : else : pgcli.dsn_alias = dsn self.dsn_alias = None * Marcin Sztolcman # \p - Database port less_chatty=less_chatty , prompt=prompt , prompt_dsn=prompt_dsn , less_chatty=less_chatty , prompt=prompt , # \dsn_alias - name of dsn alias if -D option is used ( empty otherwise ) # should be before replacing \\d len ( prompt ) > self.max_len_prompt ) : if ( self.prompt_format == self.default_prompt and len ( prompt ) > self.max_len_prompt ) : string = string.replace ( '\\dsn_alias ' , self.dsn_alias or `` ) if self.dsn_alias and self.prompt_dsn_format is not None : * Use other prompt ( prompt_dsn ) when connecting using -- dsn parameter . ( Thanks : ` Marcin Sztolcman ` _ )","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 820 from msztolcman/master
158,2c02f56c4123a8a2943ed9f7c868ea235a90f42e,2017-12-16 20:52:10+05:18,if list_databases : # because option -- list or -l are not supposed to have a db name database = 'postgres ',['pgcli/main.py'],Fixed # 816 The -- list command line option tries to connect to 'personal ' DB
159,ee3ea177a8550d43e8dc2020dfb3f86045d3d5a8,2017-12-12 08:05:31+01:00,"'Programming Language : : Python : : 2 ' , * Use temporary dir as config location in tests . ( Thanks : ` Dmitry B ` _ ) ===== 1.8.2 .. _ ` Dmitry B ` : https : //github.com/oxitnik TODO * Use temporary dir as config location in tests","['changelog.rst', 'setup.py']",Merge pull request # 819 from dbcli/j-bennet/release-1.8.2
160,c664738a79f20e2c2919177a667d586e4f802368,2017-12-01 19:37:20-06:00,"assert list ( expanded_results ) == expanded 'cli_helpers > = 0.2.3 , < 1.0.0 ' , 'cli_helpers [ styles ] > = 1.0.1 ' , assert '\n'.join ( expanded_results ) == '\n'.join ( expanded ) assert '\n'.join ( results ) == '\n'.join ( expected ) assert list ( results ) == expected","['setup.py', 'tests/test_main.py']",Merge pull request # 818 from dbcli/j-bennet/bump-cli-helpers
161,f6742261719662d71439abe9b83dc1f103a2337a,2017-10-22 07:59:54+02:00,return cur.fetchone ( ) [ 0 ] result = cur.fetchone ( ) * Fix error in `` unix_socket_directories `` ( # 805 ) . ( Thanks : ` Irina Truong ` _ ) return result [ 0 ] if result else ``,"['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 808 from dbcli/j-bennet/bugfix/unix-socket-directories
162,d1866191b8e7c4e4f9279ebff5de2628a7656289,2017-10-11 13:22:48-07:00,databases = self.escaped_names ( databases ) Bug Fixes : * Do NOT quote the database names in the completion menu ( Thanks : ` Amjith Ramanujam ` _ ),"['changelog.rst', 'pgcli/pgcompleter.py']",Merge pull request # 800 from dbcli/amjith/fix_database_case
163,7c720a07652d705376af6bf4fcfe6a65e0df3ddc,2017-10-06 12:51:45-07:00,"low_count_cursor = Mock ( ) return default_pgcli_obj.row_limit elif platform.system ( ) == 'Windows ' : 'XDG_CONFIG_HOME ' : os.environ.get ( 'XDG_CONFIG_HOME ' , None ) , over_limit_cursor.configure_mock ( rowcount=LIMIT + 10 ) * Use temporary dir as config location in tests import shutil return over_default_cursor # use temporary directory for config home so user config will not be used over_limit_cursor = Mock ( ) os.environ [ 'XDG_CONFIG_HOME ' ] = context.env_config_home * Dmitry B def low_count ( ) : def test_default_row_limit ( ) : def test_set_row_limit ( over_default , over_limit , LIMIT ) : return DEFAULT + 1000 def test_no_limit ( ) : os.environ [ 'XDG_CONFIG_HOME ' ] = str ( tmpdir_factory.mktemp ( 'data ' ) ) return ' % s/pgcli/ ' % expanduser ( os.environ [ 'XDG_CONFIG_HOME ' ] ) over_default_cursor.configure_mock ( # this function runs on start of test session . if platform.system ( ) == 'Windows ' : return low_count_cursor # after test collection so it has config loaded from temp directory import tempfile # We need this fixtures beacause we need PGCli object to be created DEFAULT = PGCli ( ) .row_limit elif 'XDG_CONFIG_HOME ' in os.environ : def test_set_row_limit ( ) : return ' % s/pgcli/ ' % expanduser ( os.environ [ 'XDG_CONFIG_HOME ' ] ) return over_limit_cursor def temp_config ( tmpdir_factory ) : low_count.configure_mock ( rowcount=1 ) rowcount=DEFAULT + 10 low_count_cursor.configure_mock ( rowcount=1 ) over_default_cursor = Mock ( ) import pytest if 'XDG_CONFIG_HOME ' in os.environ : def over_limit ( LIMIT ) : def LIMIT ( DEFAULT ) : context.env_config_home = tempfile.mkdtemp ( prefix='pgcli_home_ ' ) LIMIT = DEFAULT + 1000 # Remove temp config direcotry shutil.rmtree ( context.env_config_home ) over_default.configure_mock ( rowcount=DEFAULT + 10 ) def test_row_limit_on_non_select ( ) : def test_default_row_limit ( low_count , over_default ) : def test_no_limit ( over_limit ) : over_limit.configure_mock ( rowcount=LIMIT + 10 ) def default_pgcli_obj ( ) : low_count = Mock ( ) ) def test_row_limit_on_non_select ( over_default ) : over_default = Mock ( ) # use temporary directory as config home over_limit = Mock ( ) return PGCli ( ) def over_default ( DEFAULT ) : import os def DEFAULT ( default_pgcli_obj ) :","['AUTHORS', 'changelog.rst', 'pgcli/config.py', 'tests/conftest.py', 'tests/features/environment.py', 'tests/test_rowlimit.py']",Merge pull request # 796 from oxitnik/feature_use_temp_config_for_tests
164,5435b4671577621a3696c5ddd8182779126ccad7,2017-10-06 12:25:20-07:00,@ when ( u'we notee output ' ) # we want the latest possible version of pep8radius pip install -r requirements-dev.txt pep8radius * Fix errors in the `` tee `` test ( # 795 and # 797 ) . ( Thanks : ` Irina Truong ` _ ) docutils > =0.13.1 git+https : //github.com/hayd/pep8radius.git pip install . TODO context.cli.sendline ( 'notee ' ) install : pip install git+https : //github.com/hayd/pep8radius.git Internal changes : and we stop teeing output install : context.cli.sendline ( '\o ' ) context.cli.sendcontrol ( ' u ' ) codecov > =1.5.1 and we notee output pip install . docutils pytest mock codecov==1.5.1 behave pexpect==3.3,"['.travis.yml', 'changelog.rst', 'requirements-dev.txt', 'tests/features/environment.py', 'tests/features/iocommands.feature', 'tests/features/steps/iocommands.py']",Merge pull request # 798 from dbcli/j-bennet/bugfix/tee-test
165,22223f87486b8f790165c05d816023f83f7c3456,2017-09-19 12:21:13-07:00,1.8.1 ===== * Require cli_helpers 0.2.3 ( fix # 791 ) . ( Thanks : ` Dick Marinus ` _ ) * Require cli_helpers 0.2.3 ( fix # 513 ) . ( Thanks : ` Dick Marinus ` _ ) TODO,['changelog.rst'],Merge pull request # 793 from dbcli/j-bennet/pre-release-1.8.1
166,64f056c61f512c81b71a8b18a23d7907d9b02549,2017-09-15 14:46:13-07:00,Internal changes : * Remove shebang and git execute permission from pgcli/main.py . ( Thanks : ` Dick Marinus ` _ ) TBD # ! /usr/bin/env python,"['changelog.rst', 'pgcli/main.py']",Merge pull request # 790 from dbcli/feature/removeshebang
167,3bab2e5cae22390a85af0963b68ffa70d7b2f187,2017-09-14 13:00:09-07:00,TBD ===== 1.8.0,['changelog.rst'],Merge pull request # 788 from dbcli/j-bennet/pre-release-1.8.0
168,e733b0ea914a6744f7ffd96569b75437244aa4de,2017-09-05 14:12:41-07:00,"? column ? | 27\r single_connection=False , less_chatty=None , prompt=None , ? column ? | 31\r Scenario : auto_vertical on with small query ? column ? | 14\r def run_cli ( context ) : run_args = run_args or [ ] def step_execute_large_query ( context ) : self.auto_expand = c [ 'main ' ] .as_bool ( 'auto_expand ' ) ? column ? | 7\r less_chatty=less_chatty , prompt=prompt ) ? column ? | 3\r ? column ? | 40\r ? column ? | 5\r ? column ? | 19\r cmd_parts = [ cli_cmd ] + run_args ? column ? | 20\r ? column ? | 43\r SELECT 1\r ? column ? | 15\r and we execute a large query ? column ? | 35\r ? column ? | 44\r wrappers.run_cli ( context , run_args=arg.split ( '= ' ) ) 'auto_expand ' ) ? column ? | 21\r ? column ? | 10\r # - * - coding : utf-8 then we see small results in horizontal format ? column ? | 45\r def step_see_large_results ( context ) : [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- -\r `` `` '' ) , timeout=5 ) ? column ? | 38\r single_connection=False , less_chatty=None , prompt=None ) : def step_run_cli_with_arg ( context , arg ) : ? column ? | 23\r less_chatty , prompt , list_databases ) : ? column ? | 1\r ? column ? | 16\r | 1 |\r When we run dbcli with -- auto-vertical-output auto_vertical_output=False ) : ? column ? | 48\r self.auto_expand = auto_vertical_output or c [ 'main ' ] .as_bool ( ? column ? | 26\r then we see large results in vertical format ? column ? | 13\r ? column ? | 6\r 'select { } '.format ( ' , '.join ( [ str ( n ) for n in range ( 1 , 50 ) ] ) ) ) ? column ? | 47\r less_chatty=less_chatty , prompt=prompt , ? column ? | 49\r ? column ? | 4\r def step_execute_small_query ( context ) : ? column ? | 33\r ? column ? | 29\r from behave import then , when ? column ? | 12\r ? column ? | 25\r * Port auto_vertical feature test from mycli to pgcli . ( Thanks : ` Dick Marinus ` _ ) ? column ? | 24\r and we execute a small query ? column ? | 17\r def step_see_small_results ( context ) : ? column ? | 42\r Scenario : auto_vertical on with large query ? column ? | 9\r ? column ? | 37\r help='Automatically switch to vertical output mode if the result is wider than the terminal width . ' ) ? column ? | 28\r cmd = ' '.join ( cmd_parts ) | ? column ? |\r from __future__ import unicode_literals ? column ? | 36\r def run_cli ( context , run_args=None ) : ? column ? | 32\r ? column ? | 11\r ? column ? | 30\r wrappers.expect_pager ( context , dedent ( `` '' '' \ ? column ? | 2\r ? column ? | 8\r ? column ? | 18\r on , off context.cli = pexpect.spawnu ( cmd , cwd=context.package_root ) context.cli.sendline ( context.cli = pexpect.spawnu ( cli_cmd , cwd=context.package_root ) ? column ? | 22\r from textwrap import dedent | -- -- -- -- -- -- |\r \r ? column ? | 46\r ? column ? | 34\r Feature : auto_vertical mode : ? column ? | 39\r ? column ? | 41\r auto_vertical_output=auto_vertical_output ) context.cli.sendline ( 'select 1 ' ) import wrappers less_chatty , prompt , list_databases , auto_vertical_output ) :","['changelog.rst', 'pgcli/main.py', 'tests/features/auto_vertical.feature', 'tests/features/steps/auto_vertical.py', 'tests/features/steps/wrappers.py']",Merge pull request # 782 from dbcli/feature/auto_vertical
169,8c8b6816ca9bea1d4611e23ad73a22018605371a,2017-08-28 10:02:16-07:00,"rows = list ( cur ) column_types.append ( text_type ) else : d [ 1 ] in psycopg2.extensions.LONGINTEGER.values : rows , headers , format_name='vertical ' , * * output_kwargs ) cur , headers , format_name='vertical ' , column_types=None , * * output_kwargs ) column_types.append ( float ) if hasattr ( cur , 'description ' ) : import psycopg2 column_types = None if d [ 1 ] in psycopg2.extensions.DECIMAL.values or \ if d [ 1 ] == psycopg2.extensions.INTEGER.values or \ cur = list ( cur ) * Use less memory when formatting results for display ( Thanks : ` Dick Marinus ` _ ) . column_types.append ( int ) d [ 1 ] in psycopg2.extensions.FLOAT.values : for d in cur.description : column_types = [ ] formatted = formatter.format_output ( cur , headers , * * output_kwargs ) if max_width : formatted = formatter.format_output ( rows , headers , * * output_kwargs ) formatted = list ( formatted ) if max_width is not None :","['changelog.rst', 'pgcli/main.py']",Merge pull request # 777 from dbcli/feature/use_cursor
170,2fe9fe801f6e7cf4f64e6315af10eb7407766f24,2017-08-20 17:56:05-07:00,"from UserDict import DictMixin def __delitem__ ( self , key ) : # subject to the following conditions : return not self == other def clear ( self ) : # OTHER DEALINGS IN THE SOFTWARE . curr = end [ 1 ] class OrderedDict ( dict , DictMixin ) : if isinstance ( other , OrderedDict ) : curr = curr [ 2 ] # FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR self.__map , self.__end = tmp if p ! = q : return list ( self ) d [ key ] = value def __eq__ ( self , other ) : # NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT except AttributeError : # Permission is hereby granted , free of charge , to any person # EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES if last : # included in all copies or substantial portions of the Software . def __repr__ ( self ) : from .packages.ordereddict import OrderedDict if not self : from collections import namedtuple , defaultdict setdefault = DictMixin.setdefault raise KeyError ( 'dictionary is empty ' ) end = self.__end from collections import OrderedDict return d def popitem ( self , last=True ) : return self.__class__ ( self ) self.__end if key not in self : dict.__delitem__ ( self , key ) prev [ 2 ] = next curr = curr [ 1 ] tmp = self.__map , self.__end return ' % s ( % r ) ' % ( self.__class__.__name__ , self.items ( ) ) next [ 1 ] = prev yield curr [ 0 ] def __setitem__ ( self , key , value ) : # including without limitation the rights to use , copy , modify , merge , return key , value update = DictMixin.update self.update ( * args , * * kwds ) items = DictMixin.items @ classmethod for key in iterable : # WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING self.__end = end = [ ] def __init__ ( self , * args , * * kwds ) : return ( self.__class__ , ( items , ) , inst_dict ) if len ( self ) ! = len ( other ) : # ( the `` Software '' ) , to deal in the Software without restriction , key = reversed ( self ) .next ( ) return False def keys ( self ) : curr [ 2 ] = end [ 1 ] = self.__map [ key ] = [ key , curr , end ] else : .. _ ` Andrew Speed ` : https : //github.com/AndrewSpeed * Remove import workaround for OrderedDict , required for python < 2.7 . ( Thanks : ` Andrew Speed ` _ ) # Copyright ( c ) 2009 Raymond Hettinger def __reduce__ ( self ) : raise TypeError ( 'expected at most 1 arguments , got % d ' % len ( args ) ) from collections import namedtuple , defaultdict , OrderedDict return ' % s ( ) ' % ( self.__class__.__name__ , ) while curr is not end : # THE SOFTWARE IS PROVIDED `` AS IS '' , WITHOUT WARRANTY OF ANY KIND , # The above copyright notice and this permission notice shall be del self.__map , self.__end except ImportError : for p , q in zip ( self.items ( ) , other.items ( ) ) : return dict.__eq__ ( self , other ) curr = end [ 2 ] end = self.__end # OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND # obtaining a copy of this software and associated documentation files return False def __reversed__ ( self ) : self.__map = { } # key -- > [ key , prev , next ] key = iter ( self ) .next ( ) def copy ( self ) : def __ne__ ( self , other ) : d = cls ( ) try : def fromkeys ( cls , iterable , value=None ) : items = [ [ k , self [ k ] ] for k in self ] # and to permit persons to whom the Software is furnished to do so , # return self.__class__ , ( items , ) values = DictMixin.values return True value = self.pop ( key ) # HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , pop = DictMixin.pop try : key , prev , next = self.__map.pop ( key ) if len ( args ) > 1 : def __iter__ ( self ) : iterkeys = DictMixin.iterkeys dict.__setitem__ ( self , key , value ) if inst_dict : curr = end [ 1 ] iteritems = DictMixin.iteritems inst_dict = vars ( self ) .copy ( ) self.clear ( ) itervalues = DictMixin.itervalues # publish , distribute , sublicense , and/or sell copies of the Software , dict.clear ( self ) * Andrew Speed from collections import OrderedDict end += [ None , end , end ] # sentinel node for doubly linked list","['AUTHORS', 'changelog.rst', 'pgcli/completion_refresher.py', 'pgcli/packages/ordereddict.py', 'pgcli/pgcompleter.py']",Merge pull request # 785 from AndrewSpeed/remove-ordereddict-package
171,b136196f29599c223db5323a8020ce3aad40d41c,2017-08-18 15:27:43-07:00,"assert `` foo '' in result [ 3 ] '+ -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- +\n ' 'nested_numeric_array | { { 1,2 } , { 3,4 } } ' , result = run ( executor , '\\ ? ' , pgspecial=pgspecial ) [ 0 ] .split ( '| ' ) formatted = iter ( formatted.splitlines ( ) ) assert table_results == table '| -- -- -- -- -+ -- -- -- -- -|\n ' assert u'Command ' in result [ 1 ] result = run ( executor , '\\ ? ' , pgspecial=pgspecial ) [ 1 ] .split ( '| ' ) 'head2 | def ' , first_line = formatted [ : formatted.find ( '\n ' ) ] if isinstance ( formatted , ( text_type ) ) : assert len ( result ) == 4 # 2 * ( output+status ) assert `` bar '' in result [ 9 ] output = itertools.chain ( output , [ status ] ) 'nested_numeric_array | < null > \n ' assert u'fooé ' in result [ 3 ] '- [ RECORD 2 ] -- -- -- -- -- -- -- -- -- -- -- -- -\n ' assert results == expected 'bigint_array | { 1,2,3 } ' , '- [ RECORD 2 ] -- -- -- -- -- -- -- -- -- -- -- -- - ' , if isinstance ( formatted , ( text_type ) ) : assert u'Description ' in result [ 2 ] '配列 | { < null > } ' , '配列 | { < null > } \n ' , 'bigint_array | { } ' , output = itertools.chain ( output , formatted ) import itertools formatted = list ( formatted ) assert list ( table_results ) == table formatted = itertools.chain ( [ first_line ] , formatted ) '| abc | def | ' , '- [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- - ' , assert len ( result ) == 12 # 2 * ( output+status ) * 3 lines 'bigint_array | { 1,2,3 } \n ' 'bigint_array | { } \n ' '+ -- -- -- -- -+ -- -- -- -- -+ ' , output.append ( formatted ) '| bigint_array | nested_numeric_array | 配列 |\n ' if max_width : assert len ( result ) == 11 # 2 * ( output+status ) * 3 lines 'head1 | abc ' , formatted = iter ( formatted.splitlines ( ) ) '| { } | < null > | { < null > } | ' , '| { 1,2,3 } | { { 1,2 } , { 3,4 } } | { å , 魚 , текст } | ' , assert `` foo '' in result [ 0 ] '配列 | { å , 魚 , текст } ' , 'head1 | abc\n ' Internal changes : '| -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- | ' , '| abc | def |\n ' assert `` Schema '' in result [ 7 ] 'nested_numeric_array | { { 1,2 } , { 3,4 } } \n ' assert `` bar '' in result [ 2 ] '| bigint_array | nested_numeric_array | 配列 | ' , '配列 | { å , 魚 , текст } \n ' first_line = next ( formatted ) '- [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- -\n ' '| { 1,2,3 } | { { 1,2 } , { 3,4 } } | { å , 魚 , текст } |\n ' assert list ( results ) == expected assert u'fooé ' in result [ 0 ] output.append ( status ) \r '+ -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- + ' , 'nested_numeric_array | < null > ' , '| head1 | head2 |\n ' assert ( result [ 2 ] .find ( u'Description ' ) ! = -1 ) '| head1 | head2 | ' , assert list ( expanded_results ) == expanded assert ( result [ 1 ] .find ( u'Command ' ) ! = -1 ) '| { } | < null > | { < null > } |\n ' '+ -- -- -- -- -+ -- -- -- -- -+\n ' * Preliminary work for a future change in outputting results that uses less memory . ( Thanks : ` Dick Marinus ` _ ) assert `` Schema '' in result [ 2 ] '| -- -- -- -- -+ -- -- -- -- -| ' , 'head2 | def\n ' , '| -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- |\n ' assert expanded_results == expanded","['changelog.rst', 'pgcli/main.py', 'tests/features/steps/expanded.py', 'tests/test_main.py', 'tests/test_pgexecute.py']",Merge pull request # 780 from dbcli/feature/output_formatter_generator
172,386838b31fa4928dbbca8df1330f23df977f9b23,2017-08-18 07:38:21-07:00,"from utils import ( POSTGRES_HOST , POSTGRES_USER , POSTGRES_PASSWORD , create_db , db_connection , host=POSTGRES_HOST , password=None , port=None , dsn=None ) POSTGRES_USER = getenv ( 'PGUSER ' , 'postgres ' ) POSTGRES_PASSWORD = getenv ( 'PGPASSWORD ' , `` ) POSTGRES_USER , POSTGRES_HOST = 'postgres ' , 'localhost ' * Optionally use POSTGRES_USER , POSTGRES_HOST POSTGRES_PASSWORD from environment ( Thanks : ` Dick Marinus ` _ ) from utils import ( POSTGRES_HOST , POSTGRES_USER , create_db , db_connection , # TODO : should this be somehow be divined from environment ? POSTGRES_HOST = getenv ( 'PGHOST ' , 'localhost ' ) from os import getenv host=POSTGRES_HOST , password=POSTGRES_PASSWORD , port=None , dsn=None )","['changelog.rst', 'tests/conftest.py', 'tests/utils.py']",Merge pull request # 781 from dbcli/feature/conftest-getenv
173,1e77eab21b8e3b6592007123bf1daec759bdb5e5,2017-08-13 17:21:42-07:00,"WHERE name = 'unix_socket_directories ' infos = re.findall ( r ' '' [ ^ '' ] * '' | [ ^ '' \'\s ] + ' , pattern ) def info_connection ( self , * * _ ) : return cur.fetchone ( ) [ 0 ] self.socket_directory_query ) _logger.debug ( 'Socket directory Query . sql : % r ' , cur.execute ( self.socket_directory_query ) list ( map ( lambda s : s.strip ( ' '' ' ) , infos ) ) self.pgexecute.connect ( database=db , user=user , host=host , 'user `` % s '' ' % ( self.pgexecute.dbname , self.pgexecute.user ) ) self.pgexecute.port ) ) # Now removing quotes . with self.conn.cursor ( ) as cur : click.secho ( str ( e ) , err=True , fg='red ' ) click.echo ( `` Previous connection kept '' ) yield ( None , None , None , 'You are connected to database `` % s '' as user ' socket_directory_query = `` ' host , self.pgspecial.register ( self.info_connection , '\\conninfo ' , self.pgexecute.user , SELECT setting host = 'socket `` % s '' ' % self.pgexecute.host * Add \conninfo and handle more parameters with \c ( issue # 716 ) ( Thanks : ` François Pietka ` _ ) psycopg2.errorcodes.lookup ( e.pgcode ) ! = 'LOCK_NOT_AVAILABLE ' ) ) # Get all the parameters in pattern , handling double quotes if any . if not self.host : db = pattern [ 1 : -1 ] if pattern [ 0 ] == pattern [ -1 ] == ' '' ' else pattern ' '' host = 'host `` % s '' ' % self.pgexecute.host except OperationalError as e : ( not e.pgcode or if self.pgexecute.host.startswith ( '/ ' ) : 'user `` % s '' ' % ( self.pgexecute.dbname , self.pgexecute.user ) ) infos.extend ( [ None ] * ( 4 - len ( infos ) ) ) ' '' % s '' on % s at port `` % s '' . ' % ( self.pgexecute.dbname , self.host = self.get_socket_directory ( ) self.pgexecute.connect ( database=db ) try : FROM pg_settings '\\conninfo ' , 'Get connection details ' ) db , user , host , port = infos port=port ) def get_socket_directory ( self ) : psycopg2.errorcodes.lookup ( e.pgcode ) ! = 'LOCK_NOT_AVAILABLE ' ) else :","['changelog.rst', 'pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 773 from dbcli/fpietka/conninfo
174,03b9c9b720e30e51893fc1b85eac41362ff7ceda,2017-08-07 08:28:55-05:00,"results = run ( executor , statement , expanded=True ) if not isinstance ( val , list ) : assert results == expected table = [ [ 'head1 ' , 'head2 ' ] , 'test status ' , settings._replace ( max_width=1 ) ) results = run ( executor , statement ) 'test status ' , [ ( 'abc ' , 'def ' ) ] , 'preprocessors ' : ( format_numbers , format_arrays ) , 'head1 | abc\n ' ' { å , 魚 , текст } ' : :text [ ] as 配列 `` `` '' from decimal import Decimal 'test status ' 'nested_numeric_array | < null > \n ' for val in row if val is None : def format_arrays ( data , headers , * * _ ) : '| abc | def |\n ' '| { 1,2,3 } | { { 1,2 } , { 3,4 } } | { å , 魚 , текст } |\n ' '+ -- -- -- -- -+ -- -- -- -- -+\n ' return data , headers '配列 | { å , 魚 , текст } \n ' 'head2 | def\n ' , '| -- -- -- -- -+ -- -- -- -- -|\n ' return ' { ' + ' , '.join ( text_type ( format_array ( e ) ) for e in val ) + ' } ' table = [ 'Title ' , '+ -- -- -- -- -+ -- -- -- -- -+\n| head1 | head2 |\n| -- -- -- -- -+ -- -- -- -- -|\n| abc | def |\n+ -- -- -- -- -+ -- -- -- -- -+ ' , 'test status ' ] def test_format_array_output_expanded ( executor ) : for row in data : 'bigint_array | { 1,2,3 } \n ' 'Title ' , u'- [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- -\nhead1 | abc\nhead2 | def\n ' , 'test status ' ] settings._replace ( max_width=1 ) array [ 1 , 2 , 3 ] : :bigint [ ] as bigint_array , data = list ( data ) '| bigint_array | nested_numeric_array | 配列 |\n ' '+ -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- + ' , 'bigint_array | { } \n ' text_type = unicode if PY2 else str 'preprocessors ' : ( format_numbers , ) , statement = u '' '' '' * Improved formatting of arrays in output ( Thanks : ` Joakim Koljonen ` _ ) 'SELECT 2 ' '| { } | < null > | { < null > } |\n ' [ 'head1 ' , 'head2 ' ] , expected = [ from .encodingutils import text_type def test_format_array_output ( executor ) : '+ -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- +\n ' ] '配列 | { < null > } \n ' , expanded_results = format_output ( 'Title ' , expected = [ 'Title ' , '+ -- -- -- -- -+ -- -- -- -- -+\n| head1 | head2 |\n| -- -- -- -- -+ -- -- -- -- -|\n| abc | def |\n+ -- -- -- -- -+ -- -- -- -- -+ ' , 'test status ' ] ] '- [ RECORD 2 ] -- -- -- -- -- -- -- -- -- -- -- -- -\n ' expanded_results = format_output ( 'Title ' , [ ( 'abc ' , 'def ' ) ] , SELECT ' { } ' , NULL , array [ NULL ] SELECT return val 'nested_numeric_array | { { 1,2 } , { 3,4 } } \n ' return settings.missingval '| head1 | head2 |\n ' format_array ( val ) if isinstance ( val , list ) else val row [ : ] = [ ) # coding=utf-8 from __future__ import unicode_literals '+ -- -- -- -- -+ -- -- -- -- -+ ' , def format_array ( val ) : ' { { 1,2 } , { 3,4 } } ' : :numeric [ ] as nested_numeric_array , UNION ALL '| -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- |\n ' '- [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- -\n '","['changelog.rst', 'pgcli/encodingutils.py', 'pgcli/main.py', 'tests/test_main.py']",Merge pull request # 772 from dbcli/koljonen/array_formatting
175,3995e37a86cc70b2698fe4ca883aac90201af48d,2017-08-06 23:19:52-06:00,"======= | 3793 | New York | USA | New York | 8008278 | Assuming you have IPython installed : : : | 3794 | Los Angeles | USA | California | 3694820 | 9 rows affected . [ ( 3793 , u'New York ' , u'USA ' , u'New York ' , 8008278 ) , ( 3796 , u'Houston ' , u'USA ' , u'Texas ' , 1953631 ) , Connect to a database and construct a query : ( 3794 , u'Los Angeles ' , u'USA ' , u'California ' , 3694820 ) , | 3798 | Phoenix | USA | Arizona | 1321045 | query , then quit pgcli to find the query results in your IPython workspace . ( 3799 , u'San Diego ' , u'USA ' , u'California ' , 1223400 ) , it may be useful to drop into a pgcli session without leaving the IPython console , iterate on a | 3795 | Chicago | USA | Illinois | 2896016 | ( 3797 , u'Philadelphia ' , u'USA ' , u'Pennsylvania ' , 1517550 ) , IPython Out [ 2 ] : | 3796 | Houston | USA | Texas | 1953631 | In [ 3 ] : my_result = _ Pgcli can be run from within ` IPython < https : //ipython.org > ` _ console . When working on a query , Goodbye ! | -- -- -- + -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -+ -- -- -- -- -- -- -- + -- -- -- -- -- -- -- | Note : ` pgcli ` uses the ` tabulate ` _ package to pretty-print tables . This library does smart formatting In [ 1 ] : % load_ext pgcli.magic | 3801 | San Antonio | USA | Texas | 1144646 | Note : ` pgcli ` uses the ` tabulate ` _ package to pretty-print tables . This library does smart formatting $ pip install ipython-sql After that , run ipython and load the `` pgcli.magic `` extension : | 3797 | Philadelphia | USA | Pennsylvania | 1517550 | ( 3795 , u'Chicago ' , u'USA ' , u'Illinois ' , 2896016 ) , The results are available in special local variable `` _ `` , and can be assigned to a variable of your SELECT 9 ( 3800 , u'Dallas ' , u'USA ' , u'Texas ' , 1188580 ) , ( 3798 , u'Phoenix ' , u'USA ' , u'Arizona ' , 1321045 ) , Exit out of pgcli session with `` Ctrl + D `` and find the query results : choice : $ ipython | 3799 | San Diego | USA | California | 1223400 | Time : 0.003s ( 3801 , u'San Antonio ' , u'USA ' , u'Texas ' , 1144646 ) ] | 3800 | Dallas | USA | Texas | 1188580 | | id | name | countrycode | district | population |",['README.rst'],Merge pull request # 774 from dbcli/j-bennet/ipython-magic-docs
176,99c9040c3dad802fd0825dc10a6b09b0e3beb017,2017-08-06 21:14:40-06:00,"`` ANY '' , `` FALSE '' , `` VERBOSE '' `` THEN '' , `` ORDER '' , `` NOTNULL '' , `` CREATE '' , `` CASE '' , self.reserved_words.update ( x.split ( ) ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] for x in self.keywords : `` FOREIGN '' , `` FREEZE '' , `` JOIN '' , `` SIMILAR '' , `` CHECK '' , `` ILIKE '' , `` BOTH '' , `` VARIADIC '' , `` ELSE '' , `` TRAILING '' , `` FROM '' , `` DO '' , `` CURRENT_TIME '' , `` OVERLAPS '' , `` SELECT '' , if not name.islower ( ) or name in ( 'select ' , 'localtimestamp ' ) : `` NATURAL '' , `` LOCALTIME '' , `` DEFAULT '' , `` ASC '' , `` ONLY '' , `` AS '' , `` INNER '' , `` OFFSET '' , `` COLUMN '' , `` DISTINCT '' , `` ISNULL '' , `` WHERE '' , `` FULL '' , `` OUTER '' , `` CROSS '' , `` CURRENT_CATALOG '' , `` COLLATION '' , `` CURRENT_USER '' , `` IS '' , `` LOCALTIMESTAMP '' , `` AND '' , `` CONSTRAINT '' , `` OR '' , * Do n't quote identifiers that are non-reserved keywords . ( Thanks : ` Joakim Koljonen ` _ ) `` RETURNING '' , `` INTO '' , `` HAVING '' , `` CURRENT_ROLE '' , cols = ( ' '' select '' .id , `` select '' .insert , `` select '' . `` ABC '' , ' `` WHEN '' , `` CAST '' , `` CONCURRENTLY '' , `` ALL '' , `` LIMIT '' , `` WINDOW '' , `` WITH '' , `` USER '' , `` CURRENT_TIMESTAMP '' , `` ARRAY '' , `` REFERENCES '' , `` ANALYZE '' , `` LATERAL '' , `` GROUP '' , `` ASYMMETRIC '' , if not name.islower ( ) or name in ( 'select ' , 'insert ' ) : `` TABLESAMPLE '' , self.reserved_words = set ( ) `` AUTHORIZATION '' , `` FETCH '' , `` USING '' , `` INITIALLY '' , `` ANALYSE '' , `` EXCEPT '' , `` INTERSECT '' , `` DEFERRABLE '' , `` PLACING '' , `` TABLE '' , col_list = 'id , `` select '' . `` localtime '' , `` select '' . `` ABC '' ' `` LEADING '' , cols = ( ' '' select '' .id , `` select '' . `` insert '' , `` select '' . `` ABC '' , ' `` RIGHT '' , `` SESSION_USER '' , `` reserved '' : [ `` FOR '' , `` TRUE '' , col_list = 'id , `` select '' . `` insert '' , `` select '' . `` ABC '' ' `` LIKE '' , `` ON '' , `` END '' , `` SOME '' , `` IN '' , `` DESC '' , col_list = 'id , `` select '' .insert , `` select '' . `` ABC '' ' `` UNION '' , `` NOT '' , `` COLLATE '' , `` PRIMARY '' , `` GRANT '' , reserved_words = set ( get_literals ( 'reserved ' ) ) `` TO '' , `` CURRENT_DATE '' , `` CURRENT_SCHEMA '' , cols = ( ' '' select '' .id , `` select '' . `` localtime '' , `` select '' . `` ABC '' , ' ] , `` SYMMETRIC '' , `` UNIQUE '' , `` NULL '' , `` BINARY '' , `` LEFT '' , 'select ' : [ 'id ' , 'localtime ' , 'ABC ' ]","['changelog.rst', 'pgcli/packages/pgliterals/pgliterals.json', 'pgcli/pgcompleter.py', 'tests/metadata.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 771 from dbcli/koljonen/reservered_words
177,244043b49d3dc0fcada5aa7a043716de7d19f2d8,2017-08-06 20:57:50-06:00,"* Do n't include arguments in function suggestions for backslash commands ( Thanks : ` Joakim Koljonen ` _ ) cased_func_names = [ [ 'SELECT ' , 'PUBLIC ' ] + cased_funcs + cased_tbls + cased_views def test_list_functions_for_special ( completer ) : assert result == set ( arg_mode = 'signature ' if suggestion.usage == 'signature ' else 'call ' [ schema ( 'PUBLIC ' ) ] + [ function ( f ) for f in cased_func_names ] } .get ( suggestion.usage , 'call ' ) Function ( schema=None , usage='special ' ) , Function ( schema=None ) , assert suggestions == ( Function ( schema='myschema ' ) , ) arg_mode = { return ( Function ( schema=schema , usage='special ' ) , ) cased_funcs = [ result = result_set ( completer , r'\df ' ) 'signature ' : 'signature ' , 'special ' : None , [ 'SELECT ' , 'PUBLIC ' ] + cased_func_names + cased_tbls + cased_views if rel_type == Function : ) assert suggestions == ( Function ( schema='myschema ' , usage='special ' ) , ) return ( Schema ( ) , Function ( schema=None , usage='special ' ) , )","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_pgspecial.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 770 from dbcli/koljonen/no_args_when_suggesting_funcs_for_specials
178,9d59fa5a8ac85f0699daeb51f8602b7d01d31882,2017-07-29 17:31:45-07:00,"* Fix the way we get host when using DSN ( issue # 765 ) ( Thanks : ` François Pietka ` _ ) There are no bugs : ) cursor , db = dsn_parameters [ 'dbname ' ] port = dsn_parameters [ 'port ' ] host = dsn_parameters [ 'host ' ] user = dsn_parameters [ 'user ' ] dsn_parameters = conn.get_dsn_parameters ( ) db , user , host , port = self._select_one ( 'select current_database ( ) , current_user , inet_server_addr ( ) , inet_server_port ( ) ' )","['changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 766 from dbcli/fpietka/get-infos-when-dsn
179,323fda4b9cad52f5fbfe491f54fbe27b746c5b06,2017-07-27 10:09:42-07:00,"'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) : ,\s ] + ) $ ' ) , ( text == 'exit ' ) or # Exit does n't need semi-colon function_body_pattern = re.compile ( ' ( \\ $ . * ? \\ $ ) ( [ \s\S ] * ? ) \\1 ' , re.M ) text.startswith ( '\\ ' ) or # Special Command } # This matches everything except a space . ( text == `` ) # Just a plain enter without any text self.name_pattern = re.compile ( `` ^ [ _a-z ] [ _a-z0-9\ $ ] * $ '' ) } 'all_punctuations ' : re.compile ( ' ( [ ^\s ] + ) $ ' ) , ( text == 'quit ' ) or # Quit does n't need semi-colon `` `` '' # This matches everything except spaces , parens , colon , comma , and period query = `` ' 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) : ,\s ] + ) $ ' ) , or sql.strip ( ) == r'\q ' # This matches everything except spaces , parens , colon , and comma return ( 'alphanum_underscore ' : re.compile ( r ' ( \w+ ) $ ' ) , text.endswith ( r'\e ' ) or # Ended with \e which should launch the editor # This matches everything except spaces , parens , colon , and comma ( text == `` ) # Just a plain enter without any text 'all_punctuations ' : re.compile ( r ' ( [ ^\s ] + ) $ ' ) , _is_complete ( text ) or # A complete SQL command ( text == ' : q ' ) or # To all the vim fans out there or sql.strip ( ) == '\q ' ) 'alphanum_underscore ' : re.compile ( r ' ( \w+ ) $ ' ) , self.name_pattern = re.compile ( r '' ^ [ _a-z ] [ _a-z0-9\ $ ] * $ '' ) ( text == 'quit ' ) or # Quit does n't need semi-colon text.endswith ( '\e ' ) or # Ended with \e which should launch the editor . _is_complete ( text ) or # A complete SQL command ( text == 'exit ' ) or # Exit does n't need semi-colon 'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) : ,\s ] + ) $ ' ) , return ( text.startswith ( '\\ ' ) or # Special Command # This matches only alphanumerics and underscores . # This matches everything except spaces , parens , colon , comma , and period 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) : ,\s ] + ) $ ' ) , r '' '' '' ) ( text == ' : q ' ) or # To all the vim fans out there # This matches everything except a space . `` `` '' # This matches only alphanumerics and underscores . query = r '' ' r '' '' '' function_body_pattern = re.compile ( r ' ( \ $ . * ? \ $ ) ( [ \s\S ] * ? ) \1 ' , re.M )","['pgcli/main.py', 'pgcli/packages/parseutils/utils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgbuffer.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py']",Merge pull request # 764 from dbcli/fpietka/raw_strings
180,058b9947e4e587c9eb54f4797b1a1596fdb98cb6,2017-07-27 09:59:55-07:00,# editorconfig.org [ * ] charset = utf-8 [ travis.yml ] indent_size = 2 trim_trailing_whitespace = true end_of_line = lf indent_size = 4 # http : //editorconfig.org/ # download # Get your text editor plugin at : root = true insert_final_newline = true indent_style = space,['.editorconfig'],Merge pull request # 763 from dbcli/fpietka/add-editorconfig
181,1a2932ec0459325be1a531c280d3f26ec5d6cd7f,2017-07-27 12:56:57+02:00,|Build Status| |CodeCov| |PyPI| |Landscape| |Gitter| : target : https : //codecov.io/gh/dbcli/pgcli |Build Status| |CodeCov| |PyPI| |Gitter| : alt : Code Health .. |Landscape| image : : https : //landscape.io/github/dbcli/pgcli/master/landscape.svg ? style=flat : target : https : //landscape.io/github/dbcli/pgcli/master : target : https : //codecov.io/gh/dbcli/pgcli,['README.rst'],Merge pull request # 762 from dbcli/fpietka-badges
182,60f280b5ad6b2cc4c2419b2c7634d4ae253b53d6,2017-07-25 15:34:05-07:00,"password=password ) context.conf [ 'pass ' ] , context.conf [ 'dbname ' ] , os.environ [ 'PGPORT ' ] = context.conf [ 'port ' ] ' { python } -c `` { startup } '' '.format ( if 'PGHOST ' in os.environ : : param port : int context.conf [ 'port ' ] ) context.conf [ 'dbname ' ] ) cn = create_cn ( hostname , password , username , 'postgres ' , port ) 'port ' : context.config.userdata.get ( os.getenv ( 'PGPORT ' , '5432 ' ) cn = connect ( host=hostname , user=username , database=dbname , `` import coverage '' , cn = create_cn ( hostname , password , username , 'postgres ' ) `` `` '' context.conf [ 'pass ' ] , context.conf [ 'dbname ' ] , context.conf [ 'port ' ] ) cn = create_cn ( hostname , password , username , dbname , port ) cn = connect ( host=hostname , user=username , database=dbname , 'cli_command ' : context.config.userdata.get ( 'pg_cli_command ' , None ) or ' -c `` import coverage ; coverage.process_startup ( ) ; import pgcli.main ; pgcli.main.cli ( ) '' ' , 'cli_command ' : ( password=password , port=port ) context.config.userdata.get ( 'pg_cli_command ' , None ) or def create_db ( hostname='localhost ' , username=None , password=None , dbname=None , port=None ) : startup= ' ; '.join ( [ sys.executable cn = connect ( user=username , database=dbname ) if password : dbname=None ) : context.conf [ 'pass ' ] , dbname=None ) : `` import pgcli.main '' , else : def create_cn ( hostname , password , username , dbname , port ) : `` pgcli.main.cli ( ) '' ] ) ) ) , python=sys.executable , 'PGPORT ' : os.environ.get ( 'PGPORT ' , None ) , `` coverage.process_startup ( ) '' , 'pg_test_port ' , def create_db ( hostname='localhost ' , username=None , password=None , del os.environ [ 'PGHOST ' ] dbname=None , port=None ) : def create_cn ( hostname , password , username , dbname ) : context.conf [ 'pass ' ] , context.conf [ 'dbname ' ] ) ) , cn = create_cn ( hostname , password , username , dbname ) Create test database . `` `` '' Create test database .","['tests/features/db_utils.py', 'tests/features/environment.py']",Merge pull request # 761 from dbcli/j-bennet/let-behave-connect-to-docker
183,78365a362449179b2671d80ccc07fd5f6a4092f5,2017-07-24 13:51:48+02:00,: alt : Code coverage report |Build Status| |PyPI| |Gitter| |Build Status| |CodeCov| |PyPI| |Gitter| .. |CodeCov| image : : https : //codecov.io/gh/dbcli/pgcli/branch/master/graph/badge.svg : target : https : //codecov.io/gh/dbcli/pgcli,['README.rst'],Merge pull request # 757 from dbcli/bersace/codecov-badge
184,5a8e5d21b635882375c7c77a9b2c6dd682d6d00d,2017-07-20 09:48:28-07:00,"display=display or text , template = { assert result [ 0 ] == function ( 'extract_entry_symbols ( ) ' , -3 ) ) , function ( 'set_returning_func ( ) srf ' ) ] ) self.is_aggregate , self.is_window , self.is_set_returning ) ) return template.format ( self.arg_defaults [ num - num_args + num_defaults ] if has_default assert result [ 0 ] == function ( 'enter_entry ( ) ' , -2 ) 'set_returning_func ( ) ' , arg_names= ( ' x ' , ) , ( ] f3 = FunctionMetadata ( ) : function= ( obj_type == 'functions ' ) function ( elif char == ' , ' and not in_quote : [ 'integer ' , 'integer ' ] , [ 't ' , 't ' ] , 'record ' , False , False , True ) , return ' ( ) ' start_position=pos , pg_get_expr ( pg_catalog.pg_proc.proargdefaults , 0 ) '' '' '' yield current 'custom_func2 ( ) cf ' _SchemaObject = namedtuple ( 'SchemaObject ' , 'name schema meta ' ) # We keep a cache of { function_usage : { function_metadata : function_arg_list_string } } if arg_mode == 'call ' : cased_funcs = [ function ( f + ' ( ) ' ) for f in cased_funcs ] arg_name arg_default = arg_default_type_strip_regex.sub ( `` , arg_default ) table ( t ) for t in ( 'Users U ' , ' '' Users '' U ' , 'Orders O ' , ' '' select '' s ' ) arg_type=arg.datatype , len ( 'SELECT * FROM Functions WHERE function : text ' ) + 1 if prev in ( 'drop ' , 'alter ' , 'create ' , 'create or replace ' ) : return Candidate ( item , synonyms=synonyms , prio2=prio2 ) ) ) for f in self.populate_functions ( suggestion.schema , filt ) ] '_custom_fun ( ) cf ' , 'custom_fun ( ) cf ' , 'custom_func1 ( ) cf ' , return ( self.get_table_matches ( t_sug , word_before_cursor , alias ) self.call_arg_display_style = settings.get ( `` `` '' Returns a list of schemas from which to suggest objects . [ 'custom_func2 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , assert get_result ( completer , action + ' FUNCTION set_ret ' ) == [ f1 = FunctionMetadata ( self.is_window , self.is_set_returning , self.arg_defaults schema = stmt.get_identifier_schema ( ) cased_aliased_rels = [ prev = stmt.get_previous_token ( token ) .value.lower ( ) for func , metas in funcs.items ( ) ) arg_modes=None , return_type=None , is_aggregate=False , is_window=False , : param schema is the schema qualification input by the user ( if any ) matches = self.find_matches ( word_before_cursor , funcs , meta='function ' ) view ( 'functions f ' ) , schema= ( self._maybe_schema ( schema=sch , parent=schema ) ) , 'arg_types= % r , arg_modes= % r , return_type= % r , is_aggregate= % r , ' if suggestion.filter == 'for_from_clause ' : if in_quote and char == in_quote : f2 = FunctionMetadata ( function should be kept or discarded completer.extend_functions ( executor.functions ( ) ) 'signature_arg_style ' , ' { arg_name } { arg_type } ' meta=meta return Candidate ( item , synonyms=synonyms , prio2=prio2 , display=display ) self._refresh_arg_list_cache ( ) cased_aliased_rels = [ table ( t ) for t in ( 'Users U ' , ' '' Users '' U ' , 'Orders O ' , in_quote = None function ( f ) for f in ( ] + [ function ( 'set_returning_func ( x : = , y : = ) ' , display='set_returning_func ( x , y ) ' ) ] assert first.text == 'enter_entry ( _title : = , _text : = ) ' pass elif not in_quote : in_quote = char ) + ' ) ' , ) ] display=None func_name='func2 ' , alias = False self.signature_arg_style = settings.get ( FunctionMetadata ( 'schema1 ' , 'func2 ' , None , [ ] , [ ] , _SchemaObject = namedtuple ( 'SchemaObject ' , [ 'name ' , 'schema ' , 'function ' ] ) schema= ( self._maybe_schema ( schema=sch , parent=schema ) ) max_arg_len = max ( len ( a.name ) for a in args ) if multiline else 0 FunctionMetadata ( sch , * func_meta , arg_defaults=None ) display or completion return ColumnMetadata ( name , typ , [ ] , default , has_default ) is_set_returning=False , arg_defaults=None self._format_arg ( template , arg , arg_num + 1 , max_arg_len ) matches.append ( : param arg_mode determines what type of arg list to suffix for functions . funcs = [ _cand ( f , alias ) casing = ( [ 'SELECT ' , 'PUBLIC ' ] + cased_funcs + cased_tbls + cased_views funcs.extend ( predefined_funcs ) [ 'custom_func1 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , } `` `` '' Returns a list of function SchemaObjects . ] + [ view ( 'user_emails ue ' ) , view ( 'functions f ' ) ] + [ def _cand ( func , alias ) : : param filter_func is a function that accepts a FunctionMetadata `` `` '' Find all columns in a set of scoped_tables # For convenience , do n't require the ` filter ` argument in Function constructor ' % s ( schema_name= % r , func_name= % r , arg_names= % r , ' 'call_arg_display_style ' , ' { arg_name } ' 'custom_func2 ' , 'set_returning_func ' ] f1 = FunctionMetadata ( 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , } [ usage ] ] + [ function ( has_default = num + num_defaults > = num_args return matches cased_views = [ 'User_Emails ' , 'Functions ' ] arg_names= [ ' x ' , ' y ' ] , # Remove trailing : : ( schema . ) type 'set_returning_func ( x : = , y : = ) srf ' , expected_handlers = [ 'schemata ' , 'tables ' , 'views ' , return None for f in self.populate_functions ( suggestion.schema , filt ) assert first.display == 'enter_entry ( _title , _text ) ' : param usage is 'call ' , 'call_display ' or 'signature ' max_arg_len=max_arg_len , def function ( text , pos=0 , display=None ) : elif arg_mode == 'signature ' : completer.extend_functions ( executor.functions ( ) ) 'Candidate ' , [ 'completion ' , 'prio ' , 'meta ' , 'synonyms ' , 'prio2 ' ] arg_num=arg_num , @ refresher ( 'functions ' ) def _arg_list ( self , func , usage ) : return_type='integer ' `` `` '' Returns a Candidate namedtuple . [ ' b ' , ' b ' ] , `` , False , False , True ] ] , assert first.text == 'extract_entry_symbols ( ) ' 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , False , False , None : param func is a FunctionMetadata object matches.extend ( predefined_funcs ) def _refresh_arg_list_cache ( self ) : self.get_table_matches ( t_sug , word_before_cursor , alias ) `` `` '' Returns a list of function names self.arg_types , self.arg_modes , self.return_type , ( name , typ ) function ( return hash ( self._signature ( ) ) f2 = FunctionMetadata ( 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , return_type='record ' , 'functions ' : [ 'function ' ] , } , for usage in ( 'call ' , 'call_display ' , 'signature ' ) f_sug = Function ( s.schema , s.table_refs , filter='for_from_clause ' ) schema_name , func_name , arg_names , arg_types , arg_modes , return_type , cased_funcs = [ 'Custom_Fun ' , '_custom_fun ' , 'Custom_Func1 ' , self.get_function_matches ( f_sug , word_before_cursor , alias ) `` `` '' Find all columns in a set of scoped_tables . Function = namedtuple ( 'Function ' , [ 'schema ' , 'table_refs ' , 'filter ' ] ) filt = lambda f : not f.is_aggregate and not f.is_window func_name='func1 ' , priority=priority return self.arg_modes and any ( arg_mode == ' v ' for arg_mode in self.arg_modes ) f3 = FunctionMetadata ( 's ' , ' g ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , display_meta=display_meta , ) % ( self.__class__.__name__ , ) + self._signature ( ) FunctionMetadata ( 'public ' , 'func3 ' , [ ' x ' , ' y ' ] , def __init__ ( for arg_num , arg in enumerate ( args ) FunctionMetadata ( 'public ' , 'func1 ' , None , [ ] , [ ] , # E.g . 'DROP FUNCTION < funcname > ' , 'ALTER TABLE < tablname > ' escape ( x [ 0 ] ) + ' ( ' + ' , '.join ( for x in self.metadata.get ( 'functions ' , { } ) .get ( parent , [ ] ) ] 'user_emails ' : [ 'id ' , 'email ' ] } , arg_default_type_strip_regex = re.compile ( r ' : : [ \w\ . ] + ( \ [ \ ] ) ? $ ' ) def __init__ ( self , schema_name , func_name , arg_names , arg_types , completion , prio , meta , synonyms or [ completion ] , prio2 , return tuple ( ) self.arg_modes , self.return_type , self.is_aggregate , item , display_meta , prio , prio2 , display = cand , meta , 0 , 0 , cand elif usage == 'call ' and len ( args ) < 2 : display_suffix = self._arg_list_cache [ 'call_display ' ] [ tbl.meta ] priority=priority ) ) first = result [ 0 ] assert first.start_position == -2 table ( t ) for t in ( 'users u ' , ' '' Users '' U ' , 'orders o ' , ' '' select '' s ' ) self.call_arg_style = settings.get ( `` `` '' Returns a list of schemas from which to suggest objects ' '' select '' s ' ) ] + [ view ( 'User_Emails UE ' ) ] + [ function ( f ) for f in ( 'types ' , 'databases ' , 'casing ' ] func_name='func4 ' , ) if mode in ( ' i ' , ' b ' , ' v ' ) # IN , INOUT , VARIADIC '_custom_fun ( ) cf ' , 'Custom_Fun ( ) CF ' , 'Custom_Func1 ( ) CF ' , 'custom_func2 ( ) cf ' # End quote if arg.has_default : def SchemaObject ( name , schema=None , function=False ) : item = maybe_schema + cased_tbl + maybe_parens + maybe_alias self.arg_names , self.arg_types , self.arg_modes , display = self.case ( display ) maybe_parens = ' ( ) ' if tbl.function else `` display=display funcs = set ( def parse_defaults ( defaults_string ) : display_suffix = self._arg_list_cache [ 'signature ' ] [ tbl.meta ] except ValueError : Match ( return ' ( ' + ' , '.join ( '\n ' + a for a in args if a ) + '\n ) ' [ 'custom_func2 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , def refresh_functions ( completer , executor ) : if not template : return hash ( ( self.schema_name , self.func_name , self.arg_names , if not suggestion.schema and not suggestion.usage : # Just to make sure that this does n't crash self.schema_name , self.func_name , self.arg_names , self.arg_types , args = ( text=item , view ( 'Functions F ' ) , arg_name=self.case ( arg.name ) , ] return [ ] matches.append ( Match ( multiline = usage == 'call ' and len ( args ) > self.call_arg_oneliner_max if not defaults_string : 'custom_func2 ( ) cf ' , 'set_returning_func ( ) srf ' ) ] # is_aggregate , is_window , is_set_returning self.call_arg_oneliner_max = settings.get ( 'call_arg_oneliner_max ' , 2 ) func_name , schema_name='public ' , arg_names=None , arg_types=None , pg_get_expr ( proargdefaults , 0 ) AS arg_defaults # E.g . 'ALTER TABLE < tablname > ' schema_name='public ' , def test_drop_alter_function ( completer , action ) : and returns a boolean indicating whether that function should be cased_views = [ 'User_Emails ' ] pos , # Begin quote `` `` '' Returns a list of SchemaObjects representing tables or views . % ( self.__class__.__name__ , self.schema_name , self.func_name , # Skip space after comma separating default expressions return cased_funcs = [ assert first.start_position == -3 if multiline : def get_previous_token ( self , token ) : FunctionMetadata ( sch , * func_meta ) ) : schema_name='schema1 ' , current += char display='set_returning_func ( x , y ) srf ' 'integer ' , False , False , True ) , def Candidate ( completion , prio=None , meta=None , synonyms=None , prio2=None ) : ] current = `` self.get_function_matches ( f_sug , word_before_cursor , alias ) ) for sch , funcs in self.dbmetadata [ 'functions ' ] .items ( ) self.arg_defaults = tuple ( parse_defaults ( arg_defaults ) ) elif token_v in ( 'table ' , 'view ' , 'function ' ) : `` `` '' Returns a list of SchemaObjects representing tables , views , funcs num_args = len ( args ) completion=Completion ( item , -text_len , return_type='integer ' , def args ( self ) : try : assert first.display == 'extract_entry_symbols ( _entryid ) ' function_meta_data ( # This is used when suggesting functions , to avoid the latency that would result return ( Function ( schema=schema , usage='signature ' ) , ) meta : self._arg_list ( meta , usage ) funcs = set ( funcs ) # stmt.get_previous_token will fail for e.g . ` SELECT 1 FROM functions WHERE function : ` # Note : tbl is a SchemaObject item = maybe_schema + cased_tbl + suffix + maybe_alias UNION -- Parameter names if current == `` and char == ' ' : return self.parsed.token_prev ( self.parsed.token_index ( token ) ) [ 1 ] 'signature ' : self.signature_arg_style return _Candidate ( item , prio , display_meta , synonyms , prio2 , display = cand * Include arguments in function suggestions ( Thanks : ` Joakim Koljonen ` _ ) p.proretset is_set_returning 'set_returning_func ( x : = , y : = ) srf ' , p.proretset is_set_returning , FROM pg_proc 'call ' : self.call_arg_style , kept or discarded SELECT unnest ( proargnames ) display_suffix = `` 'is_window= % r , is_set_returning= % r ) ' ) funcs = self.find_matches ( word_before_cursor , funcs , meta='function ' ) for name , typ , mode in zip ( self.arg_names , self.arg_types , modes ) def _make_cand ( self , tbl , do_alias , suggestion , arg_mode=None ) : args = [ ' '' select '' s ' ) ] + [ view ( 'user_emails ue ' ) ] + [ function ( f ) for f in ( ] ) [ 'custom_func1 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , 'arg_types= % r , arg_modes= % r , return_type= % r , is_aggregate= % r , ' else None else : 'types ' , 'databases ' , 'casing ' , 'functions ' ] ) , NULL AS arg_defaults return_type , is_aggregate , is_window , is_set_returning , arg_defaults return _SchemaObject ( name , schema , function ) cased_users_col_names + cased_users2_col_names len ( 'SELECT * FROM Functions WHERE function : ' ) , [ ' o ' , ' o ' ] , `` , False , False , True ] ] , 'set_returning_func ( x : = , y : = ) ' , current = `` function ( 'set_returning_func ( x integer , y integer ) ' , -len ( 'set_ret ' ) ) func_name='func3 ' , def SchemaObject ( name , schema=None , meta=None ) : 'call_arg_style ' , ' { arg_name : < { max_arg_len } } : = { arg_default } ' def _make_cand ( self , tbl , do_alias , suggestion ) : item , prio , display_meta , synonyms , prio2 = cand fs = self.populate_schema_objects ( suggestion.schema , 'functions ' ) ) num_defaults = len ( self.arg_defaults ) 'is_window= % r , is_set_returning= % r , arg_defaults= % r ) ' arg_modes= [ 't ' , 't ' ] , arg_mode = 'signature ' if suggestion.usage == 'signature ' else 'call ' def filt ( f ) : return True return _SchemaObject ( name , schema , meta ) self.is_set_returning ) ) completion , prio=None , meta=None , synonyms=None , prio2=None , aliased_rels = [ 'integer ' , False , False , False ) , text , for char in defaults_string : def _format_arg ( self , template , arg , arg_num , max_arg_len ) : usage : { # For convenience , do n't require the ` usage ` argument in Function constructor start_position=-text_len , in_quote = None display_meta='function ' aliased_rels = [ table ( t ) for t in ( 'users u ' , ' '' Users '' U ' , 'orders o ' , completion=Completion ( return ( ( ' % s ( schema_name= % r , func_name= % r , arg_names= % r , ' Possible values : call , signature continue namedtuple and returns a boolean indicating whether that [ 'custom_fun ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , yield current if char == ' '' ' or char == '\ '' : self.return_type , self.is_aggregate , self.is_window , cased_users_col_names + cased_users2_col_names ) [ '_custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False ] , `` `` '' Returns a an arg list string , e.g . ` ( _foo : =23 ) ` for a func . } f_sug = Function ( s.schema , s.table_refs , usage='from ' ) def has_variadic ( self ) : elif token_v in ( 'table ' , 'view ' ) : function ( escape ( x [ 0 ] + ' ( ) ' ) , pos ) casing = ( `` `` '' Returns a list of input-parameter ColumnMetadata namedtuples . '' '' '' arg_name + ' : = ' function=True '_custom_fun ( ) cf ' , 'Custom_Fun ( ) CF ' , 'Custom_Func1 ( ) CF ' , def filt ( f ) : return not f.is_aggregate and not f.is_window return _Candidate ( completion , prio , meta , synonyms or [ completion ] , prio2 ) def test_function_column_name ( completer ) : schema is the schema qualification input by the user ( if any ) default = ( arg_default = `` 'functions ' , def Candidate ( return [ arg ( name , typ , num ) for num , ( name , typ ) in enumerate ( args ) ] '_custom_fun ( ) cf ' , 'custom_fun ( ) cf ' , 'custom_func1 ( ) cf ' , # if we 'd recalculate the arg lists each time we suggest functions ( in large DBs ) is_set_returning=True ] ) arg_types= [ 'integer ' , 'integer ' ] , def function_meta_data ( arg_default=arg_default 'Custom_Fun ' , '_custom_fun ' , 'Custom_Func1 ' , 'custom_func2 ' , 'set_returning_func ' display='set_returning_func ( x , y ) srf ' [ 'SELECT ' , 'PUBLIC ' ] + cased_funcs + cased_tbls + cased_views Function = namedtuple ( 'Function ' , [ 'schema ' , 'table_refs ' , 'usage ' ] ) 'user_emails ' : [ 'id ' , 'email ' ] , [ '_custom_fun ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , : param tbl is a SchemaObject item , display_meta , prio , prio2 = cand , meta , 0 , 0 `` `` '' Yields default values for a function , given the string provided by is_aggregate , is_window , is_set_returning , arg_defaults assert [ ] == get_result ( ] + [ view ( 'User_Emails UE ' ) , view ( 'Functions F ' ) ] + [ for meta in metas self._make_cand ( f , alias , suggestion , arg_mode ) for x in self.metadata.get ( 'functions ' , { } ) .get ( parent , [ ] ) elif token_v == 'function ' : return Completion ( # End of expression display_meta=display_meta ) , False , False ) elif usage == 'call ' and func.has_variadic ( ) : ) + ' ) ' completer , 'SELECT * FROM Functions WHERE function : text ' [ : l ] args = func.args ( ) function = partial ( completion , 'function ' ) if arg_mode in ( ' b ' , ' i ' ) if suggestion.usage == 'from ' : # with fields schema_name , func_name , arg_list , result , function ( f ) for f in ( 'Custom_Fun ( ) ' , '_custom_fun ( ) ' , 'Custom_Func1 ( ) ' , 'custom_func2 ( ) ' ) self._arg_list_cache = { def _signature ( self ) : for ( arg_name , arg_mode ) in zip ( x [ 1 ] , x [ 3 ] ) return self._make_cand ( func , alias , suggestion ) suffix = self._arg_list_cache [ arg_mode ] [ tbl.meta ] if arg_mode else `` def arg ( name , typ , num ) : # Used to strip trailing ' : :some_type ' from default-value expressions if not self.arg_names : arg_modes , return_type , is_aggregate , is_window , is_set_returning ) : 'Candidate ' , 'completion prio meta synonyms prio2 display ' arg_default = 'NULL ' if arg.default is None else arg.default self , schema_name , func_name , arg_names , arg_types , arg_modes , return ' ( ' + ' , '.join ( a for a in args if a ) + ' ) ' display = maybe_schema + cased_tbl + display_suffix + maybe_alias ) modes = self.arg_modes or [ ' i ' ] * len ( self.arg_names ) def refresh_functions ( completer , executor ) : funcs = [ _cand ( f , alias=False ) for f in fs ] FunctionMetadata ( 'public ' , 'func4 ' , ( ' x ' , ) , ( 'integer ' , ) , [ ] , return ( arg_types= ( 'integer ' , ) , filter_func is a function that accepts a FunctionMetadata namedtuple expected_handlers = [ 'schemata ' , 'tables ' , 'views ' , 'functions ' , return FunctionMetadata ( for l in range ( return funcs if not suggestion.schema and not suggestion.filter : 's ' , ' g ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , False , False , None 'call_display ' : self.call_arg_display_style , [ 'custom_fun ' , [ ] , [ ] , [ ] , `` , False , False , False ] , `` `` ''","['changelog.rst', 'pgcli/completion_refresher.py', 'pgcli/packages/parseutils/meta.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/metadata.py', 'tests/parseutils/test_function_metadata.py', 'tests/test_completion_refresher.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 677 from dbcli/koljonen/suggest_functions_with_args
185,a255c1bde0b01da1510d2f3e65bd400f56bd0c6b,2017-07-20 09:47:14-05:00,The easiest way to install pgcli is using Homebrew . Please be aware that this will install postgres if you do n't have it installed . $ brew tap-pin dbcli/tap The easiest way to install pgcli is using Homebrew . $ brew install pgcli # Only on macOS $ brew tap dbcli/tap & & brew tap-pin dbcli/tap & & brew install pgcli # Only on macOS,['README.rst'],Merge pull request # 755 from dbcli/j-bennet/brew-docs-update
186,64f1a6d317d0ecaa620ebb586fc9a62fa2a4f318,2017-07-16 17:48:34-07:00,"auto_suggest=AutoSuggestFromHistory ( ) , Features : TBD * Add fish-style auto-suggestion from history . ( Thanks : ` Amjith Ramanujam ` _ ) Bug Fixes : from prompt_toolkit.auto_suggest import AutoSuggestFromHistory There are no bugs : ) enable_auto_suggest_bindings=True ,","['changelog.rst', 'pgcli/key_bindings.py', 'pgcli/main.py']",Merge pull request # 750 from dbcli/feature/auto-suggest
187,007f75ef5e006d0b887a0c7b1f536b7852e92783,2017-07-15 20:08:03-07:00,TBD ===== 1.7.0,['changelog.rst'],Merge pull request # 747 from dbcli/j-bennet/pre-release-1.7.0
188,74699ac803fa993aa1470bda9fc95a24dea18b30,2017-07-14 22:27:54-07:00,"cur.execute ( self.full_databases_query ) * Command line option to list databases ( issue # 206 ) ( Thanks : ` François Pietka ` _ ) pg_catalog.array_to_string ( d.datacl , E'\n ' ) AS `` Access privileges '' _logger.debug ( 'Databases Query . sql : % r ' , with self.conn.cursor ( ) as cur : missingval= ' < null > ' less_chatty , prompt ) : formatted = format_output ( title , cur , headers , status , settings ) settings = OutputSettings ( single_connection , dbname , username , version , pgclirc , dsn , row_limit , ORDER BY 1 '' ' if list_databases : FROM pg_catalog.pg_database d d.datctype as `` Ctype '' , d.datcollate as `` Collate '' , return cur.fetchall ( ) , headers , cur.statusmessage cur , headers , status = pgcli.pgexecute.full_databases ( ) sys.exit ( 0 ) table_format='ascii ' , ) click.echo_via_pager ( '\n'.join ( formatted ) ) self.full_databases_query ) SELECT d.datname as `` Name '' , pg_catalog.pg_get_userbyid ( d.datdba ) as `` Owner '' , full_databases_query = `` ' pg_catalog.pg_encoding_to_char ( d.encoding ) as `` Encoding '' , 'available databases , then exit . ' ) def full_databases ( self ) : headers = [ x [ 0 ] for x in cur.description ] single_connection , dbname , username , version , pgclirc , dsn , row_limit , less_chatty , prompt , list_databases ) : title = 'List of databases '","['changelog.rst', 'pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 746 from fpietka/list-databases
189,fd5e0302438ed28d6b676261a4158debfd44058d,2017-07-09 14:28:53-07:00,"1 , name , datatype , foreignkeys=None , default=None , has_default=False [ 'name ' , 'datatype ' , 'foreignkeys ' , 'default ' , 'has_default ' ] `` `` '' extend metadata for tables or views column = ColumnMetadata ( name=colname , datatype=datatype , * Skip serial columns when expanding * for ` INSERT INTO foo ( * ` ( Thanks : ` Joakim Koljonen ` _ ) . return self.find_matches ( word_before_cursor , flat_cols ( ) , column = ColumnMetadata ( has_default=has_default , [ 'table_refs ' , 'require_last_table ' , 'local_tables ' , 'qualifiable ' , 'context ' ] ] NULL AS default def ColumnMetadata ( def filter ( col ) : expected = [ wildcard_expansion ( 'ordered_date , status ' ) ] Column.__new__.__defaults__ = ( None , None , tuple ( ) , False ) if suggestion.context == 'insert ' : ( 'schema1 ' , ' c ' , ' w ' , 'text ' , True , `` 'meow ' : :text '' ) , default=default ) : if not col.has_default : collist = sep.join ( self.case ( c.completion ) c.name for t , cs in scoped_cols.items ( ) if t.ref ! = ltbl for c in cs ) self.insert_col_skip_patterns = [ [ r'^now\ ( \ ) $ ' , r'^nextval\ ( ' ] Column ( table_refs=stmt.get_tables ( 'insert ' ) , context='insert ' ) , ( 'public ' , ' a ' , ' x ' , 'text ' ) , ( 'public ' , ' a ' , ' y ' , 'text ' ) , tbl_cols.extend ( [ self._make_col ( sch , tbl , col ) display_meta='columns ' , display= ' * ' `` `` '' extend column metadata . } , t : [ col for col in cols if col.name in other_tbl_cols ] return [ Match ( completion=Completion ( collist , -1 , } for c in cols : 'ColumnMetadata ' , p.match ( col.default ) ) ) 'INSERT INTO orders ( ' , 'INSERT INTO public.orders ( ' , ( 'public ' , ' a ' , ' x ' , 'text ' , False , None ) , scoped_cols = { Column.__new__.__defaults__ = ( None , None , tuple ( ) , False , None ) re.compile ( pattern ) for pattern in settings.get ( ColumnMetadata = namedtuple ( 'ColumnMetadata ' , [ 'name ' , 'datatype ' , 'foreignkeys ' ] ) view_cols.extend ( [ ( sch , tbl , col , 'text ' ) for col in cols ] ) ( 'public ' , 'd ' , ' e ' , 'integer ' ) ] ) } 'insert_col_skip_patterns ' , for schema , relname , colname , datatype , has_default , default in column_data : tbl_cols.extend ( [ ( sch , tbl , col , 'text ' ) for col in cols ] ) column_type , has_default , default ) tuples foreignkeys= [ ] ) name , datatype , foreignkeys or [ ] , default , has_default def flat_cols ( ) : Column ( assert suggestions == ( Column ( table_refs= ( ( None , 'abc ' , None , False ) , ) ) , ) ( 'public ' , ' b ' , ' z ' , 'text ' ) , ( 'schema1 ' , ' c ' , ' w ' , 'text ' ) ] ) : param column_data : list of ( schema_name , rel_name , column_name , column_type ) tuples 'defaults ' : { return _ColumnMetadata ( for col in cols ] ) return [ Match ( for t , cs in colit ( ) for c in cs ) expected = [ wildcard_expansion ( 'id , ordered_date , status ' ) ] def.adsrc as default def test_suggested_columns_with_insert ( completer , text ) : for t , cs in scoped_cols.items ( ) for c in cs ) typ.typname type_name ON def.adrelid = att.attrelid ] ) ) , priority= ( 1 , 1 , 1 ) if t.ref == ltbl 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , run ( executor , `` create table schema1.c ( w text ) '' ) set ( c.name for t , cs in colit ( ) if t.ref == ltbl for c in cs ) & 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' , 'datestamp ' ] , name=colname , for col in cols ] ) return self.find_matches ( word_before_cursor , flat_cols , ( 'orders ' , 'status ' ) : `` 'PENDING ' : :text '' , context='insert ' LEFT OUTER JOIN pg_attrdef def view_cols.extend ( [ self._make_col ( sch , tbl , col ) for p in self.insert_col_skip_patterns ] ) for t , cols in colit ( ) : [ 'table_refs ' , 'require_last_table ' , 'local_tables ' , 'qualifiable ' ] scoped_cols = { set ( c.name for t , cs in colit ( ) if t.ref ! = ltbl for c in cs ) ) def _make_col ( self , sch , tbl , col ) : return [ make_cand ( c.name , t.ref ) for t , cols in scoped_cols.items ( ) for c in cols ] ( 'orders ' , 'datestamp ' ) : `` now ( ) '' , t : [ col for col in cols if filter ( col ) ] for t , cols in scoped_cols.items ( ) datatype=datatype , ) `` `` '' extend column metadata for c in flat_cols ( ) ) ) , for schema , relname , colname , datatype in column_data : return ( sch , tbl , col , 'text ' , ( tbl , col ) in defaults , defaults.get ( ( tbl , col ) ) ) colit = scoped_cols.items run ( executor , `` create table schema1.c ( w text DEFAULT 'meow ' ) '' ) `` `` '' extend metadata for tables or views . NULL AS has_default , ( 'public ' , ' a ' , ' y ' , 'text ' , False , None ) , return ( Column ( table_refs=stmt.get_tables ( 'insert ' ) ) , ) : param column_data : list of ( schema_name , rel_name , column_name , att.atthasdef AS has_default , flat_cols = [ ] return not any ( display_meta='columns ' , display= ' * ' ) , priority= ( 1,1,1 ) ) ] AND def.adnum = att.attnum att.atttypid : :regtype : :text type_name , ) ] typ.typname type_name , } return ( completion=Completion ( ( 'public ' , 'd ' , ' e ' , 'integer ' , False , None ) ] ) att.atttypid : :regtype : :text type_name assert suggestions == ( 'INSERT INTO public.orders ( ' other_tbl_cols = set ( assert result_set ( completer , text ) == set ( testdata.columns ( 'orders ' ) ) ( 'orders ' , 'id ' ) : `` nextval ( 'orders_id_seq ' : :regclass ) '' , ( 'public ' , ' b ' , ' z ' , 'text ' , False , None ) , for t , cols in scoped_cols.items ( ) flat_cols.sort ( ) flat_cols.append ( make_cand ( c.name , t.ref ) ) 'INSERT INTO orders ( ' , collist = sep.join ( self.case ( c.completion ) for c in flat_cols ) table_refs= ( ( None , 'abc ' , None , False ) , ) , collist , return True ) _ColumnMetadata = namedtuple ( flat_cols = list ( defaults = self.metadata.get ( 'defaults ' , { } ) .get ( sch , { } ) 'public ' : {","['changelog.rst', 'pgcli/packages/parseutils/meta.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/metadata.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_sqlcompletion.py']",Merge pull request # 744 from dbcli/koljonen/better_insert_star_completion
190,3e0ffaa34e78e2d13942d5a0b1dcf4dc10eb48ab,2017-07-09 13:49:05-07:00,"Binary files a/.DS_Store and /dev/null differ except ( OperationalError , InterfaceError ) as e : * Donnell Muse except OperationalError as e :","['.DS_Store', 'AUTHORS', 'pgcli/main.py']",Merge pull request # 743 from donnell794/master
191,3081caa1aafde076a8472d62091d131dd8ee72c8,2017-07-01 14:48:37-07:00,".. _this issue : https : //github.com/dbcli/pgcli/issues/617 Note : ` pgcli ` uses the ` tabulate ` _ package to pretty-print tables . This library does smart formatting [ this issue ] ( https : //github.com/dbcli/pgcli/issues/617 ) for more details . package to pretty-print tables . This library does smart formatting of numbers , of numbers , which can sometimes lead to unexpected output . See ` this issue ` _ for more details . which can sometimes lead to unexpected output . See Note : ` pgcli ` uses [ tabulate ] ( https : //github.com/dbcli/pgcli/blob/master/pgcli/packages/tabulate.py ) .. _tabulate : https : //github.com/dbcli/pgcli/blob/master/pgcli/packages/tabulate.py",['README.rst'],Merge pull request # 741 from lwm/patch-3
192,0ea4c177c559ab467848af2af398bd66d46dfe95,2017-06-26 15:18:45-05:00,"`` `` '' Create table , insert a record . '' '' '' `` `` '' Set expanded to mode . '' '' '' def step_see_data ( context , which ) : | -- -- -+ -- -- -+ -- -- -- -- |\r then we see auto data selected \r timeout=1 ) from behave import when , then and we set expanded auto \r wrappers.expect_pager ( context , 'CREATE TABLE\r\n ' , timeout=2 ) dedent ( `` '\ `` `` '' Steps for behavioral style tests are defined in this module . to call the step in `` * .feature '' file . # - * - coding : utf-8 Scenario : expanded auto Feature : expanded mode : SELECT 1\r when we drop table Scenario : expanded off wrappers.expect_pager ( context , 'INSERT 0 1\r\n ' , timeout=2 ) context.cli.sendline ( y | 1.0\r on , off , auto def step_prepare_data ( context ) : then we see expanded data selected then we see table dropped def step_set_expanded ( context , mode ) : [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- -\r if which == 'expanded ' : `` `` '' Select data from expanded test table . '' '' '' and we select from table z | 1.0000\r from textwrap import dedent | 1 | 1.0 | 1.0000 |\r context.cli.sendline ( '\\ ' + ' x { } '.format ( mode ) ) | x | y | z |\r then we see nonexpanded data selected Each step is defined by the string decorating it . This string is used and we set expanded off 'create table a ( x integer , y real , z numeric ( 10 , 4 ) ) ; ' ) else : wrappers.expect_exact ( context , 'Expanded display is ' , timeout=2 ) Scenario : expanded on x | 1\r context.cli.sendline ( 'drop table if exists a ; ' ) wrappers.expect_pager ( context , import wrappers `` `` '' When we prepare the test data context.cli.sendline ( `` 'insert into a ( x , y , z ) values ( 1 , 1.0 , 1.0 ) ; ' '' ) from __future__ import unicode_literals ' '' ) , wrappers.wait_prompt ( context ) and we set expanded on","['tests/features/expanded.feature', 'tests/features/steps/expanded.py']",Merge pull request # 740 from dbcli/j-bennet/behave-tests-expanded
193,018f495f10c1e07191819a2cf11232a9b3f61327,2017-06-26 10:37:25-07:00,"headers ) : if fmt.linebelow and `` linebelow '' not in hidden : > > > _afterpoint ( `` 123e45 '' ) [ '123.4 ' , '56.7890 ' ] or > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , 'sep_character ' : '- ' , # align columns # initial rows with a line below # -- - linebelowheader > > > _isint ( `` 123 '' ) are slightly different from `` pipe '' format by not using colons to rows = list ( tabular_data ) pad = fmt.padding output.append ( title ) ( default : simple ) sex age headerrow=DataRow ( `` '' , `` `` , `` '' ) , \\begin { tabular } { lr } elif alignment == `` decimal '' : `` `` , `` '' , `` \n|+ < ! -- caption -- > \n|- '' ) , expanded = ( settings.expanded or settings.table_format == 'vertical ' ) # A table structure is suppposed to be : If you do n't know how to install python packages , please check the > > > print ( tabulate ( [ [ `` spam '' , 1 , None ] , headers = [ 'xyz ' ] # coding=UTF-8 return _text_type t_cols = cols or [ [ `` ] ] * len ( headers ) keys = [ ] # storage for set for row in padded_rows [ : -1 ] : headerrow=DataRow ( `` | '' , `` | '' , `` | '' ) , if align in [ `` right '' , `` decimal '' ] : if hasattr ( tabular_data.values , `` __call__ '' ) : 'sep_length ' : ( 1 , 25 ) , tabulate_formats = list ( sorted ( _table_formats.keys ( ) ) ) from pgspecial.main import ( PGSpecial , NO_QUERY , content_exceeds_width ) def _column_type ( strings , has_invisible=True ) : rows = list ( map ( list , rows ) ) elif alignment == `` center '' : return isinstance ( f , io.IOBase ) if not linefmt : lines.append ( _build_row ( row , padded_widths , colaligns , fmt.datarow ) ) `` headerrow '' , `` datarow '' , > > > _isint ( `` 123.45 '' ) LATEX_ESCAPE_RULES = { r '' & '' : r '' \ & '' , r '' % '' : r '' \ % '' , r '' $ '' : r '' \ $ '' , r '' # '' : r '' \ # '' , return format ( int ( val ) , dcmlfmt ) note that reStructuredText accepts also `` grid '' tables : │ eggs │ 451 │ def _isint ( string ) : values_with_attrs = [ `` < { 0 } { 1 } > { 2 } < / { 0 } > '' .format ( celltag , alignment.get ( a , `` ) , c ) output = [ ] # - or a function : [ cell_values ] , [ col_widths ] , [ col_alignments ] - > string . | strings | numbers | elif _isint ( string ) : uniq_keys.update ( keys ) Usage : tabulate [ options ] [ FILE ... ] headers = [ headers.get ( k , k ) for k in keys ] `` right '' : ' style= '' text-align : right ; '' ' , assert tbl == dedent ( `` ' padding=0 , with_header_hide=None ) , if ( not expanded and max_width and len ( first_line ) > max_width and headers ) : 'preprocessors ' : ( format_numbers , ) , return -1 # no point linebelow=None , row_result.append ( ( u '' % s '' % header ) + `` `` + ( u '' % s '' % utf8tounicode ( value ) ) .strip ( ) ) This program also bundles with it python-tabulate | spam | 41.9999 | if isinstance ( string , bool ) : return cells rst , mediawiki , html , latex , latex_booktabs , tsv headers = [ _align_header ( h , a , minw ) if opt in [ `` -1 '' , `` -- header '' ] : elif ( headers == `` keys '' `` Format row according to DataRow format without padding . '' else : # a bytestring linebelowheader=None , if _isint ( string ) : values_with_attrs = [ ' ' + alignment.get ( a , `` ) + c + ' ' import textwrap from pgspecial.main import ( PGSpecial , NO_QUERY ) def _pipe_segment_with_colons ( align , colwidth ) : tablefmt = value `` `` '' Flush right . | eggs || align= '' right '' | 451 output.append ( expanded_table ( rows , headers , missingval ) ) `` html '' produces HTML markup : # - or a list of elements not to be displayed if the table has column headers . # pad with empty headers for initial columns if necessary spam 41.9999 if python_version_tuple ( ) [ 0 ] < `` 3 '' : files = [ sys.stdin ] if not args else args if val is None : def _isnumber ( string ) : _invisible_codes = re.compile ( r '' \x1b\ [ \d * m|\x1b\ [ \d * \ ; \d * \ ; \d * m '' ) # ANSI color codes tablefmt = _table_formats.get ( tablefmt , _table_formats [ `` simple '' ] ) opts , args = getopt.getopt ( sys.argv [ 1 : ] , linebelowheader=Line ( `` ╞ '' , `` ═ '' , `` ╪ '' , `` ╡ '' ) , if _is_file ( f ) : > > > _visible_width ( '\x1b [ 31mhello\x1b [ 0m ' ) , _visible_width ( `` world '' ) ╒═══════════╤═══════════╕ _text_type_encode = lambda x : _text_type ( utf8tounicode ( x ) ) `` `` '' Return a horizontal line with optional colons to indicate column 's linebelow=Line ( `` \\hline\n\\end { tabular } '' , `` '' , `` '' , `` '' ) , True the values properly . By default it aligns decimal points of the firstdict = rows [ 0 ] if len ( rows ) > 0 else { } _long_type = long `` simple '' format is like Pandoc simple_tables : linebelowheader=Line ( `` |- '' , `` '' , `` '' , `` '' ) , _invisible_codes_bytes = re.compile ( b '' \x1b\ [ \d * m|\x1b\ [ \d * \ ; \d * \ ; \d * m '' ) # ANSI color codes [ RECORD 1 ] def escape_char ( c ) : 'integer_format ' : settings.dcmlfmt , output_kwargs [ 'preprocessors ' ] = ( align_decimals , ) # ascii , double , github , orgtbl , rst , mediawiki , html , latex , latex_booktabs , formatter = TabularOutputFormatter ( format_name=table_format ) if `` - '' or missing , read data from stdin . # dict-like and pandas.DataFrame ? def _more_generic ( type1 , type2 ) : def _build_line ( colwidths , colaligns , linefmt ) : `` latex_booktabs '' produces a tabular environment of LaTeX document markup def _pipe_line_with_colons ( colwidths , colaligns ) : _pprint_file ( f , headers=headers , tablefmt=tablefmt , sep=sep ) with the plain-text format of R and Pandas ' dataframes . pos = string.lower ( ) .rfind ( `` e '' ) if pos < 0 else pos return _build_simple_row ( padded_cells , rowfmt ) for c , a , minw in zip ( cols , aligns , minwidths ) ] from .tabulate import _text_type return _padright ( width , header ) TableFormat ( lineabove=Line ( `` { | class=\ '' wikitable\ '' style=\ '' text-align : left ; \ '' '' , ==== ======== 1 if value not in tabulate_formats : for k in row.keys ( ) : width_fn = _visible_width import re if hasattr ( rowfmt , `` __call__ '' ) : coltypes = list ( map ( _column_type , cols ) ) else : and isinstance ( rows [ 0 ] , dict ) ) : # 1 , -- header use the first row of data as a table header # TableFormat 's line * elements can be headers = [ firstdict.get ( k , k ) for k in keys ] `` latex_booktabs '' : datarow=DataRow ( `` | '' , `` | '' , `` | '' ) , alignment ( as in ` pipe ` output format ) . '' '' '' `` orgtbl '' : column indices can be used as headers if headers= '' keys '' . # -- - lineabove # -- - linebelow headerrow=_latex_row , from decimal import Decimal return ( '- ' * ( w - 1 ) ) + `` : '' if not settings.floatfmt : False linebelowheader=Line ( `` \\hline '' , `` '' , `` '' , `` '' ) , # ... ( more datarows ) ... age | 456 first_line = formatted [ : formatted.find ( '\n ' ) ] headerrow=DataRow ( `` , separator , `` ) , if padded_headers : [ '\t'.join ( map ( _text_type_encode , row ) ) for row in list_of_lists ] ) `` SELECT * FROM < tab > `` will only show table names . rows = list ( cur ) TableFormat ( lineabove=partial ( _latex_line_begin_tabular , booktabs=True ) , ... headers= '' firstrow '' , tablefmt= '' mediawiki '' ) ) __ https : //github.com/dbcli/pgcli # detailed-installation-instructions return rows , headers padded_headers = [ pad ( x , header_len ) + u '' | '' for x in headers ] # - or a Line tuple , * list of named tuples ( usually used with headers= '' keys '' ) TableFormat = namedtuple ( `` TableFormat '' , [ `` lineabove '' , `` linebelowheader '' , { | class= '' wikitable '' style= '' text-align : left ; '' if headers and len ( rows ) > 0 : Examples : TableFormat ( lineabove=_latex_line_begin_tabular , for row in padded_rows : headerrow=partial ( _html_row_with_attrs , `` th '' ) , headerrow = fmt.headerrow missingval= '' '' ) : > > > _padright ( 6 , '\u044f\u0439\u0446\u0430 ' ) == '\u044f\u0439\u0446\u0430 ' if status : # Only print the status if it 's not None . return '- ' * w headers = [ ] strings = [ s + ( maxdecimals - decs ) * `` `` ` headers ` can be an explicit list of column headers eggs & 451 \\\\ return field + ( char * ( total - len ( field ) ) ) minwidths = [ width_fn ( h ) + MIN_PADDING for h in headers ] if headers else [ 0 ] * len ( cols ) `` `` '' Format a fixed width table for pretty printing . ... [ `` strings '' , `` numbers '' ] , `` rst '' ) ) MIT License . _none_type = type ( None ) missingval=missingval , dcmlfmt=dcmlfmt , floatfmt=floatfmt ) case_function = settings.case_function print ( usage ) if pos > = 0 : expanded = [ 'Title ' , u'- [ RECORD 0 ] -- -- -- -- -- -- -- -- -- -- -- -- -\nhead1 | abc\nhead2 | def\n ' , 'test status ' ] if isinstance ( s , _text_type ) or isinstance ( s , _binary_type ) : > > > _isnumber ( `` 123.45 '' ) if headers == 'keys ' : plain_text = '\n'.join ( [ '\t'.join ( map ( _text_type_encode , headers ) ) ] + \ t_aligns = aligns or [ stralign ] * len ( headers ) format_numbers ) with_header_hide= [ `` lineabove '' ] ) , > > > _isint ( 123 ) linebelow=Line ( `` | } '' , `` '' , `` '' , `` '' ) , plain , simple , grid , fancy_grid , pipe , orgtbl , def _mediawiki_row_with_attrs ( separator , cell_values , colwidths , colaligns ) : padding=0 , _binary_type = str TableFormat ( lineabove=None , if title : # Only print the title if it 's not None . _binary_type = bytes it separates columns with a double space : headers = list ( map ( _text_type , headers ) ) `` `` '' Center string . 'disable_numparse ' : True , return _isconvertible ( float , string ) > > > _type ( `` foo '' ) is type ( `` '' ) return ( begin + sep.join ( padded_cells ) + end ) .rstrip ( ) `` `` '' Transform a supported data type to a list of lists , and a list of headers . output.append ( tabulated ) padfn = _padright for c , a in zip ( cell_values , colaligns ) ] data = [ [ ' abc ' ] ] return missingval if len ( rows ) > 0 : # take headers from the first row if necessary # - * - coding : utf-8 - * if not rowfmt : def _format_table ( fmt , headers , rows , colwidths , colaligns ) : `` \\toprule '' if booktabs else `` \hline '' ] ) `` center '' : ' style= '' text-align : center ; '' ' , r '' ~ '' : r '' \textasciitilde { } '' , `` \\ '' : r '' \textbackslash { } '' , expanded=expanded ) > > > _column_type ( [ `` 1 '' , `` 2.3 '' , `` four '' ] ) is _text_type return `` < tr > '' + `` '' .join ( values_with_attrs ) .rstrip ( ) + `` < /tr > '' TableFormat ( lineabove=Line ( `` '' , `` = '' , `` `` , `` '' ) , row_result = [ ] linebelowheader=Line ( `` + '' , `` = '' , `` + '' , `` + '' ) , header_len = max ( [ len ( x ) for x in headers ] ) # TableFormat 's * row elements can be * NumPy record arrays ( usually used with headers= '' keys '' ) Supported tabular data types : `` center '' : 'align= '' center '' | ' , 56 8.999 `` Return a string which represents a row of data cells . '' rows = [ [ v ] +list ( row ) for v , row in zip ( names , vals ) ] library rather than listing it as a dependency in setup.py , is because I had to datarow=DataRow ( `` │ '' , `` │ '' , `` │ '' ) , `` `` '' Format a value accoding to its type . `` SELECT * FROM users WHERE < tab > `` will only show column names . return TableFormat ( None , None , None , None , 'sep_title ' : 'RECORD { n } ' , tabular_columns_fmt = `` '' .join ( [ alignment.get ( a , `` l '' ) for a in colaligns ] ) with_header_hide= [ `` lineabove '' , `` linebelow '' ] ) , for this to work . > > > _isnumber ( `` 123 '' ) r '' _ '' : r '' \_ '' , r '' ^ '' : r '' \^ { } '' , r '' { `` : r '' \ { `` , r '' } '' : r '' \ } '' , 'plain ' , 'simple ' , 'grid ' , 'pipe ' , 'orgtbl ' , 'rst ' , 'mediawiki ' , return reduce ( _more_generic , types , int ) re.search ( _invisible_codes , missingval ) ) linebelow=Line ( `` < /table > '' , `` '' , `` '' , `` '' ) , if padded_rows and fmt.linebetweenrows and `` linebetweenrows '' not in hidden : # - or a function : [ col_widths ] , [ col_alignments ] - > string . `` h1f : s : '' , return ( separator + colsep.join ( values_with_attrs ) ) .rstrip ( ) max_width = settings.max_width `` SELECT * FROM users WHERE < tab > `` will only show column names . minwidths = [ width_fn ( c [ 0 ] ) for c in cols ] def tabulate ( tabular_data , headers= [ ] , tablefmt= '' simple '' , output.append ( formatted ) `` Return a string which represents a horizontal line . '' def _padleft ( width , s , has_invisible=True ) : try : __all__ = [ `` tabulate '' , `` tabulate_formats '' , `` simple_separated_format '' ] content_exceeds_width ( rows [ 0 ] , max_width ) and from collections import namedtuple return _text_type ( val , `` utf-8 '' ) headers = list ( map ( _text_type , keys ) ) # headers should be strings return format ( float ( val ) , floatfmt ) \end { tabular } results.append ( '\n'.join ( row_result ) ) expanded = settings.expanded except ( ValueError , TypeError ) : segments = [ _pipe_segment_with_colons ( a , w ) for a , w in zip ( colaligns , colwidths ) ] def _pad_row ( cells , padding ) : def simple_separated_format ( separator ) : aligns = [ numalign if ct in [ int , float ] else stralign for ct in coltypes ] return len ( string ) - pos - 1 output.append ( title ) tabular_data = [ ] if k not in uniq_keys : return _format_table ( tablefmt , headers , rows , minwidths , aligns ) , rows datarow=DataRow ( `` , separator , `` ) , types = { _none_type : 0 , int : 1 , float : 2 , _binary_type : 3 , _text_type : 4 } | spam || align= '' right '' | 41.9999 `` decimal '' : 'align= '' right '' | ' } lines.append ( _build_line ( padded_widths , colaligns , fmt.linebelow ) ) return padded_strings or list_of_lists , headers = _normalize_tabular_data ( tabular_data , headers ) return False if title : # Only print the title if it 's not None . `` fancy_grid '' : [ `` help '' , `` header '' , `` format '' , `` separator '' ] ) `` `` '' The least generic type ( type ( None ) , int , float , str , unicode ) . padding=0 , with_header_hide=None ) } | : -- -- -- -- -- | -- -- -- -- -- : | # the last row without a line below def _visible_width ( s ) : max_row_len = 0 | eggs | 451 | # headerrow return invtypes [ moregeneric ] def pad ( field , total , char=u '' `` ) : if alignment == `` right '' : if not isinstance ( tablefmt , TableFormat ) : Examples : `` `` '' vals = tabular_data.values # values matrix does n't need to be transposed eggs 451 > > > list ( map ( str , _align_column ( [ `` 12.345 '' , `` -1234.5 '' , `` 1.23 '' , `` 1234.5 '' , `` 1e+234 '' , `` 1.0e234 '' ] , `` decimal '' ) ) ) `` pipe '' is like tables in PHP Markdown Extra extension or Pandoc lines.append ( _build_line ( padded_widths , colaligns , fmt.linebetweenrows ) ) for i , result in enumerate ( results ) : `` psql '' : ( https : //pypi.python.org/pypi/tabulate ) library . This library is licensed under > > > print ( tabulate ( [ [ `` sex '' , '' age '' ] , [ `` Alice '' , '' F '' ,24 ] , [ `` Bob '' , '' M '' ,19 ] ] , if status : # Only print the status if it 's not None . tbl , _ = tabulate ( data , headers , tablefmt='psql ' ) rows = rows [ 1 : ] from .. encodingutils import utf8tounicode ... [ `` strings '' , `` numbers '' ] , `` fancy_grid '' ) ) for s , decs in zip ( strings , decimals ) ] def _build_simple_row ( padded_cells , rowfmt ) : decimals = [ _afterpoint ( s ) for s in strings ] datarow=_latex_row , define column alignment , and using a `` + '' sign to indicate line name | hello > > > _column_type ( [ dt.datetime ( 1991,2,19 ) , dt.time ( 17,35 ) ] ) is _text_type 'float_format ' : settings.floatfmt , h , -- help show this message names = tabular_data.index for this to work . `` html '' : < tr > < th > strings < /th > < th style= '' text-align : right ; '' > numbers < /th > < /tr > types = [ _type ( s , has_invisible ) for s in strings ] return `` | '' + `` | '' .join ( segments ) + `` | '' if cells : for h , a , minw in zip ( headers , t_aligns , minwidths ) ] ... [ `` strings '' , `` numbers '' ] , `` plain '' ) ) from textwrap import dedent elif opt in [ `` -f '' , `` -- format '' ] : elif opt in [ `` -s '' , `` -- sep '' ] : return _build_simple_row ( cells , ( begin , sep , end ) ) install these via your operating system package manager . if hasattr ( tabular_data , `` keys '' ) and hasattr ( tabular_data , `` values '' ) : are supposed to be names of the last columns . This is consistent padded_cells = [ pad + cell + pad for cell in cells ] _long_type = int | ╞═══════════╪═══════════╡ 'preserve_whitespace ' : True linebetweenrows=None , return `` \n '' .join ( lines ) # last datarow return int intersections : > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' latex_booktabs '' ) ) `` mediawiki '' produces a table markup used in Wikipedia and on other def _padright ( width , s , has_invisible=True ) : > > > _type ( '\x1b [ 31m42\x1b [ 0m ' ) is type ( 42 ) table_format = settings.table_format This app includes the awesome ` tabulate < https : //pypi.python.org/pypi/tabulate > ` _ headers = tabular_data.dtype.names for header , value in zip ( padded_headers , row ) : | abc | Then you can install pgcli : width_fn = wcswidth __ https : //github.com/dbcli/pgcli # detailed-installation-instructions # orgtbl , rst , mediawiki , html , latex , latex_booktabs . if fmt.lineabove and `` lineabove '' not in hidden : if ` headers= '' firstrow '' ` , then the first row of data is used return _text_type ( val ) value = missingval if value is None else value headerrow=partial ( _mediawiki_row_with_attrs , `` ! `` ) , maxdecimals = max ( decimals ) table_format = ( 'vertical ' if settings.expanded else rows = fobject.readlines ( ) ... [ `` strings '' , `` numbers '' ] , `` simple '' ) ) > > > _column_type ( [ `` 1 '' , `` 2.3 '' ] ) is _float_type ... [ `` other '' , None , 2.7 ] ] , missingval= '' ? '' ) ) usage = textwrap.dedent ( _main.__doc__ ) `` `` '' The least generic type all column values are convertible to . > > > import datetime as dt return type ( string ) is _int_type or type ( string ) is _long_type elif headers == `` keys '' and len ( rows ) > 0 : lines.append ( _build_line ( padded_widths , colaligns , fmt.lineabove ) ) currently supported formats . rwidth = 0 if xwidth < = 0 else lwidth + xwidth % 2 def _normalize_tabular_data ( tabular_data , headers ) : `` `` '' padded_widths = [ ( w + 2 * pad ) for w in colwidths ] `` orgtbl '' is like tables in Emacs org-mode and orgtbl-mode . They from functools import partial begin , fill , sep , end = linefmt ... [ `` eggs '' , 42 , 3.14 ] , everything else to the left . Possible column alignments sudo permissions . MIN_PADDING = 2 if alignment == `` left '' : # textile , moinmoin , jira , vertical , tsv , csv . rows = list ( zip ( * cols ) ) # likely a conventional dict else : from __future__ import print_function ( isinstance ( string , _text_type ) or isinstance ( string , _binary_type ) ) : def _strip_invisible ( s ) : lines.append ( _build_row ( padded_headers , padded_widths , colaligns , headerrow ) ) else : # it 's a usual an iterable of iterables , or a NumPy array # numpy record array ===========+=========== escaped_values = [ `` '' .join ( map ( escape_char , cell ) ) for cell in cell_values ] cells = [ fill * w for w in colwidths ] if cur : and hasattr ( rows [ 0 ] , `` _fields '' ) ) : contain numeric data with a decimal point . FILE a filename of the file with tabular data ; table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , max_width=100 ) ... [ `` strings '' , `` numbers '' ] , `` pipe '' ) ) _float_type = float lwidth = xwidth // 2 good_result = '\\u0431\\u0443\\u043a\\u0432\\u0430 \\u0446\\u0438\\u0444\\u0440\\u0430\\n -- -- -- - -- -- -- -\\n\\u0430\\u0437 2\\n\\u0431\\u0443\\u043a\\u0438 4 ' ; \ linebetweenrows=Line ( `` ├ '' , `` ─ '' , `` ┼ '' , `` ┤ '' ) , print ( usage ) tabulate ( [ [ `` foo '' , 1 ] , [ `` spam '' , 23 ] ] , tablefmt=tsv ) == 'foo \\t 1\\nspam\\t23 ' # values is a property , has .index = > it 's likely a pandas.DataFrame ( pandas 0.11.0 ) elif isinstance ( string , ( float , Decimal ) ) : < table > if fmt.linebelowheader and `` linebelowheader '' not in hidden : keys.extend ( firstdict.keys ( ) ) def _isconvertible ( conv , string ) : > > > list ( map ( str , _align_column ( [ '123.4 ' , '56.7890 ' ] , None ) ) ) < tr > < td > eggs < /td > < td style= '' text-align : right ; '' > 451 < /td > < /tr > < tr > < td > spam < /td > < td style= '' text-align : right ; '' > 41.9999 < /td > < /tr > Table formats case_function = settings.case_function * 2D NumPy arrays return re.sub ( _invisible_codes , `` '' , s ) return wcswidth ( _text_type ( s ) ) To print nice column headers , supply the second argument ( ` headers ` ) : hidden = fmt.with_header_hide if ( headers and fmt.with_header_hide ) else [ ] # - or a DataRow tuple , linebetweenrows=Line ( `` |- '' , `` '' , `` '' , `` '' ) , TableFormat ( lineabove=Line ( `` + '' , `` - '' , `` + '' , `` + '' ) , value = format ( float ( value ) , ' , g ' ) Various plain-text table formats ( ` tablefmt ` ) are supported : from .packages.tabulate import tabulate return rowfmt ( padded_cells , colwidths , colaligns ) * list of dicts ( usually used with headers= '' keys '' ) except getopt.GetoptError as e : > > > _padboth ( 6 , '\u044f\u0439\u0446\u0430 ' ) == ' \u044f\u0439\u0446\u0430 ' Alice F 24 sep = r '' \s+ '' headers = [ `` '' ] * ( ncols - nhs ) + headers tabulated , rows = tabulate ( cur , headers , tablefmt=table_format , def _latex_line_begin_tabular ( colwidths , colaligns , booktabs=False ) : from cli_helpers.tabular_output.preprocessors import ( align_decimals , def expanded_table ( rows , headers , missingval= '' '' ) : def _type ( string , has_invisible=True ) : TableFormat ( lineabove=Line ( `` ╒ '' , `` ═ '' , `` ╤ '' , `` ╕ '' ) , elif not alignment : print ( e ) else : elif isinstance ( headers , dict ) : pos = string.rfind ( `` . '' ) headers = `` firstrow '' linebelow=Line ( `` ╘ '' , `` ═ '' , `` ╧ '' , `` ╛ '' ) , if headers == `` firstrow '' : def test_dont_strip_leading_whitespace ( ) : return -1 if __name__ == `` __main__ '' : output.append ( sep.format ( i ) ) expected = u '' '' '' - [ RECORD 0 ] if ( max_width and rows and return `` : '' + ( '- ' * ( w - 1 ) ) A REPL for Postgres headers = list ( map ( _text_type , rows [ 0 ] ._fields ) ) uniq_keys.add ( k ) linebelowheader=Line ( `` '' , `` = '' , `` `` , `` '' ) , keys.append ( k ) `` `` '' [ string ] - > [ padded_string ] but not yet released in PyPI . r '' < `` : r '' \ensuremath { < } '' , r '' > '' : r '' \ensuremath { > } '' } > > > _type ( `` 1 '' ) is type ( 1 ) def format_output ( title , cur , headers , status , settings ) : ` None ` values are replaced with a ` missingval ` string : * Use CLI Helpers for pretty printing query results ( Thanks : ` Thomas Roten ` _ ) . If you do n't know how to install python packages , please check the return linefmt ( colwidths , colaligns ) lwidth = width - wcswidth ( _strip_invisible ( s ) if has_invisible else s ) > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' orgtbl '' ) ) output_kwargs = { > > > _isnumber ( `` spam '' ) if has_invisible and \ import sys datarow=partial ( _mediawiki_row_with_attrs , `` | '' ) , expanded=expanded ) > > > _afterpoint ( `` 123.45 '' ) def _main ( ) : print ( usage ) raise ValueError ( 'headers for a list of dicts is not a dict or a keyword ' ) keys = tabular_data.keys ( ) def _pprint_file ( fobject , headers , tablefmt , sep ) : if valtype is int : * list-of-lists or another iterable of iterables def _is_file ( f ) : return `` \n '' .join ( [ `` \\begin { tabular } { `` + tabular_columns_fmt + `` } '' , from pgcli.packages.expanded import expanded_table 'Title ' , u'- [ RECORD 1 ] -- -- -- -- -- -- -- -- -- -- -- -- -\nhead1 | abc\nhead2 | def\n ' , 'test status ' ] from cli_helpers.tabular_output import TabularOutputFormatter expected = `` '' '' - [ RECORD 0 ] string = _strip_invisible ( string ) elif isinstance ( string , _binary_type ) : ... [ `` strings '' , `` numbers '' ] , `` orgtbl '' ) ) begin , sep , end = rowfmt [ ' 12.345 ' , '-1234.5 ' , ' 1.23 ' , ' 1234.5 ' , ' 1e+234 ' , ' 1.0e234 ' ] numbers ( or flushes integer numbers to the right ) , and flushes if expanded and headers : : : `` pipe '' : `` linebetweenrows '' , `` linebelow '' , output = [ ] library for pretty printing the output of tables . The reason for vendoring this : : 2 has_invisible = ( re.search ( _invisible_codes , plain_text ) or Also returns a tuple of the raw rows pulled from tabular_data > > > _padleft ( 6 , '\u044f\u0439\u0446\u0430 ' ) == ' \u044f\u0439\u0446\u0430 ' f = sys.stdin from functools import reduce , partial # namedtuple spam & 41.9999 \\\\ padded_headers = _pad_row ( headers , pad ) with open ( f ) as fobj : > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' rst '' ) ) return _none_type `` decimal '' : ' style= '' text-align : right ; '' ' } padding=1 , with_header_hide=None ) , minwidths = [ max ( minw , width_fn ( c [ 0 ] ) ) for minw , c in zip ( minwidths , t_cols ) ] TableFormat ( lineabove=None , linebelowheader=None , 2 10001 padfn = _padleft 'missing_value ' : settings.missingval , def _align_header ( header , alignment , width ) : datarow=partial ( _html_row_with_attrs , `` td '' ) , getattr ( tabular_data.dtype , `` names '' ) ) : age | 123 assert expected == expanded_table ( input , [ `` name '' , `` age '' ] ) | spam | 41.9999 | TableFormat ( lineabove=Line ( `` '' , `` - '' , `` `` , `` '' ) , input = [ ( u ' ö ' , 123 ) ] $ pgcli postgresql : // [ user [ : password ] @ ] [ netloc ] [ : port ] [ /dbname ] _main ( ) if ` headers= '' keys '' ` , then dictionary keys or column indices are used ' '' ) .strip ( ) name | world tablefmt = `` simple '' return `` : '' + ( '- ' * ( w - 2 ) ) + `` : '' ... [ `` strings '' , `` numbers '' ] , `` grid '' ) ) print ( tabulate ( table , headers , tablefmt ) ) `` `` '' \ sys.exit ( 0 ) > > > _afterpoint ( `` eggs '' ) | -- -- -- -- -- -+ -- -- -- -- -- -| if has_invisible : tbl = [ [ '\u0430\u0437 ' , 2 ] , [ '\u0431\u0443\u043a\u0438 ' , 4 ] ] ; \ linebelowheader=Line ( `` '' , `` - '' , `` `` , `` '' ) , output.append ( expanded_table ( cur , headers , missingval ) ) ... headers= '' firstrow '' , tablefmt= '' html '' ) ) # dict or OrderedDict \\hline lines = [ ] might look something like : TableFormat ( lineabove=_pipe_line_with_colons , headers = list ( map ( _text_type , rows [ 0 ] ) ) # headers should be strings list-of-lists ( or another iterable of iterables ) , a list of named │ strings │ numbers │ print ( `` % s is not a supported table format '' % value ) dcmlfmt= '' d '' , floatfmt= '' g '' , numalign= '' decimal '' , stralign= '' left '' , if _isnumber ( string ) : 'latex ' , and 'latex_booktabs ' . Variable ` tabulate_formats ` contains the list of linebetweenrows=Line ( `` + '' , `` - '' , `` + '' , `` + '' ) , linebetweenrows=None , linebelow=None , dcmlfmt = settings.dcmlfmt `` rst '' : else : # a dict of headers for a list of dicts `` `` '' Return a segment of a horizontal line with optional colons which output.append ( status ) s REGEXP , -- sep REGEXP use a custom column separator ( default : whitespace ) The first required argument ( ` tabular_data ` ) can be a _text_type = str > > > _afterpoint ( `` 1001 '' ) return _padboth ( width , header ) return `` { 0 } '' .format ( val ) return output and len ( rows ) > 0 def test_unicode_expanded_table ( ) : raise ValueError ( `` tabular data does n't appear to be a dict or a DataFrame '' ) TableFormat ( lineabove=Line ( `` < table > '' , `` '' , `` '' , `` '' ) , `` `` '' Visible width of a printed string . ANSI color codes are removed . output.append ( result ) Then you can install pgcli : lines.append ( _build_row ( padded_rows [ -1 ] , padded_widths , colaligns , fmt.datarow ) ) formatted = formatter.format_output ( creating ` Python Prompt Toolkit < http : //github.com/jonathanslenders/python-prompt-toolkit > ` _ , eggs 42 3.14 < /table > return _build_simple_row ( escaped_values , rowfmt ) ncols = len ( rows [ 0 ] ) ` floatfmt ` is a format specification used for columns which def _afterpoint ( string ) : linebelow=Line ( `` '' , `` - '' , `` `` , `` '' ) , return True `` plain '' : > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' plain '' ) ) > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' pipe '' ) ) * pandas.DataFrame ( usually used with headers= '' keys '' ) ( only for ` numalign ` ) , and None ( to disable alignment ) . from pgcli.packages.tabulate import tabulate `` tsv '' : pipe_tables : else : for f in files : # align headers and add headers _table_formats = { `` simple '' : elif align == `` left '' : return padded_cells Pandoc grid_tables : linebelowheader=Line ( `` \\midrule '' , `` '' , `` '' , `` '' ) , for row in rows : elif headers : | xyz | linebelow=Line ( `` '' , `` = '' , `` `` , `` '' ) , for c , ct in zip ( cols , coltypes ) ] from __future__ import unicode_literals dataframe . rows = rows [ 1 : ] return -1 # not a number from platform import python_version_tuple n = conv ( string ) colsep = separator * 2 return None `` latex '' produces a tabular environment of LaTeX document markup : for opt , value in opts : } * Primitive support for `` psql `` back-slash commands . > > > print ( tabulate ( [ [ 1 , 2.34 ] , [ -56 , `` 8.999 '' ] , [ `` 2 '' , `` 10001 '' ] ] ) ) sudo permissions . import getopt install these via your operating system package manager . tabulate ( tbl , headers=hrow ) == good_result > > > _column_type ( [ `` four '' , '\u043f\u044f\u0442\u044c ' ] ) is _text_type nhs = len ( headers ) return s + ' ' * rwidth if f == `` - '' : eggs 451 moregeneric = max ( types.get ( type1 , 4 ) , types.get ( type2 , 4 ) ) settings = OutputSettings ( If the number of headers is less than the number of columns , they expanded = [ if row_len > max_row_len : rows = list ( izip_longest ( * tabular_data.values ( ) ) ) # columns have to be transposed rwidth = width - wcswidth ( _strip_invisible ( s ) if has_invisible else s ) ( ` numalign ` , ` stralign ` ) are : `` right '' , `` center '' , `` left '' , `` decimal '' cols = list ( zip ( * list_of_lists ) ) strings numbers `` `` '' Symbols after a decimal point , -1 if the string lacks the decimal point . `` latex '' : def _padboth ( width , s , has_invisible=True ) : return wcswidth ( _strip_invisible ( s ) ) # - either None , to display all table elements unconditionally , headers = list ( map ( _text_type , headers ) ) if cur : return ' ' * lwidth + s + ' ' * rwidth # -- - linebewteenrows row_len = max ( [ len ( _text_type ( utf8tounicode ( x ) ) ) for x in row ] ) `` SELECT * FROM < tab > `` will only show table names . from .packages.expanded import expanded_table hasattr ( tabular_data , `` dtype '' ) and if nhs < ncols : Please feel free to reach out to me if you need help . The first row can be used as headers if headers= '' firstrow '' , from itertools import zip_longest as izip_longest ╘═══════════╧═══════════╛ `` `` '' Pretty-print tabular data . '' '' '' ========= ========= if string is None : Unicode is supported : `` `` '' Flush left . from wcwidth import wcswidth return isinstance ( f , file ) `` rst '' is like a simple table format from reStructuredText ; please other ? 2.7 f FMT , -- format FMT set output table format ; supported formats : return strings _pprint_file ( fobj ) `` `` '' Produce a plain-text representation of the table . '' '' '' DataRow = namedtuple ( `` DataRow '' , [ `` begin '' , `` sep '' , `` end '' ] ) linebelowheader=_pipe_line_with_colons , | } input = [ ( `` hello '' , 123 ) , ( `` world '' , 456 ) ] elif hasattr ( string , `` isoformat '' ) : # datetime.datetime , date , and time `` mediawiki '' : `` `` '' Construct a simple TableFormat with columns separated by a separator . import io missingval = settings.missingval creating ` Python Prompt Toolkit < http : //github.com/jonathanslenders/python-prompt-toolkit > ` _ , and isinstance ( rows [ 0 ] , tuple ) def _html_row_with_attrs ( celltag , cell_values , colwidths , colaligns ) : > > > hrow = [ '\u0431\u0443\u043a\u0432\u0430 ' , '\u0446\u0438\u0444\u0440\u0430 ' ] ; \ results = [ ] # padding ( an integer ) is the amount of white space around data values . sys.exit ( 3 ) def _build_row ( padded_cells , colwidths , colaligns , rowfmt ) : make a change to the table format which is merged back into the original repo , formatted = formatter.format_output ( rows , headers , * * output_kwargs ) elif align == `` center '' : |+ < ! -- caption -- > elif ( len ( rows ) > 0 `` Remove invisible ANSI color codes . '' spam 1 ? `` right '' : 'align= '' right '' | ' , Table headers | eggs | 451 | table = [ re.split ( sep , r.rstrip ( ) ) for r in rows ] spam 41.9999 # hard-coded padding _around_ align attribute and value together if headers == `` keys '' : `` grid '' is similar to tables produced by Emacs table.el package or def format_output ( title , cur , headers , status , settings ) : `` fancy_grid '' draws a grid using box-drawing characters : return _padleft ( width , header ) `` padding '' , `` with_header_hide '' ] ) Bob M 19 > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' grid '' ) ) headers = list ( map ( _text_type , headers ) ) invtypes = { 4 : _text_type , 3 : _binary_type , 2 : float , 1 : int , 0 : _none_type } sep = u '' - [ RECORD { 0 } ] -- -- -- -- -- -- -- -- -- -- -- -- -\n '' return float header_len += 2 for row in rows : if headers : _int_type = int lines.append ( _build_line ( padded_widths , colaligns , fmt.linebelowheader ) ) linebelowheader=Line ( `` | '' , `` - '' , `` + '' , `` | '' ) , headerrow=DataRow ( `` '' , `` \t '' , `` '' ) , elif hasattr ( tabular_data , `` index '' ) : # format rows and columns , convert numeric values to strings linebelow=Line ( `` + '' , `` - '' , `` + '' , `` + '' ) , │ spam │ 41.9999 │ cols = [ _align_column ( c , a , minw , has_invisible ) ( 5 , 5 ) tuples , a dictionary of iterables , an iterable of dictionaries , def test_expanded_table_renders ( ) : Column alignment Please feel free to reach out to me if you need help . datarow=DataRow ( `` '' , `` `` , `` '' ) , headers = [ ] Pretty-print tabular data . See also https : //bitbucket.org/astanin/python-tabulate xwidth = width - wcswidth ( _strip_invisible ( s ) if has_invisible else s ) # optimization : look for ANSI control codes once , return `` { 0 } '' .format ( header ) > > > _column_type ( [ 1 , 2 , None ] ) is _int_type > > > _type ( None ) is type ( None ) try : headers = [ case_function ( utf8tounicode ( x ) ) for x in headers ] padded_strings = [ padfn ( maxwidth , s , has_invisible ) for s in strings ] `` plain '' format does n't use any pseudographics to draw tables , rows = [ [ row.get ( k ) for k in keys ] for row in rows ] output.append ( status ) datarow=DataRow ( `` '' , `` \t '' , `` '' ) , name | ö return ' ' * lwidth + s * dict of iterables ( usually used with headers= '' keys '' ) sys.exit ( 2 ) from itertools import izip_longest if isinstance ( s , _text_type ) : return LATEX_ESCAPE_RULES.get ( c , c ) using the booktabs.sty package : if ( headers == `` keys '' and if headers == `` firstrow '' and len ( rows ) > 0 : Options : headers = [ case_function ( utf8tounicode ( x ) ) for x in headers ] settings.table_format ) max_row_len = row_len def _latex_row ( cell_values , colwidths , colaligns ) : # with_header_hide : Line = namedtuple ( `` Line '' , [ `` begin '' , `` hline '' , `` sep '' , `` end '' ] ) ` tabulate ` tries to detect column types automatically , and aligns def _align_column ( strings , alignment , minwidth=0 , has_invisible=True ) : headers = list ( map ( _text_type , range ( len ( rows [ 0 ] ) ) ) ) cols = [ [ _format ( v , ct , dcmlfmt , floatfmt , missingval ) for v in c ] maxwidth = max ( max ( map ( width_fn , strings ) ) , minwidth ) > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' latex '' ) ) a two-dimensional NumPy array , NumPy record array , or a Pandas ' > > > _column_type ( [ `` 1 '' , `` 2 '' ] ) is _int_type floatfmt = settings.floatfmt return _binary_type _text_type = unicode padding=1 , alignment = { `` left '' : `` , sep = value > > > print ( tabulate ( [ [ `` strings '' , `` numbers '' ] , [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , except TypeError : * Primitive support for `` psql `` back-slash commands . MediaWiki-based sites : rowfmt = DataRow ( `` '' , `` & '' , `` \\\\ '' ) # enable smart width functions only if a control code is found \\bottomrule pad = `` `` * padding indicate column 's alignment ( as in ` pipe ` output format ) . '' '' '' might look something like : 'cli_helpers > = 0.2.0 , < 1.0.0 ' , | -- -- -- -- -| 1 2.34 | : -- -- -| -- -- -- -- - : | # datarow # rather than padding parameter which affects only the value Otherwise a headerless table is produced . elif valtype is _binary_type : `` grid '' : max_width = settings.max_width elif headers == `` firstrow '' : output.append ( '\n ' ) __version__ = `` 0.7.4 '' uniq_keys = set ( ) # implements hashed lookup padfn = _padboth headerrow=DataRow ( `` │ '' , `` │ '' , `` │ '' ) , ├───────────┼───────────┤ ! strings ! ! align= '' right '' | numbers # keys are column indices elif valtype is _text_type : alignment = { `` left '' : `` l '' , `` right '' : `` r '' , `` center '' : `` c '' , `` decimal '' : `` r '' } padding=0 , with_header_hide=None ) > > > tsv = simple_separated_format ( `` \\t '' ) ; \ padded_rows = [ _pad_row ( row , pad ) for row in rows ] headers = keys > > > print ( tabulate ( [ [ `` spam '' , 41.9999 ] , [ `` eggs '' , `` 451.0 '' ] ] , tablefmt= '' simple '' ) ) \\end { tabular } return output w = colwidth settings = OutputSettings ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , max_width=100 ) # Save unique items in input order A REPL for Postgres * list of OrderedDicts ( usually used with headers= '' keys '' ) ... headers= '' firstrow '' ) ) elif valtype is float : if tabular_data is None : linebelow=Line ( `` \\bottomrule\n\\end { tabular } '' , `` '' , `` '' , `` '' ) , > > > _column_type ( [ None , `` brux '' ] ) is _text_type \\toprule rows , headers , format_name='vertical ' , * * output_kwargs ) return re.sub ( _invisible_codes_bytes , `` '' , s ) if hasattr ( linefmt , `` __call__ '' ) : return `` .join ( output ) # - either None , if the element is not used , elif opt in [ `` -h '' , `` -- help '' ] : def _format ( val , valtype , dcmlfmt , floatfmt , missingval= '' '' ) :","['LICENSE.txt', 'README.rst', 'changelog.rst', 'pgcli/main.py', 'pgcli/packages/expanded.py', 'pgcli/packages/tabulate.py', 'pgcli/pgclirc', 'setup.py', 'tests/test_expanded.py', 'tests/test_main.py', 'tests/test_pgexecute.py', 'tests/test_tabulate.py', 'tests/utils.py']",Merge pull request # 735 from dbcli/feature/cli_helpers_output_format
194,a7a7d09f446cad7f34be04ceb47bd8512b9cd344,2017-06-15 09:00:58-05:00,"# no-op logging handler pass class NullHandler ( logging.Handler ) : handler = logging.NullHandler ( ) def emit ( self , record ) : handler = NullHandler ( )",['pgcli/main.py'],Merge pull request # 734 from dbcli/bersace/golf-logging
195,9d74cd138d6a023cd5e8d94aec92ab984c0a5e57,2017-06-14 09:45:56-07:00,pep8radius master -- docformatter -- error-status || ( pep8radius master -- docformatter -- diff ; false ) pep8radius master -- docformatter -- diff -- error-status,"['.travis.yml', 'pgcli/completion_refresher.py', 'pgcli/encodingutils.py', 'pgcli/filters.py', 'pgcli/magic.py', 'pgcli/packages/expanded.py', 'pgcli/packages/ordereddict.py', 'pgcli/packages/parseutils/ctes.py', 'pgcli/packages/parseutils/utils.py', 'pgcli/packages/pgliterals/__init__.py', 'pgcli/packages/prioritization.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/packages/tabulate.py', 'pgcli/pgcompleter.py', 'pgcli/pgtoolbar.py', 'tests/conftest.py', 'tests/features/steps/basic_commands.py', 'tests/parseutils/test_ctes.py', 'tests/parseutils/test_parseutils.py', 'tests/test_expanded.py', 'tests/test_fuzzy_completion.py', 'tests/test_main.py', 'tests/test_naive_completion.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 732 from dbcli/bersace/pep8
196,f4d6adfc2c7c34799711c5ed7d425c55f9719e4a,2017-06-11 12:00:44-05:00,"* Only set ` LESS ` environment variable if it 's unset . ( Thanks : ` Irina Truong ` _ ) self.logger.info ( 'No default pager found in environment . Using os default pager ' ) # They are ignored if pager is different than less . self.logger.info ( if not os.environ.get ( 'LESS ' ) : 'Default pager found in config file : `` { } '' '.format ( configured_pager ) ) # Set default set of less recommended options , if they are not already set . os_environ_pager ) ) self.logger.info ( 'Default pager found in PAGER environment variable : ' + '\ '' + os_environ_pager + '\ '' ) os.environ [ 'LESS ' ] = '-SRXF ' 'No default pager found in environment . Using os default pager ' ) os.environ [ 'LESS ' ] = '-SRXF ' # different than less or is already parameterized with their own arguments # Always set default set of less recommended options , they are ignored if pager is self.logger.info ( 'Default pager found in config file : ' + '\ '' + configured_pager + '\ '' ) self.logger.info ( 'Default pager found in PAGER environment variable : `` { } '' '.format (","['changelog.rst', 'pgcli/main.py']",Merge pull request # 729 from dbcli/j-bennet/set-less-if-unset
197,af27c34521b183db4a11dfc5e69a84c7a1759dc6,2017-06-10 16:53:22-07:00,"# DROP SCHEMA schema_name schema ( u '' 'Custom ' '' ) , return self.find_matches ( word_before_cursor , schema_names , result = result_set ( completer , text ) prev_keyword = stmt.reduce_to_prev_keyword ( n_skip=2 ) assert result == set ( [ Schema.__new__.__defaults__ = ( False , ) if suggestion.quoted : Schema = namedtuple ( 'Schema ' , [ 'quoted ' ] ) schema ( u '' 'custom ' '' ) , def get_schema_matches ( self , suggestion , word_before_cursor ) : if not s.startswith ( 'pg_ ' ) ] assert result == expected meta='schema ' ) return self.find_matches ( word_before_cursor , schema_names , meta='schema ' ) return `` ' { } ' '' .format ( self.unescape_name ( name ) ) * Quote schema in ` SET SCHEMA ` statement ( issue # 469 ) ( Thanks : ` Irina Truong ` _ ) def get_schema_matches ( self , _ , word_before_cursor ) : expected = set ( [ schema ( u '' 'public ' '' ) ] ) schema_names = [ self.escape_schema ( s ) for s in schema_names ] schema ( u '' 'public ' '' ) ] ) text = ( 'SET SCHEMA ' ) schema ( u '' 'blog ' '' ) , def test_set_schema ( completer ) : for s in schema_names quoted = prev_keyword and prev_keyword.value.lower ( ) == 'set ' return ( Schema ( ) , ) return ( Schema ( quoted ) , ) Schema = namedtuple ( 'Schema ' , [ ] ) schema_names = [ s # DROP SCHEMA schema_name , SET SCHEMA schema name def escape_schema ( self , name ) : schema_names = [ s for s in schema_names if not s.startswith ( 'pg_ ' ) ]","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 730 from dbcli/j-bennet/set-schema-escape
198,ec9873fa85fddc330e55de4ab792bff799fe7c29,2017-06-02 12:31:31-07:00,"====== * Use dbcli 's Homebrew tap for installing pgcli on macOS ( issue # 718 ) ( Thanks : ` Thomas Roten ` _ ) . The easiest way to install pgcli is using Homebrew . Please be aware that this will install postgres via brew if it was n't installed via brew . $ brew tap-pin dbcli/tap & & brew install pgcli # Only on macOS ===== postgres via brew if postgres is available in the path . macOS : If you have postgres installed via a different means ( such as PostgresApp ) , you install postgres if you do n't have it installed . Easiest way to install pgcli is using brew . Please be aware that this will $ brew tap-pin dbcli/tap $ brew install pgcli # Only on OS X OS X : can `` brew install -- build-from-source pgcli `` which will skip installing","['README.rst', 'changelog.rst']",Merge pull request # 727 from dbcli/update_homebrew_install_instructions
199,837c8051e42d9de458c60a2ac55ab1eeeac33021,2017-05-29 08:18:45-05:00,"if first_token.lower ( ) in ( 'alter ' , 'create ' , 'drop ' ) : * Refresh completions after ` COMMIT ` or ` ROLLBACK ` . ( Thanks : ` Irina Truong ` _ ) statement is an alter , create , or drop '' '' '' if first_token.lower ( ) in ( 'alter ' , 'create ' , 'drop ' , 'commit ' , 'rollback ' ) : `` ROLLBACK '' : [ ] , `` COMMIT '' : [ ] , statement is an alter , create , drop , commit or rollback . '' '' ''","['changelog.rst', 'pgcli/main.py', 'pgcli/packages/pgliterals/pgliterals.json']",Merge pull request # 724 from dbcli/j-bennet/refresh-after-rollback
200,85167d3589643b9dcf8ef7b35937f2ff0d036efb,2017-05-28 20:50:13-07:00,"* TBD cfg = load_config ( config_full_path ) cfg = load_config ( pgclirc , config_full_path ) * Fixed DSN aliases not being read from custom pgclirc ( issue # 717 ) . ( Thanks : ` Irina Truong ` _ ) .","['changelog.rst', 'pgcli/config.py', 'pgcli/main.py']",Merge pull request # 722 from dbcli/j-bennet/fix-alias-dsn-from-custom-rcfile
201,565dc02a16c98042dd9267e92c835dcbfa423cd6,2017-05-26 20:34:38-07:00,"] 'prompt_toolkit > =1.0.10 , < 1.1.0 ' , 'psycopg2 > = 2.5.4 ' , 'wcwidth > = 0.1.6 ' , 'humanize > = 0.5.1 ' , 'pgspecial > =1.8.0 ' , 'sqlparse > =0.2.2 , < 0.3.0 ' , 'psycopg2 > = 2.5.4 ' , 'sqlparse > =0.2.2 , < 0.3.0 ' , 'prompt_toolkit > =1.0.10 , < 1.1.0 ' , * TBD 'click > = 4.1 ' , 'humanize > = 0.5.1 ' , ===== 'Pygments > = 2.0 ' , # Pygments has to be Capitalcased . WTF ? ] 'click > = 4.1 ' , 'Pygments > = 2.0 ' , # Pygments has to be Capitalcased . WTF ? 'wcwidth > = 0.1.6 ' , 1.6.0 'configobj > = 5.0.6 ' , 'configobj > = 5.0.6 ' , 'pgspecial > =1.7.0 ' ,","['changelog.rst', 'setup.py']",Merge pull request # 719 from dbcli/j-bennet/release-1.6.0
202,6a58bd08d98bbf4f812dc347537c8d4ab3663cc7,2017-05-26 13:52:15-07:00,"'sslmode=verify-full & sslcert=m % 79.pem & sslkey=my-key.pem & sslrootcert=c % 61.pem ' ) with mock.patch.object ( PGCli , 'connect ' ) as mock_connect : def test_ssl_db_uri ( tmpdir ) : uri.port , uri.password ] port=unicode2utf8 ( port ) , host=unicode2utf8 ( host ) , dsn , * * kwargs ) dsn= '' ) : user=unicode2utf8 ( user ) , port=None , passwd=fixup_possible_percent_encoding ( uri.password ) ) port=unicode2utf8 ( port ) ) pgexecute.extra_args = { } e.dbname , e.user , e.password , e.host , e.port , e.dsn ) .. _ ` Alexander Schmolck ` : https : //github.com/aschmolck self.extra_args = { k : unicode2utf8 ( v ) for k , v in kwargs.items ( ) } dsn= '' , * * kwargs ) : arguments = dict ( mock_connect.assert_called_with ( database='testdb [ ' , port=fixup_possible_percent_encoding ( uri.port ) , cli.connect_uri ( * * kwargs ) port=None , dsn=None , * * kwargs ) : sslcert='my.pem ' , Project Lead : * Support query options in postgres URIs such as ? sslcert=foo.pem ( Thanks : ` Alexander Schmolck ` _ ) user=unicode2utf8 ( user ) , # Deal with extra params e.g . ? sslmode=verify-ca & ssl-cert=/mycert from urlparse import urlparse , unquote arguments = [ database , uri.hostname , uri.username , host='baz.com ' , * * arguments ) Many thanks to the following contributors . if uri.query : database=unicode2utf8 ( db ) , from urllib.parse import urlparse , unquote * * e.extra_args ) dsn ) pgexecute = PGExecute ( database , user , passwd , host , port , dsn , self.connect ( * * arguments ) user='bar ' , passwd= ' ] foo ' , return unquote ( str ( s ) ) if s else s pgexecute = PGExecute ( database , user , passwd , host , port , dsn ) mock_connect.assert_called_with ( 'testdb [ ' , 'baz.com ' , 'bar^ ' , None , ' ] foo ' ) passwd='foo ' , arguments = dict ( database=fixup_possible_percent_encoding ( database ) , sslmode='verify-full ' , sslkey='my-key.pem ' , mock_connect.assert_called_with ( database='testdb ' , port='2543 ' ) host=unicode2utf8 ( host ) , Many thanks to the following contributors . def fixup_possible_percent_encoding ( s ) : * Alexander Schmolck host=fixup_possible_percent_encoding ( uri.hostname ) , user='bar^ ' , from urlparse import urlparse , unquote , parse_qs sslrootcert='ca.pem ' ) { k : v for k , ( v , ) in parse_qs ( uri.query ) .items ( ) } , e.dbname , e.user , e.password , e.host , e.port , e.dsn , def __init__ ( self , database , user , password , host , port , dsn ) : # unquote str ( each URI part ( they may be percent encoded ) port=None , dsn=None ) : from urllib.parse import urlparse , unquote , parse_qs mock_connect.assert_called_with ( 'testdb ' , 'baz.com ' , 'bar ' , '2543 ' , 'foo ' ) def __init__ ( self , database , user , password , host , port , dsn , * * kwargs ) : database=unicode2utf8 ( db ) , Project Lead : # unquote each URI part ( they may be percent encoded ) password=unicode2utf8 ( password ) , self.connect ( * list ( map ( lambda p : unquote ( str ( p ) ) if p else p , arguments ) ) ) cli = PGCli ( pgclirc_file=str ( tmpdir.join ( `` rcfile '' ) ) ) * * kwargs ) passwd= ' ] foo ' ) password=unicode2utf8 ( password ) , user=fixup_possible_percent_encoding ( uri.username ) , kwargs = ( kwargs or self.extra_args )","['AUTHORS', 'changelog.rst', 'pgcli/completion_refresher.py', 'pgcli/main.py', 'pgcli/pgexecute.py', 'tests/test_completion_refresher.py', 'tests/test_main.py']",Merge pull request # 721 from smarkets/pgcli-ssl-url-support
203,666aeee79f849d4a8d02d2860b2f33a9bd105e93,2017-05-23 15:43:36-07:00,"if os.path.exists ( os.path.join ( * context.tee_file_name ) ) : ] if os.path.exists ( context.editor_file_name ) : 'user ' : context.config.userdata.get ( 'pg_test_user ' , 'postgres ' ) , 'host ' : context.config.userdata.get ( passenv = PGHOST pg_test_db = pgcli_behave_tests sys.executable , `` tests/features/wrappager.py '' , 'pg_test_user ' , context.editor_file_name = [ 'pass ' : context.config.userdata.get ( 'pg_test_host ' , context.package_root , 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) ) if os.path.exists ( context.tee_file_name ) : context.package_root = os.path.abspath ( [ behave.userdata ] sys.executable , context.cli.sendline ( '\o { 0 } '.format ( context.tee_file_name [ 1 ] ) ) '.coveragerc ' ) os.getenv ( 'PGUSER ' , 'postgres ' ) context.cli.sendline ( '\o { 0 } '.format ( os.path.dirname ( os.path.dirname ( os.path.dirname ( __file__ ) ) ) ) context.cli.sendline ( '\e { 0 } '.format ( 'user ' : context.config.userdata.get ( os.environ [ `` COVERAGE_PROCESS_START '' ] = os.path.join ( context.package_root , context.conf [ 'pager_boundary ' ] ) context.cli = pexpect.spawnu ( cli_cmd , cwd= ' .. ' ) os.environ [ `` COVERAGE_PROCESS_START '' ] = os.getcwd ( ) + `` / .. /.coveragerc '' 'tee_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) os.remove ( os.path.join ( * context.tee_file_name ) ) .. _ ` Gustavo Castro ` : https : //github.com/gustavo-castro context.cli = pexpect.spawnu ( cli_cmd , cwd=context.package_root ) pg_test_host = localhost if os.path.join ( * context.editor_file_name ) and os.path.exists ( os.path.join ( * context.editor_file_name ) ) : context.tee_file_name = os.path.join ( pg_test_pass = 'pg_test_pass ' , ) db_name = context.config.userdata.get ( 'pg_test_db ' , None ) os.remove ( context.tee_file_name ) ' .. ' , context.editor_file_name = os.path.join ( if context.editor_file_name and os.path.exists ( context.editor_file_name ) : context.cli.sendline ( '\e { 0 } '.format ( context.editor_file_name [ 1 ] ) ) pg_test_user = postgres 'pass ' : context.config.userdata.get ( 'pg_test_pass ' , None ) , if os.path.exists ( os.path.join ( * context.editor_file_name ) ) : with open ( context.tee_file_name ) as f : envlist = py27 , py33 , py34 , py35 , py36 os.path.join ( context.package_root , `` tests/features/wrappager.py '' ) , PGPASSWORD db_name = context.config.userdata.get ( 'pg_test_db ' , 'pgcli_behave_tests ' ) behave tests/features with open ( os.path.join ( * context.tee_file_name ) ) as f : .. _ ` Gustavo Castro ` : https : //github.com/gustavo-castro * Add behave to tox ( Thanks : ` Dick Marinus ` _ ) . os.remove ( os.path.join ( * context.editor_file_name ) ) os.getenv ( 'PGHOST ' , 'localhost ' ) context.conf [ 'pager_boundary ' ] os.path.basename ( context.tee_file_name ) ) ) os.path.basename ( context.editor_file_name ) ) ) PGUSER os.remove ( context.editor_file_name ) 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) os.getenv ( 'PGPASSWORD ' , None ) 'host ' : context.config.userdata.get ( 'pg_test_host ' , 'localhost ' ) , context.package_root , 'tee_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) ) ) , context.tee_file_name = [ envlist = py26 , py27 , py33 , py34 , py35 , py36","['changelog.rst', 'tests/behave.ini', 'tests/features/environment.py', 'tests/features/steps/iocommands.py', 'tests/features/steps/wrappers.py', 'tox.ini']",Merge pull request # 714 from dbcli/feature/tox_behave
204,bc6883a308055bd76f6ec82d5d2afdd3d911d528,2017-05-11 10:05:10-07:00,"* Gustavo Castro .. _ ` Gustavo Castro ` : https : //github.com/gustavo-castro string = string.replace ( '\\t ' , self.now.strftime ( ' % x % X ' ) ) * Add time option for prompt ( Thanks : ` Gustavo Castro ` _ ) import datetime as dt self.now = dt.datetime.today ( ) self.now = dt.datetime.today ( )","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 715 from gustavo-castro/adding_date_feature
205,d62f1e5030fc5fca0428144b5b98b6438631b018,2017-05-06 15:25:18-07:00,"When `` on_error = STOP `` in the config file , pgcli will abort execution if one of the queries results in an error . .. _ ` Thomas Roten ` : https : //github.com/tsroten .. _ ` Jay Zeng ` : https : //github.com/jayzeng Functions that return table like results will now be suggested in places of tables . * Results from a pgcli query are sent back to ipython . * Override the LESS options completely instead of appending to it . * Add auto-completion support for datatypes in CREATE , SELECT etc . ( Thanks : ` Darik Gamble ` _ ) * Add an ipython magic extension to embed pgcli inside ipython . * Faster rendering of expanded mode output by making the horizontal separator a fixed length string . fuzzy match works like the fuzzy open in SublimeText or Vim 's Ctrl-P plugin . * Add \timing command to time the sql commands . * Upgrade to prompt_toolkit version 0.26 ( Thanks : https : //github.com/macobo ) query = ( special.get_editor_query ( document.text ) or * Completion suggestions for the `` \c `` command are not auto-escaped by default . * Add \timing command to time the sql commands . * Change the timing information to seconds . * Results from a pgcli query are sent back to ipython . Add this line to your config file ( ~/.pgclirc ) to customize where to store the history file . fuzzy match works like the fuzzy open in SublimeText or Vim 's Ctrl-P plugin . * Change Postgres adapter to psycopg2cffi , to make it PyPy compatible . * Add fuzzy matching for the table names and column names . * Add \ds special command to show sequences . * Faster rendering of expanded mode output by making the horizontal separator a fixed length string . return self.query_history [ -1 ] [ 0 ] if self.query_history else None * Add an ipython magic extension to embed pgcli inside ipython . * Add -d/ -- dbname option to the commandline . * Change the timing information to seconds . eg : When you type 'mig ' , 'django_migrations ' will be suggested . When `` on_error = STOP `` in the config file , pgcli will abort execution if one of the queries results in an error . * Add \ds special command to show sequences . * Make column name display unicode compatible . * Add LIMIT keyword to completion . * Opening an external editor will edit the last-run query . ( Thanks : ` Thomas Roten ` _ ) .. _ ` Daniel Rocco ` : https : //github.com/drocco007 .. _ ` Sergii ` : https : //github.com/foxyterkel * Add LIMIT keyword to completion . * Add -d/ -- dbname option to the commandline . * Add auto-completion support for datatypes in CREATE , SELECT etc . ( Thanks : ` Darik Gamble ` _ ) * Add different table styles for displaying output . * Make column name display unicode compatible . * Complete refactor of handling the back-slash commands . .. _ ` Jay Zeng ` : https : //github.com/jayzeng statements are separated by semi-colon in the same line . sql=document.text ) * Add completion for TEMPLATE keyword and smart-completion for Functions that return table like results will now be suggested in places of tables . eg : When you type 'mig ' , 'django_migrations ' will be suggested . .. _ ` Sergii ` : https : //github.com/foxyterkel .. _ ` Brett Atoms ` : https : //github.com/brettatoms * Display NULL values as < null > instead of empty strings . * Add fuzzy matching for the table names and column names . * Completion suggestions for the `` \c `` command are not auto-escaped by default . sql , message = special.open_external_editor ( filename , sql=query ) * Better unicode handling for datatypes , dbname and roles . .. _ ` Daniel Rocco ` : https : //github.com/drocco007 * Override the LESS options completely instead of appending to it . self.get_last_query ( ) ) def get_last_query ( self ) : .. _ ` Brett Atoms ` : https : //github.com/brettatoms eg : sql , message = special.open_external_editor ( filename , * * Add completion for TEMPLATE keyword and smart-completion for * Add confirmation before printing results that have more than 1000 rows . * Better unicode handling for datatypes , dbname and roles . statements are separated by semi-colon in the same line . `` `` '' Get the last query executed or None . '' '' '' * * Complete refactor of handling the back-slash commands . * Add different table styles for displaying output . * Upgrade to prompt_toolkit version 0.26 ( Thanks : https : //github.com/macobo ) * Add confirmation before printing results that have more than 1000 rows . Add this line to your config file ( ~/.pgclirc ) to customize where to store the history file . * Revert back to using psycopg2 as the postgres adapter . psycopg2cffi fails for some tests in Python 3 . * Change Postgres adapter to psycopg2cffi , to make it PyPy compatible . * Revert back to using psycopg2 as the postgres adapter . psycopg2cffi fails for some tests in Python 3 . eg : * Display NULL values as < null > instead of empty strings .","['changelog.rst', 'pgcli/main.py']",Merge pull request # 710 from dbcli/tsroten/edit_last_command
206,11959265eef44ec984297aa3a5ee39ca5e8e3ffa,2017-05-06 14:36:59-07:00,"List databases . List indexes . List sequences . \pset [ key ] [ value ] List roles . Delete a named query . Execute commands from file . List views . * Behave fix pgspecial update ( Thanks : ` Dick Marinus ` _ ) . List tables . \d [ pattern ] Save a named query . \n [ + ] [ name ] [ param1 param2 ... ] \h Show SQL syntax and help . \dx [ + ] [ pattern ] \n [ + ] [ name ] \x List functions . \x List schemas . \db [ + ] [ pattern ] Send all query results to file . \sf [ + ] FUNCNAME A limited version of traditional \pset \o [ filename ] Show a function 's definition . \i filename Toggle timing of commands . \copy [ tablename ] to/from [ filename ] Edit the query with external editor . Change to a new database . List data types \dm [ + ] [ pattern ] Show Commands . Refresh auto-completions . List or execute named queries . List or describe tables , views and sequences . | Set PAGER . Pring the query results via PAGER . | List tablespaces . Description Toggle expanded output . List extensions . Copy data between a file and a table . List materialized views . \d [ + ] [ pattern ] \pager [ command ]","['changelog.rst', 'tests/features/fixture_data/help_commands.txt']",Merge pull request # 713 from dbcli/feature/fix_pgspecial_update
207,bb9d8ac38ef76599b39942835bcd82694f7b4f53,2017-05-02 15:06:35-07:00,"Scenario : run the cli When we refresh completions wrappers.expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) When we send `` \ ? '' command then we see dbcli prompt context.cli = pexpect.spawnu ( cli_cmd , cwd= ' .. ' ) `` `` '' Make sure prompt is displayed . '' '' '' and we start external editor providing a file name cli_cmd = context.conf.get ( 'cli_command ' ) * Behave remove boiler plate code ( Thanks : ` Dick Marinus ` _ ) . When we run dbcli `` `` '' context.cli = pexpect.spawnu ( cli_cmd , cwd= ' .. ' ) and we connect to test database run_cli ( context ) expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) from steps.wrappers import run_cli , wait_prompt When we start external editor providing a file name def run_cli ( context ) : import pexpect context.currentdb = context.conf [ 'dbname ' ] Run the process using pexpect . context.exit_sent = False def before_scenario ( context , _ ) : Make sure prompt is displayed . context.currentdb = context.conf [ 'dbname ' ] wrappers.run_cli ( context ) When we send `` ctrl + d '' and we wait for prompt and we create database wait_prompt ( context ) and we send `` \ ? '' command and we send `` ctrl + d '' and we send source command When we connect to test database import pexpect `` `` '' Run the process using pexpect . '' '' '' When we send source command When we create database When we tee output wrappers.wait_prompt ( context ) and we tee output context.exit_sent = False def wait_prompt ( context ) : cli_cmd = context.conf.get ( 'cli_command ' ) and we refresh completions","['changelog.rst', 'tests/features/__init__.py', 'tests/features/basic_commands.feature', 'tests/features/crud_database.feature', 'tests/features/crud_table.feature', 'tests/features/environment.py', 'tests/features/iocommands.feature', 'tests/features/named_queries.feature', 'tests/features/specials.feature', 'tests/features/steps/__init__.py', 'tests/features/steps/basic_commands.py', 'tests/features/steps/wrappers.py']",Merge pull request # 709 from dbcli/feature/behave_remove_boiler_plat_code
208,2e4b907b19403960bcb0882b150c732e5d47ec5d,2017-04-30 16:12:27-07:00,"# Always raise operational errors , regardless of on_error if ( isinstance ( e , psycopg2.OperationalError ) if ( self._must_raise ( e ) `` OperationalError `` s are raised for errors that are not under the def _must_raise ( self , e ) : `` `` '' Return true if e is an error that should not be caught in `` run `` . return ( isinstance ( e , psycopg2.OperationalError ) and import psycopg2.errorcodes user to reconnect . We * do * want to catch OperationalErrors caused by a psycopg2.errorcodes.lookup ( e.pgcode ) ! = 'LOCK_NOT_AVAILABLE ' ) : return : Bool . True if `` run `` must raise this exception . which we should n't catch ; we handle uncaught errors by prompting the control of the programmer . Usually that means unexpected disconnects , : param e : DatabaseError . An exception raised while executing a query . * Improve handling of `` lock_not_available `` error ( issue # 700 ) . ( Thanks : ` Jackson Popkin < https : //github.com/jdpopkin > ` _ ) lock being unavailable , as reconnecting wo n't solve that problem . # specification * Jackson Popkin `` `` ''","['AUTHORS', 'changelog.rst', 'pgcli/pgexecute.py']",Merge pull request # 701 from jdpopkin/fix_lock_error
209,43f072f16f4e21c2a19ec1f7fa7eb73667f102f4,2017-04-29 15:27:44-07:00,"Edit file with external editor . context.editor_file_name = [ wrappers.expect_exact ( context , 'Entering Ex mode . Type `` visual '' to go to Normal mode . ' , timeout=2 ) if context.editor_file_name and os.path.exists ( context.editor_file_name ) : context , 'Entering Ex mode . Type `` visual '' to go to Normal mode . ' , timeout=2 ) if os.path.exists ( context.editor_file_name ) : * Behave fix clean up . ( Thanks : ` Dick Marinus ` _ ) . `` `` '' context.cli.sendline ( '\e { 0 } '.format ( context.editor_file_name [ 1 ] ) ) context.cli.sendline ( '\e { 0 } '.format ( context.editor_file_name ) ) 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) import os.path ' .. ' , context.editor_file_name = 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) if os.path.exists ( os.path.join ( * context.editor_file_name ) ) : ] os.remove ( os.path.join ( * context.editor_file_name ) ) wrappers.expect_exact ( os.remove ( context.editor_file_name ) if os.path.join ( * context.editor_file_name ) and os.path.exists ( os.path.join ( * context.editor_file_name ) ) : `` `` '' Edit file with external editor . '' '' ''","['changelog.rst', 'tests/features/steps/iocommands.py']",Merge pull request # 703 from dbcli/feature/behave_fix_cleanup
210,b2a22580a6c25d686efbb46730f429bf6b188ed3,2017-04-29 14:51:48-07:00,"with open ( os.path.join ( * context.tee_file_name ) ) as f : context.atprompt = True and we notee output def step_query_select_123456 ( context ) : if os.path.exists ( os.path.join ( * context.tee_file_name ) ) : def step_tee_ouptut ( context ) : then we see 123456 in tee output wrappers.expect_exact ( context , `` Time '' , timeout=5 ) def step_notee_output ( context ) : Scenario : tee output from query context , context.conf [ 'pager_boundary ' ] + '\r\n ' , timeout=5 ) and we tee output context.cli.sendline ( 'notee ' ) and we wait for prompt context.cli.sendline ( 'select 123456 ' ) ' .. ' , When we run dbcli context.cli.sendline ( '\o { 0 } '.format ( context.tee_file_name [ 1 ] ) ) ] context.tee_file_name = [ os.remove ( os.path.join ( * context.tee_file_name ) ) wrappers.expect_exact ( assert '123456 ' in f.read ( ) 'tee_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) and we query `` select 123456 '' wrappers.expect_exact ( context , `` Writing to file '' , timeout=5 ) * Test using behave the tee command ( Thanks : ` Dick Marinus ` _ ) . def step_see_123456_in_ouput ( context ) :","['changelog.rst', 'tests/features/iocommands.feature', 'tests/features/steps/iocommands.py']",Merge pull request # 706 from dbcli/feature/behave_tee
211,5508d725b92284b78f3fc5c30db448ba68e3c4dd,2017-04-29 15:47:33-04:00,"`` AGGREGATE '' , assert expected == set ( suggestions ) `` VARCHAR '' : [ ] , `` ALTER TABLE '' , text = 'ALTER ' assert Keyword ( 'ALTER ' ) in set ( suggest_type ( sql , sql ) ) `` VIEW '' `` keywords '' : { assert set ( suggestions ) == cols_etc ( 'tabl ' , 'sch ' , last_keyword='SELECT ' ) Keyword ( 'SELECT ' ) Function ( schema=None ) , `` COLLATION '' , `` BETWEEN '' , keywords = tuple ( set ( chain ( keywords_tree.keys ( ) , * keywords_tree.values ( ) ) ) ) `` INTEGER '' : [ ] , `` LEVEL '' , `` SHARE '' , `` EXISTS '' : [ ] , Column ( table_refs= ( ) , qualifiable=True ) , `` EVENT TRIGGER '' , `` CHAR '' : [ ] , `` keywords '' : [ assert set ( suggestions ) == cols_etc ( 'tabl ' ) last_keyword ) : `` HAVING '' : [ ] , `` AUDIT '' : [ ] , `` CURRENT '' , `` FORCE_QUOTE '' : [ ] , `` INDEX '' : [ ] , `` LEVEL '' : [ ] , `` VALUES '' , `` ESCAPE '' : [ ] , `` FORMAT '' , `` LEFT '' : [ ] , assert set ( suggestions ) == cols_etc ( ' b ' , last_keyword='SELECT ' ) `` OR REPLACE '' , `` START '' , 'func ' , is_function=True , last_keyword='SELECT ' ) `` PCTFREE '' : [ ] , `` FOREIGN '' , `` SET '' : [ ] , `` UNLOGGED '' , 'SELECT DISTINCT ' `` ONLINE '' , `` NOT '' : [ ] , `` FOR '' , `` EXTENSION '' , `` INSERT INTO '' , `` IF NOT EXISTS '' , `` UNIQUE '' : [ ] , `` FILE '' : [ ] , complete_event , Keyword ( 'SELECT ' ) , `` MAXEXTENTS '' : [ ] , def test_distinct_and_order_by_suggestions_with_aliases ( text , text_before ) : Keyword.__new__.__defaults__ = ( None , ) assert set ( suggestions ) == cols_etc ( 'tabl ' , alias= ' '' tabl '' ' ) `` NOCOMPRESS '' : [ ] , `` DECIMAL '' : [ ] , ( '\\ns abc SELECT foo ' , 'SELECT foo ' , ( Keyword ( ) , ) ) , `` CONCURRENTLY '' : [ ] , def cols_etc ( table , schema=None , alias=None , is_function=False , parent=None , `` PCTFREE '' , position = len ( text ) `` MINUS '' : [ ] , `` CASE '' : [ ] , `` TO '' , `` WHEN '' , `` DROP '' , `` IS '' : [ ] , `` GROUP BY '' : [ ] , `` TRANSFORM '' , `` DELETE FROM '' : [ ] , `` TEMPLATE '' : [ ] , `` `` '' Where ` literal_type ` is one of 'keywords ' , 'functions ' , 'datatypes ' , `` ELSE '' : [ ] , Completion ( text= '' SYSTEM '' , display_meta='keyword ' ) , `` FOR '' : [ ] , `` OPERATOR '' , `` RIGHT '' , assert set ( suggestions ) == cols_etc ( 'tabl ' , last_keyword='SELECT ' ) `` NOWAIT '' : [ ] , `` BEGIN '' : [ ] , `` OFFLINE '' : [ ] , `` VALUES '' : [ ] , `` CLUSTER '' , `` INCREMENT '' : [ ] , `` DROP '' : [ `` FORCE_NOT_NULL '' , `` ENCODING '' : [ ] , assert result > set ( [ `` EXCLUSIVE '' : [ ] , def get_literals ( literal_type , type_=tuple ) : `` MATERIALIZED VIEW '' , `` RENAME '' , `` OIDS '' , `` DEFAULT '' , `` FLOAT '' : [ ] , `` GROUP '' , `` PRIOR '' , `` TRIGGER '' , assert set ( suggestions ) == cols_etc ( 'foo ' ) `` INTERSECT '' : [ ] , `` UPDATE '' , return tuple ( literals [ literal_type ] ) `` OUTER '' : [ ] , `` POLICY '' , `` CREATE '' , `` COLUMN '' , `` COPY '' : [ ] , `` NOT '' , `` USER MAPPING '' , `` IMMEDIATE '' , `` INDEX '' , `` ROWS '' : [ ] , `` TRUNCATE '' , # keywords_tree : A dict mapping keywords to well known following keywords . `` PRIVILEGES '' , `` NUMBER '' : [ ] , `` NOCOMPRESS '' , `` LANGUAGE '' , `` EXPLAIN '' : [ ] , `` BY '' , `` PRIVILEGES '' : [ ] , `` WHENEVER '' , `` JOIN '' : [ ] , `` COLUMN '' , `` UID '' : [ ] , def test_alter_well_known_keywords_completion ( completer , complete_event ) : `` USING '' : [ ] , `` SMALLINT '' : [ ] , keywords = next_keywords assert set ( suggestions ) == cols_etc ( 'tabl ' , 'sch ' ) ( '\\ns abc SELECT foo ' , 'SELECT foo ' , ( Keyword ( ) , ) ) , `` DOMAIN '' , `` VARCHAR2 '' : [ ] , `` OFFLINE '' , `` ELSE '' , `` CASE '' , `` RAW '' , `` DATE '' , `` NOTICE '' , `` GLOBAL '' , `` THEN '' , `` UNION '' , `` AS '' : [ ] , `` QUOTE '' , `` HEADER '' , `` NULL '' , `` SELECT '' , `` ROWNUM '' , `` AND '' , `` ROW '' : [ ] , `` ANY '' : [ ] , 'func ' , is_function=True ) `` SESSION '' , `` WHEN '' : [ ] , `` NOTICE '' : [ ] , `` FORCE_NOT_NULL '' : [ ] , } , `` LEFT '' , `` CHECK '' : [ ] , assert set ( suggestions ) == set ( [ Keyword ( ) ] ) * Narrow keyword candidates based on previous keyword . ( Thanks : ` Étienne Bersac ` _ ) `` ROWID '' , 'SELECT ' , `` LIKE '' : [ ] , `` INTEGER '' , `` MLSLABEL '' : [ ] , `` ALL '' , @ pytest.mark.parametrize ( 'text , text_before ' , [ `` AUDIT '' , `` DESCRIBE '' , `` REFRESH MATERIALIZED VIEW '' , `` NUMBER '' , `` NOAUDIT '' : [ ] , `` OF '' , `` PRIMARY '' : [ ] , `` START '' : [ ] , `` FOREIGN EXTENSION '' , `` SIZE '' , `` MINUS '' , returns a tuple of literal values of that type '' '' '' `` LIMIT '' : [ ] , return [ keyword ( kw , pos ) for kw in self.completer.keywords ] `` INTERVAL '' , `` DISTINCT '' , from itertools import count , repeat , chain `` ASC '' , elif token_v == 'alter ' : Function ( schema=None ) , `` COMPRESS '' : [ ] , `` FREEZE '' : [ ] , `` ADD '' , `` FULL '' : [ ] , `` RIGHT '' : [ ] , # candidates to this list . assert set ( suggestions ) == cols_etc ( 'foo ' , last_keyword='WHERE ' ) return ( Keyword ( token_v.upper ( ) ) , ) `` INTERVAL '' : [ ] , `` VIEW '' , `` OR '' : [ ] , return type_ ( literals [ literal_type ] ) `` MODE '' , `` SET '' , `` RAW '' : [ ] , `` EXTENSION '' , `` INTO '' , `` SYNONYM '' : [ ] , Keyword ( ) `` GRANT '' : [ ] , `` ACCESS METHOD '' , `` RAISE '' , `` EXCLUSIVE '' , `` BETWEEN '' : [ ] , `` TYPE '' , `` OUTER '' , `` REFRESH MATERIALIZED VIEW '' : [ ] , `` LOCAL '' , `` DESC '' , `` CHECK '' , `` SYNONYM '' , `` CONCURRENTLY '' , `` USE '' : [ ] , `` FOREIGN TABLE '' , `` ON '' , .. _ ` Étienne Bersac ` : https : //github.com/bersace `` COMPRESS '' , `` IN '' : [ ] , `` LONG '' : [ ] , `` DECIMAL '' , Keyword ( ) , `` UID '' , Completion ( text= '' TABLE '' , display_meta='keyword ' ) , Keyword ( ) ] ) from itertools import count , repeat keywords = [ k.lower ( ) for k in self.keywords ] `` CURRENT '' : [ ] , `` SELECT '' : [ ] , `` UPDATE '' : [ ] , `` TABLESPACE '' , assert set ( suggestions ) == set ( [ Keyword ( ) , Special ( ) ] ) `` FULL '' , `` AS '' , `` SYSDATE '' , Keyword ( ) , Completion ( text= '' DATABASE '' , display_meta='keyword ' ) , def cols_etc ( table , schema=None , alias=None , is_function=False , parent=None ) : next_keywords = self.keywords_tree.get ( suggestion.last_token , [ ] ) `` SIZE '' : [ ] , `` FLOAT '' , `` QUOTE '' : [ ] , assert Keyword ( ) in set ( suggest_type ( sql , sql ) ) `` CAST '' , `` OR '' , `` IS '' , `` PRIOR '' : [ ] , `` REPLACE '' , keywords = [ k.lower ( ) for k in keywords ] `` CONNECT '' : [ ] , assert Completion ( text= '' CREATE '' , display_meta= '' keyword '' ) not in result `` FOREIGN DATA WRAPPER '' , Keyword ( last_keyword ) # e.g . 'CREATE ' : [ 'TABLE ' , 'USER ' , ... ] , def get_keyword_matches ( self , _ , word_before_cursor ) : `` SYSDATE '' : [ ] , assert set ( suggestions ) == cols_etc ( ' a ' , last_keyword='SELECT ' ) `` VIEW '' : [ ] , return [ keyword ( kw , pos ) for kw in self.completer.keywords_tree.keys ( ) ] `` LANGUAGE '' : [ ] , `` UNION '' : [ ] , `` NOAUDIT '' , Document ( text=text , cursor_position=position ) , return ( Keyword ( ) , ) Keyword = namedtuple ( 'Keyword ' , [ ] ) `` ONLINE '' : [ ] , if next_keywords : `` USE '' , `` MATERIALIZED VIEW '' : [ ] , `` EXISTS '' , `` EXPLAIN '' , `` OF '' : [ ] , `` INTERSECT '' , `` MODIFY '' , `` ROWS '' , `` IDENTIFIED '' , keywords = [ k.upper ( ) for k in keywords ] ] , `` ESCAPE '' , `` CONVERSION '' , keywords_tree = get_literals ( 'keywords ' , type_=dict ) `` SHOW '' : [ ] , def get_literals ( literal_type ) : `` DATE '' : [ ] , `` ROWNUM '' : [ ] , `` WHENEVER '' : [ ] , `` RESOURCE '' , `` MLSLABEL '' , `` WHERE '' : [ ] , `` SERVER '' , `` UNIQUE '' , `` IN '' , `` DATABASE '' , `` SEQUENCE '' , * Étienne BERSAC ( bersace ) `` ANY '' , keywords = get_literals ( 'keywords ' ) `` FORMAT '' : [ ] , `` DESCRIBE '' : [ ] , `` SESSION '' : [ ] , `` ROW '' , `` WHERE '' , `` FROM '' : [ ] , `` TABLE '' , `` ADD '' : [ ] , assert set ( suggestions ) == cols_etc ( ' a ' ) `` SUCCESSFUL '' : [ ] , `` VALIDATE '' : [ ] , `` SYSTEM '' , `` FREEZE '' , `` WITH '' : [ ] `` INSERT INTO '' : [ ] , assert set ( suggestions ) == cols_etc ( 'tabl ' , last_keyword='WHERE ' ) def test_distinct_and_order_by_suggestions_with_aliases ( text , text_before , `` NULL '' : [ ] , `` LIMIT '' , `` OIDS '' : [ ] , ] ) `` RAISE '' : [ ] , `` OWNER '' , Keyword ( last_keyword ) ] ) `` DESC '' : [ ] , `` THEN '' : [ ] , `` LONG '' , `` INITIAL '' : [ ] , smart_completion=True ) ) keywords = [ k.upper ( ) for k in self.keywords ] `` RETURNS '' , `` COMMENT '' : [ ] , `` DEFAULT '' : [ ] , `` RULE '' , `` MODIFY '' : [ ] , `` HAVING '' , `` REVOKE '' , `` CREATE '' : [ Keyword ( ) , ) `` INITIAL '' , `` DELETE FROM '' , Column ( table_refs= ( ) , qualifiable=True ) , `` MAXEXTENTS '' , `` LARGE OBJECT '' , `` FROM '' , `` RETURNS '' : [ ] , `` DISTINCT '' : [ ] , 'SELECT DISTINCT ' , `` FUNCTION '' , `` TRUNCATE '' : [ ] , last_keyword=None ) : `` ROWID '' : [ ] , `` TEMPORARY '' , `` ROLE '' , `` JOIN '' , `` DELIMITER '' : [ ] , `` WITH '' 'BY ' , `` RESET '' : [ `` ALL '' ] , `` ALL '' : [ ] , `` NOWAIT '' , `` USING '' , `` ACCESS '' : [ ] , `` OWNED '' , `` REVOKE '' : [ ] , `` DELIMITER '' , `` SUCCESSFUL '' , `` ENCODING '' , `` ACCESS '' , `` TRIGGER '' : [ ] , `` FILE '' , Keyword ( token_v.upper ( ) ) , ) `` LANGUAGE '' , `` OWNER '' : [ ] , `` SMALLINT '' , `` TO '' : [ ] , `` USER '' , `` TABLE '' : [ ] , `` RENAME '' : [ ] , `` ORDER BY '' : [ ] , `` USER '' : [ ] , `` MATERIALIZED VIEW '' , `` VALIDATE '' , `` OPTION '' : [ ] , `` VARCHAR '' , Keyword ( 'DISTINCT ' ) `` DATABASE '' , `` COMMENT '' , expected = cols_etc ( 'tabl ' , alias= ' '' tabl '' ' , last_keyword='WHERE ' ) return ( Keyword ( ) , ) `` PRIMARY '' , Keyword = namedtuple ( 'Keyword ' , [ 'last_token ' ] ) `` LOCK '' , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' elif token_v in { 'alter ' , 'create ' , 'drop ' } : `` TEXT SEARCH '' , `` DEFAULT '' , `` USER '' , `` INDEX '' , `` ON '' : [ ] , ] , `` IMMEDIATE '' : [ ] , `` ORDER BY '' , `` ALTER '' : [ `` SCHEMA '' , `` INCREMENT '' , `` COLUMN '' : [ ] , # Where ` literal_type ` is one of 'keywords ' , 'functions ' , 'datatypes ' , `` INTO '' : [ ] , `` TEMPLATE '' , # returns a tuple of literal values of that type . `` FORCE_QUOTE '' , `` FUNCTION '' : [ ] , `` VARCHAR2 '' , `` TRIGGER '' , `` REPLACE '' : [ ] , `` GRANT '' , `` LIKE '' , `` CLUSTER '' : [ ] , `` BY '' : [ ] , `` LOCK '' : [ ] , return ( Keyword ( token_v.upper ( ) ) , ) `` MODE '' : [ ] , `` FUNCTION '' , `` GROUP BY '' , `` OPTION '' , result = set ( completer.get_completions ( keywords = self.keywords_tree.keys ( ) `` UNIQUE '' , `` SHARE '' : [ ] , `` AND '' : [ ] , `` IDENTIFIED '' : [ ] , `` TABLE '' , `` EXTENSION '' : [ ] , `` HEADER '' : [ ] , `` ASC '' : [ ] , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' , `` RESOURCE '' : [ ] , # Get well known following keywords for the last token . If any , narrow `` CONNECT '' , def get_keyword_matches ( self , suggestion , word_before_cursor ) : `` CHAR '' , assert set ( suggestions ) == cols_etc ( ' b ' ) `` DATABASE '' : [ ] , `` COPY '' ,","['AUTHORS', 'changelog.rst', 'pgcli/packages/pgliterals/main.py', 'pgcli/packages/pgliterals/pgliterals.json', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/metadata.py', 'tests/test_naive_completion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 693 from bersace/well-known-following-keywords
212,e4d75fcfb6901af25f51261085a3da6ea770553e,2017-04-28 23:28:50-07:00,"wrappers.expect_exact ( Scenario : run source command f.write ( b'\ ? ' ) and we send source command import tempfile context.cli.sendline ( '\i { 0 } '.format ( f.name ) ) When we run dbcli * Behave test source command ( Thanks : ` Dick Marinus ` _ ) . def step_send_source_command ( context ) : context , context.conf [ 'pager_boundary ' ] + '\r\n ' , timeout=5 ) f.flush ( ) context.cli.logfile = open ( '/tmp/dmtest ' , ' a ' ) then we see help output with tempfile.NamedTemporaryFile ( ) as f : and we wait for prompt","['changelog.rst', 'tests/features/basic_commands.feature', 'tests/features/steps/basic_commands.py']",Merge pull request # 699 from dbcli/feature/behave_source_command
213,7eef21e3d371bd2a87bcd8a170e162991fa9cef1,2017-04-28 09:27:14-07:00,"context.cli.sendcontrol ( ' c ' ) wrappers.expect_pager ( context , 'CREATE DATABASE\r\n ' , timeout=5 ) context.cli.expect_exact ( context.atprompt = True context.atprompt = False wrappers.expect_exact ( context , 'DROP DATABASE ' , timeout=2 ) `` `` '' Cleans up after each test complete . '' '' '' context.cli.expect_exact ( pexpect.EOF , timeout=5 ) ) wrappers.expect_exact ( context , 'CREATE DATABASE ' , timeout=2 ) def before_step ( context , _ ) : dbname = context.currentdb context.cli.terminate ( ) `` `` '' timeout=5 context.currentdb = 'postgres ' import pexpect # Quit nicely . * Behave quit pgcli nicely ( Thanks : ` Dick Marinus ` _ ) . if not context.atprompt : context.currentdb = context.conf [ 'dbname ' ] Cleans up after each test complete . wrappers.expect_pager ( context , 'DROP DATABASE\r\n ' , timeout=2 ) ' { 0 } > '.format ( dbname ) , context.cli.sendcontrol ( ' u ' ) # Terminate nicely . context.cli.sendcontrol ( 'd ' )","['changelog.rst', 'tests/features/environment.py', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/iocommands.py']",Merge pull request # 698 from dbcli/feature/behave_quit_nicely
214,219b4a52d950255010b072634a9102b49982dc09,2017-04-27 21:32:44+02:00,"# returns a tuple of literal values of that type . assert expected == set ( suggestions ) Function ( schema=None ) , Column ( table_refs= ( ) , qualifiable=True ) , Function ( schema=None ) , # Where ` literal_type ` is one of 'keywords ' , 'functions ' , 'datatypes ' , `` `` '' Where ` literal_type ` is one of 'keywords ' , 'functions ' , 'datatypes ' , Keyword ( 'SELECT ' ) , expected = cols_etc ( 'tabl ' , alias= ' '' tabl '' ' , last_keyword='WHERE ' ) returns a tuple of literal values of that type '' '' '' assert set ( suggestions ) == cols_etc ( 'tabl ' , alias= ' '' tabl '' ' , last_keyword='WHERE ' ) Column ( table_refs= ( ) , qualifiable=True ) , Keyword ( 'SELECT ' ) ,","['pgcli/packages/pgliterals/main.py', 'tests/test_sqlcompletion.py']",Fix PEP8 for # 693
215,7858cbc4736a9caaa3cfb0274695a29cf04eb319,2017-04-27 11:05:29-07:00,.. _ ` Dick Marinus ` : https : //github.com/meeuw pip install . docutils pytest mock codecov==1.5.1 behave pexpect==3.3 pip install . pytest mock codecov==1.5.1 behave pexpect==3.3 rst2html.py -- halt=warning changelog.rst > /dev/null ======== ======= ===== # check for changelog ReST compliance,"['.travis.yml', 'changelog.rst']",Merge pull request # 694 from bersace/changelog
216,c9ade68443fe0195003ebcb7e62dbda94d35dc84,2017-04-27 11:04:27-07:00,"you need to contribute to ` pgspecial < https : //github.com/pgcli/pgspecial/ > ` _ For example , ` \l ` is a meta-command that lists all the databases . The way you is to launch ` psql -E ` and entering ` \l ` . can see the SQL statement issued by PostgreSQL when this command is executed dictionary called ` CASE_SENSITIVE_COMMANDS ` . The special command us used as it 's a series of sql statements that feed the results to each other to get to to produce that result . In most cases it 's a single sql statement , but sometimes command itself with possible options and the second item is the plain english the dictionary key , and the value is a tuple . for that special command . The list will have two items , the first item is the The first item in the tuple is either a string ( sql statement ) or a function . description of that command . you 'll be changing the code of ` packages/pgspecial.py ` . Search for the The second item in the tuple is a list of strings which is the documentation project . the final result . That will print the results and also print the sql statement that was executed",['DEVELOP.rst'],Merge pull request # 692 from bersace/pgspecial
217,bad238f9964b31ceb3f1801d7a5e47c1b2549383,2017-04-26 11:01:32-07:00,"TableReference ( None , 'tbl ' , ' x ' , False ) , qualifiable=True ) , def test_distinct_and_order_by_suggestions_with_alias_given ( text , text_before ) : 'SELECT DISTINCT x . FROM tbl x JOIN tbl1 y ' , * Completions after ORDER BY and DISTINCT now take account of table aliases . ( Thanks : ` Owen Stephens ` _ ) qualifiable=False table_refs= ( TableReference ( None , 'tbl ' , ' x ' , False ) , ) , Column ( Table ( schema= ' x ' ) , View ( schema= ' x ' ) , return ( Column ( table_refs=stmt.get_tables ( ) , Function ( schema=None ) , 'SELECT DISTINCT x . ' 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' , ( Column ( table_refs= ( ) , local_tables= ( ) , qualifiable=True ) , Keyword ( ) select . '' '' '' table_refs= ( ] ) suggestions = suggest_type ( text , text_before ) assert suggestions == ( Column ( table_refs= ( ) , qualifiable=True ) , ) ) , 'SELECT DISTINCT ' Function ( schema= ' x ' ) , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' local_tables= ( ) , elif token_v in ( 'select ' , 'where ' , 'having ' , 'by ' , 'distinct ' ) : ) , elif token_v in ( 'select ' , 'where ' , 'having ' ) : elif token_v in ( 'by ' , 'distinct ' ) : ] ) local_tables=stmt.local_tables , qualifiable=True ) , ) 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . ' , # Returns the expected select-clause suggestions for a single-table select 'SELECT DISTINCT FROM tbl x JOIN tbl1 y ' , `` `` '' Returns the expected select-clause suggestions for a single-table ) assert set ( suggestions ) == set ( [ def test_distinct_and_order_by_suggestions_with_aliases ( text , text_before ) : TableReference ( None , 'tbl1 ' , ' y ' , False ) , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . '","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 686 from owst/column_completion_for_order_by_and_distinct
218,3d560baf6c84070da60fb0552722bb86db78a90e,2017-04-26 01:10:57+01:00,"TableReference ( None , 'tbl ' , ' x ' , False ) , qualifiable=True ) , def test_distinct_and_order_by_suggestions_with_alias_given ( text , text_before ) : 'SELECT DISTINCT x . FROM tbl x JOIN tbl1 y ' , * Completions after ORDER BY and DISTINCT now take account of table aliases . ( Thanks : ` Owen Stephens ` _ ) qualifiable=False table_refs= ( TableReference ( None , 'tbl ' , ' x ' , False ) , ) , Column ( Table ( schema= ' x ' ) , View ( schema= ' x ' ) , return ( Column ( table_refs=stmt.get_tables ( ) , Function ( schema=None ) , 'SELECT DISTINCT x . ' 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' , ( Column ( table_refs= ( ) , local_tables= ( ) , qualifiable=True ) , Keyword ( ) select . '' '' '' table_refs= ( ] ) suggestions = suggest_type ( text , text_before ) assert suggestions == ( Column ( table_refs= ( ) , qualifiable=True ) , ) ) , 'SELECT DISTINCT ' Function ( schema= ' x ' ) , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY ' local_tables= ( ) , elif token_v in ( 'select ' , 'where ' , 'having ' , 'by ' , 'distinct ' ) : ) , elif token_v in ( 'select ' , 'where ' , 'having ' ) : elif token_v in ( 'by ' , 'distinct ' ) : ] ) local_tables=stmt.local_tables , qualifiable=True ) , ) 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . ' , # Returns the expected select-clause suggestions for a single-table select 'SELECT DISTINCT FROM tbl x JOIN tbl1 y ' , `` `` '' Returns the expected select-clause suggestions for a single-table ) assert set ( suggestions ) == set ( [ def test_distinct_and_order_by_suggestions_with_aliases ( text , text_before ) : TableReference ( None , 'tbl1 ' , ' y ' , False ) , 'SELECT * FROM tbl x JOIN tbl1 y ORDER BY x . '","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Suggest columns for ` ORDER BY ` and ` DISTINCT ` ( fixes # 685 )
219,a238f0a891031261dd735e82d7713937155f1384,2017-04-25 14:08:49-07:00,"elif cmd [ 1 : ] in SPECIALS_SUGGESTION : } SPECIALS_SUGGESTION = { # \d can descibe tables or views 'dT ' : Datatype , 'sf ' : Function , } [ cmd [ 1 : ] ] 'dT ' : Datatype , 'dv ' : View , 'df ' : Function , 'dv ' : View , 'dt ' : Table , # \d can describe tables or views rel_type = { 'dt ' : Table , elif cmd [ 1 : ] in ( 'dt ' , 'dv ' , 'df ' , 'dT ' ) : 'df ' : Function , rel_type = SPECIALS_SUGGESTION [ cmd [ 1 : ] ]",['pgcli/packages/sqlcompletion.py'],Merge pull request # 688 from lelit/slash_sf
220,b9ad881b67a1f64c2303eb0bb1b2145f32475ea6,2017-04-25 08:10:50-07:00,"| yyy |\r wrappers.expect_exact ( context , 'DELETE 1 ' , timeout=2 ) wrappers.expect_exact ( context , 'INSERT 0 1 ' , timeout=2 ) | x |\r context.conf [ 'pager_boundary ' ] wrappers.expect_pager ( context , 'CREATE TABLE\r\n ' , timeout=2 ) wrappers.expect_exact ( context , 'UPDATE 1 ' , timeout=2 ) \r wrappers.expect_pager ( context.conf [ 'pager_boundary ' ] , expected ) , timeout=timeout ) timeout=1 ) dedent ( `` '\ print ( boundary ) def wrappager ( boundary ) : wrappers.expect_pager ( context , 'INSERT 0 1\r\n ' , timeout=2 ) wrappers.expect_pager ( context , 'DROP TABLE\r\n ' , timeout=2 ) if __name__ == `` __main__ '' : ' -c `` import coverage ; coverage.process_startup ( ) ; import pgcli.main ; pgcli.main.cli ( ) '' ' , wrappers.expect_exact ( context , 'CREATE TABLE ' , timeout=2 ) import sys wrappers.expect_exact ( context , 'foo : Deleted ' , timeout=1 ) if not buf : sys.stdout.write ( buf ) wrappers.expect_exact ( context , 'Saved . ' , timeout=1 ) expect_exact ( context , `` { 0 } \r\n { 1 } { 0 } \r\n '' .format ( from textwrap import dedent wrappers.expect_exact ( context , 'SELECT 1 ' , timeout=1 ) wrappers.expect_pager ( context , 'foo : Deleted\r\n ' , timeout=1 ) | -- -- -|\r wrappers.expect_pager ( context , 'UPDATE 1\r\n ' , timeout=2 ) context , 'Auto-completion refresh started in the background.\r\n ' , timeout=2 ) 'pager_boundary ' : ' -- -boundary -- - ' , ' '' ) , wrappers.expect_pager ( context , 'Saved.\r\n ' , timeout=1 ) # ! /usr/bin/env python os.environ [ 'PAGER ' ] = `` { 0 } { 1 } { 2 } '' .format ( sys.executable , `` tests/features/wrappager.py '' , while 1 : wrappers.expect_exact ( context , 'refresh started in the background ' , timeout=2 ) wrappers.expect_pager ( context , 'DELETE 1\r\n ' , timeout=2 ) SELECT 1\r * Add pager wrapper for behave tests ( Thanks : ` Dick Marinus ` _ ) . wrappers.expect_exact ( context , 'yyy ' , timeout=1 ) ) break context , ' -c `` import coverage ; coverage.process_startup ( ) ; import pgcli.main ; pgcli.main.cli ( ) '' ' wrappers.expect_exact ( context , 'DROP TABLE ' , timeout=2 ) buf = sys.stdin.read ( 2048 ) wrappager ( sys.argv [ 1 ] ) * Dick Marinus def expect_pager ( context , expected , timeout ) :","['AUTHORS', 'changelog.rst', 'tests/features/environment.py', 'tests/features/steps/crud_table.py', 'tests/features/steps/named_queries.py', 'tests/features/steps/specials.py', 'tests/features/steps/wrappers.py', 'tests/features/wrappager.py']",Merge pull request # 687 from dbcli/feature/behave_pager_wrapper
221,1e1d980ae2967a9fee14dfeb13a63cbe34769fd5,2017-04-21 07:40:13-07:00,"[ join ( 'public.users ON users.id = `` Users '' .userid ' ) ] testdata.keywords ( ) text = 'SELECT * from `` sele ' text = 'SELECT p.id , p. from custom.products p ' join ( 'custom.shipments ON shipments.user_id = { 0 } .id'.format ( tbl ) ) , def test_schema_qualified_type_name ( text , completer , complete_event ) : def test_suggest_columns_from_cte ( completer , complete_event ) : return testdata.get_completer ( { 'generate_aliases ' : True } , casing ) : param completer : assert set ( result ) == set ( cased_funcs + cols list ( testdata.builtin_functions ( ) 'users ' , 'custom ' def completers ( casing=None , filtr=None , aliasing=None , qualify=None ) : def test_column_alias_search_qualified ( completer ) : def test_suggest_columns_from_unquoted_table ( completer , text ) : def test_suggested_column_names_from_qualified_shadowed_table ( completer , complete_event , text ) : def test_suggested_join_conditions_with_invalid_qualifier ( completer , complete_event , text ) : ] def test_suggest_columns_from_set_returning_function ( completer ) : assert expected in set ( result ) text = 'SELECT u. from users u ' ) : assert result == set ( testdata.columns_functions_and_keywords ( 'users ' ) ) result = completer.get_completions ( alias ( ' o ' ) ] ) def test_all_schema_objects ( completer_all_schemas , complete_event ) : assert set ( result ) == set ( testdata.columns ( 'users ' ) + testdata.functions ( ) def test_suggest_columns_from_aliased_set_returning_function ( completer ) : def test_suggested_multiple_column_names_with_alias ( completer , complete_event ) : pos = text.index ( ' * ' ) + 1 testdata.functions ( 'custom ' , start_pos ) ) completer_all_schemas_aliases , complete_event assert set ( result ) == set ( testdata.columns ( 'products ' , 'custom ' ) + testdata.functions ( ) def test_suggest_columns_after_three_way_join ( completer , complete_event ) : name_join ( ' y = f2.y ' ) , def test_duplicate_table_aliases ( completer , text ) : text = 'SEL ' text = 'SELECT * FROM `` select '' JOIN users u ON true ' def test_suggested_multiple_column_names_with_dot ( completer ) : position = text.find ( ' ( ' ) + 1 def test_suggest_datatype ( text , completer ) : def test_suggested_joins_fuzzy ( completer , complete_event , text ) : testdata.functions ( ) ) result = result_set ( completer , 'SELECT from users ' , len ( 'SELECT ' ) ) def test_function_alias_search_without_aliases ( completer_with_casing , assert result == set ( testdata.from_clause_items ( 'Custom ' , start_position ) ) def test_table_aliases ( completer , text ) : keyword ( 'MAXEXTENTS ' , -2 ) , keyword ( 'MATERIALIZED VIEW ' , -2 ) , ] + testdata.functions ( ) ) def test_wildcard_column_expansion_with_insert ( completer , complete_event , text ) : result = get_result ( completer , text ) testdata.functions ( ) def test_wildcard_column_expansion_with_table_qualifier ( completer , complete_event ) : Suggest column names on table alias and dot for x in self.metadata.get ( 'views ' , { } ) .get ( parent , [ ] ) ] [ join ( 'custom.shipments ON shipments.user_id = { 0 } .id'.format ( tbl ) ) ] def test_empty_string_completion ( completer , complete_event ) : completer_all_schemas.get_completions ( def test_learn_table_names ( completer , complete_event ) : assert result == set ( [ def test_cased_joins ( completer , text ) : @ pytest.mark.parametrize ( 'text , expected ' , [ completer.extend_query_history ( history ) position = len ( 'SELECT U . ' ) def test_learn_keywords ( completer ) : return self.from_clause_items ( parent , pos ) + self.schemas ( pos ) def test_suggested_multiple_column_names_with_alias ( completer ) : for sch , tbls in metadata [ 'tables ' ] .items ( ) : def test_alias_search_with_aliases1 ( completer_aliases_casing , complete_event ) : def test_suggested_tables_after_on ( completer , complete_event , text ) : assert set ( testdata.keywords ( ) ) == result 'products ' , 'custom ' schema = partial ( completion , 'schema ' ) def result_set ( completer , text , position=None ) : aliases = [ True , False ] if aliasing is None else [ aliasing ] fk_join ( 'U2.userid = U.id ' ) ] ) completer , 'SELECT U . FROM `` Users '' U ' , len ( 'SELECT U . ' ) def test_suggested_auto_qualified_column_names ( result = result_set ( completer , 'SELECT om ' ) casing , without ` search_path ` filtering of objects , with table join = partial ( completion , 'join ' ) assert result == set ( testdata.types ( 'custom ' ) ) def test_suggested_joins ( completer , text ) : assert set ( result ) == set ( testdata.tables ( 'custom ' , start_pos ) def test_suggest_columns_from_set_returning_function ( completer , complete_event ) : def test_suggested_auto_qualified_column_names ( text , completer ) : def test_duplicate_aliases_with_casing ( cased_aliased_completer , display_meta=display_meta ) when selecting multiple columns from table return testdata.get_completer ( assert set ( result ) == set ( [ column ( 'foo ' ) ] + testdata.functions ( ) def test_suggest_cte_names ( completer , complete_event ) : complete_event ) def test_join_using_suggests_from_last_table ( completer , text ) : def functions ( self , schema='public ' , pos=0 ) : testdata.views ( ) + testdata.functions ( ) ) text = 'SELECT id , from users u ' Document ( text=sql , cursor_position=len ( sql ) ) , complete_event ) assert set ( result ) == set ( cols ) completions = result_set ( completer , text ) def test_suggested_join_conditions ( completer , text ) : Document ( text=text ) , complete_event ) for schema , funcs in metadata [ 'functions ' ] .items ( ) len ( 'select f . ' ) result = [ c.text for c in get_result ( completer , text ) ] text = 'SELECT cu ' return [ view ( escape ( x ) , pos ) for x in self.metadata.get ( 'tables ' , { } ) .get ( schema , [ ] ) ] tbl_cols.extend ( [ ( schema , table , col , 'text ' ) for col in cols ] ) alias ( ' U ' ) , start_pos = -1 Suggest column names on table name and dot for schema , tbls in metadata [ 'tables ' ] .items ( ) : alias ( ' u ' ) , sql = 'CREATE VIEW v AS SELECT 1 ' completer.get_completions ( schema , table , function , wildcard_expansion , column , def test_column_alias_search ( completer ) : disable=missing-docstring , invalid-name result = completer.get_completions ( Document ( text=text ) , complete_event ) testdata.columns ( 'set_returning_func ' , typ='functions ' ) text = 'SELECT u.id , u. from users u ' completer , 'SELECT E.ei FROM blog.Entries E ' , len ( 'SELECT E.ei ' ) result = aliased_completer.get_completions ( def test_wildcard_column_expansion_with_function ( completer , complete_event , text ) : text = 'SELECT E.ei FROM blog.Entries E ' 'keyword ' , 'datatype ' , 'table alias ' , 'name join ' , 'fk join ' , 'join ' ) ] for datatype in datatypes ] 'users ' , from functools import partial def _cfgs ( casing , filtr , aliasing , qualify ) : text = 'SELECT * FROM ' def test_suggested_column_names_from_schema_qualifed_table ( completer , complete_event ) : def test_suggested_joins_quoted_schema_qualified_table ( completer , text ) : text = 'SELECT MA ' keyword = partial ( completion , 'keyword ' ) columns from table def test_schema_or_visible_table_completion ( completer , text ) : def test_suggested_table_names_with_schema_dot ( def test_suggested_aliases_after_on_right_side ( completer ) : parametrize = pytest.mark.parametrize assert set ( result ) == set ( testdata.columns ( 'Users ' ) ) cfg [ 'casing ' ] = casing cfg [ 'settings ' ] [ 'generate_aliases ' ] = aliasing def test_function_alias_search_without_aliases ( completer ) : completer , 'SELECT MAX ( from custom.products ' , len ( 'SELECT MAX ( ' ) def test_suggested_tables_after_on ( completer , text ) : pos = len ( 'select f . ' ) def test_user_function_name_completion ( completer , complete_event ) : @ pytest.mark.parametrize ( ( 'query ' , 'tbl ' ) , itertools.product ( ( Document ( text=text ) , complete_event ) ) alias ( 'orders ' ) ] ) assert result == set ( [ alias ( 'users ' ) , alias ( 'orders ' ) ] ) def completer_with_casing ( ) : completions = completer_.get_completions ( position = text.index ( ' * ' ) + 1 def from_clause_items ( self , parent='public ' , pos=0 ) : casings = [ True , False ] if casing is None else [ casing ] fun = [ x for x in self.metadata [ typ ] [ parent ] if x [ 0 ] == tbl ] [ 0 ] datatypes = [ alias ( ' x ' ) , schema , table , view , function , column , wildcard_expansion , @ pytest.mark.parametrize ( 'text ' , join_texts ) def test_column_alias_search ( completer_aliases_casing , complete_event ) : def test_suggested_column_names_from_qualified_shadowed_table ( completer , text ) : return [ def test_wildcard_column_expansion_with_alias ( completer , complete_event , sql ) : def test_wildcard_column_expansion_with_table_qualifier ( settings= { 'generate_aliases ' : True , 'search_path_filter ' : True } sql = 'select from set_returning_func ( ) ' position = len ( 'SELECT om ' ) return self.datatypes ( parent , pos ) + self.tables ( parent , pos ) def escape ( name ) : text = 'SELECT U . FROM `` Users '' U ' assert result == set ( testdata.columns ( 'select ' ) ) def test_table_casing ( cased_completer , complete_event , text ) : get_comp = self.get_completer testdata.schemas ( ) + testdata.types ( ) + testdata.builtin_datatypes ( ) for schema , datatypes in metadata [ 'datatypes ' ] .items ( ) ) assert expected in result assert result == set ( testdata.columns ( 'users ' ) ) result = result_set ( completer , 'SELECT from `` select '' ' , len ( 'SELECT ' ) ) completer , 'SELECT et FROM blog.Entries E ' , len ( 'SELECT et ' ) @ pytest.mark.parametrize ( 'text ' , join_condition_texts ) list ( testdata.builtin_functions ( ) + testdata.keywords ( ) ) def test_insert ( completer , text ) : completer , 'SELECT id , from custom.products ' , len ( 'SELECT id , ' ) sql = 'SELECT `` select '' . * FROM public . `` select '' ' @ pytest.mark.parametrize ( ( 'text ' , 'ref ' ) , [ completions = get_result ( completer , text , position ) def test_columns_before_keywords ( completer , complete_event ) : alias ( ' y ' ) ] ) completer , text , expected def completer_all_schemas_aliases ( ) : assert set ( result ) == set ( cased_users_cols ) def test_schema_object_order ( completer_all_schemas , complete_event ) : testdata.schemas_and_from_clause_items ( ) + [ def test_cased_joins ( cased_completer , complete_event , text ) : def test_join_functions_on_suggests_columns_and_join_conditions ( completer ) : for func_meta in funcs ] def test_suggested_joins ( completer , query , tbl ) : result = result_set ( completer , text , position = text.find ( ' ' ) + 1 ) Document ( text , cursor_position=len ( 'SELECT et ' ) ) , complete_event ) position = text.find ( ' * ' ) + 1 assert set ( result ) == set ( testdata.columns ( 'products ' , 'custom ' ) complete_event ) : display = ' * ' ) def test_suggested_column_names_from_visible_table ( completer ) : assert result == set ( testdata.columns ( 'products ' , 'custom ' ) ) def test_join_functions_using_suggests_common_columns ( completer ) : def test_suggested_column_names_with_table_dot ( completer ) : assert set ( result ) == set ( [ schema ( 'PUBLIC ' ) ] + cased_aliased_rels ) join ( 'public.users ON users.id = `` Users '' .userid ' ) , sql = 'SELECT * FROM ' return name Completion ( 'foo ' , 0 , display_meta='column ' ) , result = result_set ( def test_aliased_joins ( completer , text ) : text = 'create v ' def test_no_column_qualification ( text = 'SELECT users . from users ' return Mock ( ) def views ( self , schema='public ' , pos=0 ) : def test_schema_or_visible_table_completion ( completer , complete_event , text ) : @ pytest.mark.parametrize ( 'sql ' , [ def test_no_column_qualification ( text , completer ) : def test_function_alias_search_with_aliases ( completer ) : assert result == set ( [ alias ( ' u ' ) , alias ( ' o ' ) ] ) def test_aliases_with_casing ( cased_aliased_completer , complete_event , text ) : def test_wildcard_column_expansion_with_alias ( completer , text ) : def test_suggested_column_names_from_cte ( completer , text ) : keyword ( 'MAXEXTENTS ' , -2 ) , keyword ( 'MATERIALIZED VIEW ' , -2 ) 'WITH users as ( SELECT 1 AS foo ) SELECT from users ' , result = result_set ( completer , 'select * from `` select '' s where s . ' ) sql = 'select f. from set_returning_func ( ) f ' 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' return testdata.get_completer ( { 'qualify_columns ' : 'if_more_than_one_table ' } ) qualifys = qualify or [ 'always ' , 'if_more_than_one_table ' , 'never ' ] def test_join_using_suggests_columns_after_first_column ( completer , complete_event , text ) : Document ( text=text , cursor_position=postion ) , complete_event ) ) ] complete_event ) ) def test_suggest_columns_from_quoted_table ( completer , text ) : assert result == set ( [ schema ( 'PUBLIC ' ) ] + cased_aliased_rels ) def test_join_alias_search_without_aliases1 ( completer ) : def test_suggested_join_conditions_with_invalid_qualifier ( completer , text ) : 'select ' , 'insert ' ) else name ) complete_event , text ) : result = result_set ( completer , 'SELECT u. from users u ' , len ( 'SELECT u . ' ) ) Document ( text=sql , cursor_position=pos ) , complete_event ) def test_all_schema_objects_with_casing ( text = 'SELECT `` select '' . * FROM `` select '' JOIN users u ON true ' alias ( 'U2 ' ) , assert result == set ( [ keyword ( 'SELECT ' , -3 ) ] ) : param complete_event : def get_completers ( self , casing ) : Document ( text=text , cursor_position=len ( text ) ) , complete_event ) def test_join_alias_search_without_aliases2 ( completer_with_casing , alias ( ' U ' ) , alias ( 'U2 ' ) , fk_join ( 'U2.userid = U.id ' ) def test_all_schema_objects_with_aliases ( assert result == set ( ) def test_suggested_multiple_column_names_with_dot ( completer , complete_event ) : position = len ( 'SELECT * FROM ' ) assert set ( result ) == set ( testdata.columns ( 'users ' , 'custom ' ) ) def columns ( self , parent , schema='public ' , typ='tables ' , pos=0 ) : return testdata.get_completer ( { 'generate_aliases ' : True } ) complete_event ) ) pos = len ( 'SELECT p. * ' ) Returns a list of completers . from itertools import product [ name_join ( ' y = f2.y ' ) , name_join ( ' x = f2.x ' ) ] def test_suggested_column_names_with_alias ( completer ) : completer , 'select from set_returning_func ( ) ' , len ( 'select ' ) for func_meta in funcs ] ( True , False , True , [ 'never ' ] ) results in the one completer with views.append ( ( sch , tbl ) ) datatype = partial ( completion , 'datatype ' ) def test_empty_string_completion ( completer ) : text = 'SELECT id , from custom.products ' from functools import partial ] + testdata.functions ( ) assert result == set ( testdata.schemas_and_from_clause_items ( ) ) def test_auto_escaped_col_names ( completer ) : @ pytest.mark.parametrize ( 'text ' , [ 'SELECT * FROM Orders o CROSS JOIN ' ] ) testdata.builtin_functions ( ) + testdata.keywords ( ) ) def test_suggested_join_conditions_with_same_table_twice ( completer , complete_event , text ) : result = result_set ( completer , 'SELECT cu ' ) assert set ( result ) == set ( testdata.columns ( 'users ' ) def test_suggested_join_conditions ( completer , complete_event , text ) : ' '' users '' ' , complete_event ) testdata.schemas_and_from_clause_items ( ) def test_suggestions_after_on ( completer , complete_event , text ) : ] ) ] testdata.views ( ) + [ 'select f. from custom.set_returning_func ( ) f ' , Suggest column and function names when selecting from a qualified-table def test_suggested_aliases_after_on_right_side ( completer , text ) : def test_suggested_joins_quoted_schema_qualified_table ( completer , complete_event , text ) : self.functions ( parent , pos ) + self.views ( parent , pos ) def test_all_schema_objects_with_aliases ( completer ) : text = 'ALTER TABLE users ALTER ' result = get_result ( for x in self.metadata.get ( 'functions ' , { } ) .get ( parent , [ ] ) ] cols = self.metadata [ typ ] [ schema ] [ parent ] @ pytest.mark.parametrize ( 'keyword_casing , expected , texts ' , [ position = len ( text ) if position is None else position position = len ( assert result == set ( testdata.columns_functions_and_keywords ( def test_suggested_cased_column_names_with_alias ( completer ) : assert set ( result ) == set ( testdata.schemas ( ) + [ for typ in datatypes ] def test_builtin_function_name_completion ( completer , complete_event ) : pos = text.index ( ' ' ) + 1 sql = 'SELECT `` select '' . * FROM `` select '' JOIN users u ON true ' text = 'SELECT MAX ( from custom.products ' Suggest column and function names when selecting from table text = 'SELECT * FROM orders WHERE s ' assert set ( testdata.keywords ( ) ) == result def test_wildcard_column_expansion_with_two_tables ( completer , complete_event ) : function = partial ( completion , 'function ' ) def schemas_and_from_clause_items ( self , parent='public ' , pos=0 ) : position = 0 result = [ c.text for c in import pytest view ( escape ( x ) , pos ) settings= { 'search_path_filter ' : True } , text = `` text = 'SELECT from custom.products ' Document ( text=text , cursor_position=position ) , complete_event ) ) from prompt_toolkit.document import Document def completer_with_aliases ( ) : def test_suggest_columns_from_quoted_table ( completer , complete_event , text ) : self , tbl , parent='public ' , typ='tables ' , pos=0 def test_suggested_aliases_after_on ( completer , text ) : testdata.tables ( 'Custom ' , start_pos ) ) pos = len ( 'SELECT users . * ' ) completions = completer.get_completions ( completer_all_schemas_casing.get_completions ( assert set ( expected ) == result def test_all_schema_objects ( completer ) : assert expected < = result def test_join_using_suggests_columns_after_first_column ( completer , text ) : def datatypes ( self , schema='public ' , pos=0 ) : testdata.keywords ( ) ) def types ( self , parent='public ' , pos=0 ) : result = result_set ( completer , `` ) def test_cte_qualified_columns ( completer , complete_event , text ) : alias = partial ( completion , 'table alias ' ) def test_suggested_column_names_with_alias ( completer , complete_event ) : position = len ( 'SELECT MAX ( ' ) assert result == set ( cols ) def test_alias_search_with_aliases2 ( completer_aliases_casing , complete_event ) : def test_alias_search_without_aliases1 ( completer_with_casing , complete_event ) : function ( escape ( x [ 0 ] + ' ( ) ' ) , pos ) result = completer_with_casing.get_completions ( completions = get_result ( completer , text ) completer.extend_query_history ( sql ) def test_suggested_table_names_with_schema_dot2 ( def test_suggested_aliases_after_on_right_side ( completer , complete_event , text ) : position = text.index ( ' ( ) ' ) + 1 filtrs = [ True , False ] if filtr is None else [ filtr ] assert set ( result ) == set ( [ ( sch , typ ) return [ self.keywords ( pos ) def test_insert ( completer , complete_event , text ) : assert set ( result ) == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels ) result = result_set ( completer , text ) completer_all_schemas_casing , complete_event assert result == set ( testdata.schemas ( ) + aliased_rels ) for tbl , cols in tbls.items ( ) : result = set ( `` `` '' cfg = { 'settings ' : { } } def test_cased_join_conditions ( cased_completer , complete_event , text ) : pos = len ( 'SELECT U . ' ) def test_suggested_tables_after_on_right_side ( completer , text ) : def test_suggested_joins ( completer , complete_event , text ) : def test_wildcard_column_expansion_with_table_qualifier ( completer , complete_event , text , expected ) : result = completer_aliases_casing.get_completions ( assert set ( result ) == set ( testdata.columns ( 'select ' ) + [ def test_learn_keywords ( completer , complete_event ) : tbl_cols.extend ( [ ( sch , tbl , col , 'text ' ) for col in cols ] ) result = cased_aliased_completer.get_completions ( foreignkeys = [ ForeignKey ( * fk ) for fks in metadata [ 'foreignkeys ' ] .values ( ) completer , 'select f. from set_returning_func ( ) f ' , len ( 'select f . ' ) for table , cols in tbls.items ( ) : complete_event ) : assert result == set ( [ alias ( ' x ' ) , alias ( ' y ' ) ] ) ] assert set ( result ) == set ( testdata.functions ( 'Custom ' , start_pos ) def completer_all_schemas_casing ( ) : def test_suggest_columns_from_cte ( completer ) : sql = 'SELECT p. * FROM custom.products p ' def test_table_names_after_from ( completer , complete_event ) : [ assert result == set ( [ column ( 'id ' ) , column ( 'email ' ) ] ) position = len ( 'SELECT id , ' ) text = query.format ( tbl ) testdata.builtin_functions ( ) @ pytest.mark.parametrize ( 'text ' , [ return testdata.get_completer ( settings= { 'search_path_filter ' : True } ) len ( 'SELECT u.id , u . ' ) def test_column_alias_search_qualified ( completer_aliases_casing , text = 'SELECT p. from custom.products p ' position = len ( 'SELECT users . * ' ) return [ function ( escape ( x [ 0 ] + ' ( ) ' ) , pos ) expected = ( def test_suggest_columns_from_quoted_table ( completer , complete_event ) : the list ` qualify ` , all defaulting to None . assert result == set ( complete_event ) : history = 'CREATE VIEW v AS SELECT 1 ' def test_allow_leading_double_quote_in_last_word ( completer , complete_event ) : def test_suggested_table_names_with_schema_dot ( completer , complete_event , ) ) def test_function_alias_search_with_aliases ( completer_aliases_casing , def test_allow_leading_double_quote_in_last_word ( completer ) : get_comp ( * * c ) for c in _cfgs ( casing , filtr , aliasing , qualify ) def completer_aliases_casing ( ) : def test_wildcard_column_expansion ( completer , text ) : @ pytest.fixture assert result == set ( testdata.columns ( 'Users ' ) ) def test_suggested_column_names_with_qualified_alias ( completer , complete_event ) : assert set ( result ) == set ( testdata.schemas ( ) + testdata.datatypes ( ) Document ( text=text , cursor_position=position ) , Mock ( ) schema , table , view , function , column , keyword , datatype , alias , name_join , \ fun = [ x for x in self.metadata [ typ ] [ schema ] if x [ 0 ] == parent ] [ 0 ] self.columns ( tbl , parent , typ , pos ) assert set ( result ) == set ( testdata.schemas ( ) + aliased_rels ) completer , 'SELECT from custom.products ' , len ( 'SELECT ' ) ) : def test_suggested_cased_column_names ( cased_completer , complete_event ) : assert set ( result ) == set ( testdata.schemas ( ) + aliased_rels + [ position = text.index ( ' ' ) + 1 from mock import Mock def test_auto_escaped_col_names ( completer , complete_event ) : testdata.functions ( ) Document ( text=text , cursor_position=position ) , complete_event ) def test_suggested_multiple_column_names ( completer , complete_event ) : assert set ( result ) == set ( testdata.schemas ( ) set ( result ) ) pos = len ( 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT ' ) assert result == set ( cased_funcs + cols def test_table_aliases ( aliased_completer , complete_event , text ) : position = len ( 'SELECT * ' ) results in all 24 possible completers , whereas e.g . schemata.append ( schema ) def functions ( self , parent='public ' , pos=0 ) : def cased_aliased_completer ( ) : completer = testdata.get_completer ( { 'keyword_casing ' : keyword_casing } ) Document ( text=text , cursor_position=position ) , sql = 'ALTER TABLE users ALTER ' Document ( text=text , cursor_position=pos ) , complete_event ) result = completer_with_aliases.get_completions ( def test_suggested_cased_column_names ( completer ) : def test_suggest_columns_from_aliased_set_returning_function ( completer , complete_event ) : assert set ( result ) == set ( testdata.columns ( 'users ' , 'custom ' ) complete_event ) : return Completion ( text , start_position=pos , display_meta=display_meta ) def test_duplicate_table_aliases ( aliased_completer , complete_event , text ) : result = set ( aliased_completer.get_completions ( return Completion ( text , start_position=pos , return Completion ( cols , start_position=pos , display_meta='columns ' , complete_event def test_alias_search_without_aliases2 ( completer_with_casing , complete_event ) : def test_wildcard_column_expansion_with_two_tables ( completer ) : text = ( 'SELECT * FROM ' ) ) def test_suggested_column_names_from_shadowed_visible_table ( completer , complete_event , table ) : testdata.tables ( 'custom ' ) ) list ( testdata.builtin_functions ( ) assert set ( expected ) == set ( result ) assert result == set ( testdata.schemas ( ) + aliased_rels + [ def test_all_schema_objects_with_casing ( completer ) : result = result_set ( completer , 'SEL ' ) def test_table_casing ( completer_with_casing , complete_event , text ) : def test_user_function_name_completion_matches_anywhere ( completer , sql = 'select * from `` select '' s where s . ' testdata.tables ( ) + list ( testdata.builtin_datatypes ( ) ) ) def test_aliases_with_casing ( completer , text ) : Suggest column names on table names and dot assert set ( result ) == set ( tables.append ( ( schema , table ) ) schema , table , view , function , column , wildcard_expansion ) result = completer.get_completions ( Document ( text=text , cursor_position=pos ) , def test_join_using_suggests_common_columns ( completer , complete_event , text ) : cfg [ 'settings ' ] [ 'search_path_filter ' ] = filtr def test_schema_qualified_function_name ( completer ) : result = get_result ( completer , 'SELECT * FROM u ' ) def test_join_using_suggests_from_last_table ( completer , complete_event , text ) : completer from mock import Mock Document ( text=text , cursor_position=pos ) , complete_event ) ) position = len ( 'SELECT users.id , users . ' ) def test_suggested_tables_after_on_right_side ( completer , complete_event , text ) : def _cfg ( _casing , filtr , aliasing , qualify ) : def test_suggested_column_names_in_function ( completer , complete_event ) : completer_all_schemas_aliases.get_completions ( def test_join_alias_search_with_aliases1 ( completer ) : postion = len ( text ) ] + testdata.functions_and_keywords ( ) def test_join_alias_search_without_aliases1 ( completer_with_casing , def test_user_function_name_completion_matches_anywhere ( completer ) : text = 'SELECT * FROM u ' [ alias ( ' U ' ) , alias ( 'U2 ' ) , fk_join ( 'U2.UserID = U.ID ' ) ] for sch , funcs in metadata [ 'functions ' ] .items ( ) cased_always_qualifying_completer , complete_event cfg [ 'settings ' ] [ 'qualify_columns ' ] = qualify def test_wildcard_column_expansion_with_function ( completer , text ) : completer , 'SELECT users . from users ' , len ( 'SELECT users . ' ) views.append ( ( schema , view ) ) return [ table ( escape ( x ) , pos ) _cfg ( * p ) for p in product ( casings , filtrs , aliases , qualifys ) import pytest result = result_set ( completer , 'SELECT * from `` sele ' ) return cfg def tables ( self , schema='public ' , pos=0 ) : ] ) completer , text , use_leading_double_quote def columns_functions_and_keywords ( alias ( 'orders ' ) for sch , datatypes in metadata [ 'datatypes ' ] .items ( ) position = text.find ( ' ' ) + 1 pos = text.find ( ' ( ' ) + 1 position = len ( 'SEL ' ) assert set ( result ) == set ( testdata.functions ( ) + cols def test_table_casing ( completer , text ) : self.functions ( parent , pos ) + self.builtin_functions ( pos ) def test_suggest_columns_from_unquoted_table ( completer , complete_event , text ) : def test_suggested_join_conditions_with_same_table_twice ( completer , text ) : Document ( text , cursor_position=len ( 'SELECT E.ei ' ) ) , complete_event ) position = len ( text ) @ pytest.mark.parametrize ( 'text ' , [ 'SELECT * FROM ' , assert set ( result ) == set ( testdata.columns ( 'Users ' , 'custom ' ) ) assert result == set ( testdata.columns ( 'Users ' , 'custom ' ) ) def test_wildcard_column_expansion_with_two_tables_and_parent ( completer ) : @ pytest.mark.parametrize ( 'text ' , texts ) def test_alias_search_without_aliases1 ( completer ) : completer parameters , ` None ` meaning any , i.e . ( None , None , None , None ) settings= { 'generate_aliases ' : True , 'search_path_filter ' : True } , def test_learn_table_names ( completer ) : def cased_completer ( ) : len ( 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT ' ) def test_suggested_join_conditions_with_invalid_table ( completer , complete_event , text , ref ) : def test_suggested_column_names_from_schema_qualifed_table ( completer ) : sql = 'SELECT * FROM `` select '' JOIN users u ON true ' assert set ( result ) == set ( ) completer , text , auto_qualifying_completer , complete_event for sch , tbls in metadata.get ( 'views ' , { } ) .items ( ) : def test_suggest_columns_from_escaped_table_alias ( completer , complete_event ) : start_position = 0 result = completer_all_schemas.get_completions ( def test_user_function_name_completion ( completer ) : for x in self.metadata.get ( 'datatypes ' , { } ) .get ( parent , [ ] ) ] def test_alias_search_with_aliases2 ( completer ) : def test_suggested_cased_column_names_with_alias ( cased_completer , complete_event ) : position = len ( 'SELECT u.id , u . ' ) def test_join_functions_on_suggests_columns_and_join_conditions ( completer , complete_event ) : fk_join = partial ( completion , 'fk join ' ) 'SELECT p.id , p. from custom.products p ' , completer , 'SELECT p. from custom.products p ' , len ( 'SELECT p . ' ) def views ( self , parent='public ' , pos=0 ) : FunctionMetadata ( sch , * func_meta ) pos = len ( sql ) position = len ( 'SELECT IN ' ) def auto_qualifying_completer ( ) : functions = [ testdata.functions ( ) return [ datatype ( escape ( x ) , pos ) def test_select_keyword_completion ( completer , complete_event ) : ] + testdata.columns ( 'set_returning_func ' , typ='functions ' ) ) def functions_and_keywords ( self , parent='public ' , pos=0 ) : assert result == set ( cased_funcs + cased_users_cols name_join = partial ( completion , 'name join ' ) def test_table_names_after_from ( completer , text ) : def test_builtin_function_matches_only_at_start ( completer ) : column ( 'id ' ) , def aliased_completer ( ) : def complete_event ( ) : if not name.islower ( ) or name in ( 'select ' , 'insert ' ) : def test_suggested_aliases_after_on ( completer , complete_event , text ) : assert set ( result ) == set ( testdata.schemas ( ) + testdata.tables ( ) ) column ( 'email ' ) , len ( 'SELECT users.id , users . ' ) for view , cols in tbls.items ( ) : ) return completer.get_completions ( def datatypes ( self , parent='public ' , pos=0 ) : result = result_set ( completer , 'SELECT MA ' ) Document ( text=text , cursor_position=position ) , assert result == set ( cols + testdata.functions_and_keywords ( ) ) result = result_set ( completer , 'SELECT FROM ' + table , len ( 'SELECT ' ) ) def test_select_keyword_completion ( completer ) : @ pytest.mark.parametrize ( 'table ' , [ view_cols.extend ( [ ( schema , view , col , 'text ' ) for col in cols ] ) @ pytest.mark.parametrize ( 'text ' , [ 'SELECT * FROM ' ] ) def test_suggested_auto_qualified_column_names_two_tables ( start_pos = 0 def test_alias_search_with_aliases1 ( completer ) : self.functions_and_keywords ( pos=pos ) def test_suggest_datatype ( text , completer , complete_event ) : completers = testdata.get_completers ( casing ) def test_cased_join_conditions ( completer , text ) : assert set ( result ) == set ( [ keyword ( 'SELECT ' , -3 ) ] ) result = set ( completer.get_completions ( : return : def test_builtin_function_name_completion ( completer ) : assert set ( result ) == set ( testdata.schemas ( ) + testdata.tables ( ) + [ def test_suggestions_after_on ( completer , text ) : cols = self.metadata [ typ ] [ parent ] [ tbl ] pos = len ( 'SELECT * ' ) result = set ( cased_completer.get_completions ( return testdata.get_completer ( ) text = 'SELECT from `` select '' ' for schema , tbls in metadata.get ( 'views ' , { } ) .items ( ) : text = 'SELECT et FROM blog.Entries E ' def test_suggested_column_names_from_cte ( completer , complete_event , text ) : assert set ( result ) == set ( testdata.columns ( 'users ' ) ) def test_join_alias_search_without_aliases2 ( completer ) : def test_schema_qualified_type_name ( completer , text ) : def test_suggested_join_conditions_with_invalid_table ( completer , text , ref ) : text = 'SELECT om ' def completer_all_schemas ( ) : def test_table_names_after_from ( completer , complete_event , text ) : def test_suggested_column_names_from_shadowed_visible_table ( completer , table ) : assert set ( result ) == set ( testdata.datatypes ( 'custom ' ) def test_suggested_joins ( completer , complete_event , query , tbl ) : text = 'SELECT * FROM public . `` select '' JOIN custom.users ON true ' escape = lambda name : ( ' '' ' + name + ' '' ' if not name.islower ( ) or name in ( pos = len ( 'select ' ) pos = sql.find ( ' * ' ) + 1 position = len ( 'SELECT MA ' ) assert result == set ( cased_users_cols ) schemata.append ( sch ) def test_wildcard_column_expansion_with_table_qualifier ( completer ) : position = len ( 'SELECT p . ' ) return testdata.get_completer ( settings= { 'generate_aliases ' : True } ) def test_alias_search_without_aliases2 ( completer ) : def test_suggested_column_names_with_qualified_alias ( completer ) : completions = get_result ( completer , text ) for x in self.metadata.get ( 'datatypes ' , { } ) .get ( schema , [ ] ) ] result = completer.get_completions ( Document ( text=sql , cursor_position=pos ) , for x in self.metadata.get ( 'views ' , { } ) .get ( schema , [ ] ) ] return ' '' ' + name + ' '' ' assert set ( result ) == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels + [ Completion ( 'bar ' , 0 , display_meta='column ' ) , assert result == set ( testdata.columns_functions_and_keywords ( 'select ' ) ) def tables ( self , parent='public ' , pos=0 ) : alias ( 'users ' ) , tables.append ( ( sch , tbl ) ) self.tables ( parent , pos ) def test_suggested_column_names_from_visible_table ( completer , complete_event ) : pos = len ( text ) assert set ( result ) == set ( [ alias ( 'users ' ) , alias ( ref ) ] ) assert result == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels + [ aliasing , and without column qualification . result = result_set ( completer , text , position ) text = 'SELECT p. * FROM custom.products p ' assert result == set ( [ column ( 'foo ' ) ] + testdata.functions_and_keywords ( ) ) def completer ( ) : return completers completer.get_completions ( document , complete_event ) ] def test_join_alias_search_with_aliases1 ( completer_aliases_casing , assert result == set ( testdata.schemas ( ) + [ def test_suggest_columns_after_three_way_join ( completer ) : complete_event def test_wildcard_column_expansion_with_alias_qualifier ( completer , complete_event ) : view_cols.extend ( [ ( sch , tbl , col , 'text ' ) for col in cols ] ) def columns ( self , tbl , parent='public ' , typ='tables ' , pos=0 ) : @ pytest.mark.parametrize ( 'use_leading_double_quote ' , [ False , True ] ) position = len ( 'SELECT * FROM u ' ) Document ( text=text , ) , complete_event ) ) ] # Note that the filtering parameters here only apply to the columns text = 'SELECT from users ' def get_result ( completer , text , position=None ) : def test_builtin_function_matches_only_at_start ( completer , complete_event ) : def test_cte_qualified_columns ( completer , text ) : def test_suggested_column_names_with_table_dot ( completer , complete_event ) : expected = ( [ Completion ( 'foo ' , 0 , display_meta='column ' ) , def test_suggested_auto_qualified_column_names_two_tables ( text , completer ) : completer_ = testdata.get_completer ( { 'keyword_casing ' : keyword_casing } ) def cased_always_qualifying_completer ( ) : completer , 'SELECT id , from users u ' , len ( 'SELECT id , ' ) result = set ( cased_always_qualifying_completer.get_completions ( fk_join , join = [ partial ( completion , display_meta ) text , cased_always_qualifying_completer , complete_event def test_suggested_multiple_column_names ( completer ) : def test_wildcard_column_expansion_with_alias_qualifier ( completer ) : assert set ( result ) == set ( testdata.columns ( 'set_returning_func ' , typ='functions ' ) ) for display_meta in ( 'schema ' , 'table ' , 'view ' , 'function ' , 'column ' , Document ( text=text , cursor_position=pos ) , datatype ( escape ( x ) , pos ) assert set ( result ) == set ( cased_funcs + cased_users_cols def test_table_names_after_from ( completer ) : Returns a function taking three bools ` casing ` , ` filtr ` , ` aliasing ` and assert set ( result ) == set ( testdata.columns ( 'select ' ) ) assert result == set ( [ alias ( 'users ' ) , alias ( ref ) ] ) assert set ( result ) == set ( testdata.schemas_and_from_clause_items ( ) ) assert expected < = set ( result ) document = Document ( text=text , cursor_position=position ) start_position = -1 text = 'SELECT * FROM ' position = len ( 'SELECT cu ' ) sql = 'SELECT `` select '' . * FROM public . `` select '' JOIN custom.users u ON true ' get_result , result_set , qual , no_qual , parametrize ) schema , table , function , wildcard_expansion , column ) These parameters specify the allowed values for the corresponding return testdata.completer fk_join ( 'U2.UserID = U.ID ' ) ] ) for x in self.metadata.get ( 'tables ' , { } ) .get ( parent , [ ] ) ] return Completion ( result = result_set ( completer , query.format ( tbl ) ) def test_schema_qualified_function_name ( completer , complete_event ) : return set ( get_result ( completer , text , position ) ) ] ) def test_suggested_column_names_in_function ( completer ) : def test_join_using_suggests_common_columns ( completer , text ) : 'set_returning_func ' , typ='functions ' cols , start_position=pos , display_meta='columns ' , display= ' * ' ) 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT FROM cte ' , text = 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT FROM cte ' ] ) assert result == set ( testdata.from_clause_items ( 'custom ' , start_position ) ) sql = 'SELECT * FROM public . `` select '' JOIN custom.users ON true ' assert set ( result ) == set ( testdata.columns ( 'products ' , 'custom ' ) ) result = result_set ( completer , text , text.find ( ' ' ) + 1 ) def test_join_functions_using_suggests_common_columns ( completer , complete_event ) : Suggest column and function names when selecting multiple functions = [ FunctionMetadata ( schema , * func_meta ) def test_duplicate_aliases_with_casing ( completer , text ) : def test_columns_before_keywords ( completer ) : text , use_leading_double_quote ) : completer , 'SELECT MAX ( from users ' , len ( 'SELECT MAX ( ' ) def test_suggested_joins_fuzzy ( completer , text ) : assert result == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels ) def test_suggested_aliases_after_on_right_side ( completer , complete_event ) : table = partial ( completion , 'table ' ) testdata.views ( ) + testdata.tables ( ) + testdata.functions ( ) ) position = len ( 'SELECT `` select '' . * ' ) ) : position = len ( 'SELECT ' ) def test_suggest_columns_from_quoted_table ( completer ) : sql = 'SELECT * FROM orders WHERE s ' assert result == set ( cased_schemas + [ testdata.keywords ( ) ) ) 'SELECT users.id , users . from users u ' , if _casing : sql = 'select f. from custom.set_returning_func ( ) f ' return testdata.get_completer ( casing=casing ) def test_wildcard_column_expansion ( completer , complete_event , sql ) : def test_wildcard_column_expansion_with_two_tables_and_parent ( completer , complete_event ) : foreignkeys = [ no_qual = [ 'if_more_than_one_table ' , 'never ' ] sql = 'create v ' complete_event ) : def test_schema_object_order ( completer ) : table ( escape ( x ) , pos ) assert ( column ( 'id ' ) in [ MESSAGES CONTROL ] datatypes = [ ( schema , datatype ) text = 'SELECT `` select '' . * FROM public . `` select '' ' position = len ( 'SELECT p. * ' ) def test_suggest_columns_from_escaped_table_alias ( completer ) : ForeignKey ( * fk ) for fks in metadata [ 'foreignkeys ' ] .values ( ) assert set ( result ) == set ( cased_schemas + [ position = len ( 'SELECT users . ' ) ) completer , 'SELECT u.id , u. from users u ' , len ( 'SELECT u.id , u . ' ) for x in self.metadata.get ( 'functions ' , { } ) .get ( schema , [ ] ) ] text = 'SELECT FROM ' + table result = set ( auto_qualifying_completer.get_completions ( name_join ( ' x = f2.x ' ) , from prompt_toolkit.document import Document return ( def test_suggest_cte_names ( completer ) : def test_suggested_table_names_with_schema_dot2 ( completer , complete_event , assert ( column ( 'id ' ) in result ) testdata.columns ( 'set_returning_func ' , typ='functions ' ) ) position = len ( 'SELECT u . ' ) text = 'SELECT MAX ( from users ' def test_join_alias_search_with_aliases2 ( completer ) : assert result == set ( testdata.columns ( 'users ' , 'custom ' ) ) qual = [ 'if_more_than_one_table ' , 'always ' ] result = cased_completer.get_completions ( def test_join_alias_search_with_aliases2 ( completer_aliases_casing , view = partial ( completion , 'view ' ) Completion ( 'bar ' , 0 , display_meta='column ' ) , def test_aliases_with_casing ( completer_aliases_casing , complete_event , text ) : column = partial ( completion , 'column ' ) text = 'SELECT users.id , users . from users u ' pos = text.index ( ' ( ) ' ) + 1 position = len ( 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' ) def test_table_aliases ( completer_with_aliases , complete_event , text ) : return testdata.get_completer ( { 'qualify_columns ' : 'always ' } , casing ) def test_wildcard_column_expansion_with_insert ( completer , text ) : pos = len ( 'SELECT `` select '' . * ' ) casing=casing text = 'SELECT `` select '' . * FROM public . `` select '' JOIN custom.users u ON true ' def test_aliased_joins ( aliased_completer , complete_event , text ) : `` `` ''","['pylintrc', 'tests/metadata.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 667 from dbcli/koljonen/tests_parametrize_completer
222,db634a459638f36cd9091677142dbdc476eca778,2017-04-21 07:39:19-07:00,"======= title , cur , headers , status , self.table_format , self.decimal_format , [ 'head1 ' , 'head2 ' ] , 'test status ' , settings._replace ( max_width=1 ) ) self.float_format , self.null_string , expanded , max_width ) floatfmt=self.float_format , max_width=1 ) [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , case_function= ( dcmlfmt = settings.dcmlfmt def format_output ( title , cur , headers , status , table_format , dcmlfmt , floatfmt , formatted.extend ( format_output ( title , rows , headers , status , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , ) ) settings = OutputSettings ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , * Casing for column headers ( Thanks : ` Joakim Koljonen ` _ ) headers = [ case_function ( utf8tounicode ( x ) ) for x in headers ] obfuscate_process_password , format_output , PGCli , OutputSettings 'OutputSettings ' , max_width = settings.max_width max_width=max_width , expanded=expanded , missingval = settings.missingval [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , floatfmt = settings.floatfmt case_column_headers = True headers = [ utf8tounicode ( x ) for x in headers ] OutputSettings = namedtuple ( OutputSettings.__new__.__defaults__ = ( def format_output ( title , cur , headers , status , settings ) : settings = OutputSettings ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , max_width=100 ) formatted = format_output ( title , cur , headers , status , settings ) from pgcli.main import format_output , OutputSettings missingval=self.null_string , from pgcli.main import obfuscate_process_password , format_output , PGCli formatted = format_output ( 'case_column_headers ' : c [ 'main ' ] .as_bool ( 'case_column_headers ' ) , expanded=expanded ) ) else lambda x : x case_function = settings.case_function 'test status ' , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , ) table_format=self.table_format , ) None , None , None , ' < null > ' , False , None , lambda x : x max_width=100 ) missingval= ' < null > ' , expanded=False , max_width=None ) : table_format = settings.table_format expanded=expanded ) 'test status ' , settings ) from pgcli.main import format_output settings = OutputSettings ( table_format='psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' ) from pgcli.main import ( formatted.extend ( format_output ( title , rows , headers , status , settings ) ) 'table_format dcmlfmt floatfmt missingval expanded max_width case_function ' # Casing of column headers based on the casing_file described above dcmlfmt=self.decimal_format , [ 'head1 ' , 'head2 ' ] , 'test status ' , settings ) self.completer.case if self.settings [ 'case_column_headers ' ] expanded = settings.expanded settings = OutputSettings (","['changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc', 'tests/test_main.py', 'tests/utils.py']",Merge pull request # 654 from dbcli/koljonen/case_column_titles
223,66cd634de462c685cd11d08b56e39289dbdd109e,2017-04-19 15:34:49-07:00,"'Programming Language : : Python ' , install_requires=install_requirements , 'Topic : : Software Development ' , 'Intended Audience : : Developers ' , 'Programming Language : : SQL ' , 'Operating System : : Unix ' , description=description , 'Topic : : Database ' , 'packages/pgliterals/pgliterals.json ' ] } , license='LICENSE.txt ' , entry_points= '' ' name='pgcli ' , 'Programming Language : : SQL ' , ) 'Programming Language : : Python : : 3.3 ' , 'Programming Language : : Python : : 2.6 ' , 'License : : OSI Approved : : BSD License ' , long_description=open ( 'README.rst ' ) .read ( ) , author='Amjith Ramanujam ' , 'Programming Language : : Python : : 3 ' , package_data= { 'pgcli ' : [ 'pgclirc ' , 'Topic : : Software Development : : Libraries : : Python Modules ' , pgcli=pgcli.main : cli pgcli=pgcli.main : cli 'Programming Language : : Python : : 2.7 ' , 'Topic : : Software Development : : Libraries : : Python Modules ' , long_description=open ( 'README.rst ' ) .read ( ) , 'License : : OSI Approved : : BSD License ' , 'Programming Language : : Python ' , 'Topic : : Database : : Front-Ends ' , author_email='amjith.r+pgcli @ gmail.com ' , [ console_scripts ] ' '' , 'Topic : : Database : : Front-Ends ' , author='Pgcli Core Team ' , 'Programming Language : : Python : : 3.4 ' , entry_points= '' ' version=version , 'Programming Language : : Python : : 2.6 ' , 'Programming Language : : Python : : 2.7 ' , version=version , 'Topic : : Database ' , ] , packages=find_packages ( ) , ' '' , license='LICENSE.txt ' , 'Topic : : Software Development ' , package_data= { 'pgcli ' : [ 'pgclirc ' , packages=find_packages ( ) , 'Operating System : : Unix ' , 'Programming Language : : Python : : 3.3 ' , 'Programming Language : : Python : : 3 ' , [ console_scripts ] 'Programming Language : : Python : : 3.4 ' , 'Intended Audience : : Developers ' , ] , 'packages/pgliterals/pgliterals.json ' ] } , name='pgcli ' , description=description , classifiers= [ url='http : //pgcli.com ' , ) install_requires=install_requirements , classifiers= [ url='http : //pgcli.com ' ,",['setup.py'],Merge pull request # 684 from dbcli/amjith/author-update
224,da434103cc3d61180b876bc965b4bf71f670a83b,2017-04-19 10:08:36-07:00,"Pgcli can be run from within Docker . This can be useful to try pgcli without the docker container : : : To create a container from the image : $ docker run -- rm -ti -v /var/run/postgres : /var/run/postgres pgcli pgcli foo To connect to a locally running instance over a unix socket , bind the socket to CMD pgcli To access postgresql databases listening on localhost , make sure to run the $ docker run -- rm -ti pgcli pgcli < ARGS > FROM python:2.7 COPY . /app $ docker run -- rm -ti -- net host pgcli pgcli -h localhost foo postgresql server running on localhost:5432 ( the standard port ) : Docker $ docker build -t pgcli . * Hraban Luyat RUN cd /app & & pip install -e . ====== To build the image : docker in `` host net mode '' . E.g . to access a database called `` foo '' on the installing it , or any dependencies , system-wide .","['AUTHORS', 'Dockerfile', 'README.rst']",Merge pull request # 660 from hraban/docker
225,a85b68962e0ae5cc2e10db4f0da09f1ac856a758,2017-04-12 20:22:58-07:00,Config * Config file is automatically created at `` ~/.config/pgcli/config `` at first launch . See the file itself for a description of all available options . A config file is automatically created at `` ~/.config/pgcli/config `` at first launch .,['README.rst'],Merge pull request # 681 from AlexTes/patch-1
226,dc7e73524f7c9c6c9456ec1aa5499da84f8b7386,2017-04-08 18:41:38-07:00,"* Run pep8 checks in travis ( Thanks : ` Irina Truong ` _ ) . : : $ pep8radius -- docformatter -- diff # view a diff of proposed fixes Then commit and push the fixes . # check for pep8 errors , only looking at branch vs master . If there are errors , show diff and return an error code . ` pep8radius < https : //github.com/hayd/pep8radius > ` _ . If you see a build failing because pep8radius When you submit a PR , the changeset is checked for pep8 compliance using $ pip install pep8radius Internal changes : coverage==4.3.4 pep8radius master -- docformatter -- error-status || ( pep8radius master -- docformatter -- diff ; false ) pip install git+https : //github.com/hayd/pep8radius.git PEP8 checks of these checks , install pep8radius and apply style fixes : coverage==4.3.4 $ pep8radius -- docformatter -- in-place # apply the fixes","['.travis.yml', 'DEVELOP.rst', 'changelog.rst', 'requirements-dev.txt']",Merge pull request # 680 from dbcli/j-bennet/pep8radius-travis
227,eab935034e6b93cde75f273500d0361565aaa699,2017-04-07 10:38:44-07:00,"help='Username to connect to the postgres database . ' ) * Standardize command line option names . ( Thanks : ` Russell Davies ` _ ) @ click.option ( '-R ' , ' -- row-limit ' , default=None , envvar='PGROWLIMIT ' , type=click.INT , def cli ( database , user , host , port , prompt_passwd , never_prompt , user = username or username_opt @ click.option ( '-U ' , ' -- user ' , envvar='PGUSER ' , help='User name to ' 'connect to the postgres database . ' ) * Russell Davies .. _ ` Russell Davies ` : https : //github.com/russelldavies user = username or user def cli ( database , username_opt , host , port , prompt_passwd , never_prompt ,","['AUTHORS', 'changelog.rst', 'pgcli/main.py']",Merge pull request # 679 from russelldavies/fix_cli
228,56af64585f4f033c25cd574072185c85c26e52a2,2017-04-01 10:11:05-07:00,"context.cli.sendline ( '\\nd foo ' ) if 'PGPASSWORD ' in os.environ : Wait to see insert output . context.cli.sendline ( 'select * from abc ' ) context.response = { def step_select_from_table ( context ) : expected , db_name = context.conf [ 'dbname ' ] assert 'pgcli ' in dists This string is used to call the step in `` * .feature '' file . then we see dbcli prompt cd .. def step_see_data_selected ( context ) : def _expect_exact ( context , expected , timeout ) : Send \nd command Send \ns command def step_send_help ( context ) : def step_db_create ( context ) : context.cli.sendline ( `` 'update a set x = 'yyy ' where x = 'xxx ' ; ' '' ) Make sure the cli exits . context.cli.sendcontrol ( ' u ' ) @ when ( 'we connect to postgres ' ) context.cli.sendline ( '\\connect postgres ' ) wrappers.expect_exact ( context , 'CREATE DATABASE ' , timeout=2 ) def step_edit_file ( context ) : from behave import when , then context.cli.sendline ( 'drop database { 0 } ; '.format ( @ when ( 'we send `` ctrl + d '' ' ) # - * - coding : utf-8 context.cli.sendline ( '\\ns foo SELECT 12345 ' ) context.cli.sendline ( `` 'insert into a ( x ) values ( 'xxx ' ) ; ' '' ) @ when ( 'we create database ' ) Check that pgcli is in installed modules . context.cli.sendline ( '\\connect postgres ' ) @ when ( 'we start external editor providing a file name ' ) def step_insert_into_table ( context ) : @ when ( 'we wait for prompt ' ) @ then ( 'we see help output ' ) Wait to see select output . context.cli.expect_exact ( expected , timeout=timeout ) db_name = context.conf [ 'dbname ' ] def step_delete_named_query ( context ) : def expect_exact ( context , expected , timeout ) : os.environ [ 'EDITOR ' ] = 'nano ' Send \ns command Send \n command Send insert into table . Send connect to database . wrappers.expect_exact ( context , '12345 ' , timeout=1 ) def step_db_connect_test ( context ) : Send deete from table . Send select from table . import re def step_see_db_connected ( context ) : Steps for behavioral style tests are defined in this module . except : def step_see_record_updated ( context ) : context.cli.sendline ( '\\refresh ' ) _expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) context.editor_file_name = 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) context.cli.sendcontrol ( ' u ' ) def step_edit_type_sql ( context ) : 'PGPASS ' : os.environ.get ( 'PGPASS ' , None ) , def step_edit_type_sql ( context ) : def step_use_named_query ( context ) : def step_delete_named_query ( context ) : from __future__ import unicode_literals wrappers.expect_exact ( context , 'SELECT 1 ' , timeout=1 ) wrappers.expect_exact ( context , 'DROP DATABASE ' , timeout=2 ) @ when ( 'we run pgcli ' ) @ then ( 'we see completions refresh started ' ) Edit file with external editor . 'vi ' : vi , context.cli.sendline ( 'drop table a ; ' ) wrappers.expect_exact ( context , 'CREATE TABLE ' , timeout=2 ) Send \ ? to see help . @ when ( 'we exit the editor ' ) def step_save_named_query ( context ) : if context.editor_file_name and os.path.exists ( context.editor_file_name ) : context.cli.sendline ( 'select * from abc ' ) def step_see_record_updated ( context ) : @ then ( 'we see data selected ' ) _expect_exact ( context , 'DELETE 1 ' , timeout=2 ) import pip 'database_name ' : context.conf [ 'dbname_tmp ' ] Wait to see create table output . context.exit_sent = False if context.editor_file_name and os.path.exists ( context.editor_file_name ) : @ then ( 'we see the named query deleted ' ) # Strip color codes out of the output . Send drop database . Each step is defined by the string decorating it . @ when ( 'we insert into table ' ) def step_db_connect_test ( context ) : # Write the file . context.cli.sendline ( 'drop table a ; ' ) and we see the sql in prompt Send Ctrl + D to hopefully exit . Wait to see refresh output . } wrappers.expect_exact ( context , 'DROP TABLE ' , timeout=2 ) if 'PGPASS ' in os.environ : context.response = { Wait to see query saved . Send create database . def step_see_help ( context ) : # - * - coding : utf-8 - * @ then ( 'we see record inserted ' ) Wait to see query deleted . def step_db_connect_postgres ( context ) : Run the process using pexpect . Wait to see update output . context.cli.sendline ( `` 'delete from a where x = 'yyy ' ; ' '' ) raise Exception ( 'Expected : \n -- -\n { 0 } \n -- -\n\nActual : \n -- -\n { 1 } \n -- -'.format ( def step_see_table_created ( context ) : Make sure the cli exits . Send refresh command . try : Send select from table . # if step.status == `` failed '' : # - * - coding : utf-8 - * # Cleanup the command line . @ then ( 'we see table created ' ) def step_ctrl_d ( context ) : def step_run_cli ( context ) : def step_run_cli ( context ) : wrappers.expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) sys.executable import pexpect context.cli.sendline ( '\\n foo ' ) context.editor_file_name = 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) @ when ( 'we save a named query ' ) _expect_exact ( context , 'DROP DATABASE ' , timeout=2 ) source=pgcli def step_send_help ( context ) : _expect_exact ( context , 'foo : Deleted ' , timeout=1 ) _expect_exact ( context , 'DROP TABLE ' , timeout=2 ) `` `` '' Send create table . @ when ( 'we select from table ' ) 'database_name ' : context.conf [ 'dbname_tmp ' ] def step_install_cli ( _ ) : `` `` '' context.cli.sendcontrol ( ' x ' ) context.conf [ 'dbname_tmp ' ] ) ) Wait to see insert output . def step_see_named_query_deleted ( context ) : when we run pgcli `` `` '' @ when ( 'we type sql in the editor ' ) then we see the sql in prompt Steps for behavioral style tests are defined in this module . def step_refresh_completions ( context ) : context.cli.sendline ( '\\ns foo SELECT 12345 ' ) Send deete from table . context.cli.sendline ( ' i ' ) Make sure prompt is displayed . _expect_exact ( context , 'You are now connected to database ' , timeout=2 ) Send insert into table . When we run dbcli Send connect to database . def step_wait_exit ( context ) : Send refresh command . Wait to see query deleted . def step_delete_from_table ( context ) : import pexpect @ when ( 'we drop database ' ) @ then ( 'we see table dropped ' ) @ when ( 'we create table ' ) coverage==4.3.4 _expect_exact ( context , 'INSERT 0 1 ' , timeout=2 ) 'cli_command ' : context.config.userdata.get ( 'pg_cli_command ' , None ) or os.remove ( context.editor_file_name ) def step_refresh_completions ( context ) : context.cli.sendcontrol ( 'd ' ) import os dists = set ( [ di.key for di in pip.get_installed_distributions ( ) ] ) context.cli.sendline ( '\\connect { 0 } '.format ( db_name ) ) context.cli = pexpect.spawnu ( cli_cmd , cwd= ' .. ' ) wrappers.expect_exact ( context , 'refresh started in the background ' , timeout=2 ) wrappers.expect_exact ( context , 'INSERT 0 1 ' , timeout=2 ) wrappers.expect_exact ( context , 'You are now connected to database ' , timeout=2 ) `` `` '' context.cli.sendline ( '\e { 0 } '.format ( context.editor_file_name ) ) _expect_exact ( context , 'CREATE DATABASE ' , timeout=2 ) raise Exception ( 'Expected : \n -- -\n { 0 ! r } \n -- -\n\nActual : \n -- -\n { 1 ! r } \n -- -'.format ( Wait to see drop output . _expect_exact ( context , 'Saved . ' , timeout=1 ) context.cli.sendcontrol ( 'd ' ) def step_see_db_created ( context ) : from behave import given , when , then then pgcli exits context.cli.sendline ( '\\nd foo ' ) import wrappers try : def step_see_refresh_started ( context ) : def step_see_table_dropped ( context ) : Wait to see create database output . def step_db_connect_dbserver ( context ) : except : Send drop database . def step_see_named_query_saved ( context ) : actual ) ) 'vi ' : vi # Cleanup the edited file . def step_see_db_dropped ( context ) : def step_see_db_connected ( context ) : _expect_exact ( context , 'nano ' , timeout=2 ) context.cli.sendline ( 'drop database { 0 } ; '.format ( def step_see_refresh_started ( context ) : import os Send create database . # Strip color codes out of the output . context.cli.sendline ( '\\refresh ' ) @ when ( 'we delete from table ' ) coverage combine context.cli.sendline ( `` 'update a set x = 'yyy ' where x = 'xxx ' ; ' '' ) _expect_exact ( context , 'yyy ' , timeout=1 ) Send \nd command def step_see_named_query_saved ( context ) : context.cli.sendline ( 'create table a ( x text ) ; ' ) @ then ( 'we see pgcli prompt ' ) def step_edit_done_sql ( context ) : def step_see_record_inserted ( context ) : for expected_line in context.fixture_data [ 'help_commands.txt ' ] : context.cli.sendline ( '\ ? ' ) # TODO : uncomment to debug a failure del os.environ [ 'PGPASSWORD ' ] [ run ] os.environ [ 'PGPASSWORD ' ] = context.conf [ 'pass ' ] Make sure prompt is displayed . del os.environ [ 'PGPASS ' ] @ when ( 'we connect to test database ' ) when we connect to postgres def step_see_named_query_deleted ( context ) : for match in 'select * from abc'.split ( ' ' ) : context.cli.sendline ( '\\connect { 0 } '.format ( db_name ) ) context.cli.sendline ( ' . ' ) def step_see_data_deleted ( context ) : import re wrappers.expect_exact ( context , 'foo : Deleted ' , timeout=1 ) def step_see_table_created ( context ) : # def after_step ( context , step ) : context.cli.sendcontrol ( ' o ' ) actual ) ) def step_create_table ( context ) : def step_see_record_inserted ( context ) : def step_see_named_query_executed ( context ) : def step_db_drop ( context ) : # Cleanup the edited file . Edit file with external editor . @ then ( 'we see the sql in prompt ' ) def step_select_from_table ( context ) : context.cli.sendline ( 'create database { 0 } ; '.format ( Send drop table . @ when ( 'we drop table ' ) context.exit_sent = True def step_see_prompt ( context ) : Wait to see delete output . Wait to see the prompt . context.cli.sendline ( 'select * from a ; ' ) Wait to see create database output . def step_db_create ( context ) : context.cli.sendline ( 'create database { 0 } ; '.format ( _expect_exact ( context , 'UPDATE 1 ' , timeout=2 ) os.remove ( context.editor_file_name ) @ then ( 'we see database connected ' ) This string is used to call the step in `` * .feature '' file . cli_cmd = context.conf.get ( 'cli_command ' ) def step_update_table ( context ) : def step_see_db_created ( context ) : context.cli.sendline ( '\e { 0 } '.format ( context.editor_file_name ) ) def step_see_db_dropped ( context ) : def step_edit_quit ( context ) : wrappers.expect_exact ( context , ' : ' , timeout=2 ) context.cli = pexpect.spawnu ( 'pgcli ' ) 'PGPASSWORD ' : os.environ.get ( 'PGPASSWORD ' , None ) , _expect_exact ( context , 'refresh started in the background ' , timeout=2 ) Send Ctrl + D to hopefully exit . Wait to see query saved . os.environ [ 'EDITOR ' ] = 'ex ' def step_insert_into_table ( context ) : then dbcli exits Send create table . Send \n command @ when ( 'we send `` \ ? '' command ' ) # Cleanup the command line . context.cli.sendline ( 'create table a ( x text ) ; ' ) context.cli.sendline ( `` 'delete from a where x = 'yyy ' ; ' '' ) @ then ( 'we see record deleted ' ) from __future__ import unicode_literals Wait to see drop database output . Send drop table . def step_db_drop ( context ) : @ then ( 'we see database created ' ) Wait to see delete output . } wrappers.expect_exact ( context , 'Entering Ex mode . Type `` visual '' to go to Normal mode . ' , timeout=2 ) def step_wait_prompt ( context ) : then we see pgcli prompt def step_update_table ( context ) : for expected_line in context.fixture_data [ 'help_commands.txt ' ] : if os.path.exists ( context.editor_file_name ) : context.cli.sendline ( 'select * from a ; ' ) actual = re.sub ( r'\x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? ' , `` , context.cli.before ) # Confirm file name sending `` enter '' . def step_ctrl_d ( context ) : def step_drop_table ( context ) : @ then ( 'we see the named query saved ' ) os.environ [ `` COVERAGE_PROCESS_START '' ] = os.getcwd ( ) + `` / .. /.coveragerc '' def step_see_table_dropped ( context ) : context.cli.sendline ( ' x ' ) Wait to see drop output . expected , def step_edit_file ( context ) : def step_use_named_query ( context ) : def step_see_prompt ( context ) : @ then ( 'we see the named query executed ' ) context.conf [ 'dbname_tmp ' ] ) ) Run the process using pexpect . @ given ( 'we have pgcli installed ' ) _expect_exact ( context , expected_line , timeout=1 ) context.exit_sent = False def step_wait_exit ( context ) : @ when ( 'we use a named query ' ) context.exit_sent = True from behave import when Wait to see create table output . _expect_exact ( context , 'select * from abc ' , timeout=2 ) # import ipdb ; ipdb.set_trace ( ) ' -c `` import coverage ; coverage.process_startup ( ) ; import pgcli.main ; pgcli.main.cli ( ) '' ' _expect_exact ( context , pexpect.EOF , timeout=5 ) context.cli.expect_exact ( expected , timeout=timeout ) _expect_exact ( context , '12345 ' , timeout=1 ) @ then ( 'pgcli exits ' ) Wait to see drop database output . def step_drop_table ( context ) : wrappers.expect_exact ( context , pexpect.EOF , timeout=5 ) Send \ ? to see help . os.environ [ 'PGPASS ' ] = context.conf [ 'pass ' ] Wait to see the prompt . when we connect to dbserver actual = re.sub ( r'\x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? ' , `` , context.cli.before ) def step_create_table ( context ) : Wait to see select output . wrappers.expect_exact ( context , `` written '' , timeout=2 ) wrappers.expect_exact ( context , expected_line , timeout=1 ) parallel=True _expect_exact ( context , 'CREATE TABLE ' , timeout=2 ) @ when ( 'we refresh completions ' ) wrappers.expect_exact ( context , 'Saved . ' , timeout=1 ) @ when ( 'we delete a named query ' ) def step_save_named_query ( context ) : wrappers.expect_exact ( context , 'UPDATE 1 ' , timeout=2 ) @ then ( 'we see database dropped ' ) @ when ( 'we update table ' ) Wait to see update output . if os.path.exists ( context.editor_file_name ) : def step_see_data_deleted ( context ) : wrappers.expect_exact ( context , '\r\n : ' , timeout=2 ) def step_delete_from_table ( context ) : wrappers.expect_exact ( context , 'DELETE 1 ' , timeout=2 ) def step_edit_quit ( context ) : def step_wait_prompt ( context ) : _expect_exact ( context , 'SELECT 1 ' , timeout=1 ) @ then ( 'we see record updated ' ) context.cli.sendline ( '\ ? ' ) wrappers.expect_exact ( context , 'yyy ' , timeout=1 ) context.cli.sendline ( `` 'insert into a ( x ) values ( 'xxx ' ) ; ' '' ) context.cli.sendcontrol ( 'm ' ) wrappers.expect_exact ( context , match , timeout=1 ) def step_see_data_selected ( context ) : Given we have pgcli installed Wait to see refresh output . def step_see_help ( context ) : context.cli.sendline ( '\\n foo ' ) Each step is defined by the string decorating it . def step_edit_done_sql ( context ) : def step_see_named_query_executed ( context ) :","['.coveragerc', '.travis.yml', 'requirements-dev.txt', 'tests/features/basic_commands.feature', 'tests/features/crud_database.feature', 'tests/features/crud_table.feature', 'tests/features/environment.py', 'tests/features/iocommands.feature', 'tests/features/named_queries.feature', 'tests/features/specials.feature', 'tests/features/steps/basic_commands.py', 'tests/features/steps/crud_database.py', 'tests/features/steps/crud_table.py', 'tests/features/steps/iocommands.py', 'tests/features/steps/named_queries.py', 'tests/features/steps/specials.py', 'tests/features/steps/step_definitions.py', 'tests/features/steps/wrappers.py']",Merge pull request # 673 from dbcli/j-bennet/behave-tests-housekeeping
229,1b50f04a89dd7af7931c53ec41385f3c16135322,2017-03-30 21:19:53-07:00,"continuation=self.multiline_continuation_char * ( width - 1 ) + ' ' return [ ( Token.Continuation , continuation ) ] * Allow configurable character to be used for multi-line query continuations . ( Thanks : ` Owen Stephens ` _ ) * Owen Stephens .. _ ` Owen Stephens ` : https : //github.com/owst self.multiline_continuation_char = c [ 'main ' ] [ 'multiline_continuation_char ' ] multiline_continuation_char = ' . ' return [ ( Token.Continuation , ' . ' * ( width - 1 ) + ' ' ) ] # Character used to left pad multi-line queries to match the prompt size .","['AUTHORS', 'changelog.rst', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 678 from owst/configurable_continuation_char
230,733a6073802775d2fcf9086ac73ec39fff8fd1e0,2017-03-21 22:23:31-07:00,"'prompt_toolkit > =1.0.10 , < 1.1.0 ' , 'prompt_toolkit > =1.0.9 , < 1.1.0 ' , * Fixed external editor bug ( issue # 668 ) . ( Thanks : ` Irina Truong ` _ ) . Bug fixes :","['changelog.rst', 'setup.py']",Merge pull request # 676 from dbcli/j-bennet/bump-prompt-toolkit-for-fix-edit-bug
231,534dbbfce193451a00628167e0f50e36f191fa0b,2017-03-20 09:31:56-07:00,# We may find a better way to do it in the future . document = cli.run ( False ) document = self.cli.run ( ) cli.application.pre_run_callables = [ ] saved_callables = cli.application.pre_run_callables # It 's internal api of prompt_toolkit that may change . This was added to fix # 668 . # FIXME : using application.pre_run_callables like this here is not the best solution . document = cli.run ( ) document = self.cli.run ( True ) cli.application.pre_run_callables = saved_callables,['pgcli/main.py'],Merge pull request # 670 from dbcli/j-bennet/fix-edit-bug
232,915dd237450120c6b658c95b4a87b575b8df0cbc,2017-03-19 12:49:32-07:00,# # Checklist # # Description [ ] What is the output of `` pip freeze `` command . < ! -- - Describe your problem as fully as you can . -- > [ ] I 've added my name to the ` AUTHORS ` file ( or it 's already there ) . # # Your environment [ ] Please provide your OS and version information . < ! -- This gives us some more context to work with . -- > [ ] Please provide your CLI version . [ ] I 've added this contribution to the ` changelog.md ` . < ! -- - Describe your changes in detail . -- > < ! -- - We appreciate your help and want to give you credit . Please take a moment to put an ` x ` in the boxes below as you complete them . -- >,"['.github/ISSUE_TEMPLATE.md', '.github/PULL_REQUEST_TEMPLATE.md']",Merge pull request # 671 from dbcli/j-bennet/pr-templates
233,7e5ae94dba1bdc5358adad3bc7a427f92436d3a2,2017-03-15 21:18:21-07:00,document = cli.run ( False ) document = self.cli.run ( ) cli.application.pre_run_callables = [ ] saved_callables = cli.application.pre_run_callables document = cli.run ( ) document = self.cli.run ( True ) cli.application.pre_run_callables = saved_callables,['pgcli/main.py'],Attempt to fix # 668 ( not pretty ) .
234,7b14da9b4c5a61b4c852f9e3e13c2786317df50e,2017-03-14 16:36:36-04:00,"return self._make_cand ( func , alias , suggestion ) def completer_all_schemas ( ) : tables = [ t for t in tables if not t.startswith ( 'pg_ ' ) ] return Candidate ( item , synonyms=synonyms ) def _make_cand ( self , tbl , do_alias , suggestion , function=False ) : return testdata.get_completer ( { 'generate_aliases ' : True } , casing ) schema= ( self._maybe_schema ( schema=sch , parent=schema ) ) , for meta in metas alias = self.alias ( cased_tbl , suggestion.table_refs ) table ( t , pos=-1 ) for t in ( 'users ' , 'custom . `` Users '' ' , 'custom.users ' ) types = [ self._make_cand ( t , False , suggestion ) for t in types ] settings= { 'search_path_filter ' : True } , def SchemaObject ( name , schema=None , function=False ) : tables = [ t for t in tables if not t.name.startswith ( 'pg_ ' ) ] ] return [ ] # Note : tbl is a SchemaObject item , prio , display_meta , synonyms , prio2 = cand settings= { 'generate_aliases ' : True , 'search_path_filter ' : True } , schema is the schema qualification input by the user ( if any ) schema = self.escape_name ( schema ) return Candidate ( item , synonyms=synonyms , prio2=prio2 ) tables.extend ( SchemaObject ( tbl.name ) for tbl in suggestion.local_tables ) tables.extend ( tbl.name for tbl in suggestion.local_tables ) def test_all_schema_objects_with_casing ( [ table ( x ) for x in ( 'Orders ' , ' '' select '' ' , 'CUSTOM.shipments ' ) ] sort_key , type_priority , prio , priority_func ( item ) , ) : return self._make_cand ( func_name , alias , suggestion , function=True ) item , display_meta , prio = cand , meta , 0 def _cand ( func_name , alias ) : objects = [ obj for schema in schemas search_path_filter = False maybe_parens = ' ( ) ' if function else `` assert result > = set ( for sch in self._get_schemas ( obj_type , schema ) maybe_schema = ( self.case ( tbl.schema ) + ' . ' ) if tbl.schema else `` def _get_schemas ( self , obj_typ , schema ) : settings= { 'generate_aliases ' : True , 'search_path_filter ' : True } metadata = self.dbmetadata [ obj_typ ] return testdata.get_completer ( { 'generate_aliases ' : True } ) ) ) Document ( text=text , cursor_position=position ) , completer_all_schemas_casing.get_completions ( if filter_func ( meta ) return [ func for ( func , metas ) in metadata [ schema ] .items ( ) cased_tbl = self.case ( tbl ) complete_event 'Candidate ' , [ 'completion ' , 'prio ' , 'meta ' , 'synonyms ' , 'prio2 ' ] objects = [ ] `` `` '' Returns a list of SchemaObjects representing tables , views , funcs _Candidate = namedtuple ( 'Candidate ' , [ 'completion ' , 'priority ' , 'meta ' , 'synonyms ' ] ) item = maybe_schema + cased_tbl + maybe_parens + maybe_alias alias = self.alias ( cased_tbl , suggestion.table_refs ) ) SchemaObject ( def test_all_schema_objects ( completer_all_schemas , complete_event ) : # schema does n't exist [ function ( x+ ' ( ) ' ) for x in ( 'func2 ' , 'CUSTOM.func3 ' ) ] def Candidate ( completion , prio=None , meta=None , synonyms=None , prio2=None ) : def test_all_schema_objects_with_aliases ( for meta in metas `` `` '' Returns list of tables or functions for a ( optional ) schema '' '' '' [ function ( x ) for x in ( 'func2 ( ) f ' , 'custom.func3 ( ) f ' ) ] _SchemaObject = namedtuple ( 'SchemaObject ' , [ 'name ' , 'schema ' , 'function ' ] ) return _SchemaObject ( name , schema , function ) function=True [ table ( x ) for x in ( 'orders ' , ' '' select '' ' , 'custom.shipments ' ) ] def test_schema_object_order ( completer_all_schemas , complete_event ) : def completer_aliases_casing ( ) : schemas = self.search_path if do_alias : assert result [ :3 ] == [ casing=casing return [ func for schema in self.search_path _Candidate = namedtuple ( text = 'SELECT * FROM ' for obj in metadata [ schema ] .keys ( ) ] def completer_all_schemas_casing ( ) : return testdata.completer for sch in self._get_schemas ( 'functions ' , schema ) completer_all_schemas_aliases.get_completions ( def completer_aliases_casing ( request ) : if schema : views = [ v for v in views if not v.startswith ( 'pg_ ' ) ] def completer_all_schemas_aliases ( ) : views = [ v for v in views if not v.name.startswith ( 'pg_ ' ) ] return _Candidate ( completion , prio , meta , synonyms or [ completion ] , prio2 ) [ table ( x ) for x in ( 'orders o ' , ' '' select '' s ' , 'custom.shipments s ' ) ] return _Candidate ( completion , priority , meta , synonyms or [ completion ] ) try : schema = self.escape_name ( schema ) def _make_cand ( self , tbl , do_alias , suggestion ) : maybe_parens = ' ( ) ' if tbl.function else `` name=obj , [ function ( x+ ' ( ) ' ) for x in ( 'func2 ' , 'custom.func3 ' ) ] cased_tbl = self.case ( tbl.name ) prio2 = 0 if tbl.schema else 1 'search_path_filter ' : c [ 'main ' ] .as_bool ( 'search_path_filter ' ) , `` `` '' Returns a list of schemas from which to suggest objects # When no schema is entered , only suggest objects in search_path function= ( obj_type == 'functions ' ) item , display_meta , prio , prio2 = cand , meta , 0 , 0 except KeyError : def _maybe_schema ( self , schema , parent ) : objects = metadata [ self.escape_name ( schema ) ] .keys ( ) item , prio , display_meta , synonyms = cand self.search_path_filter = settings.get ( 'search_path_filter ' ) result = completer_all_schemas.get_completions ( complete_event return [ metadata = self.dbmetadata [ 'functions ' ] return testdata.get_completer ( casing=casing ) metadata = self.dbmetadata [ obj_type ] text = 'SELECT * FROM u ' name=func , return testdata.get_completer ( settings= { 'search_path_filter ' : True } ) prio2 , lexical_priority return [ self.case ( o ) for o in objects ] for obj in self.dbmetadata [ obj_type ] [ sch ] .keys ( ) return testdata.get_completer ( casing=casing ) position = len ( 'SELECT * FROM u ' ) completer_all_schemas_aliases , complete_event result = set ( return testdata.get_completer ( ) def Candidate ( completion , priority=None , meta=None , synonyms=None ) : priority = sort_key , type_priority , prio , priority_func ( item ) , lexical_priority return testdata.get_completer ( settings= { 'generate_aliases ' : True } ) priority = ( Document ( text=text , cursor_position=position ) , else : ] return None if parent or schema in self.search_path else schema item = cased_tbl + maybe_parens + maybe_alias return self.search_path if self.search_path_filter else metadata.keys ( ) for ( func , metas ) in metadata [ schema ] .items ( ) def _cand ( func , alias ) : if schema : ) if filter_func ( meta ) ] completer_all_schemas_casing , complete_event completer_all_schemas.get_completions ( for ( func , metas ) in self.dbmetadata [ 'functions ' ] [ sch ] .items ( ) `` `` '' return [ schema ] if schema in metadata else [ ] return testdata.get_completer ( ) position = len ( 'SELECT * FROM ' )","['pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py']",Merge pull request # 649 from dbcli/koljonen/suggest_from_all_schemas
235,ffc7f7a64f157526726c1b30311c8ca65fde82db,2017-03-13 23:04:02-07:00,Upcoming ======== 1.5.1 ===== * Added `` MATERIALIZED VIEW `` keywords . ( Thanks : ` Joakim Koljonen ` _ ) . * Fixed `` set_session can not be used inside a transaction '' when using dsn . ( Thanks : ` Irina Truong ` _ ) .,['changelog.rst'],Merge pull request # 666 from dbcli/j-bennet/release-1.5.1
236,efe905a2aa924592bec6bf38e5c20269cd0dd771,2017-03-13 11:16:34-07:00,"# When we connect using a DSN , we do n't really know what db , port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) [ 0 ] # user , etc . we connected to . Let 's read it . # user , etc . we connected to . Let 's read it . host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) [ 0 ] if dsn : user = self._select_one ( cursor , 'select current_user ' ) [ 0 ] db = self._select_one ( cursor , 'select current_database ( ) ' ) [ 0 ] # Note : moved this after setting autocommit because of # 664 . 'select current_database ( ) , current_user , inet_server_addr ( ) , inet_server_port ( ) ' ) cursor , db , user , host , port = self._select_one ( # When we connect using a DSN , we do n't really know what db ,",['pgcli/pgexecute.py'],Merge pull request # 665 from dbcli/j-bennet/bugfix-dsn-set-session-transaction
237,dcd9cbac4f3492b674b414c9bc1ddc54cbf61c98,2017-03-13 11:02:16-07:00,"db = self._select_one ( cursor , 'select current_database ( ) ' ) [ 0 ] # When we connect using a DSN , we do n't really know what db , port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) [ 0 ] # user , etc . we connected to . Let 's read it . # user , etc . we connected to . Let 's read it . host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) [ 0 ] if dsn : user = self._select_one ( cursor , 'select current_user ' ) [ 0 ] db = self._select_one ( cursor , 'select current_database ( ) ' ) [ 0 ] # Note : moved this after setting autocommit because of # 664 . user = self._select_one ( cursor , 'select current_user ' ) [ 0 ] host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) [ 0 ] # When we connect using a DSN , we do n't really know what db , port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) [ 0 ]",['pgcli/pgexecute.py'],Fix set_session can not be used inside a transaction when using dsn . Connect # 664 .
238,91a3a9da6da1a8ca2ad27ac6e53062fa0aa802a9,2017-03-11 15:31:55-08:00,.. _ ` tk ` : https : //github.com/kanet77 * Command line option for `` -- less-chatty `` . ( Thanks : ` tk ` _ ) ===== ======== * Support unicode chars in expanded mode . ( Thanks : ` Amjith Ramanujam ` _ ) Bug fixes :,['changelog.rst'],Merge pull request # 663 from dbcli/j-bennet/changelog-upcoming
239,6592b73657f0007892d7c348d504cd9be7a551f8,2017-03-11 15:13:07-08:00,"self.less_chatty = bool ( less_chatty ) or c [ 'main ' ] .as_bool ( 'less_chatty ' ) self.less_chatty = c [ 'main ' ] .as_bool ( 'less_chatty ' ) single_connection , dbname , username , version , pgclirc , dsn , row_limit , prompt ) : single_connection , dbname , username , version , pgclirc , dsn , row_limit , 'less_chatty ' : less_chatty , single_connection=False , prompt=None ) : row_limit=row_limit , single_connection=single_connection , prompt=prompt ) less_chatty , prompt ) : row_limit=row_limit , single_connection=single_connection , single_connection=False , less_chatty=None , prompt=None ) : help='Skip intro on startup and goodbye on exit . ' ) default=False , less_chatty=less_chatty , prompt=prompt )",['pgcli/main.py'],Merge pull request # 659 from kanet77/tk/less-chatty-cmdline-option
240,13be7e295be87cad9a1198e71bfe3ed9ca1556bb,2017-03-11 14:52:53-08:00,Project Lead : * Irina Truong * Iryna Cherniavska,['AUTHORS'],Merge pull request # 661 from dbcli/amjith/maintainers
241,6a42d4e91eb33b15369a0113e66a93dbe9e6c029,2017-03-10 02:44:24-06:00,"self.less_chatty = c [ 'main ' ] .as_bool ( 'less_chatty ' ) self.less_chatty = less_chatty single_connection , dbname , username , version , pgclirc , dsn , row_limit , prompt ) : single_connection , dbname , username , version , pgclirc , dsn , row_limit , 'less_chatty ' : less_chatty , single_connection=False , prompt=None ) : less_chatty=less_chatty , prompt=prompt ) if less_chatty is not None : row_limit=row_limit , single_connection=single_connection , prompt=prompt ) less_chatty , prompt ) : row_limit=row_limit , single_connection=single_connection , default=None , else : single_connection=False , less_chatty=None , prompt=None ) : help='Skip intro on startup and goodbye on exit . ' ) self.less_chatty = c [ 'main ' ] .as_bool ( 'less_chatty ' ) or False",['pgcli/main.py'],Add a command line option for -- less-chatty . Fix # 626 .
242,83442f8ebf3b855ccc9ea691e6797dc63a5648bc,2017-03-08 18:50:59-08:00,"statement = None def test_statements_in_function_body ( text ) : split = function_body_pattern.search ( text ) SELECT count ( 1 ) FROM users ; language sql AS if body_start is None : SELECT 3 FROM foo ; Function ( schema=None ) , return _split_multiple_statements ( full_text , text_before_cursor , parsed ) current_pos = len ( text_before_cursor ) def _statement_from_function ( full_text , text_before_cursor , statement ) : body_start , body_end = _find_function_body ( full_text ) ' '' suggestions = suggest_type ( text , text [ : text.find ( ' ' ) + 1 ] ) $ foo $ ; ' '' suggestions = suggest_type ( text , `` ) token1_idx = statement.token_index ( token1 ) SELECT 2 FROM bar ; CREATE FUNCTION foo ( custom.products _products ) returns custom.shipments ' return ( split.start ( 2 ) , split.end ( 2 ) ) if split else ( None , None ) if token2 and token2.value.upper ( ) == 'FUNCTION ' : ] LANGUAGE SQL RETURNS text text_before_cursor = text_before_cursor [ body_start : ] $ $ language sql ; Upcoming SELECT count ( 1 ) FROM custom.shipments ; parsed = sqlparse.parse ( text_before_cursor ) suggestions = suggest_type ( text , text [ : text.find ( ' ; ' ) + 1 ] ) Column ( table_refs= ( ( None , 'foo ' , None , False ) , ) , qualifiable=True ) , full_text , text_before_cursor , statement token1 = statement.token_first ( ) SELECT * FROM qux ; INSERT INTO public.orders ( * ) values ( -1 , now ( ) , 'preliminary ' ) ; assert set ( suggestions ) == set ( [ assert set ( suggestions ) == set ( [ Keyword ( ) ] ) def _find_function_body ( text ) : $ func $ CREATE OR REPLACE FUNCTION func ( ) RETURNS setof int AS $ func $ functions = [ Keyword ( ) function_body_pattern = re.compile ( ' ( \\ $ . * ? \\ $ ) ( [ \s\S ] * ? ) \\1 ' , re.M ) ] ) SELECT * FROM baz ; full_text = full_text [ body_start : body_end ] ' '' create function func2 ( int , varchar ) if statement.get_type ( ) in ( 'CREATE ' , 'CREATE OR REPLACE ' ) : create function func2 ( int , varchar ) def test_statements_with_cursor_before_function_body ( text ) : SELECT FROM foo ; ] ) token2 = None SELECT 3 FROM bar ; token2 = statement.token_next ( token1_idx ) [ 1 ] return full_text , text_before_cursor , statement ' ; return full_text , text_before_cursor , None CREATE OR REPLACE FUNCTION func ( ) RETURNS setof int AS $ $ SELECT 1 FROM custom.shipments ; full_text , text_before_cursor , statement = _statement_from_function ( SELECT 1 FROM foo ; def test_statements_with_cursor_after_function_body ( text ) : if not body_start < = current_pos < body_end : ) Features : if token1 : ===== * Better suggestions when editing functions ( Thanks : ` Joakim Koljonen ` _ ) AS $ foo $ SELECT 2 FROM custom.users ; ' '' ,","['changelog.rst', 'pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_sqlcompletion.py']",Merge pull request # 655 from dbcli/koljonen/parse_function_body
243,4904a982dd9970f843a0c368d62de55cd6f1c0a4,2017-03-07 15:02:52+01:00,"row_result.append ( ( u '' % s '' % header ) + `` `` + ( u '' % s '' % utf8tounicode ( value ) ) .strip ( ) ) from .. encodingutils import utf8tounicode def test_unicode_expanded_table ( ) : row_result.append ( ( u '' % s '' % header ) + `` `` + ( u '' % s '' % value ) .strip ( ) ) age | 123 expected = u '' '' '' - [ RECORD 0 ] name | ö `` `` '' row_len = max ( [ len ( _text_type ( x ) ) for x in row ] ) assert expected == expanded_table ( input , [ `` name '' , `` age '' ] ) row_len = max ( [ len ( _text_type ( utf8tounicode ( x ) ) ) for x in row ] ) # coding=UTF-8 input = [ ( u ' ö ' , 123 ) ]","['pgcli/packages/expanded.py', 'tests/test_expanded.py']",Merge pull request # 656 from dbcli/amjith/support-unicode-expanded-display
244,6e38853c99a6b01513dc4595e5103e848a09e63d,2017-03-06 16:57:50-08:00,"keyword ( 'MAXEXTENTS ' , -2 ) , keyword ( 'MATERIALIZED VIEW ' , -2 ) , `` REFRESH MATERIALIZED VIEW '' , Completion ( text='MATERIALIZED VIEW ' , start_position=-2 ) , assert set ( result ) == set ( [ assert set ( result ) == set ( [ function ( 'MAX ' , -2 ) , function ( 'MAX ' , -2 ) , ] ) `` MATERIALIZED VIEW '' , keyword ( 'MAXEXTENTS ' , -2 ) , ] )","['pgcli/packages/pgliterals/pgliterals.json', 'tests/test_naive_completion.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 653 from dbcli/koljonen/materialized_view_keywords
245,54d08ba9cd8f4c0db7931484c28fe8e3d29a586d,2017-03-06 16:18:21-08:00,* Make the menu size configurable . ( Thanks ` Darik Gamble ` _ ) Features : * Handle more connection failure cases . ( Thanks : ` Amjith Ramanujam ` _ ) * Add testing for Python 3.5 and 3.6 . ( Thanks : ` Amjith Ramanujam ` _ ) * Add additional completion for `` ALTER `` keyword ( Thanks : ` Darik Gamble ` _ ) * Make pgcli prompt width short when the prompt is too long ( Thanks : ` Jonathan Virga < https : //github.com/jnth > ` _ ) * Upgraded pgspecial to 1.7.0 . ( See ` pgspecial changelog < https : //github.com/dbcli/pgspecial/blob/master/changelog.rst > ` _ for list of fixes ) Bug Fixes : ===== * Add a new config setting to allow expandable mode ( Thanks : ` Jonathan Boudreau < https : //github.com/AGhost-7 > ` _ ) Internal Changes : * Fix the connection failure issues with latest psycopg2 . ( Thanks : ` Amjith Ramanujam ` _ ) 1.5.0,['changelog.rst'],Merge pull request # 648 from dbcli/amjith/release-1.5.0
246,5b2c3151e0c636ca3bf8c5632542167536ebe3d2,2017-03-03 11:19:33-08:00,"envlist = py26 , py27 , py33 , py34 , py35 , py36 `` 3.6 '' envlist = py26 , py27 , py33 , py34 `` 3.5 ''","['.travis.yml', 'tox.ini']",Merge pull request # 645 from dbcli/amjith/add-py36
247,132f2bd7583326f75a8673b9b69b08a7e7c0960f,2017-03-03 11:17:51-08:00,"self._handle_server_closed_connection ( ) else : self._handle_server_closed_connection ( ) if ( 'server closed the connection ' click.secho ( str ( e ) , err=True , fg='red ' ) in utf8tounicode ( e.args [ 0 ] ) ) : logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) logger.error ( `` sql : % r , error : % r '' , text , e ) logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) logger.error ( `` sql : % r , error : % r '' , text , e )",['pgcli/main.py'],Merge pull request # 644 from dbcli/amjith/operational-error
248,b273d1375500a436ba09d80688f50766d51d6b6f,2017-03-03 10:26:24-08:00,"cursor.execute ( `` SHOW ALL '' ) cursor.execute ( `` SHOW ALL '' ) pid = self._select_one ( cursor , 'select pg_backend_pid ( ) ' ) [ 0 ] db_parameters = dict ( name_val_desc [ :2 ] for name_val_desc in cursor.fetchall ( ) ) pid = self._select_one ( cursor , 'select pg_backend_pid ( ) ' ) [ 0 ] db_parameters = dict ( name_val_desc [ :2 ] for name_val_desc in cursor.fetchall ( ) )",['pgcli/pgexecute.py'],Merge pull request # 647 from dbcli/amjith/fix-psycopg2-bug
249,9cc58b7087eb31eb1ca142a0fe4cab7814b43437,2017-02-25 14:23:35-08:00,"self.min_num_menu_lines = c [ 'main ' ] .as_int ( 'min_num_menu_lines ' ) # Number of lines to reserve for the suggestion menu reserve_space_for_menu=4 , min_num_menu_lines = 4 reserve_space_for_menu=self.min_num_menu_lines ,","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 642 from dbcli/darikg/reserve-more-menu-space
250,b07d63be4c5cdc53f008575cdbda67b310a2eebf,2017-02-25 14:16:12-08:00,"elif token_v == 'alter ' : sql = 'ALTER TABLE users ALTER ' return ( Keyword ( ) , ) completions = completer.get_completions ( ] ) Document ( text=sql , cursor_position=len ( sql ) ) , complete_event ) expected = Completion ( 'COLUMN ' , start_position=0 , display_meta='keyword ' ) def test_keyword_after_alter ( completer ) : def test_keyword_after_alter ( sql ) : assert Keyword ( ) in set ( suggest_type ( sql , sql ) ) assert expected in set ( completions ) 'ALTER ' , 'ALTER TABLE foo ALTER ' ,","['pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 641 from dbcli/darikg/keywords-after-alter
251,5d2c084d1b0a12af240a45b7c396af3d18de0e7d,2017-02-09 20:40:55-08:00,"len ( prompt ) > self.max_len_prompt ) : prompt = self.get_prompt ( '\\d > ' ) return [ ( Token.Prompt , prompt ) ] prompt = self.get_prompt ( self.prompt_format ) max_len_prompt = 30 return [ ( Token.Prompt , self.get_prompt ( self.prompt_format ) ) ] if ( self.prompt_format == self.default_prompt and",['pgcli/main.py'],Merge pull request # 639 from jnth/master
252,0559c5119eb686f5fe59cea716381f404c6e0516,2017-02-08 10:32:01+01:00,"len ( prompt ) > self.max_len_prompt ) : prompt = self.get_prompt ( '\\d > ' ) return [ ( Token.Prompt , prompt ) ] prompt = self.get_prompt ( self.prompt_format ) max_len_prompt = 30 return [ ( Token.Prompt , self.get_prompt ( self.prompt_format ) ) ] if ( self.prompt_format == self.default_prompt and",['pgcli/main.py'],Switch the shorted prompt when prompt length is too long . Connect # 587
253,4ad7c0f11b92348fe5b5b8d6a67c62f80e1d05d5,2017-02-04 19:42:05-08:00,"package to pretty-print tables . This library does smart formatting of numbers , [ this issue ] ( https : //github.com/dbcli/pgcli/issues/617 ) for more details . Note : ` pgcli ` uses [ tabulate ] ( https : //github.com/dbcli/pgcli/blob/master/pgcli/packages/tabulate.py ) which can sometimes lead to unexpected output . See",['README.rst'],Merge pull request # 638 from dbcli/bugfix/document-tabulate-number-formatting
254,fdda8c4e5d5009eb7bdeb7b556b84fe2dce2d850,2017-02-04 18:56:20-08:00,"package to pretty-print tables . This library does smart formatting of numbers , [ this issue ] ( https : //github.com/dbcli/pgcli/issues/617 ) for more details . Note : ` pgcli ` uses [ tabulate ] ( https : //github.com/dbcli/pgcli/blob/master/pgcli/packages/tabulate.py ) which can sometimes lead to unexpected output . See",['README.rst'],Added documantation about tabulate 's number formatting . Connect # 617 .
255,2a83436f14dd8c9d4dbad4889c530b5398463dfc,2017-01-21 13:56:38-08:00,"if self.pgspecial.auto_expand or self.auto_expand : self.float_format , self.null_string , expanded , max_width ) self.auto_expand = c [ 'main ' ] .as_bool ( 'auto_expand ' ) self.expanded_output = c [ 'main ' ] .as_bool ( 'expand ' ) self.float_format , self.null_string , self.pgspecial.expanded_output , max_width ) auto_expand = False expand = False # Enables auto expand mode , which is similar to ` \x auto ` in psql . if self.pgspecial.auto_expand : expanded = self.pgspecial.expanded_output or self.expanded_output # Enables expand mode , which is similar to ` \x ` in psql .","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 633 from AGhost-7/master
256,81aad79cab9d68d4dc4f8173a3b193f03b87cc2f,2017-01-21 12:51:12-05:00,"if self.pgspecial.auto_expand or self.auto_expand : self.float_format , self.null_string , expanded , max_width ) self.auto_expand = c [ 'main ' ] .as_bool ( 'auto_expand ' ) self.expanded_output = c [ 'main ' ] .as_bool ( 'expand ' ) self.float_format , self.null_string , self.pgspecial.expanded_output , max_width ) auto_expand = False expand = False # Enables auto expand mode , which is similar to ` \x auto ` in psql . if self.pgspecial.auto_expand : expanded = self.pgspecial.expanded_output or self.expanded_output # Enables expand mode , which is similar to ` \x ` in psql .","['pgcli/main.py', 'pgcli/pgclirc']","Per # 298 , make expand modes configurable ."
257,67ed13498d2efb210ebdd8c284165eca637aaa46,2017-01-11 17:54:31-08:00,"* Support for table-qualifying column suggestions . ( Thanks : ` Joakim Koljonen ` _ ) . * Fix crash after ` with ` . ( Thanks : ` Joakim Koljonen ` _ ) . * Fix issue # 603 ( ` \i ` raises a TypeError ) . ( Thanks : ` Emanuele Gaifas ` _ ) . * Increased minimum prompt_toolkit requirement to 1.0.9 . ( Thanks : ` Irina Truong ` _ ) . * Set default data_formatting to nothing . ( Thanks : ` Amjith Ramanujam ` _ ) . ======= 1.4.0 * Search table suggestions using initialisms . ( Thanks : ` Joakim Koljonen ` _ ) . Internal Changes : * Fix scoping for columns from CTEs . ( Thanks : ` Joakim Koljonen ` _ ) * Display transaction status in the toolbar . ( Thanks : ` Joakim Koljonen ` _ ) . Features : * Updated version of prompt_toolkit , now matching braces are highlighted . ( Thanks : ` Jonathan Slenders ` ) * Display vi mode in the toolbar . ( Thanks : ` Joakim Koljonen ` _ ) . ===== * Updated version of prompt_toolkit , now matching braces are highlighted . ( Thanks : ` Jonathan Slenders ` _ ) .. _ ` Jonathan Slenders ` : https : //github.com/jonathanslenders ====== Bug Fixes : * Added -- prompt option . ( Thanks : ` Irina Truong ` _ ) .",['changelog.rst'],Merge pull request # 631 from dbcli/j-bennet/release-1.4.0
258,44c7eb10c6532e45df66dbb552408455480156c6,2017-01-09 10:54:31-05:00,"funcs = [ self.case ( f ) + ' ( ) ' for f in funcs ] synonyms = ( name , generate_alias ( self.case ( name ) ) ) fs = self.populate_schema_objects ( suggestion.schema , 'functions ' ) 'entrytags ' : [ 'entryid ' , 'tagid ' ] , complete_event ) : return self.find_matches ( word_before_cursor , tables , meta='table ' ) 'EntryID ' , 'EntryTitle ' , 'EntryText ' ) def generate_alias ( tbl , tbs ) : text = 'SELECT et FROM blog.Entries E ' def test_alias_search_without_aliases2 ( completer_with_casing , complete_event ) : if display_meta is None : 'EntAccLog EAL ON EAL.EntryID = E.EntryID ' , -1 ) ] ( 'blog ' , 'tags ' , 'tagid ' , 'blog ' , 'entrytags ' , 'tagid ' ) , def test_alias_search_without_aliases1 ( completer_with_casing , complete_event ) : funcs = [ _cand ( f , alias=False ) for f in fs ] schema ( ' '' Custom '' ' ) , return Candidate ( item , synonyms=synonyms ) sort_key = max ( syn_matches ) if syn_matches else None # Nones need to be removed to avoid max ( ) crashing in Python 3 casing = ( 'SELECT ' , 'Orders ' , 'User_Emails ' , 'CUSTOM ' , 'Func1 ' ) def Candidate ( completion , priority=None , meta=None , synonyms=None ) : 'tags ' : [ 'tagid ' , 'name ' ] , 'Tags ' , 'EntryTags ' , 'EntAccLog ' , return Candidate ( qualify ( name , ref ) , 0 , 'column ' , synonyms ) assert result [ 0 ] == join ( 'EntryTags ET ON ET.EntryID = E.EntryID ' , -2 ) ( 'blog ' , 'entries ' , 'entryid ' , 'blog ' , 'entrytags ' , 'entryid ' ) , maybe_alias = ( ' ' + alias ) if do_alias else `` [ 'text ' , 'text ' , 'integer ' ] , [ ' i ' , ' i ' , ' o ' ] , text = 'SELECT E.ei FROM blog.Entries E ' complete_event ) : def test_join_alias_search_with_aliases1 ( completer_aliases_casing , else : } , } result = completer_aliases_casing.get_completions ( # Exact match of first word in suggestion return Candidate ( qualify ( name , ref ) , 0 , 'column ' , [ name ] ) assert result [ 0 ] == table ( 'Entries E ' , -1 ) Document ( text=text ) , complete_event ) result = completer_with_casing.get_completions ( suggestion.table_refs ) for f in funcs ] return float ( 'Infinity ' ) , -1 'entacclog ' : [ 'entryid ' , 'username ' , 'datestamp ' ] , for t in tables ] views = [ self.case ( v ) + ' ' + self.alias ( v , suggestion.table_refs ) } } , syn_matches = ( _match ( x ) for x in synonyms ) alias = self.alias ( cased_tbl , suggestion.table_refs ) if alias : [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] synonyms = [ join , ' { 0 } ON { 0 } . { 1 } = { 2 } . { 3 } '.format ( text = 'SELECT * FROM blog.Entries JOIN blog.e ' text = 'SELECT blog.ee ' def test_column_alias_search_qualified ( completer_aliases_casing , for v in views ] synonyms = ( cased_tbl , generate_alias ( cased_tbl ) ) [ 'integer ' , 'text ' ] , [ ' i ' , ' o ' ] , `` , False , False , True ] , '' , False , False , False ] ] , Document ( text , cursor_position=len ( 'SELECT et ' ) ) , complete_event ) joins.append ( Candidate ( join , prio , 'join ' ) ) ] , schema ( 'public ' ) , def _cand ( func_name , alias ) : joins.append ( Candidate ( join , prio , 'join ' , synonyms=synonyms ) ) cased_tbl = self.case ( tbl ) param tbls - set TableReference objects for tables already in query display_meta = meta 'EntryTags ON EntryTags.EntryID = Entries.EntryID ' , -2 ) def test_function_alias_search_without_aliases ( completer_with_casing , # ( before e.g . ` EndUsers EU ` ) tbl = generate_alias ( self.unescape_name ( tbl ) ) suggestion.schema , 'functions ' ) ] complete_event ) : item = cased_tbl + maybe_parens + maybe_alias text = 'SELECT * FROM blog.Entries E JOIN blog.et ' text = 'SELECT * FROM blog.e ' funcs = [ self.case ( f ) + ' ( ) ' + self.alias ( f , 'EntAccLog ON EntAccLog.EntryID = Entries.EntryID ' , -1 ) ] def test_join_alias_search_without_aliases2 ( completer_with_casing , def Candidate ( completion , priority , meta , synonyms = None ) : # E.g . for input ` e ` , 'Entries E ' should be on top assert result [ 0 ] == table ( 'EntryTags ET ' , -2 ) if item.lower ( ) [ : len ( text ) + 1 ] in ( text , text + ' ' ) : assert set ( result ) == set ( cased_schemas + [ assert result [ 0 ] == function ( 'extract_entry_symbols ( ) ' , -3 ) def _make_cand ( self , tbl , do_alias , suggestion , function=False ) : text = 'SELECT * FROM blog.et ' [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] , funcs = [ f + ' ( ) ' for f in self.populate_schema_objects ( # This is to get exact alias matches to the top funcs = [ _cand ( f , alias ) 'blog ' : { def test_join_alias_search_without_aliases1 ( completer_with_casing , def generate_alias ( tbl ) : sort_key = max ( _match ( x ) for x in synonyms ) if alias : def test_alias_search_with_aliases1 ( completer_aliases_casing , complete_event ) : maybe_parens = ' ( ) ' if function else `` 'blog ' : [ [ 'extract_entry_symbols ' , [ '_entryid ' , 'symbol ' ] , assert result [ 0 ] == join ( assert result [ 0 ] == table ( 'Entries ' , -1 ) tables = [ self.case ( t ) + ' ' + self.alias ( t , suggestion.table_refs ) assert set ( result ) == set ( [ text = 'SELECT * FROM blog.Entries E JOIN blog.e ' ( 'blog ' , 'entries ' , 'entryid ' , 'blog ' , 'entacclog ' , 'entryid ' ) , assert result [ 0 ] == table ( 'EntryTags ' , -2 ) 'entries ' : [ 'entryid ' , 'entrytitle ' , 'entrytext ' ] , for f in self.populate_functions ( suggestion.schema , filt ) ] alias , c ( left.col ) , rtbl.ref , c ( right.col ) ) ] return self._make_cand ( func_name , alias , suggestion , function=True ) cols = ( 'EntryText ' , 'EntryTitle ' , 'EntryID ' ) meta='table ' ) syn_matches = [ m for m in syn_matches if m ] cols = ( 'EntryID ' , 'EntryTitle ' ) assert result [ :3 ] == [ column ( c , -2 ) for c in cols ] ] } , tbl = generate_alias ( self.unescape_name ( tbl ) , tbls ) views = [ self._make_cand ( v , alias , suggestion ) for v in views ] } , casing = ( 'SELECT ' , 'Orders ' , 'User_Emails ' , 'CUSTOM ' , 'Func1 ' , 'Entries ' , def test_function_alias_search_with_aliases ( completer_aliases_casing , def test_alias_search_with_aliases2 ( completer_aliases_casing , complete_event ) : def test_column_alias_search ( completer_aliases_casing , complete_event ) : [ 'enter_entry ' , [ '_title ' , '_text ' , 'entryid ' ] , funcs = self.populate_functions ( suggestion.schema , filt ) assert result [ :2 ] == [ table ( 'Entries ' , -1 ) , join ( complete_event ) : tables = [ self._make_cand ( t , alias , suggestion ) for t in tables ] Document ( text , cursor_position=len ( 'SELECT E.ei ' ) ) , complete_event ) assert result [ :2 ] == [ table ( 'Entries E2 ' , -1 ) , join ( assert result [ 0 ] == function ( 'enter_entry ( ) ' , -2 ) alias = generate_alias ( self.case ( left.tbl ) ) schema ( 'CUSTOM ' ) , text = 'SELECT * FROM blog.Entries JOIN blog.et ' return self.find_matches ( word_before_cursor , tables , def test_join_alias_search_with_aliases2 ( completer_aliases_casing , text = 'SELECT blog.ees ' cased_schemas = [ schema ( x ) for x in ( 'public ' , 'blog ' , 'CUSTOM ' , ' '' Custom '' ' ) ]","['pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py']",Merge pull request # 624 from dbcli/koljonen/search_by_alias
259,77e21b03791cce0a52ca3ac3591f0c797c5e9134,2017-01-07 11:53:00+00:00,"float = `` '' float = `` , g '' decimal = `` '' decimal = `` , d ''",['pgcli/pgclirc'],Merge pull request # 630 from dbcli/amjith/data-formatting-1
260,4edd124c0dcbf24ff898eaac855f0a76c7c1e8bb,2016-12-12 15:06:51-08:00,"failed_transaction , valid_transaction ) : if valid_transaction ( ) : self.pgexecute.failed_transaction , result.append ( ( token.Transaction.Valid , ' Transaction ' ) ) status = self.conn.get_transaction_status ( ) status == ext.TRANSACTION_STATUS_INTRANS ) result.append ( ( token.Transaction.Failed , ' Failed transaction ' ) ) lambda : self.vi_mode , self.completion_refresher.is_refreshing ) def create_toolbar_tokens_func ( get_vi_mode_enabled , get_is_refreshing ) : def failed_transaction ( self ) : self.pgexecute.valid_transaction ) def create_toolbar_tokens_func ( get_vi_mode_enabled , get_is_refreshing , return ( status == ext.TRANSACTION_STATUS_ACTIVE or lambda : self.vi_mode , self.completion_refresher.is_refreshing , return status == ext.TRANSACTION_STATUS_INERROR def valid_transaction ( self ) : Token.Toolbar.Transaction.Failed = 'bg : # 222222 # ff005f bold ' Token.Toolbar.Transaction.Valid = 'bg : # 222222 # 00ff5f bold ' if failed_transaction ( ) :","['pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgexecute.py', 'pgcli/pgtoolbar.py']",Merge pull request # 621 from dbcli/koljonen/show_transaction_status
261,a9352bdb221b7df0c3bec67167e1a8f73d8a2514,2016-12-10 10:42:26-05:00,"return ( Column ( table_refs=tables , local_tables=stmt.local_tables , matches = self.find_matches ( word_before_cursor , conds , return self.find_matches ( word_before_cursor , conds , meta='join ' ) text , cased_always_qualifying_completer , complete_event 0 if ( left.schema , left.tbl ) in other_tbls else 1 ) cmd_names = commands.keys ( ) # Multiple tables ; qualify all columns def test_suggested_cased_always_qualified_column_names ( completion=Completion ( item , -text_len , def add_cond ( lcol , rcol , rref , prio ) : Column ( table_refs= ( ) , qualifiable=True ) , qualifiable=True ) def test_suggested_auto_qualified_column_names_two_tables ( qualifiable=True ) , elif token_v in ( 'by ' , 'distinct ' ) : from itertools import count , repeat , chain joins.append ( join ) def find_matches ( self , text , collection , mode='fuzzy ' , meta=None ) : Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) ) ] ) expected = Column ( table_refs= ( ( None , 'sessions ' , None , False ) , ) , Document ( text=text , cursor_position=pos ) , for t , cols in colit ( ) : return _Candidate ( completion , priority , meta , synonyms or [ completion ] ) def Candidate ( completion , priority , meta , synonyms = None ) : return ( Column ( table_refs=tables , local_tables=stmt.local_tables ) , prio = 1000 if c.datatype in ( return Candidate ( qualify ( name , ref ) , 0 , 'column ' , [ name ] ) # Fallback to meta param if meta_collection param is None Column ( table_refs= ( ) , qualifiable=True ) , complete_event ) ) namedtuples . 'integer ' , 'bigint ' , 'smallint ' ) else 0 if not collection : def find_matches ( self , text , collection , mode='fuzzy ' , cols = [ column ( 'users . ' + c ) for c in cased_users_col_names ] from pgcli.packages.parseutils.tables import TableReference ) : if isinstance ( cand , _Candidate ) : qualify = lambda col , tbl : ( priority_collection=prios ) return self.find_matches ( word_before_cursor , cmd_names , mode='strict ' , return self.find_matches ( word_before_cursor , joins , meta='join ' ) prio = ref_prio [ normalize_ref ( rtbl.ref ) ] * 2 + ( 'qualify_columns ' , 'if_more_than_one_table ' ) elif token_v == 'set ' : local_tables=stmt.local_tables ) , ) display_meta = display_meta [ :47 ] + u ' ... ' assert suggestions == ( Column ( table_refs= ( ) , qualifiable=True ) , ) conds.append ( Candidate ( cond , prio + ref_prio [ rref ] , meta ) ) completion=Completion ( item , -text_len , display_meta=meta ) , def cased_aliased_completer ( ) : cased_users_cols + cased_users2_cols ) cased_users_cols = [ column ( c ) for c in cased_users_col_names ] # Fallback to 0 if priority_collection param is None return self.find_matches ( word_before_cursor , cmds , mode='strict ' ) else : cmds = [ Candidate ( cmd , 0 , commands [ cmd ] .description ) for cmd in cmds ] 'UPDATE users SET ' , Column.__new__.__defaults__ = ( None , None , tuple ( ) ) ) def cased_always_qualifying_completer ( ) : conds , found_conds = [ ] , set ( ) Document ( text=text , cursor_position=position ) , Column.__new__.__defaults__ = ( None , None , tuple ( ) , False ) 'Column ' , do_qualify = suggestion.qualifiable and { 'always ' : True , 'never ' : False , qualifiable=True ) , result = set ( cased_always_qualifying_completer.get_completions ( cols = [ column ( ' U . ' + c.lower ( ) ) for c in cased_users_col_names ] joins , prios = [ ] , [ ] meta=None , meta_collection=None , for c in cols : position = len ( 'SELECT ' ) self.qualify_columns = settings.get ( Column ( table_refs= ( ( None , ' b ' , None , False ) , ) ) , elif token_v in ( 'set ' , 'by ' , 'distinct ' ) : meta_collection = meta_collection or repeat ( meta ) Column ( table_refs= ( TableReference ( schema , table , alias , is_function ) , ) , ( tbl + ' . ' + self.case ( col ) ) if do_qualify else self.case ( col ) ) flat_cols = list ( chain ( * ( ( c.name for c in cols ) Column ( table_refs= ( ( None , 'abc ' , None , False ) , ) , qualifiable=True ) , sort_key = max ( _match ( x ) for x in synonyms ) Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) , qualifiable=True ) , text , auto_qualifying_completer , complete_event meta='fk join ' , priority_collection=prios ) expected = Column ( table_refs= ( ( None , 'sessions ' , None , False ) , ) ) collist = ' , '.join ( self.case ( c ) for c in flat_cols ) 'SELECT from users ' , cols += [ column ( ' '' Users '' . ' + c.lower ( ) ) for c in cased_users2_col_names ] joins.append ( Candidate ( join , prio , 'join ' ) ) collist = sep.join ( self.case ( c.completion ) for c in flat_cols ) collection = zip ( collection , meta_collection , priority_collection ) priority_collection = priority_collection or repeat ( 0 ) 'INSERT INTO users ( ' , cols = [ column ( c ) for c in cased_users_col_names ] meta = meta [ :47 ] + u ' ... ' desc = [ commands [ cmd ] .description for cmd in cmd_names ] prios.append ( prio + ref_prio [ rref ] ) def test_suggested_auto_qualified_column_names ( 'INSERT INTO Orders SELECT from users ' , cased_users_col_names + cased_users2_col_names ) from itertools import count , repeat assert set ( result ) == set ( cased_funcs + cols item , display_meta , prio = cand , meta , 0 assert set ( result ) == set ( cols ) _Candidate = namedtuple ( 'Candidate ' , [ 'completion ' , 'priority ' , 'meta ' , 'synonyms ' ] ) 'qualify_columns ' : c [ 'main ' ] [ 'qualify_columns ' ] , for item , meta , prio in collection : collist = ' , '.join ( qualify ( c.name , t.ref ) 'SELECT from users U NATURAL JOIN `` Users '' ' , ` collection ` can be either a list of strings or a list of Candidate # Plain columns collist = sep.join ( self.case ( c ) for c in flat_cols ) meta_collection=desc ) item , prio , display_meta , synonyms = cand add_cond ( c.name , c.name , rtbl.ref , prio , 'name join ' ) conds , prios = [ ] , [ ] ] ) conds.append ( cond ) else : cased_always_qualifying_completer , complete_event text = 'SELECT from users ' if display_meta and len ( display_meta ) > 50 : # Whether to qualify with table alias/name when suggesting columns # Possible values : `` always '' , never '' and `` if_more_than_one_table '' priority_collection = None ) : add_cond ( left.col , right.col , rtbl.ref , 2000 ) for cand in collection : [ 'table_refs ' , 'require_last_table ' , 'local_tables ' , 'qualifiable ' ] assert set ( result ) == set ( testdata.functions ( ) + cols flat_cols = [ ] return testdata.get_completer ( { 'qualify_columns ' : 'if_more_than_one_table ' } ) result = set ( auto_qualifying_completer.get_completions ( Column ( table_refs= ( ) ) , for t , cols in colit ( ) ) ) ) def test_no_column_qualification ( qualify_columns = if_more_than_one_table 'Column ' , [ 'table_refs ' , 'require_last_table ' , 'local_tables ' ] ) 'if_more_than_one_table ' : len ( tables ) > 1 } [ self.qualify_columns ] assert suggestions == ( Column ( table_refs= ( ) ) , ) testdata.builtin_functions ( ) + testdata.keywords ( ) ) add_cond ( c.name , c.name , rtbl.ref , 1000 Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) , qualifiable=True ) ] ) def cased_aliased_completer ( request ) : 'INSERT INTO Orders SELECT from users U NATURAL JOIN `` Users '' ' , cmds = commands.keys ( ) cased_users_cols = [ column ( c ) for c in cased_users_cols ] Column ( table_refs= ( ( None , 'abc ' , None , False ) , ) ) , flat_cols.append ( make_cand ( c.name , t.ref ) ) cased_users_cols = [ 'ID ' , 'PARENTID ' , 'Email ' , 'First_Name ' , 'last_name ' ] def add_cond ( lcol , rcol , rref , prio , meta ) : if c.datatype in ( 'integer ' , 'bigint ' , 'smallint ' ) else 0 ) cased_users_col_names = [ 'ID ' , 'PARENTID ' , 'Email ' , 'First_Name ' , 'last_name ' ] prios.append ( ref_prio [ normalize_ref ( rtbl.ref ) ] * 2 + ( Column ( table_refs= ( ( None , ' b ' , None , False ) , ) , qualifiable=True ) , def auto_qualifying_completer ( ) : cased_users2_col_names = [ 'UserID ' , 'UserName ' ] Column ( table_refs= ( ) ) , return matches + self.find_matches ( word_before_cursor , conds , conds , prios , found_conds = [ ] , [ ] , set ( ) if meta and len ( meta ) > 50 : collist = ' , '.join ( t.ref + ' . ' + self.case ( c.name ) Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) ) , joins = [ ] return self.find_matches ( word_before_cursor , joins , meta='join ' , return testdata.get_completer ( { 'qualify_columns ' : 'always ' } , casing ) def make_cand ( name , ref ) : 0 if ( left.schema , left.tbl ) in other_tbls else 1 ) ) return ( Column ( table_refs=stmt.get_tables ( ) , pos = text.index ( ' ' ) + 1 display_meta=display_meta ) , cased_users2_cols = [ 'UserID ' , 'UserName ' ] local_tables=stmt.local_tables , qualifiable=True ) , ) pos = len ( text ) return [ ] add_cond ( left.col , right.col , rtbl.ref , 2000 , 'fk join ' ) sort_key = _match ( item ) cols = [ column ( c.lower ( ) ) for c in cased_users_col_names ] meta='name join ' , priority_collection=prios ) elif len ( scoped_cols ) > 1 : Column ( table_refs= ( ( schema , table , alias , is_function ) , ) ) , sort_key = _match ( cand )","['pgcli/main.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 619 from dbcli/koljonen/qualify_columns
262,062d9dcc2e262d8ceb4cdbca3241a1fb9875e5dd,2016-12-06 21:41:45-08:00,"result.append ( ( token.On , ' [ F4 ] Vi-mode ( ' + _get_vi_mode ( cli ) + ' ) ' ) ) from prompt_toolkit.key_binding.vi_state import InputMode InputMode.INSERT : ' I ' , InputMode.REPLACE : ' R ' , } [ cli.vi_state.input_mode ] def _get_vi_mode ( cli ) : return { InputMode.NAVIGATION : ' N ' , result.append ( ( token.On , ' [ F4 ] Vi-mode ' ) ) InputMode.INSERT_MULTIPLE : 'M ' ,",['pgcli/pgtoolbar.py'],Merge pull request # 620 from dbcli/koljonen/show_vi_mode
263,d964c74bc414f8c51d4b146511f6dede93aa1c65,2016-11-20 15:31:32-08:00,"assert set ( result ) == set ( [ column ( 'foo ' ) ] + testdata.functions ( ) result = set ( completer.get_completions ( list ( testdata.builtin_functions ( ) + testdata.keywords ( ) ) position = len ( 'SELECT ' ) 'WITH users as ( SELECT 1 AS foo ) SELECT from custom.users ' , for tbl in local_tbls : ctes = dict ( ( normalize_ref ( t.name ) , t.columns ) for t in local_tbls ) addcols ( None , tbl.name , 'CTE ' , tbl.alias , cols ) Document ( text=text , cursor_position=position ) , schema , table , function , wildcard_expansion , column ) # Local tables should shadow database tables def test_suggested_column_names_from_qualified_shadowed_table ( completer , complete_event , text ) : if tbl.schema is None and normalize_ref ( tbl.name ) in ctes : def test_suggested_column_names_from_cte ( completer , complete_event , text ) : position = text.find ( ' ' ) + 1 schema , table , function , wildcard_expansion ) cols = ctes [ normalize_ref ( tbl.name ) ] continue 'SELECT from custom.users ' , complete_event ) ) # Local tables should shadow database tables columns [ tbl.name ] = tbl.columns 'WITH users as ( SELECT 1 AS foo ) SELECT from users ' , ] ) text = 'SELECT from custom.users ' ) def test_suggested_column_names_from_qualified_shadowed_table ( completer , complete_event ) :","['pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py']",Merge pull request # 614 from dbcli/koljonen/cte_column_scoping
264,9bde65edda7a917a14c0f649e3f6748017e0db62,2016-11-20 13:13:07-08:00,"for i in range ( len ( sql ) ) : suggestions = suggest_type ( sql [ : i+1 ] , sql [ : i+1 ] ) def test_cte_does_not_crash ( ) : sql = 'WITH CTE AS ( SELECT F. * FROM Foo F WHERE F.Bar > 23 ) SELECT C. * FROM CTE C WHERE C.FooID BETWEEN 123 AND 234 ; ' return ( [ ] , `` ) if not tok :","['pgcli/packages/parseutils/ctes.py', 'tests/test_sqlcompletion.py']",Merge pull request # 613 from dbcli/koljonen/crash_after_with
265,2f34bcedcec5a5b1a458ecd3eb1adde520b08576,2016-11-15 08:12:19-08:00,"single_connection=False , prompt=None ) : self.prompt_format = c [ 'main ' ] .get ( 'prompt ' , self.default_prompt ) row_limit=row_limit , single_connection=single_connection ) single_connection , dbname , username , version , pgclirc , dsn , row_limit ) : self.prompt_format = prompt if prompt is not None else c [ 'main ' ] .get ( 'prompt ' , self.default_prompt ) single_connection=False ) : row_limit=row_limit , single_connection=single_connection , prompt=prompt ) single_connection , dbname , username , version , pgclirc , dsn , row_limit , prompt ) :",['pgcli/main.py'],Merge pull request # 612 from dbcli/j-bennet/feature/customize-prompt
266,d997bddc54d4910630ced55eefbd6b2f7051b777,2016-11-01 15:29:04-07:00,"position = len ( text ) yield Match ( completion=c , priority = None ) smart_completion=True ) ) result = set ( completer.get_completions ( assert result > set ( [ Completion ( text= '' setup.py '' , start_position=0 ) ] ) def test_paths_completion ( completer , complete_event ) : text = '\i ' complete_event , Document ( text=text , cursor_position=position ) , yield Match ( completion=c , priority= ( 0 , ) )","['pgcli/pgcompleter.py', 'tests/test_naive_completion.py']",Merge pull request # 608 from lelit/issue-603
267,d923ab3efdc0c39d517e797e39d1cc19e2e2da28,2016-10-31 18:33:07+01:00,"position = len ( text ) yield Match ( completion=c , priority = None ) smart_completion=True ) ) result = set ( completer.get_completions ( assert result > set ( [ Completion ( text= '' setup.py '' , start_position=0 ) ] ) def test_paths_completion ( completer , complete_event ) : text = '\i ' complete_event , Document ( text=text , cursor_position=position ) , yield Match ( completion=c , priority= ( 0 , ) )","['pgcli/pgcompleter.py', 'tests/test_naive_completion.py']",Fix issue # 603
268,7110018a8bda23d9abadb6144d896fbbe589279c,2016-10-26 16:21:36-04:00,Bug Fixes : ===== 1.3.1 * Fix a crashing bug due to sqlparse upgrade . ( Thanks : ` Darik Gamble ` _ ),['changelog.rst'],Merge pull request # 607 from dbcli/amjith/release-1.3.1
269,a2f1f6352352a8993b391df10a8740ab3c366585,2016-10-26 12:36:31-07:00,"if tok.match ( Token.Error , `` ' '' ) : if tok2.match ( Token.Name.Builtin , tok.value ) : i = 0 else : and dollar_quote_regex.match ( tok.value ) ) : # Do n't suggest anything for aliases return ( ) i = j i += 1 tokens = list ( parsed.flatten ( ) ) if not parsed.is_group : elif ( tok.ttype in Token.Name.Builtin # Look for unmatched single quotes , or unmatched dollar sign quotes # Find the matching closing dollar quote sign # Found the matching closing quote - continue our scan for # No matching dollar sign quote if not parsed.is_group ( ) : 'sqlparse > =0.2.2 , < 0.3.0 ' , return True for ( j , tok2 ) in enumerate ( tokens [ i+1 : ] , i+1 ) : elif token_v == 'as ' : tok = tokens [ i ] while i < len ( tokens ) : return False 'sqlparse > =0.2.0 , < 0.3.0 ' , # open quotes thereafter # An unmatched single quote return any ( tok.match ( Token.Error , ( `` ' '' , `` $ '' ) ) for tok in parsed.flatten ( ) ) break return True","['pgcli/packages/parseutils/tables.py', 'pgcli/packages/parseutils/utils.py', 'pgcli/packages/sqlcompletion.py', 'setup.py']",Merge pull request # 606 from dbcli/darikg/sqlparse022
270,72afbd8e77d0400c237b645e86638095532b2e65,2016-10-26 10:46:18-04:00,"* Sergii V * Fix crash bug with leading parenthesis . ( Thanks : ` Joakim Koljonen ` _ ) . * Add delimiters to displayed numbers . This can be configured via the config file . ( Thanks : ` Sergii ` _ ) . Setting `` multi_line_mode = safe `` will make sure that a query will only be executed when Alt+Enter is pressed . .. _ ` Sergii ` : https : //github.com/foxyterkel * Emanuele Gaifas * Use raw strings in regex specifiers . This preemptively fixes a crash in Python 3.6 . ( Thanks ` Emanuele Gaifas ` _ ) Internal Changes : * Support configuring keyword casing preferences . ( Thanks : ` Darik Gamble ` _ ) . * Set sqlparse version dependency to > 0.2.0 , < 0.3.0 . ( Thanks : ` Amjith Ramanujam ` _ ) . Features : * Fabien Meghazi .. _ ` Manuel Barkhau ` : https : //github.com/mbarkhau IMPORTANT : Python 2.6 is not officially supported anymore . ===== * Handle unrecognized keywords gracefully . ( Thanks : ` Darik Gamble ` _ ) * XDG_CONFIG_HOME support for config file location . ( Thanks : ` Fabien Meghazi ` _ ) . .. _ ` Emanuele Gaifas ` : https : //github.com/lelit * Add a new multi_line_mode option in config file . The values can be ` psql ` or ` safe ` . ( Thanks : ` Joakim Koljonen ` _ ) 1.3.0 * Remove Python 2.6 from travis test suite . ( Thanks : ` Amjith Ramanujam ` _ ) Bug Fixes : * Remove cumulative addition of timing data . ( Thanks : ` Amjith Ramanujam ` _ ) . * Fix broken 'SHOW ALL ' in redshift . ( Thanks : ` Manuel Barkhau ` _ ) . .. _ ` Fabien Meghazi ` : https : //github.com/amigrave * Manuel Barkhau","['AUTHORS', 'changelog.rst']",Merge pull request # 602 from dbcli/amjith/release-1.3.0
271,4d149e827d3ffee210a898689ecd48a66c80fbd1,2016-10-19 20:46:42-07:00,"assert expected in set ( suggestions ) prev_keyword = stmt.reduce_to_prev_keyword ( n_skip=1 ) def find_prev_keyword ( sql ) : def reduce_to_prev_keyword ( self , n_skip=0 ) : def reduce_to_prev_keyword ( self ) : expected = Column ( table_refs= ( ( None , 'sessions ' , None , False ) , ) ) def test_handle_unrecognized_kw_generously ( ) : suggestions = suggest_type ( sql , sql ) find_prev_keyword ( self.text_before_cursor , n_skip=n_skip ) return ( Keyword ( ) , ) flattened = flattened [ : len ( flattened ) -n_skip ] def find_prev_keyword ( sql , n_skip=0 ) : find_prev_keyword ( self.text_before_cursor ) elif token.is_keyword : # go backwards in the query until we find one we do recognize # token is a keyword we have n't implemented any special handling for if prev_keyword : sql = 'SELECT * FROM sessions WHERE session = 1 AND ' return suggest_based_on_last_token ( prev_keyword , stmt ) else :","['pgcli/packages/parseutils/utils.py', 'pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 598 from dbcli/darikg/unrecognized-keywords
272,1b6fee1f6e5ad1686f622758d6cecf2996dd3050,2016-10-16 10:41:36-07:00,"in the `` tests `` directory . in root directory . pattern = '\\b ' + re.sub ( white_space_regex , '\\s+ ' , keyword ) + '\\b ' pattern = '\\b ' + white_space_regex.sub ( r'\\s+ ' , keyword ) + '\\b '","['DEVELOP.rst', 'pgcli/packages/prioritization.py']",Merge pull request # 596 from lelit/issue595
273,12c268c13b848ba3a2408b05e4371c300a7d457e,2016-10-03 20:42:49-07:00,"True _isconvertible ( int , string ) ( isinstance ( string , _binary_type ) or isinstance ( string , _text_type ) ) and \ > > > _isint ( 123 ) return format ( val , dcmlfmt ) def _format ( val , valtype , dcmlfmt , floatfmt , missingval= '' '' ) : elif isinstance ( string , ( float , Decimal ) ) : True from decimal import Decimal return type ( string ) is _int_type or type ( string ) is _long_type or \ return type ( string ) is _int_type or type ( string ) is _long_type def _format ( val , valtype , dcmlfmt , floatfmt , missingval= '' '' ) : return format ( int ( val ) , dcmlfmt ) False elif _isnumber ( string ) :",['pgcli/packages/tabulate.py'],Merge pull request # 591 from dbcli/darikg/fix-formatting-bug
274,ab6efc7457bc2d764610b0bbcc8cc464925b18f0,2016-09-29 06:57:02-07:00,"missingval=missingval , dcmlfmt=dcmlfmt , floatfmt=floatfmt ) if valtype is int : missingval= ' < null > ' , expanded=False , max_width=None ) : self.decimal_format = c [ 'data_formats ' ] [ 'decimal ' ] if isinstance ( string , ( bool , Decimal , ) ) : if isinstance ( string , bool ) : # for decimal `` d '' - 12345678 , `` , d '' - 123,456,78 self.pgspecial.expanded_output , max_width ) title , cur , headers , status , self.table_format , self.null_string , [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , def _format ( val , valtype , dcmlfmt , floatfmt , missingval= '' '' ) : missingval=missingval ) if valtype in [ int , _text_type ] : decimal = `` , d '' 'test status ' , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , ) dcmlfmt= '' d '' , floatfmt= '' g '' , numalign= '' decimal '' , stralign= '' left '' , # for float `` g '' - 123456.78 , `` , g '' - 123,456.78 [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , def format_output ( title , cur , headers , status , table_format , dcmlfmt , floatfmt , elif valtype is _text_type : [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , self.float_format , self.null_string , self.pgspecial.expanded_output , max_width ) cols = [ [ _format ( v , ct , dcmlfmt , floatfmt , missingval ) for v in c ] value = format ( float ( value ) , ' , g ' ) floatfmt= '' g '' , numalign= '' decimal '' , stralign= '' left '' , formatted.extend ( format_output ( title , rows , headers , status , 'psql ' , [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , cols = [ [ _format ( v , ct , floatfmt , missingval ) for v in c ] 'test status ' , 'psql ' ) # Format for number representation from decimal import Decimal def format_output ( title , cur , headers , status , table_format , missingval= ' < null > ' , expanded=False , max_width=None ) : formatted.extend ( format_output ( title , rows , headers , status , 'psql ' , dcmlfmt= 'd ' , floatfmt= ' g ' , self.float_format = c [ 'data_formats ' ] [ 'float ' ] def _format ( val , valtype , floatfmt , missingval= '' '' ) : return format ( val , dcmlfmt ) [ data_formats ] title , cur , headers , status , self.table_format , self.decimal_format , float = `` , g ''","['pgcli/main.py', 'pgcli/packages/tabulate.py', 'pgcli/pgclirc', 'tests/test_main.py', 'tests/test_pgexecute.py', 'tests/utils.py']",Merge pull request # 583 from foxyterkel/master
275,a39f5c5cb38143e8d185e48af8315ed6e5d45bf4,2016-09-25 21:35:20-07:00,"cursor.execute ( `` SHOW ALL '' ) self.superuser = db_parameters.get ( 'is_superuser ' ) == ' 1 ' db_parameters = dict ( name_val_desc [ :2 ] for name_val_desc in cursor.fetchall ( ) ) superuser = self._select_one ( cursor , `` select current_setting ( 'is_superuser ' ) : :bool '' ) [ 0 ] superuser = False self.superuser = superuser",['pgcli/pgexecute.py'],Merge pull request # 589 from mbarkhau/fix/588
276,185620bb3fe891fa6e074555f256df4bb2c58c63,2016-09-21 19:24:21+02:00,"cursor.execute ( `` SHOW ALL '' ) db_parameters = dict ( cursor.fetchall ( ) ) superuser = self._select_one ( cursor , `` select current_setting ( 'is_superuser ' ) : :bool '' ) [ 0 ] superuser = False self.superuser = superuser self.superuser = db_parameters.get ( 'is_superuser ' ) == ' 1 '",['pgcli/pgexecute.py'],fixes # 588 invalid setting for redshift
277,153a72944c80b44da957390dd37c754bbab5e3d5,2016-09-12 14:57:39-07:00,"] ) prev_prev_tok = prev_tok and p.token_prev ( p.token_index ( prev_tok ) ) [ 1 ] def test_leading_parenthesis ( sql ) : suggest_type ( sql , sql ) prev_prev_tok = p.token_prev ( p.token_index ( prev_tok ) ) [ 1 ] # No assertion for now ; just make sure it does n't crash ' ( ' ,","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 581 from dbcli/koljonen/leading_parenthesis_crash
278,a0f1826be39bccb651bee58ccf3f5c95a76aeb6b,2016-09-12 14:28:05-07:00,"self.multiline_mode = c [ 'main ' ] .get ( 'multi_line_mode ' , 'psql ' ) if cli.buffers [ DEFAULT_BUFFER ] .multiline_mode == 'safe ' : # insert a newline , and [ Esc ] [ Enter ] or [ Alt ] - [ Enter ] must be used to execute # a command . result.append ( ( token , multi_line_mode = psql return False self.multiline_mode = multiline_mode # the current input if the input ends in a semicolon . return not _multiline_exception ( doc.text ) result.append ( ( token , ' ( Semi-colon [ ; ] will end the line ) ' ) ) return True else : if self.multiline_mode == 'safe ' : return self.always_multiline and not _multiline_exception ( doc.text ) multiline_mode=self.multiline_mode , # If multi_line_mode is set to `` safe '' , in multi-line mode , [ Enter ] will always def __init__ ( self , always_multiline , * args , * * kwargs ) : def __init__ ( self , always_multiline , multiline_mode , * args , * * kwargs ) : # If multi_line_mode is set to `` psql '' , in multi-line mode , [ Enter ] will execute ' ( Semi-colon [ ; ] will end the line ) ' ) ) result.append ( ( token , ' ( [ Esc ] [ Enter ] to execute ] ) ' ) ) if not self.always_multiline :","['pgcli/main.py', 'pgcli/pgbuffer.py', 'pgcli/pgclirc', 'pgcli/pgtoolbar.py']",Merge pull request # 577 from dbcli/koljonen/multiline_enter
279,8f4dad15d4a7789b49e865cadda882aff7f817e4,2016-09-04 21:00:17+02:00,"'generate_aliases ' : c [ 'main ' ] .as_bool ( 'generate_aliases ' ) , 'single_connection ' : single_connection , completer_ = testdata.get_completer ( { 'keyword_casing ' : keyword_casing } ) 'casing_file ' : get_casing_file ( c ) , 'keyword_casing ' : keyword_casing , keyword_casing = settings.get ( 'keyword_casing ' , 'upper ' ) .lower ( ) completions = completer_.get_completions ( return self.find_matches ( word_before_cursor , self.keywords , } ( 'lower ' , 'select ' , ( `` , 's ' , 'S ' , 'Sel ' ) ) , keywords = [ k.upper ( ) for k in self.keywords ] if keyword_casing not in ( 'upper ' , 'lower ' , 'auto ' ) : 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , casing = self.keyword_casing Document ( text=text , cursor_position=len ( text ) ) , complete_event ) if word_before_cursor and word_before_cursor [ -1 ] .islower ( ) : for text in texts : if casing == 'upper ' : self.keyword_casing = keyword_casing 'single_connection ' : single_connection } ] ) 'generate_aliases ' : c [ 'main ' ] .as_bool ( 'generate_aliases ' ) , assert expected in [ cpl.text for cpl in completions ] else : def test_keyword_casing_upper ( keyword_casing , expected , texts ) : if casing == 'auto ' : 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] , ( 'auto ' , 'select ' , ( 's ' , 'sel ' , 'SEl ' ) ) , ( 'auto ' , 'SELECT ' , ( `` , 'S ' , 'SEL ' , 'seL ' ) ) , keywords = [ k.lower ( ) for k in self.keywords ] casing = 'lower ' 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , keyword_casing = upper self.settings = { 'casing_file ' : get_casing_file ( c ) , else : keyword_casing = c [ 'main ' ] [ 'keyword_casing ' ] # keyword casing preference . Possible values `` lower '' , `` upper '' , `` auto '' return self.find_matches ( word_before_cursor , keywords , keyword_casing = 'upper ' ( 'upper ' , 'SELECT ' , ( `` , 's ' , 'S ' , 'Sel ' ) ) , self.settings = { 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] , casing = 'upper '","['pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 576 from dbcli/darikg/keyword-casing
280,979d07097f3762bedc7259fb1350e89e3c367060,2016-09-02 20:06:37-07:00,* Do not install setproctitle on cygwin . ( Thanks : ` Janus Troelsen ` _ ) . .. _ ` Janus Troelsen ` : https : //github.com/ysangkok .. _ ` Julien Rouhaud ` : https : //github.com/rjuju 1.2.0 `` > SELECT * FROM django_migrations ; \watch 1 / * Runs the command every second * / `` * Upgrade to sqlparse-0.2.0 . ( Thanks : ` Tiziano Müller ` _ ) . .. _ ` Stuart Quin ` : https : //github.com/stuartquin * Prevent pgcli from hanging indefinitely when Postgres instance is not running . ( Thanks : ` Darik Gamble ` _ ) Internal Changes : * Work around sqlparse crashing after AS keyword . ( Thanks : ` Joakim Koljonen ` _ ) . * Upgrade to pgspecial 1.6.0 . ( Thanks : ` Stuart Quin ` _ ) . .. _ ` avdd ` : https : //github.com/avdd * Better scoping for tables in insert statements to improve suggestions . ( Thanks : ` Joakim Koljonen ` _ ) . * Add support for CTE aware auto-completion . ( Thanks : ` Darik Gamble ` _ ) . Features : * Add priority to the suggestions to sort based on relevance . ( Thanks : ` Joakim Koljonen ` _ ) . .. _ ` Lim H ` : Lim H ===== * Configurable null format via the config file . ( Thanks : ` Adrian Dries ` _ ) . .. _ ` Tiziano Müller ` : https : //github.com/dev-zero * Add command-line option -- single-connection to prevent pgcli from using multiple connections . ( Thanks : ` Joakim Koljonen ` _ ) . .. _ ` Tahir Butt ` : Tahir Butt * Add host and user information to default pgcli prompt . ( Thanks : ` Lim H ` _ ) . * Add more specifiers to pgcli prompt . ( Thanks : ` Julien Rouhaud ` _ ) . `` \p `` for port info `` \ # `` for super user and `` \i `` for pid . Bug Fixes : * Fix a crashing bug with named queries . ( Thanks : ` Joakim Koljonen ` _ ) . * Replace timestampz alias since AWS Redshift does not support it . ( Thanks : ` Tahir Butt ` _ ) . * Add ` \watch ` command to periodically execute a command . ( Thanks : ` Stuart Quin ` _ ) . .. _ ` Adrian Dries ` : Adrian Dries,['changelog.rst'],Merge pull request # 574 from dbcli/amjith/release-1.2.0
281,f9b73bfa25f2a2351fbd7355a7ffcf7945ca6ac8,2016-09-02 06:44:19-07:00,"elif state == POLL_READ : from psycopg2.extensions import POLL_OK , POLL_READ , POLL_WRITE `` `` '' import itertools break the default implementation does n't define a timeout in the select calls select.select ( [ conn.fileno ( ) ] , [ ] , [ ] , _WAIT_SELECT_TIMEOUT ) elif state == POLL_WRITE : ext.set_wait_callback ( _wait_select ) def _wait_select ( conn ) : try : # See also https : //github.com/psycopg/psycopg2/issues/468 conn.cancel ( ) _WAIT_SELECT_TIMEOUT = 1 except KeyboardInterrupt : else : copy-pasted from psycopg2.extras.wait_select select.select ( [ ] , [ conn.fileno ( ) ] , [ ] , _WAIT_SELECT_TIMEOUT ) # the loop will be broken by a server error if state == POLL_OK : raise conn.OperationalError ( `` bad state from poll : % s '' % state ) import select while 1 : continue state = conn.poll ( ) # TODO : Get default timeout from pgclirc ? ext.set_wait_callback ( psycopg2.extras.wait_select )",['pgcli/pgexecute.py'],Merge pull request # 571 from dbcli/darikg/no-hang-wait-select
282,6d15d46a310b29f9c0936347693dddc7001d2ebe,2016-08-26 07:52:26-07:00,"superuser = False string = string.replace ( '\\i ' , str ( self.pgexecute.pid ) or ' ( none ) ' ) user = self._select_one ( cursor , 'select current_user ' ) port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) [ 0 ] db = self._select_one ( cursor , 'select current_database ( ) ' ) [ 0 ] string = string.replace ( '\\ # ' , `` # '' if ( self.pgexecute.superuser ) else `` > '' ) pid = self._select_one ( cursor , 'select pg_backend_pid ( ) ' ) [ 0 ] self.pid = pid host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) string = string.replace ( '\\p ' , str ( self.pgexecute.port ) or ' ( none ) ' ) user = self._select_one ( cursor , 'select current_user ' ) [ 0 ] cursor = conn.cursor ( ) self.superuser = superuser db = self._select_one ( cursor , 'select current_database ( ) ' ) superuser = self._select_one ( cursor , `` select current_setting ( 'is_superuser ' ) : :bool '' ) [ 0 ] host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) [ 0 ] pid = -1","['pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 572 from rjuju/more_prompt
283,db496fb35456a907ff1dc4b460947bd80cb4f37c,2016-08-23 17:23:46-07:00,"] ) def test_after_as ( expression ) : 'SELECT 1 AS ' , return [ ] stmt = SqlStatement ( full_text , text_before_cursor ) suggestions = suggest_type ( expression , expression ) # This is a temporary hack ; the exception handling # here should be removed once sqlparse has been fixed try : stmt = SqlStatement ( full_text , text_before_cursor ) assert set ( suggestions ) == set ( ) 'SELECT 1 FROM tabl AS ' , except ( TypeError , AttributeError ) :","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 568 from dbcli/koljonen/hack_for_sqlparse_crashes
284,fee9074c8e809ee158cd8d3501cb90720b06c852,2016-08-23 11:25:05-07:00,"Send \nd command context.cli.sendline ( '\\nd foo ' ) def step_see_named_query_saved ( context ) : `` `` '' def step_save_named_query ( context ) : then we see database connected Feature : named queries : ] Wait to see query saved . context.cli.sendline ( '\\ns foo SELECT 12345 ' ) _expect_exact ( context , 'Saved . ' , timeout=1 ) prio_order = [ _expect_exact ( context , 'SELECT 1 ' , timeout=1 ) when we run pgcli context.cli.sendline ( '\\n foo ' ) and we wait for prompt _expect_exact ( context , '12345 ' , timeout=1 ) _expect_exact ( context , 'foo : Deleted ' , timeout=1 ) Send \n command when we delete a named query type_priority = prio_order.index ( meta ) if meta in prio_order else -1 def step_see_named_query_deleted ( context ) : then we see the named query deleted Send \ns command Wait to see query deleted . def step_use_named_query ( context ) : ] .index ( meta ) if meta else -1 def step_delete_named_query ( context ) : Wait to see select output . when we save a named query then we see the named query saved and we connect to test database Scenario : save , use and delete named queries save , use and delete named queries def step_see_named_query_executed ( context ) : Given we have pgcli installed type_priority = [","['pgcli/pgcompleter.py', 'tests/features/named_queries.feature', 'tests/features/steps/step_definitions.py']",Merge pull request # 566 from dbcli/koljonen/saved_query_crash
285,beb9ceae946c3db9cff6d21d0f35485e853411d6,2016-08-15 13:53:12-07:00,"# Check if we need to update completions , in order of most self.pgexecute.connect ( ) logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) click.secho ( str ( e ) , err=True , fg='red ' ) elif query.meta_changed : try : click.echo ( `` , file=f ) # extra newline self.refresh_completions ( persist_priorities='keywords ' ) self.refresh_completions ( persist_priorities='all ' ) with open ( self.output_file , ' a ' , encoding='utf-8 ' ) as f : # Only add humanized time display if > 1 second click.secho ( `` cancelled query '' , err=True , fg='red ' ) self.refresh_completions ( persist_priorities='keywords ' ) in utf8tounicode ( e.args [ 0 ] ) ) : self.completer.search_path ) except IOError as e : humanize.time.naturaldelta ( query.total_time ) ) ) # Check if we need to update completions , in order of most if query.db_changed : logger.debug ( `` cancelled query , sql : % r '' , text ) return query print ( 'Time : % 0.03fs ' % query.total_time ) click.secho ( str ( e ) , err=True , fg='red ' ) # Restart connection to the database watch_command , timing = special.get_watch_command ( document.text ) query = self.execute_command ( document.text , query ) elif query.meta_changed : print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , in utf8tounicode ( e.args [ 0 ] ) ) : # to least drastic changes except KeyboardInterrupt : click.secho ( str ( e ) , err=True , fg='red ' ) # Restart connection to the database from time import time , sleep except KeyboardInterrupt : logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) click.secho ( str ( e ) , err=True , fg='red ' ) if self.pgspecial.timing_enabled : query = self.execute_command ( watch_command , query ) click.secho ( 'Not Yet Implemented . ' , fg= '' yellow '' ) try : try : click.echo ( text , file=f ) except OperationalError as e : click.echo_via_pager ( '\n'.join ( output ) ) except NotImplementedError : self.completer.reset_completions ( ) output , query = self._evaluate_command ( text ) with self._completer_lock : pass humanize.time.naturaldelta ( query.total_time ) ) ) click.echo ( `` , file=f ) # extra newline logger = self.logger sleep ( timing ) try : self.completer.set_search_path ( try : if self.output_file and not text.startswith ( ( '\\o ' , '\\ ? ' ) ) : watch_command = None click.secho ( str ( e ) , err=True , fg='red ' ) self._handle_server_closed_connection ( ) logger.debug ( 'Search path : % r ' , self.completer.set_search_path ( # Only add humanized time display if > 1 second print ( 'Time : % 0.03fs ' % query.total_time ) else : if watch_command : else : click.secho ( str ( e ) , err=True , fg='red ' ) click.secho ( 'Not Yet Implemented . ' , fg= '' yellow '' ) pass self.completer.reset_completions ( ) logger.debug ( 'Refreshing search path ' ) click.echo ( 'Waiting for { 0 } seconds before repeating'.format ( timing ) ) click.echo ( document.text , file=f ) self.completer.search_path ) click.echo_via_pager ( '\n'.join ( output ) ) except KeyboardInterrupt : logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) with self._completer_lock : click.echo ( '\n'.join ( output ) , file=f ) try : except KeyboardInterrupt : else : logger.error ( `` sql : % r , error : % r '' , document.text , e ) logger.debug ( `` cancelled query , sql : % r '' , document.text ) logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) logger.debug ( 'Refreshing search path ' ) self._handle_server_closed_connection ( ) if query.db_changed : 'pgspecial > =1.6.0 ' , if ( 'server closed the connection ' self.pgexecute.search_path ( ) ) else : if ( 'server closed the connection ' except NotImplementedError : logger.error ( `` sql : % r , error : % r '' , text , e ) print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , click.echo ( '\n'.join ( output ) , file=f ) click.secho ( `` cancelled query '' , err=True , fg='red ' ) except Exception as e : else : logger.error ( `` sql : % r , error : % r '' , text , e ) elif query.path_changed : if self.output_file and not document.text.startswith ( ( '\\o ' , '\\ ? ' ) ) : from time import time self.pgexecute.connect ( ) logger.debug ( 'Search path : % r ' , if query.total_time > 1 : output , query = self._evaluate_command ( document.text ) elif query.path_changed : except Exception as e : # to least drastic changes 'pgspecial > =1.5.0 ' , except KeyboardInterrupt : while watch_command : except OperationalError as e : if self.pgspecial.timing_enabled : try : logger.error ( `` sql : % r , error : % r '' , document.text , e ) except IOError as e : self.refresh_completions ( persist_priorities='all ' ) self.pgexecute.search_path ( ) ) with open ( self.output_file , ' a ' , encoding='utf-8 ' ) as f : def execute_command ( self , text , query ) : if query.total_time > 1 :","['pgcli/main.py', 'setup.py']",Merge pull request # 561 from dbcli/stuartquin/watch
286,ab6e54b2cf5fd3badb1a31143146b36beaeb88d9,2016-08-08 22:10:29-07:00,"# Collapse everything after the ctes into a remainder query sql = 'select * from ( select t. from tabl t ' if n_tok == 1 and isinstance ( p.tokens [ 0 ] , Identifier ) : if cte.start < current_position < cte.stop : remainder = u '' .join ( str ( tok ) for tok in p.tokens [ idx : ] ) return t , text from pgcli.packages.parseutils.utils import find_prev_keyword , is_open_quote JoinCondition = namedtuple ( 'JoinCondition ' , [ 'tables ' , 'parent ' ] ) > > > last_word ( 'bac $ def ' ) # Minimal example : `` `` '' Attempt to parse a ( partially typed ) word as an identifier Column ( tables= ( ( None , 'tbl ' , None , False ) , ) ) ] ) n_tok = len ( p.tokens ) cte_start_offset = token_start_pos ( tok.tokens , tok.token_index ( t ) ) stop_pos = start_pos + cte_len from .packages.function_metadata import FunctionMetadata , ForeignKey if text [ -1 ] .isspace ( ) : 'all_punctuations ' : re.compile ( ' ( [ ^\s ] + ) $ ' ) , def parse_partial_identifier ( word ) : text_before_cursor = full_text [ cte.start : current_position ] tables = suggestion.table_refs return parse_partial_identifier ( word + ' '' ' ) TableMetadata = namedtuple ( 'TableMetadata ' , 'name columns ' ) return None > > > last_word ( 'abc def ' ) from pgcli.packages.parseutils.ctes import ( def test_multiple_column_name_extraction ( ) : FromClauseItem.__new__.__defaults__ = ( None , tuple ( ) , tuple ( ) ) lref = self.alias ( left.tbl , suggestion.tables ) # Find the matching closing dollar quote sign idx = p.token_index ( p.tokens [ -1 ] ) from .packages.parseutils import is_open_quote return full_text , text_before_cursor , tuple ( ) SELECT * FROM if text [ -1 ] .isspace ( ) : if t.value == ' ( ' or ( t.is_keyword and ( parsed = sqlparse.parse ( sql ) # Found the matching closing quote - continue our scan for # This matches only alphanumerics and underscores . from sqlparse.sql import Identifier 'DELETE FROM foo WHERE x > y RETURNING x , y ' , idx = flattened.index ( t ) # query string with everything after the keyword token removed assert tuple ( ctes ) == ( ( ' a ' , ( 'abc ' , ) , start_pos , stop_pos ) , ) Column ( table_refs= ( ( None , 'tabl ' , None , False ) , ) ) , views = [ self.case ( v ) + ' ' + self.alias ( v , suggestion.table_refs ) testdata.functions ( ) ) Column ( tables= ( ( schema , table , alias , is_function ) , ) ) , return True cte_len = len ( str ( parens ) ) # includes parens Column ( table_refs= ( ( schema , table , alias , is_function ) , ) ) , FromClauseItem ( schema=None , table_refs=tbls ) , remainder_sql is the text from the original query after the CTEs have lref = self.alias ( left.tbl , suggestion.table_refs ) FromClauseItem.__new__.__defaults__ = ( None , tuple ( ) ) return any ( _parsed_is_open_quote ( p ) for p in parsed ) # Local tables should shadow database tables return ( ) > > > last_word ( 'abc def ' ) sql = 'SELECT abc FROM xxx ' require_last_table=True , `` `` '' Find the last sql keyword in an SQL statement 'all_punctuations ' : re.compile ( ' ( [ ^\s ] + ) $ ' ) , local_tables=stmt.local_tables ) ) sql = 'SELECT abc , def FROM xxx ' yield t matches = regex.search ( text ) import re tokens = list ( parsed.flatten ( ) ) Join = namedtuple ( 'Join ' , [ 'tables ' , 'schema ' ] ) SELECT * FROM a , b '' ' flattened = list ( parsed.flatten ( ) ) Column ( table_refs= ( ) ) , # p = sqlparse.parse ( 'select * from foo where bar ' ) # Minimal example : # open quotes thereafter complete_event ) # This matches everything except a space . return True y AS ( SELECT ghi , jkl FROM y ) ' '' ) FromClauseItem ( schema='sch ' , tables=tbls ) , tables = [ self.case ( t ) + ' ' + self.alias ( t , suggestion.table_refs ) > > > last_word ( 'bac \def ; ' , include='most_punctuations ' ) # up to and including the target keyword token t , to produce a assert tuple ( ctes ) == ( parsed = sqlparse.parse ( sql ) [ 0 ] 'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) : ,\s ] + ) $ ' ) , suggest.append ( FromClauseItem ( schema=schema , been stripped . if tok2.match ( Token.Name.Builtin , tok.value ) : Column ( tables=tables , require_last_table=True ) , ] ) assert suggestions == ( Column ( tables= ( ) ) , ) t_sug = Table ( s.schema , s.table_refs , s.local_tables ) Column = namedtuple ( 'Column ' , [ 'tables ' , 'require_last_table ' ] ) Column ( tables= ( ( None , 'tabl2 ' , 't2 ' , False ) , ) ) , ctes , remainder = extract_ctes ( sql ) i = 0 def find_prev_keyword ( sql ) : lref = ( suggestion.parent or suggestion.tables [ -1 ] ) .ref '' WITH cte1 AS ( SELECT a , b , c FROM foo ) , # Close the double quote , then reparse from pgcli.packages.parseutils import extract_tables assert extract_column_names ( sql ) == ( 'def ' , 'jkl ' ) Column ( tables= ( ( None , 'tabl ' , None , False ) , ) ) , cte = get_cte_from_token ( t , start_pos + cte_start_offset ) # Find the start position of the opening parens enclosing the cte body Returns the value of the last keyword , and the text of the query with elif ( tok.ttype in Token.Name.Builtin # This matches everything except spaces , parens , colon , comma , and period def _identifiers ( tok ) : return False '\\\\def ' # Multiple ctes # Jump ahead to the RETURNING clause where the list of column names is # No matching dollar sign quote regex = cleanup_regex [ include ] > > > last_word ( 'abc def ' ) # Get the next ( meaningful ) token , which should be the first CTE parsed = sqlparse.parse ( sql ) from .packages.function_metadata import ColumnMetadata , ForeignKey # TableExpression is a namedtuple representing a CTE , used internally result = completer.get_completions ( Document ( text=text , cursor_position=pos ) , return None , `` pos = len ( text ) Returns tuple ( ctes , remainder_sql ) scoped_cols = self.populate_scoped_cols ( tables , suggestion.local_tables ) current_position = len ( text_before_cursor ) def test_table_qualified_column_name_extraction ( ) : matches = regex.search ( text ) Column ( tables= ( ( None , 'foo ' , ' f ' , False ) , ) ) , > > > last_word ( 'bac $ def ' , include='most_punctuations ' ) logical_operators = ( 'AND ' , 'OR ' , 'NOT ' , 'BETWEEN ' ) def test_aliased_expression_name_extraction ( ) : suggest.append ( Join ( table_refs=tables , schema=schema ) ) if tok2.match ( Token.Name.Builtin , tok.value ) : start1 = len ( `` 'WITH ( ' y ' , ( 'ghi ' , 'jkl ' ) , start2 , stop2 ) ) from .packages.parseutils import last_word , TableReference sql = 'SELECT abc def , ghi jkl FROM xxx ' > > > last_word ( 'abc ' ) views = [ self.case ( v ) + ' ' + self.alias ( v , suggestion.tables ) last_word , find_prev_keyword , parse_partial_identifier ) full_text , text_before_cursor , self.local_tables = \ local_tables=stmt.local_tables ) , text = `` .join ( tok.value for tok in flattened [ : idx+1 ] ) or ` schema_name. ` There may also be unclosed quotation marks , like Table = namedtuple ( 'Table ' , [ 'schema ' , 'tables ' ] ) return None , `` if not ctes : Document ( text=text , cursor_position=pos ) , # Must be invalid CTE > > > last_word ( 'bac \def ' , include='most_punctuations ' ) from .parseutils.tables import extract_tables JoinCondition ( table_refs=tables , parent= ( None , 'abc ' , ' a ' , False ) ) ' '' stop2 = len ( `` 'WITH from .parseutils.utils import ( expected = [ Completion ( 'foo ' , 0 , display_meta='column ' ) ] from pgcli.packages.parseutils.meta import FunctionMetadata elif not tok_val == 'select ' : # We ca n't use parsed.token_index ( t ) because t may be a child token def test_aliased_single_column_name_extraction ( ) : # name : cte alias assigned in the query column_names = extract_column_names ( parens ) Column ( tables= ( ( None , 'foo ' , None , False ) , ) ) , return ( Column ( table_refs=stmt.get_tables ( 'insert ' ) ) , ) : param local_tbls : tuple ( TableMetadata ) start2 = len ( `` 'WITH # An unmatched single quote assert tuple ( ctes ) == ( ( ' a ' , ( 'def ' , ) , start_pos , stop_pos ) , ) if __name__ == '__main__ ' : Column ( table_refs= ( ) ) , WITH a AS `` ' ) Join = namedtuple ( 'Join ' , [ 'table_refs ' , 'schema ' ] ) JoinCondition ( tables=tables , parent= ( None , 'abc ' , ' a ' , False ) ) sql = 'SELECT abc.def , ghi.jkl FROM xxx ' table_refs=tables , 'alphanum_underscore ' : re.compile ( r ' ( \w+ ) $ ' ) , def get_cte_from_token ( tok , pos0 ) : '\\\\def ' from pgcli.packages.parseutils.tables import extract_tables last_word , extract_tables , find_prev_keyword , parse_partial_identifier ) pos = len ( 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT ' ) 'INSERT INTO foo ( x , y , z ) VALUES ( 5 , 6 , 7 ) RETURNING x , y ' , # p = sqlparse.parse ( 'select * from foo where bar ' ) dollar_quote_regex = re.compile ( r'^\ $ [ ^ $ ] * \ $ $ ' ) f_sug = Function ( s.schema , s.table_refs , filter='for_from_clause ' ) Column.__new__.__defaults__ = ( None , None ) word may include a schema qualification , like ` schema_name.partial_name ` 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) : ,\s ] + ) $ ' ) , return ( Column ( tables=tables ) , View = namedtuple ( 'View ' , [ 'schema ' , 'table_refs ' ] ) meta.append ( TableMetadata ( cte.name , cols ) ) assert extract_column_names ( sql ) == ( ' x ' , ' y ' ) cte2 AS ( SELECT d , e , f FROM bar ) parsed = sqlparse.parse ( sql ) [ 0 ] > > > last_word ( 'bac : :def ' , include='most_punctuations ' ) # An unmatched single quote for ( j , tok2 ) in enumerate ( tokens [ i+1 : ] , i+1 ) : Completion ( 'bar ' , 0 , display_meta='column ' ) , everything after the last keyword stripped print ( extract_tables ( sql ) ) 'abc ' tok = tokens [ i ] # parsed can contain one or more semi-colon separated commands > > > last_word ( ' '' foo * bar ' , include='most_punctuations ' ) return full_text , text_before_cursor , ( ) from pgcli.packages.parseutils.meta import FunctionMetadata , ForeignKey ` `` schema ` , or ` schema . `` partial_name ` # A single CTE # Postgresql dollar quote signs look like ` $ $ ` or ` $ tag $ ` tok_val = tok and tok.value.lower ( ) Function = namedtuple ( 'Function ' , [ 'schema ' , 'table_refs ' , 'filter ' ] ) y AS `` ' ) Column ( tables= ( ( None , 'abc ' , None , False ) , ) ) , '\\\\def ; ' 'def ' assert suggestions == ( Column ( table_refs= ( ) ) , ) `` `` '' s = suggestion def is_open_quote ( sql ) : i = j # No matching dollar sign quote sql = 'SELECT * FROM \nxxx ' def is_open_quote ( sql ) : # inside a TokenList , in which case token_index thows an error > > > last_word ( `` ) t_sug = Table ( * suggestion ) return `` stop1 = len ( `` 'WITH # ` tables ` contains the list of tables/ ... already in the statement , if isinstance ( tok , IdentifierList ) : def extract_column_names ( sql ) : if not sql.strip ( ) : # Found the matching closing quote - continue our scan for > > > last_word ( 'abc def ; ' ) 'alphanum_underscore ' : re.compile ( r ' ( \w+ ) $ ' ) , return p.tokens [ 0 ] if not parens : FromClauseItem = namedtuple ( 'FromClauseItem ' , 'schema table_refs local_tables ' ) if not text : # Empty string v_sug = View ( s.schema , s.table_refs ) `` `` '' Returns true if the query contains an unclosed quote '' '' '' def find_prev_keyword ( sql ) : p = sqlparse.parse ( word ) [ 0 ] elif isinstance ( tok , Identifier ) : from sqlparse.tokens import Token , Error i = 0 tbls = suggestion.table_refs # open quotes thereafter Column ( table_refs= ( ( None , 'tabl1 ' , 't1 ' , False ) , ) ) , if not full_text : sugs = [ Column ( tables=filteredtables ) , : return : sqlparse.sql.Identifier , or None 'Column ' , [ 'table_refs ' , 'require_last_table ' , 'local_tables ' ] ) Column ( tables= ( ( None , 'abc ' , ' a ' , False ) , ) ) , if not text : # Empty string table_refs=tables , parent=None ) ) flattened = list ( parsed.flatten ( ) ) } # Suggest set-returning functions in the FROM clause > > > last_word ( 'abc ' ) # columns : list of column names `` `` '' TableExpression = namedtuple ( 'TableExpression ' , 'name columns start stop ' ) # Find the matching closing dollar quote sign ` `` schema ` , or ` schema . `` partial_name ` > > > last_word ( `` ) return tuple ( t.get_name ( ) for t in _identifiers ( tok ) ) # Combine the string values of all tokens in the original list tables.extend ( tbl.name for tbl in suggestion.local_tables ) return ( Column ( table_refs=stmt.get_tables ( ) , Column ( tables= ( ( None , 'tbl ' , None , False ) , ) ) , from __future__ import print_function else : if tok.match ( Token.Error , `` ' '' ) : if matches : Table.__new__.__defaults__ = ( None , tuple ( ) , tuple ( ) ) tok = tokens [ i ] assert token_start_pos ( p.tokens , idx ) == len ( 'SELECT * FROM ' ) y AS ( SELECT ghi , jkl FROM y ) Returns the value of the last keyword , and the text of the query with sql = 'WITH a AS ( SELECT abc FROM xxx ) SELECT * FROM a ' break assert extract_column_names ( sql ) == ( 'abc ' , ) > > > last_word ( 'bac $ def ' , include='most_punctuations ' ) cleanup_regex = { # An unmatched double quote , e.g . ' '' foo ' , 'foo . `` ' , or 'foo . `` bar ' # Postgresql dollar quote signs look like ` $ $ ` or ` $ tag $ ` start_pos = pos0 + token_start_pos ( tok.tokens , idx ) f_sug = Function ( * suggestion , filter='for_from_clause ' ) def last_word ( text , include='alphanum_underscore ' ) : def populate_scoped_cols ( self , scoped_tbls , local_tbls= ( ) ) : from .packages.parseutils.utils import last_word i = j elif p.token_next_by ( m= ( Error , ' '' ' ) ) [ 1 ] : for t in reversed ( flattened ) : return None , `` everything after the last keyword stripped def populate_scoped_cols ( self , scoped_tbls ) : Column ( table_refs= ( ( None , 'def ' , 'd ' , False ) , ) ) , FromClauseItem ( schema=None , tables=tbls ) , from .packages.parseutils.utils import is_open_quote cols = ( ColumnMetadata ( name , None , ( ) ) for name in cte.columns ) expected = ( [ Completion ( 'foo ' , 0 , display_meta='column ' ) , 'WITH cte AS ( SELECT foo FROM bar ) SELECT * FROM cte c WHERE c. ' , # Editing past the last cte ( ie the main body of the query ) > > > last_word ( ' '' foo * bar ' , include='most_punctuations ' ) if not sql.strip ( ) : > > > last_word ( 'abc ' ) def _parsed_is_open_quote ( parsed ) : return ( Column ( tables=stmt.get_tables ( ) ) , ) sugs = [ Column ( table_refs=filteredtables , Column ( table_refs= ( ( None , 'foo ' , ' f ' , False ) , ) ) , > > > last_word ( 'bac : :def ' , include='most_punctuations ' ) def test_extract_column_names_from_returning_clause ( sql ) : # query string with everything after the keyword token removed # p.token_index ( t ) # Throws ValueError : not in list `` `` '' Attempt to parse a ( partially typed ) word as an identifier isolate_query_ctes ( full_text , text_before_cursor ) for cte in ctes : from sqlparse import parse Column ( tables= ( ( None , 'tabl1 ' , 't1 ' , False ) , ) ) , return [ ] , sql return matches.group ( 0 ) else : x AS ( SELECT abc , def FROM x ) ' '' ) sql = 'SELECT 99 abc FROM xxx ' assert expected < = set ( result ) ctes = [ ] 'def ' sugs.append ( JoinCondition ( table_refs=tables , sql = 'SELECT abc , 99 FROM xxx ' Column ( table_refs= ( ( None , 'tabl ' , 't ' , False ) , ) ) , cte = get_cte_from_token ( tok , start_pos ) for tbl in local_tbls : FromClauseItem ( schema='sch ' , table_refs=tbls ) , testdata.keywords ( ) x AS `` ' ) Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) ) , def test_cte_qualified_columns ( completer , complete_event , text ) : # NB : IdentifierList.get_identifiers ( ) can return non-identifiers ! sql = 'SELECT * FROM xxx ' from sqlparse.tokens import Keyword , DML , Punctuation , Token , Error idx , tok = parsed.token_next_by ( idx , ( Keyword , 'returning ' ) ) dollar_quote_regex = re.compile ( r'^\ $ [ ^ $ ] * \ $ $ ' ) # inside a TokenList , in which case token_index thows an error lref = ( suggestion.parent or suggestion.table_refs [ -1 ] ) .ref assert extract_column_names ( sql ) == ( 'def ' , ) : return : sqlparse.sql.Identifier , or None tables = [ self.case ( t ) + ' ' + self.alias ( t , suggestion.tables ) else : regex = cleanup_regex [ include ] def isolate_query_ctes ( full_text , text_before_cursor ) : start_pos = len ( `` ' -- blah blah blah from pgcli.packages.parseutils import find_prev_keyword , is_open_quote or ` schema_name. ` There may also be unclosed quotation marks , like WITH a AS ( SELECT abc def FROM x ) from sqlparse.tokens import Keyword , CTE , DML return True from sqlparse.sql import Identifier , IdentifierList , Parenthesis # This matches everything except spaces , parens , colon , and comma idx = p.token_index ( tok ) + 1 import re tables = suggestion.tables and dollar_quote_regex.match ( tok.value ) ) : return sum ( len ( str ( t ) ) for t in tokens [ : idx ] ) return True local_tables=stmt.local_tables ) , ) return ctes , remainder assert remainder.strip ( ) == 'SELECT * FROM a ' # Close the double quote , then reparse elif p.token_next_by ( m= ( Error , ' '' ' ) ) [ 1 ] : stop_pos = len ( `` ' -- blah blah blah # up to and including the target keyword token t , to produce a Column ( tables= ( ( None , ' b ' , None , False ) , ) ) , return ( Column ( table_refs=tables , suggestion.tables ) for f in funcs ] ( ' x ' , ( 'abc ' , 'def ' ) , start1 , stop1 ) , expected = set ( [ def token_start_pos ( tokens , idx ) : result = completer.get_completions ( v_sug = View ( * suggestion ) assert suggestions == ( Column ( tables= ( ( None , 'abc ' , None , False ) , ) ) , ) else : def test_simple_cte_extraction ( ) : from prompt_toolkit.completion import Completion idx , parens = tok.token_next_by ( Parenthesis ) assert token_start_pos ( p.tokens , idx ) == len ( 'SELECT * FROM \n ' ) FromClauseItem ( schema=None , tables=tables ) , # Append this cte to the list of available table metadata import pytest return `` `` `` '' Simplify a query by converting CTEs into table metadata objects ] ) in enumerate ( suggestion.table_refs ) ) def last_word ( text , include='alphanum_underscore ' ) : # parsed can contain one or more semi-colon separated commands if matches : Column ( table_refs= ( ( None , 'abc ' , None , False ) , ) ) , cleanup_regex = { 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) : ,\s ] + ) $ ' ) , > > > last_word ( 'bac $ def ' ) Table.__new__.__defaults__ = ( None , tuple ( ) ) in enumerate ( suggestion.tables ) ) from sqlparse.tokens import Keyword , DML , Punctuation def test_token_str_pos ( ) : return full_text , text_before_cursor , meta else : from .packages.parseutils.meta import ColumnMetadata , ForeignKey extract_column_names as _extract_column_names ) return p.tokens [ 0 ] text_before_cursor = text_before_cursor [ ctes [ -1 ] .stop : current_position ] Column ( tables= ( ( None , 'def ' , 'd ' , False ) , ) ) , Column ( table_refs=tables , require_last_table=True ) , ] ) # Find the location of token t in the original parsed statement n_tok = len ( p.tokens ) def parse_partial_identifier ( word ) : # ` table_refs ` contains the list of tables/ ... already in the statement , > > > last_word ( ' ' ) text = `` ' > > > last_word ( 'abc def ; ' ) def test_suggest_columns_from_cte ( completer , complete_event ) : # This matches everything except spaces , parens , colon , comma , and period '\\\\def ; ' stop_pos = len ( 'WITH a AS ( SELECT abc FROM xxx ) ' ) # This matches everything except spaces , parens , colon , and comma assert set ( suggestions ) == set ( ( JoinCondition ( table_refs=tables , parent=None ) , tokens = list ( parsed.flatten ( ) ) # p.token_index ( t ) # Throws ValueError : not in list from .parseutils import ( ctes.append ( cte ) idx = flattened.index ( t ) > > > last_word ( 'bac \def ; ' , include='most_punctuations ' ) else : def test_aliased_multiple_column_name_extraction ( ) : full_text = full_text [ ctes [ -1 ] .stop : ] Function = namedtuple ( 'Function ' , [ 'schema ' , 'tables ' , 'filter ' ] ) return ( Column ( tables=extract_tables ( stmt.full_text ) ) , ) ' '' foo * bar ' while i < len ( tokens ) : assert set ( suggestions ) == set ( ( JoinCondition ( tables=tables , parent=None ) , Column ( table_refs= ( ( None , 'foo ' , None , False ) , ) ) , return None for ( j , tok2 ) in enumerate ( tokens [ i+1 : ] , i+1 ) : ctes is a list of TableExpression namedtuples ' '' foo * bar ' tbls = suggestion.tables if cte : assert extract_column_names ( sql ) == ( 'abc ' , 'def ' ) Find the last word in a sentence . > > > last_word ( ' ' ) Table = namedtuple ( 'Table ' , [ 'schema ' , 'table_refs ' , 'local_tables ' ] ) return any ( _parsed_is_open_quote ( p ) for p in parsed ) def test_suggest_cte_names ( completer , complete_event ) : and dollar_quote_regex.match ( tok.value ) ) : token_start_pos , extract_ctes , return ( Column ( tables=stmt.get_tables ( 'insert ' ) ) , ) return ( Column ( table_refs=stmt.get_tables ( ) ) , ) Find the last word in a sentence . # t = list ( p.flatten ( ) ) [ -3 ] # The `` Where '' token # Find the first DML token to check if it 's a SELECT or INSERT/UPDATE/DELETE from pgcli.packages.function_metadata import FunctionMetadata , ForeignKey View = namedtuple ( 'View ' , [ 'schema ' , 'tables ' ] ) def test_missing_column_name_handled_gracefully ( ) : Column ( table_refs= ( ( None , 'abc ' , ' a ' , False ) , ) ) , Column = namedtuple ( return ( Column ( tables=tables , require_last_table=True ) , ) from .packages.parseutils.meta import FunctionMetadata , ForeignKey columns [ tbl.name ] = tbl.columns complete_event ) tables=tables , parent=None ) ) `` `` '' Extract constant table expresseions from a query 'WITH cte AS ( SELECT foo FROM bar ) SELECT * FROM cte WHERE cte . ' , Column ( tables= ( ) ) , testdata.builtin_functions ( ) Completion ( 'cte1 ' , 0 , display_meta='table ' ) , idx , tok = p.token_next ( idx ) WITH a AS ( SELECT abc def FROM x ) ' '' ) return False return `` assert Column ( table_refs= ( ( None , 't3 ' , None , False ) , ) ) in set ( suggestions ) Column ( table_refs= ( ( None , 'tabl2 ' , 't2 ' , False ) , ) ) , return _extract_column_names ( p ) if n_tok == 1 and isinstance ( p.tokens [ 0 ] , Identifier ) : if not ( tok and tok.ttype == CTE ) : if tok.match ( Token.Error , `` ' '' ) : from pgcli.packages.function_metadata import FunctionMetadata # start : index into the original string of the left parens starting the CTE i += 1 'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) : ,\s ] + ) $ ' ) , sql = `` 'WITH } def test_cte_extraction_around_comments ( ) : sql = `` ' -- blah blah blah meta = [ ] x AS ( SELECT abc , def FROM x ) , FromClauseItem ( schema=None , table_refs=tbls ) , full_text = full_text [ cte.start : cte.stop ] t.value.upper ( ) not in logical_operators ) ) : from .meta import TableMetadata , ColumnMetadata if not cte_name : ' $ def ' > > > last_word ( 'abc ' ) return ( Column ( table_refs=extract_tables ( stmt.full_text ) , 'abc ' assert set ( expected ) == set ( result ) > > > last_word ( ' abc ' ) # t = list ( p.flatten ( ) ) [ -3 ] # The `` Where '' token for t in reversed ( flattened ) : > > > last_word ( ' abc ' ) sugs.append ( JoinCondition ( tables=tables , text = `` .join ( tok.value for tok in flattened [ : idx+1 ] ) def extract_ctes ( sql ) : # Combine the string values of all tokens in the original list Column.__new__.__defaults__ = ( None , None , tuple ( ) ) yield tok SELECT * FROM a '' ' return ( Column ( table_refs=tables , local_tables=stmt.local_tables ) , word may include a schema qualification , like ` schema_name.partial_name ` from collections import namedtuple : param word : string representing a ( partially complete ) identifier Column ( table_refs= ( ( None , ' b ' , None , False ) , ) ) , from .packages.parseutils.tables import TableReference Column ( tables= ( ( None , 'tabl ' , 't ' , False ) , ) ) , idx , tok = parsed.token_next ( idx , skip_ws=True , skip_cm=True ) return full_text , text_before_cursor , tuple ( meta ) # An unmatched double quote , e.g . ' '' foo ' , 'foo . `` ' , or 'foo . `` bar ' sql = 'SELECT abc def FROM xxx ' t.value.upper ( ) not in logical_operators ) ) : tbls = self.populate_scoped_cols ( suggestion.tables ) .items ctes , remainder = extract_ctes ( full_text ) elif ( tok.ttype in Token.Name.Builtin i += 1 if isinstance ( t , Identifier ) : scoped_cols = self.populate_scoped_cols ( tables ) def test_single_column_name_extraction ( ) : for t in tok.get_identifiers ( ) : assert suggestions == ( Column ( table_refs= ( ( None , 'abc ' , None , False ) , ) ) , ) p = sqlparse.parse ( word ) [ 0 ] ] ) '' start_pos = token_start_pos ( p.tokens , idx ) cte_name = tok.get_real_name ( ) Column ( table_refs= ( ( None , 'tbl ' , None , False ) , ) ) ] ) if not cte : # Find the location of token t in the original parsed statement while i < len ( tokens ) : return None , `` suggest.append ( FromClauseItem ( schema=schema , tables=tables ) ) FromClauseItem = namedtuple ( 'FromClauseItem ' , 'schema tables ' ) if tok_val in ( 'insert ' , 'update ' , 'delete ' ) : idx , tok = parsed.token_next_by ( t=DML ) return parse_partial_identifier ( word + ' '' ' ) assert Column ( tables= ( ( None , 't3 ' , None , False ) , ) ) in set ( suggestions ) # stop : index into the original string of the right parens ending the CTE # Make sure the first meaningful token is `` WITH '' which is necessary to def _parsed_is_open_quote ( parsed ) : JoinCondition = namedtuple ( 'JoinCondition ' , [ 'table_refs ' , 'parent ' ] ) return t , text # We ca n't use parsed.token_index ( t ) because t may be a child token start_pos = len ( 'WITH a AS ' ) 'UPDATE foo SET x = 9 RETURNING x , y ' , > > > last_word ( 'bac \def ' , include='most_punctuations ' ) text = 'WITH cte AS ( SELECT foo , bar FROM baz ) SELECT FROM cte ' `` `` '' Returns true if the query contains an unclosed quote '' '' '' p = parse ( sql ) [ 0 ] sql = 'SELECT abc , 99 , def FROM xxx ' Completion ( 'cte2 ' , 0 , display_meta='table ' ) , : param word : string representing a ( partially complete ) identifier logical_operators = ( 'AND ' , 'OR ' , 'NOT ' , 'BETWEEN ' ) return `` break continue # Currently editing a cte - treat its body as the current full_text # The next token should be either a column name , or a list of column names ' $ def ' idx , tok = p.token_next ( -1 , skip_ws=True , skip_cm=True ) return TableExpression ( cte_name , column_names , start_pos , stop_pos ) local_tables=stmt.local_tables ) , ) `` `` '' Find the last sql keyword in an SQL statement def test_multiple_cte_extraction ( ) : suggest.append ( Join ( tables=tables , schema=schema ) ) ] import sqlparse def extract_column_names ( parsed ) : # This matches only alphanumerics and underscores . Column ( tables= ( ) ) , > > > last_word ( 'abc def ' ) suggestion.table_refs ) for f in funcs ] FromClauseItem ( schema=None , tables=tbls ) , from .parseutils.ctes import isolate_query_ctes # This matches everything except a space . tbls = self.populate_scoped_cols ( suggestion.table_refs ) .items if t.value == ' ( ' or ( t.is_keyword and ( return matches.group ( 0 ) FromClauseItem ( schema=None , table_refs=tables ) , # define CTEs","['pgcli/packages/parseutils/__init__.py', 'pgcli/packages/parseutils/ctes.py', 'pgcli/packages/{function_metadata.py => parseutils/meta.py}', 'pgcli/packages/{parseutils.py => parseutils/tables.py}', 'pgcli/packages/parseutils/utils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgbuffer.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/metadata.py', 'tests/parseutils/test_ctes.py', 'tests/{ => parseutils}/test_function_metadata.py', 'tests/{ => parseutils}/test_parseutils.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 553 from dbcli/darikg/cte-suggestions
287,28d01e44ae4b7741c461116d660b05bc27b5ab60,2016-08-03 18:25:03-04:00,"'single_connection ' : single_connection } if settings.get ( 'single_connection ' ) : help='Do not use a separate connection for completions . ' ) single_connection=False ) : 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] } e = pgexecute single_connection , dbname , username , version , pgclirc , dsn , row_limit ) : pgexecute=None , pgclirc_file=None , row_limit=None , default=False , 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] , executor = PGExecute ( e.dbname , e.user , e.password , e.host , e.port , e.dsn ) row_limit=row_limit ) e.dbname , e.user , e.password , e.host , e.port , e.dsn ) executor = pgexecute settings = settings or { } username , version , pgclirc , dsn , row_limit ) : def cli ( database , user , host , port , prompt_passwd , never_prompt , dbname , def cli ( database , user , host , port , prompt_passwd , never_prompt , pgexecute=None , pgclirc_file=None , row_limit=None ) : e = pgexecute # Create a new pgexecute method to popoulate the completions . # Create a new pgexecute method to popoulate the completions . executor = PGExecute ( row_limit=row_limit , single_connection=single_connection ) else :","['pgcli/completion_refresher.py', 'pgcli/main.py']",Merge pull request # 557 from dbcli/koljonen/single_connection
288,986fd2d9921ee433436d72b3ff5e8b6c2daae34e,2016-08-03 17:57:23+01:00,"# Check if we need to update completions , in order of most self.pgexecute.connect ( ) logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) click.secho ( str ( e ) , err=True , fg='red ' ) elif query.meta_changed : try : click.echo ( `` , file=f ) # extra newline self.refresh_completions ( persist_priorities='keywords ' ) self.refresh_completions ( persist_priorities='all ' ) with open ( self.output_file , ' a ' , encoding='utf-8 ' ) as f : # Only add humanized time display if > 1 second click.secho ( `` cancelled query '' , err=True , fg='red ' ) self.refresh_completions ( persist_priorities='keywords ' ) in utf8tounicode ( e.args [ 0 ] ) ) : self.completer.search_path ) except IOError as e : humanize.time.naturaldelta ( query.total_time ) ) ) # Check if we need to update completions , in order of most if query.db_changed : query = self.execute_command ( watch_command ) logger.debug ( `` cancelled query , sql : % r '' , text ) return query print ( 'Time : % 0.03fs ' % query.total_time ) click.secho ( str ( e ) , err=True , fg='red ' ) # Restart connection to the database watch_command , timing = special.get_watch_command ( document.text ) elif query.meta_changed : print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , in utf8tounicode ( e.args [ 0 ] ) ) : # to least drastic changes except KeyboardInterrupt : click.secho ( str ( e ) , err=True , fg='red ' ) # Restart connection to the database from time import time , sleep except KeyboardInterrupt : logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) click.secho ( str ( e ) , err=True , fg='red ' ) if self.pgspecial.timing_enabled : click.secho ( 'Not Yet Implemented . ' , fg= '' yellow '' ) try : try : click.echo ( text , file=f ) def execute_command ( self , text ) : except OperationalError as e : click.echo_via_pager ( '\n'.join ( output ) ) except NotImplementedError : self.completer.reset_completions ( ) output , query = self._evaluate_command ( text ) with self._completer_lock : query = self.execute_command ( document.text ) pass humanize.time.naturaldelta ( query.total_time ) ) ) click.echo ( `` , file=f ) # extra newline logger = self.logger sleep ( timing ) try : self.completer.set_search_path ( try : if self.output_file and not text.startswith ( ( '\\o ' , '\\ ? ' ) ) : watch_command = None click.secho ( str ( e ) , err=True , fg='red ' ) self._handle_server_closed_connection ( ) logger.debug ( 'Search path : % r ' , self.completer.set_search_path ( # Only add humanized time display if > 1 second print ( 'Time : % 0.03fs ' % query.total_time ) else : if watch_command : else : click.secho ( str ( e ) , err=True , fg='red ' ) click.secho ( 'Not Yet Implemented . ' , fg= '' yellow '' ) pass self.completer.reset_completions ( ) logger.debug ( 'Refreshing search path ' ) click.echo ( document.text , file=f ) self.completer.search_path ) click.echo_via_pager ( '\n'.join ( output ) ) except KeyboardInterrupt : logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) with self._completer_lock : click.echo ( '\n'.join ( output ) , file=f ) try : except KeyboardInterrupt : else : logger.error ( `` sql : % r , error : % r '' , document.text , e ) logger.debug ( `` cancelled query , sql : % r '' , document.text ) logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) logger.debug ( 'Refreshing search path ' ) self._handle_server_closed_connection ( ) if query.db_changed : if ( 'server closed the connection ' self.pgexecute.search_path ( ) ) else : if ( 'server closed the connection ' except NotImplementedError : logger.error ( `` sql : % r , error : % r '' , text , e ) print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , click.echo ( '\n'.join ( output ) , file=f ) click.secho ( `` cancelled query '' , err=True , fg='red ' ) except Exception as e : else : logger.error ( `` sql : % r , error : % r '' , text , e ) elif query.path_changed : if self.output_file and not document.text.startswith ( ( '\\o ' , '\\ ? ' ) ) : from time import time self.pgexecute.connect ( ) logger.debug ( 'Search path : % r ' , if query.total_time > 1 : output , query = self._evaluate_command ( document.text ) elif query.path_changed : except Exception as e : # to least drastic changes except KeyboardInterrupt : watch_command , timing = special.get_watch_command ( document.text ) while watch_command : except OperationalError as e : if self.pgspecial.timing_enabled : try : logger.error ( `` sql : % r , error : % r '' , document.text , e ) except IOError as e : self.refresh_completions ( persist_priorities='all ' ) self.pgexecute.search_path ( ) ) with open ( self.output_file , ' a ' , encoding='utf-8 ' ) as f : if query.total_time > 1 :",['pgcli/main.py'],Issue # 544 Implementation of watch command
289,0c226e6e7e1b93b48ba3ba7ad9ade5ff38b06987,2016-08-01 21:56:33+02:00,"cfg.merge ( ConfigObj ( expanduser ( usr_cfg ) , interpolation=False , encoding='utf-8 ' ) ) cfg.merge ( ConfigObj ( expanduser ( usr_cfg ) , interpolation=False ) ) def expanded_table ( rows , headers , missingval=u '' '' ) : def expanded_table ( rows , headers , missingval= '' '' ) :","['pgcli/config.py', 'pgcli/packages/expanded.py']",Merge pull request # 559 from dbcli/amjith/unicode-config-file
290,b1cf9575050de7ae1d65f38b6dea297e5cee6fba,2016-07-31 21:33:30-07:00,"title , cur , headers , status , self.table_format , self.null_string , output.append ( expanded_table ( cur , headers , missingval ) ) def format_output ( title , cur , headers , status , table_format , missingval= ' < null > ' , expanded=False , max_width=None ) : value = missingval if value is None else value title , cur , headers , status , self.table_format , missingval= ' < null > ' ) self.null_string = c [ 'main ' ] .get ( 'null_string ' , ' < null > ' ) output.append ( expanded_table ( rows , headers , missingval ) ) output.append ( expanded_table ( cur , headers ) ) output.append ( expanded_table ( rows , headers ) ) def expanded_table ( rows , headers ) : missingval=missingval ) def format_output ( title , cur , headers , status , table_format , expanded=False , max_width=None ) : re.search ( _invisible_codes , missingval ) ) has_invisible = ( re.search ( _invisible_codes , plain_text ) or value = ' < null > ' if value is None else value has_invisible = re.search ( _invisible_codes , plain_text ) def expanded_table ( rows , headers , missingval=u '' '' ) :","['pgcli/main.py', 'pgcli/packages/expanded.py', 'pgcli/packages/tabulate.py']",Merge pull request # 556 from avdd/master
291,fb23a1e4ec0eb4b76fe30b3f86f1ba05e934f369,2016-07-29 07:33:37-07:00,"return self.find_matches ( word_before_cursor , tables , return self.find_matches ( word_before_cursor , flat_cols , meta='column ' ) add_cond ( c.name , c.name , rtbl.ref , 1000 return self.find_matches ( word_before_cursor , schema_names , meta='schema ' ) 'public ' , conds , metas , prios = zip ( * conds ) if conds else ( [ ] , [ ] , [ ] ) priority_collection=prios , type_priority=100 ) meta='schema ' ) def add_cond ( lcol , rcol , rref , prio ) : ' '' select '' ' , conds , found_conds = [ ] , set ( ) type_priority = [ ] .index ( meta ) if meta else -1 conds , prios = [ ] , [ ] 'keyword ' , 'function ' , 'view ' , 'table ' , 'datatype ' , 'database ' , ' '' select '' ' , ' '' Users '' ' , ' '' Users '' ' , 'user_emails ' , add_cond ( c.name , c.name , rtbl.ref , 'name join ' , 1000 priority = sort_key , type_priority , prio , priority_func ( item ) , lexical_priority return self.find_matches ( word_before_cursor , schema_names , meta='name join ' , priority_collection=prios ) return self.find_matches ( word_before_cursor , tables , meta='table ' ) 'user_emails ' , 'schema ' , 'column ' , 'table alias ' , 'join ' , 'name join ' , 'fk join ' 'users ' , add_cond ( left.col , right.col , rtbl.ref , 2000 ) conds , prios , found_conds = [ ] , [ ] , set ( ) priority_collection = None ) : 'orders ' , matches = self.find_matches ( word_before_cursor , conds , conds.append ( cond ) meta_collection=metas , type_priority=100 , priority_collection=prios ) add_cond ( left.col , right.col , rtbl.ref , 'fk join ' , 2000 ) def add_cond ( lcol , rcol , rref , meta , prio ) : meta='fk join ' , priority_collection=prios ) meta='table ' ) priority_collection=prios ) conds.append ( ( cond , meta , prio + ref_prio [ rref ] ) ) priority = type_priority , prio , sort_key , priority_func ( item ) , lexical_priority return self.find_matches ( word_before_cursor , conds , type_priority=0 , priority_collection = None ) : return matches + self.find_matches ( word_before_cursor , conds , return self.find_matches ( word_before_cursor , flat_cols , prios.append ( prio + ref_prio [ rref ] ) meta='column ' ) 'users ' , 'public ' , 'orders ' ,","['pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 554 from dbcli/koljonen/suggestion_sorting
292,c125c0455775564ef42b93156819d4d1d43115dd,2016-07-27 05:55:08-04:00,"run ( executor , u '' insert into unicodechars ( t ) values ( ' é ' ) '' ) run ( executor , u '' '' '' insert into jsontest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) run ( executor , `` '' '' insert into jsontest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) result = run ( executor , u '' SELECT d FROM jsontest LIMIT 1 '' , assert u'日本語 ' in run ( executor , `` SELECT '日本語 ' AS japanese ; '' , join=True ) run ( executor , u '' create table jsontest ( d json ) '' ) run ( executor , `` CREATE TYPE mood AS ENUM ( 'sad ' , 'ok ' , 'happy ' , '日本語 ' ) '' ) run ( executor , u '' CREATE TYPE mood AS ENUM ( 'sad ' , 'ok ' , 'happy ' , '日本語 ' ) '' ) run ( executor , `` INSERT INTO person VALUES ( 'Moe ' , '日本語 ' ) '' ) run ( executor , `` '' '' insert into jsonbtest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) assert u'日本語 ' in run ( executor , `` SELECT * FROM person '' , join=True ) run ( executor , `` create table jsontest ( d json ) '' ) result = run ( executor , `` SELECT d FROM jsontest LIMIT 1 '' , run ( executor , u '' CREATE TABLE person ( name TEXT , current_mood mood ) '' ) run ( executor , u '' '' '' insert into jsonbtest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) run ( executor , `` CREATE TABLE person ( name TEXT , current_mood mood ) '' ) assert u'日本語 ' in run ( executor , u '' SELECT '日本語 ' AS japanese ; '' , join=True ) assert u'日本語 ' in run ( executor , u '' SELECT * FROM person '' , join=True ) run ( executor , u '' INSERT INTO person VALUES ( 'Moe ' , '日本語 ' ) '' ) run ( executor , `` insert into unicodechars ( t ) values ( ' é ' ) '' )",['tests/test_pgexecute.py'],Merge pull request # 552 from dbcli/amjith/fix-failing-tests
293,51fe5fafbf5fa8db0757473313419a4eca9642ca,2016-07-26 23:16:36-07:00,"self.last_token = parsed and parsed.token_prev ( len ( parsed.tokens ) ) or `` elif p.token_next_match ( 0 , Error , ' '' ' ) : self.last_token = parsed and parsed.token_prev ( len ( parsed.tokens ) ) [ 1 ] or `` last_tok = statement.token_prev ( len ( statement.tokens ) ) last_tok = statement.token_prev ( len ( statement.tokens ) ) [ 1 ] 'sqlparse == 0.2.0 ' , 'sqlparse == 0.1.19 ' , prev_tok = p.token_prev ( len ( p.tokens ) - 1 ) [ 1 ] prev_tok = p.token_prev ( len ( p.tokens ) - 1 ) prev_tok = where.token_prev ( len ( where.tokens ) - 1 ) [ 1 ] stmt_len = len ( str ( statement ) ) prev_prev_tok = p.token_prev ( p.token_index ( prev_tok ) ) [ 1 ] stmt_len = len ( statement.to_unicode ( ) ) elif p.token_next_by ( m= ( Error , ' '' ' ) ) [ 1 ] : prev_prev_tok = p.token_prev ( p.token_index ( prev_tok ) ) prev_tok = where.token_prev ( len ( where.tokens ) - 1 )","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'setup.py']",Merge pull request # 549 from dev-zero/master
294,d7117dd4b55ea3956a543fd69f5af5f74d0fe3cf,2016-07-17 20:13:24-07:00,"self.prompt_format = c [ 'main ' ] .get ( 'prompt ' , self.default_prompt ) # \n - Newline # \u - Username # Postgres prompt # \h - Hostname of the server string = string.replace ( '\\h ' , self.pgexecute.host or ' ( none ) ' ) string = string.replace ( '\\n ' , `` \n '' ) return [ ( Token.Prompt , ' % s > ' % self.pgexecute.dbname ) ] # \d - Database name return string string = string.replace ( '\\u ' , self.pgexecute.user or ' ( none ) ' ) return [ ( Token.Prompt , self.get_prompt ( self.prompt_format ) ) ] string = string.replace ( '\\d ' , self.pgexecute.dbname or ' ( none ) ' ) def get_prompt ( self , string ) :","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 548 from limdauto/feature-host-information
295,6894c8ecaac64f4b5baaa383ea689e658782d05e,2016-07-06 16:50:20-07:00,"tables = extract_tables ( stmt.text_before_cursor ) return ( Column ( tables=tables ) , def test_wildcard_column_expansion ( completer , complete_event ) : INNER JOIN `` ' , ) ) ' '' insert into hij ( a , b , c ) pos = len ( 'SELECT u . * ' ) def test_distinct_suggests_cols ( ) : return ( Column ( tables=stmt.get_tables ( 'insert ' ) ) , ) 'INSERT INTO abc ( ' , pos = len ( 'SELECT * ' ) from pgcli.packages.function_metadata import FunctionMetadata , ForeignKey return tables suggestions = suggest_type ( 'SELECT DISTINCT ' , 'SELECT DISTINCT ' ) tables = tables [ 1 : ] 'INSERT INTO users ( ) SELECT * FROM orders ; ' , 'SELECT u . * FROM users u ' , tables = stmt.get_tables ( ) FROM users u '' ' , sql = 'SELECT * FROM users ' 'INSERT INTO users ( ) SELECT * FROM users u cross join orders o ' , sql = 'SELECT u . * FROM users u ' assert set ( result ) == set ( testdata.columns ( 'users ' ) ) 'INSERT INTO foo SELECT DISTINCT ' tables = tables [ :1 ] 'SELECT * FROM users ' , suggestions = suggest_type ( 'INSERT INTO abc ( ' , 'INSERT INTO abc ( ' ) ' '' INSERT INTO public . `` Users '' ( username ) 'INSERT INTO abc ( ) SELECT * FROM hij ; ' , tables = stmt.get_tables ( 'before ' ) self.full_text if scope == 'full ' else self.text_before_cursor ) tables = extract_tables ( stmt.text_before_cursor ) # [ ( schema , table , alias ) , ... ] ' '' INSERT INTO public.orders ( orderid ) 'INSERT INTO public.users SELECT u . * FROM users u ' , def test_wildcard_column_expansion_with_alias_qualifier ( completer , complete_event ) : tables = extract_tables ( stmt.full_text ) select * from abc inner join def using ( col1 , `` ' , 'SELECT DISTINCT ' , suggestions = suggest_type ( text , text ) suggestions = suggest_type ( text , 'INSERT INTO abc ( ' ) prev_prev_tok = p.token_prev ( p.token_index ( prev_tok ) ) If 'before ' , only tables before the cursor are returned . ' '' INSERT INTO `` Users '' def get_tables ( self , scope='full ' ) : 'INSERT INTO OtherTabl SELECT * FROM tabl WHERE ' , def test_wildcard_column_expansion_with_alias ( completer , complete_event , sql ) : elif self.is_insert ( ) : SELECT * pos = text.find ( ' ( ' ) + 1 If 'insert ' , only the first table is returned . FROM Users def test_insert ( completer , complete_event , text ) : def test_join_using_suggests_common_columns ( col_list ) : ] ) 'INSERT INTO users SELECT * FROM users u ' , complete_event ) If not 'insert ' and the stmt is an insert , the first table is skipped . 'insert into hij select * from abc inner join def using ( ' , def test_join_using_suggests_common_columns ( text ) : if scope == 'insert ' : return ( Column ( tables=extract_tables ( stmt.full_text ) ) , if prev_prev_tok and prev_prev_tok.normalized == 'INTO ' : def test_insert_into_lparen_suggests_cols ( ) : ] ) 'INSERT INTO users ( ) ' , tables = stmt.get_tables ( 'before ' ) def is_insert ( self ) : def test_wildcard_column_expansion ( completer , complete_event , sql ) : def test_distinct_suggests_cols ( text ) : param ` scope : ` possible values : 'full ' , 'insert ' , 'before ' text = 'select * from abc inner join def using ( ' + col_list return self.parsed.token_first ( ) .value.lower ( ) == 'insert ' 'INSERT INTO OtherTabl ( ID , Name ) SELECT * FROM tabl WHERE ' , `` `` '' Gets the tables available in the statement . 'select * from abc inner join def using ( ' , SELECT * FROM users U JOIN `` Users '' U2 ON `` ' , SELECT u . * pos = sql.find ( ' * ' ) + 1 'INSERT INTO orders SELECT * FROM users U JOIN `` Users '' U2 ON ' , ' '' INSERT INTO users ( id , parentid , email , first_name , last_name ) return ( Column ( tables=extract_tables ( stmt.text_before_cursor ) ) , ) result = completer.get_completions ( Document ( text=text , cursor_position=pos ) , @ pytest.mark.parametrize ( 'col_list ' , ( `` , 'col1 , ' , ) ) tables = extract_tables ( return ( Column ( tables=extract_tables ( stmt.full_text ) ) , ) 'select * from abc inner join def using ( col1 , ' , def test_insert_into_lparen_suggests_cols ( text ) : 'INSERT INTO users ( ) ' , ' '' insert into hij ( x , y , z ) return ( Column ( tables=stmt.get_tables ( ) ) , ) `` `` ''","['pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 543 from dbcli/koljonen/insert_table_scope
296,1605bf1cdb7c4f7bd10f3f215451195d3286fedf,2016-07-06 07:39:56-04:00,"alias ( 'U2 ' ) , tables = extract_tables ( stmt.text_before_cursor ) generate_aliases = False Column ( tables= ( ( None , 'func ' , None , True ) , ) ) , settings=self.settings ) table ( 'Orders O ' if text == 'SELECT * FROM ' else 'Orders O2 ' ) , Keyword ( ) aliases = ( ' '' ' + tbl [ 1 : -1 ] + str ( i ) + ' '' ' for i in count ( 2 ) ) suggest = [ Table ( schema=schema ) ] cased_views = [ 'User_Emails ' ] result = completer.get_completions ( if ( token_v.endswith ( 'join ' ) and token.is_keyword return self.find_matches ( word_before_cursor , tables , meta='table ' ) table ( 'orders o ' if text == 'SELECT * FROM ' else 'orders o2 ' ) , flat_cols = list ( itertools.chain ( * ( ( c.name for c in cols ) def cased_completer ( ) : alias = self.generate_aliases def get_view_matches ( self , suggestion , word_before_cursor , alias=False ) : Table ( schema='sch ' ) , cased_funcs = [ 'Custom_Fun ' , '_custom_fun ' , 'Custom_Func1 ' , tuple ( c for c in item ) ) function , wildcard_expansion ) function ( 'custom_func2 ' , -2 ) , Column ( tables= ( ( None , 'tabl ' , ' '' tabl '' ' , False ) , ) ) , table ( 'users u ' ) , Function ( schema=None , filter='for_from_clause ' ) , alias ( 'users ' ) , join ( 'users u ON u.parentid = Users.id ' ) , 'SELECT * FROM users u right outer join `` Users '' u2 ON ' , settings=settings ) Document ( text=text ) , complete_event ) return `` .join ( [ l for l in tbl if l.isupper ( ) ] or def test_sub_select_table_name_completion ( expression ) : function ( 'func3 ' , -len ( 'func ' ) ) , def test_table_aliases ( completer_with_aliases , complete_event , text ) : self.get_function_matches ( f_sug , word_before_cursor , alias ) ) # We first do a case-insensitive sort and then a 'custom_func2 ( ) ' , return [ function ( escape ( x [ 0 ] + ' ( ) ' ) , pos ) def test_table_aliases ( aliased_completer , complete_event , text ) : Function.__new__.__defaults__ = ( None , tuple ( ) , None ) 'SELECT * FROM users u FULL OUTER JOIN `` Users '' u2 ON ' , result = aliased_completer.get_completions ( function ( 'Custom_Func1 ( ) CF ' ) , def test_schema_or_visible_table_completion ( completer , complete_event ) : aliased_rels = [ table ( t ) for t in ( 'users u ' , ' '' Users '' U ' , 'orders o ' , function ( 'custom_fun ( ) ' , -2 ) , suggest.append ( Table ( schema ) ) join ( ' '' Users '' ON `` Users '' .UserID = Users.ID ' ) , def get_view_matches ( self , suggestion , word_before_cursor ) : ( None , 'bcd ' , None , False ) ) , ( None , 'bcd ' , ' b ' , False ) ) , ( None , 'def ' , 'd ' , False ) ) , FromClauseItem ( schema=None , tables=tbls ) , View = namedtuple ( 'View ' , [ 'schema ' , 'tables ' ] ) View = namedtuple ( 'View ' , [ 'schema ' ] ) position = len ( 'SELECT u.id , u . ' ) if is_join and _allow_join ( stmt.parsed ) : 'custom_func2 ( ) cf ' , 'set_returning_func ( ) srf ' ) ] function ( 'custom_func2 ( ) ' , -2 ) , '_custom_fun ( ) cf ' , 'Custom_Fun ( ) CF ' , 'Custom_Func1 ( ) CF ' , tbls = set ( normalize_ref ( t.ref ) for t in tbls ) Document ( text=text , ) , complete_event ) ) table ( 'Orders ' ) , alias ( ' u ' ) , 'custom_func1 ( ) ' , table ( ' '' select '' ' ) , # but there 's a bug with commas table ( 'users ' ) , def get_function_matches ( self , suggestion , word_before_cursor , alias=False ) : self.settings = { 'casing_file ' : get_casing_file ( c ) , join ( 'users users2 ON users2.parentid = Users.id ' ) , text = 'SELECT * FROM ' return [ self.case ( o ) for o in objects ] table ( ' '' Users '' U ' ) , Suggest column names on table alias and dot assert set ( suggestions ) == set ( [ FromClauseItem ( schema='sch ' ) ] ) return set ( [ View ( schema='sch ' ) , FromClauseItem , Function , Datatype , Alias , JoinCondition , Join ) Join ( tables , None ) , Join ( tbls , None ) , def get_completer ( self , settings=None , casing=None ) : 'SELECT * FROM users U LEFT JOIN `` Users '' U2 ON ' , 'custom_func2 ' , result = cased_aliased_completer.get_completions ( JoinCondition ( tables= ( ( None , 'abc ' , ' a ' , False ) , False ] , tables = extract_tables ( stmt.text_before_cursor ) join_texts = [ Column ( tables= ( ( None , 'tabl ' , None , False ) , ) ) , 'UPDATE sch . ' , view ( 'user_emails ue ' ) , text = 'SELECT u.id , u. from users u ' function ( 'custom_func1 ' , -2 ) , self.get_view_matches ( v_sug , word_before_cursor , alias ) Function ( schema=parent ) , when selecting multiple columns from table : param completer : ( None , 'abc ' , None , False ) , FromClauseItem = namedtuple ( 'FromClauseItem ' , 'schema tables ' ) Table.__new__.__defaults__ = ( None , tuple ( ) ) [ 'custom_fun ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , from .packages.sqlcompletion import ( FromClauseItem , FULL OUTER JOIN `` Users '' U2 ON return objects View.__new__.__defaults__ = ( None , tuple ( ) ) table ( 'Users U ' ) , aliases = ( ' '' ' + tbl [ 1 : -1 ] + str ( i ) + ' '' ' for i in itertools.count ( 2 ) ) FromClauseItem ( schema=None ) , if self.generate_aliases or normalize_ref ( left.tbl ) in refs : 'SELECT * FROM Orders o CROSS JOIN ' ] ) schema ( ' '' Custom '' ' ) , FromClauseItem.__new__.__defaults__ = ( None , tuple ( ) ) def get_table_matches ( self , suggestion , word_before_cursor , alias=False ) : Function = namedtuple ( 'Function ' , [ 'schema ' , 'filter ' ] ) # Lists for use in assertions Document ( text=text ) , complete_event ) ) : param complete_event : def get_function_matches ( self , suggestion , word_before_cursor ) : alias ( ' U ' ) , comp.extend_casing ( casing or [ ] ) for c in self.unescape_name ( item.lower ( ) ) ) + ( 1 , ) funcs = self.populate_schema_objects ( 'SELECT * FROM users U right outer join `` Users '' U2 ON ' , t_sug = Table ( * suggestion ) Table ( schema=None ) , [ l for l , prev in zip ( tbl , ' _ ' + tbl ) if prev == ' _ ' and l ! = ' _ ' ] ) ' '' select '' s ' ) ] + [ view ( 'user_emails ue ' ) ] + [ function ( f ) for f in ( priority_collection = priority_collection or itertools.repeat ( 0 ) Column ( tables= ( ( None , 'foo ' , None , False ) , ) ) , def alias ( self , tbl , tbls ) : complete_event ) ) function ( 'custom_func2 ( ) cf ' ) , FULL OUTER JOIN `` Users '' u2 ON ( None , 'def ' , None , False ) ) , Column ( tables= ( ( None , ' a ' , None , False ) , ) ) , return testdata.get_completer ( { 'generate_aliases ' : True } ) param tbl - unescaped name of the table to alias 'SELECT * FROM users U INNER join `` Users '' U2 ON ' , Table ( schema='sch ' ) , result = completer_aliases_casing.get_completions ( ) , result = completer_with_casing.get_completions ( suggest = [ ] assert set ( result ) == set ( testdata.schemas ( ) + testdata.functions ( ) + testdata.tables ( ) ) cased_aliased_rels = [ table ( t ) for t in ( 'Users U ' , ' '' Users '' U ' , 'Orders O ' , function ( 'Func1 ( ) F ' ) , position = len ( 'SELECT ' ) 'SELECT * FROM Users U LEFT OUTER JOIN `` Users '' U2 ON ' , Function ( schema='sch ' , filter='for_from_clause ' ) , function ( 'custom_func1 ( ) ' , -2 ) , settings = { 'casing_file ' : get_casing_file ( c ) , assert set ( suggestions ) == cols_etc ( ' a ' ) suggestion.schema , 'functions ' ) ] Function ( schema=None , filter='for_from_clause ' ) , ] ) lref = self.alias ( left.tbl , suggestion.tables ) Function , Datatype , Alias , JoinCondition , Join ) 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] } cased_users_cols = [ 'ID ' , 'PARENTID ' , 'Email ' , 'First_Name ' , 'last_name ' ] ] ) def test_suggested_cased_column_names ( cased_completer , complete_event ) : suggest.append ( View ( schema=schema ) ) def test_cased_joins ( cased_completer , complete_event , text ) : Column ( tables= ( ( None , 'abc ' , None , False ) , ) ) , assert set ( suggestions ) == cols_etc ( 'foo ' ) function ( 'set_returning_func ' , -len ( 'func ' ) ) ] ) `` `` '' join ( ' '' Users '' ON `` Users '' .userid = Users.id ' ) , meta_collection = meta_collection or itertools.repeat ( meta ) tables = [ self.case ( t ) + ' ' + self.alias ( t , suggestion.tables ) from itertools import count , repeat , chain 'SELECT * FROM users u INNER join `` Users '' u2 ON ' , assert set ( suggestions ) == set ( ( JoinCondition ( tables=tables , parent=None ) , comp = pgcompleter.PGCompleter ( smart_completion=True ) return self.get_completer ( ) result = set ( aliased_completer.get_completions ( def test_table_casing ( completer_with_casing , complete_event , text ) : ( None , 'bcd ' , None , False ) ) , Column ( tables= ( ( None , 'abc ' , None , False ) , schema ( 'PUBLIC ' ) , lref = self.generate_alias ( left.tbl , refs ) tables = tuple ( [ ( None , 'foo ' , None , False ) , ( None , 'bar ' , None , False ) ] ) ] ) self.generate_aliases = settings.get ( 'generate_aliases ' ) assert set ( suggestions ) == set ( ( JoinCondition ( 'SELECT * FROM Users U FULL JOIN `` Users '' U2 ON ' , 'UPDATE sch . ' , Column ( tables= ( ( 'sch ' , 'tabl ' , None , False ) , ) ) , testdata.builtin_functions ( ) + testdata.keywords ( ) ) and _allow_join ( stmt.parsed ) ) : table ( 'orders o2 ' ) , view ( 'User_Emails UE ' ) , suggest.append ( Function ( schema=schema , filter='for_from_clause ' ) ) from pgcli.pgcompleter import PGCompleter funcs = [ f + ' ( ) ' for f in self.populate_schema_objects ( Table = namedtuple ( 'Table ' , [ 'schema ' ] ) join ( 'Users Users2 ON Users2.ID = Users.PARENTID ' ) , Keyword ( ) `` `` '' Generate a table alias , consisting of all upper-case letters in function ( 'custom_fun ( ) cf ' ) , table ( ' '' select '' s ' ) , def cased_aliased_completer ( request ) : 'users ' , callback , history=history , settings=settings ) aliases = ( tbl + str ( i ) for i in count ( 2 ) ) def generate_alias ( self , tbl , tbls ) : def test_suggest_qualified_aliasable_tables_and_views ( expression ) : ] join ( ' '' Users '' U ON U.userid = Users.id ' ) , [ '_custom_fun ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , if self.generate_aliases : Function.__new__.__defaults__ = ( None , None ) @ pytest.mark.parametrize ( 'text ' , [ [ 'custom_func1 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , c = self.config Function = namedtuple ( 'Function ' , [ 'schema ' , 'tables ' , 'filter ' ] ) lexical_priority = ( tuple ( 0 if c in ( ' _ ' ) else -ord ( c ) schema , table , function , wildcard_expansion ) if alias : def aliased_completer ( ) : return ( self.get_table_matches ( t_sug , word_before_cursor , alias ) Schema ( ) , function ( 'func3 ( ) ' , -len ( 'func ' ) ) , param tbls - set TableReference objects for tables already in query cased_tbls = [ table ( t ) for t in ( cased_tbls + [ ' '' Users '' ' , ' '' select '' ' ] ) ] parent=None ) , tbls = tuple ( [ ( None , 'abc ' , tbl_alias or None , False ) ] ) Keyword ( ) , function ( 'Func1 ( ) ' ) , Column ( tables= ( ( schema , table , alias , is_function ) , ) ) , def test_sub_select_table_name_completion ( expression ) : lexical_priority = tuple ( -ord ( c ) for c in self.unescape_name ( item ) ) + ( 1 , ) function ( 'func2 ( ) ' ) ] ) def get_table_matches ( self , suggestion , word_before_cursor ) : View ( schema='sch ' ) , return testdata.get_completer ( { 'generate_aliases ' : True } , casing ) tables = ( ( None , 'abc ' , None , False ) , ( None , 'bcd ' , None , False ) ) Document ( text=text , cursor_position=position ) , complete_event ) def completer_aliases_casing ( request ) : assert set ( result ) == set ( testdata.schemas ( ) join ( 'users users2 ON users2.id = Users.parentid ' ) , ] def test_aliases_with_casing ( cased_aliased_completer , complete_event , text ) : result = set ( cased_completer.get_completions ( 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] } FROM users Document ( text=text , cursor_position=position ) , 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , assert set ( result ) == set ( testdata.schemas ( ) + [ [ 'custom_func2 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , Document ( text=text , cursor_position=position ) , v_sug = View ( * suggestion ) function ( 'func2 ( ) f ' ) ] ) Join ( tbls , 'sch ' ) , function ( 'Custom_Fun ( ) CF ' ) , if tbl [ 0 ] == ' '' ' : '_custom_fun ( ) cf ' , 'custom_fun ( ) cf ' , 'custom_func1 ( ) cf ' , cased_users2_cols = [ 'UserID ' , 'UserName ' ] def test_sub_select_table_name_completion_with_outer_table ( expression ) : suggestion.schema , 'functions ' ) ' '' select '' s ' ) ] + [ view ( 'User_Emails UE ' ) ] + [ function ( f ) for f in ( 'SELECT * FROM users u LEFT JOIN `` Users '' u2 ON ' , aliases = ( self.case ( tbl ) + str ( i ) for i in itertools.count ( 2 ) ) cased_users_cols = [ column ( c ) for c in cased_users_cols ] tbls = tuple ( [ ( None , 'foo ' , ' f ' , False ) ] ) FROM users U texts = [ 'SELECT * FROM ' , 'SELECT * FROM public.Orders O CROSS JOIN ' ] assert set ( result ) == set ( testdata.schemas ( ) + aliased_rels + [ assert set ( suggestions ) == cols_etc ( 'tabl ' ) views = [ self.case ( v ) + ' ' + self.alias ( v , suggestion.tables ) complete_event , text ) : tables= ( ( None , 'abc ' , ' a ' , False ) , for t in tables ] cased_funcs = [ function ( f + ' ( ) ' ) for f in cased_funcs ] assert set ( suggestions ) == set ( [ if token_v == 'from ' or is_join : assert set ( result ) == set ( testdata.schemas ( ) testdata.views ( ) + testdata.tables ( ) + testdata.functions ( ) ) def completer_with_casing ( ) : join ( 'Users Users2 ON Users2.PARENTID = Users.ID ' ) , ' '' Users '' ' , suggest.extend ( ( Table ( schema ) , View ( schema ) ) ) Column ( tables= ( ( None , ' b ' , None , False ) , ) ) , if normalize_ref ( left.tbl ) in refs : function ( 'set_returning_func ( ) ' , -len ( 'func ' ) ) ] ) def test_aliased_joins ( aliased_completer , complete_event , text ) : if token_v == 'from ' or ( token_v.endswith ( 'join ' ) and token.is_keyword ) : elif token_v == 'truncate ' : elif tbl [ 0 ] == ' '' ' : alias ( ' '' Users '' ' ) Join ( ( ( None , 'foo ' , None , False ) , ) , 'sch ' ) , else : def completer_with_aliases ( ) : is_join = token_v.endswith ( 'join ' ) and token.is_keyword 'set_returning_func ' , 'SELECT * FROM Users u LEFT OUTER JOIN `` Users '' u2 ON ' , ] ) def test_aliases_with_casing ( completer_aliases_casing , complete_event , text ) : FromClauseItem ( schema='sch ' , tables=tbls ) , # If set to True , table suggestions will include a table alias 'SELECT * FROM Users JOIN ' , '_custom_fun ( ) ' , tbls = tuple ( [ ( None , 'foo ' , None , False ) ] ) tbls - TableReference iterable of tables already in query def test_cased_join_conditions ( cased_completer , complete_event , text ) : tables = ( ( None , 'abc ' , None , False ) , ( None , 'def ' , None , False ) ) else : function ( '_custom_fun ( ) cf ' ) , position = len ( text ) function ( 'func1 ( ) f ' ) , 'SELECT * FROM users JOIN ' , import itertools 'SELECT * FROM users u JOIN `` Users '' u2 ON ' , result = completer.get_completions ( Document ( text=text ) , complete_event ) 'users ' def test_duplicate_aliases_with_casing ( cased_aliased_completer , schema , table , view , function , column , wildcard_expansion ) 'custom_func2 ' , 'set_returning_func ' ] callback , history=history , settings=self.settings ) View ( schema=None ) , 'custom_func1 ' , 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , 'SELECT * FROM USERS U right JOIN `` Users '' U2 ON ' , schema ( 'CUSTOM ' ) , Join ( ( ( None , 'abc ' , tbl_alias if tbl_alias else None , False ) , ) , None ) , assert set ( suggestion ) == set ( [ def test_schema_or_visible_table_completion ( completer , complete_event , text ) : 'SELECT * FROM users U JOIN `` Users '' U2 ON ' , assert set ( suggestions ) == set ( [ return self.find_matches ( word_before_cursor , tables , meta='table ' ) parent=None 'custom_fun ( ) ' , Suggest column and function names when selecting from table tbls - set of table refs already in use , normalized with normalize_ref schema ( 'public ' ) , flat_cols = list ( chain ( * ( ( c.name for c in cols ) [ 'custom_func1 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , ' '' Users '' ' , tables = ( ( None , 'abc ' , ' a ' , False ) , ( None , 'def ' , 'd ' , False ) ) def generate_alias ( tbl , tbs ) : suggestion.tables ) for f in funcs ] table , function , column , wildcard_expansion ) Keyword ( ) ] ) 'generate_aliases ' : c [ 'main ' ] .as_bool ( 'generate_aliases ' ) , if normalize_ref ( tbl ) not in tbls : all letters preceded by _ fk_join ( 'U2.UserID = U.ID ' ) ] ) return tbl def test_suggested_cased_column_names_with_alias ( cased_completer , complete_event ) : assert set ( result ) == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels ) if alias : assert set ( result ) == set ( cased_funcs + cased_users_cols complete_event ) ) # Returns the expected select-clause suggestions for a single-table select comp = PGCompleter ( smart_completion=True , settings=settings ) Join ( ( ( None , 'foo ' , None , False ) , ( None , 'bar ' , None , False ) ) , None ) , assert set ( result ) == set ( [ schema ( 'PUBLIC ' ) ] + cased_aliased_rels ) View ( schema=None ) , funcs = [ self.case ( f ) + ' ( ) ' + self.alias ( f , cased_rels = [ view ( t ) for t in cased_views ] + cased_funcs + cased_tbls result = cased_completer.get_completions ( funcs = [ self.case ( f ) + ' ( ) ' for f in funcs ] ] ) tables= ( f_sug = Function ( * suggestion , filter='for_from_clause ' ) function ( 'custom_func2 ( ) ' , -2 ) ] ) 'func ' , is_function=True ) assert set ( suggestions ) == cols_etc ( 'tabl ' , 'sch ' ) Function ( schema=None ) , alias ( ' '' Users '' ' ) , casing = ( [ 'SELECT ' , 'PUBLIC ' ] + cased_funcs + cased_tbls + cased_views # ` tables ` contains the list of tables/ ... already in the statement , Function ( schema=None ) , # used to ensure that the alias we suggest is unique if token_v ! = 'truncate ' : Column ( tables=tables , require_last_table=True ) , ] ) assert set ( result ) == set ( testdata.schemas ( ) + aliased_rels ) JoinCondition ( tables=tables , parent= ( None , 'abc ' , ' a ' , False ) ) # case-sensitive one as a tie breaker . alias ( 'u2 ' ) , suggestion = suggest_type ( expression , expression ) assert set ( result ) == set ( [ schema ( 'PUBLIC ' ) ] + cased_rels + [ from .packages.sqlcompletion import ( assert set ( suggestions ) == cols_etc ( 'tabl ' , alias= ' '' tabl '' ' ) assert set ( suggestions ) == set ( ( JoinCondition ( tables= ( return [ function ( escape ( x [ 0 ] ) , pos ) # FromClauseItem is a table/view/function used in the FROM clause def test_duplicate_table_aliases ( aliased_completer , complete_event , text ) : assert FromClauseItem ( schema=None ) in set ( suggestions ) fk_join ( 'u2.userid = u.id ' ) ] ) from .config import load_config , config_location cased_users_cols + cased_users2_cols ) FromClauseItem : get_from_clause_item_matches , assert set ( result ) == set ( [ import pgcli.pgcompleter as pgcompleter FROM Users fk_join ( 'U2.userid = U.id ' ) ] ) parent= ( None , 'abc ' , ' a ' , False ) ) casing = ( 'SELECT ' , 'Orders ' , 'User_Emails ' , 'CUSTOM ' , 'Func1 ' ) ] ) assert set ( suggestions ) == cols_etc ( join ( 'users u ON u.id = Users.parentid ' ) , FROM users u 'SELECT * FROM USERS u right JOIN `` Users '' u2 ON ' , text = 'SELECT from users ' # Only tables can be TRUNCATED , otherwise suggest views function ( '_custom_fun ( ) ' , -2 ) , function ( 'custom_func2 ' , -2 ) ] ) FromClauseItem ( schema=None , tables=tables ) , 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , def test_table_casing ( cased_completer , complete_event , text ) : tbl = generate_alias ( self.unescape_name ( tbl ) , tbls ) assert set ( suggestions ) == cols_etc ( ' b ' ) alias ( 'users ' ) ] tbl = self.case ( tbl ) priority_collection = priority_collection or repeat ( 0 ) testdata.views ( ) + testdata.tables ( ) + testdata.functions ( ) ) join_condition_texts = [ for v in views ] : return : tables = ( ( None , 'abc ' , ' a ' , False ) , ( None , 'bcd ' , ' b ' , False ) ) FromClauseItem ( schema=None , tables=tbls ) , def cols_etc ( table , schema=None , alias=None , is_function=False , parent=None ) : def get_from_clause_item_matches ( self , suggestion , word_before_cursor ) : suggestions = suggest_type ( expression , expression ) ( None , 'abc ' , None , False ) , 'SELECT * FROM users U FULL OUTER JOIN `` Users '' U2 ON ' , 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] } join ( ' '' Users '' ON `` Users '' .userid = users.id ' ) , Table = namedtuple ( 'Table ' , [ 'schema ' , 'tables ' ] ) join ( 'users users2 ON users2.id = users.parentid ' ) , return testdata.get_completer ( casing=casing ) cased_tbls = [ 'Users ' , 'Orders ' ] assert set ( result ) == set ( cased_users_cols ) 'set_returning_func ( ) ' , meta_collection = meta_collection or repeat ( meta ) [ 'custom_func2 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , False ] , assert set ( suggestions ) == cols_etc ( 'abc ' ) require_last_table=True ) , tables = ( ( None , 'foo ' , None , False ) , ) assert Table ( schema=None ) in set ( suggestions ) join ( 'users users2 ON users2.parentid = users.id ' ) , function ( 'set_returning_func ( ) srf ' ) ] ) from .config import load_config , config_location , get_config Table ( schema=None ) , # tbls should also include ( None , 'bar ' , ' b ' , False ) 'SELECT * FROM Users u FULL JOIN `` Users '' u2 ON ' , table ( 'Orders O2 ' ) , result = completer_with_aliases.get_completions ( suggest.append ( FromClauseItem ( schema=schema , tables=tables ) ) the table name , or , if there are no upper-case letters , the first letter function ( 'custom_func1 ( ) cf ' ) ,","['pgcli/main.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'tests/metadata.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 531 from dbcli/koljonen/generate_aliases
297,d947031e9968493f59fdc97ab0236cc1d8b6ee06,2016-07-03 20:31:38-07:00,Features : * Fix the crash with Redshift databases . ( Thanks : ` Darik Gamble ` _ ) Bugs : 1.1.0 .. _ ` Eric Wald ` : https : //github.com/eswald Internal Changes : ===== * Add support for `` \db `` command . ( Thanks : ` Irina Truong ` _ ) * Fix the crash at startup while parsing the postgres url with port number . ( Thanks : ` Eric Wald ` _ ) * Upgrade pgspecial to 1.5.0 and above .,['changelog.rst'],Merge pull request # 541 from dbcli/amjith/release-1.1.0
298,eb536a6f64672e54e4dec346c8de602d7de435b9,2016-06-29 21:42:27-07:00,"false is_window , INNER JOIN pg_catalog.pg_class cls att.atttypid : :regtype : :text type_name SELECT n.nspname schema_name , self.arg_types = tuple ( [ None ] * len ( arg_names ) ) self.arg_types = None ORDER BY 1 , 2 SELECT n.nspname schema_name , FROM pg_catalog.pg_proc p ' '' COALESCE ( proallargtypes : :regtype [ ] , proargtypes : :regtype [ ] ) : :text [ ] , att.attname column_name , sql = cur.mogrify ( columns_query , [ kinds ] ) SELECT nsp.nspname schema_name , NULL arg_types , if self.conn.server_version > = 80400 : '' ret_type , p.proiswindow is_window , query = `` ' self.arg_types = tuple ( arg_types ) if arg_types : ON n.oid = p.pronamespace ORDER BY 1 , 2 , att.attnum '' ' self.arg_modes = tuple ( arg_modes ) if arg_modes else None p.proisagg is_aggregate , INNER JOIN pg_catalog.pg_namespace n ON n.oid = p.pronamespace else : yield FunctionMetadata ( * row ) # where such info is hard to get . prorettype : :regtype : :text , att.attname column_name , SELECT nsp.nspname schema_name , WHERE p.prorettype : :regtype ! = 'trigger ' : :regtype columns_query = `` ' cls.relname table_name , yield FunctionMetadata ( * row ) elif arg_names : INNER JOIN pg_catalog.pg_namespace n for row in cur : COALESCE ( proallargtypes : :regtype [ ] , proargtypes : :regtype [ ] ) : :text [ ] , ON cls.relnamespace = nsp.oid NULL arg_modes , INNER JOIN pg_catalog.pg_type typ AND att.attnum > 0 if self.conn.server_version > 90000 : p.proretset is_set_returning AND NOT att.attisdropped for row in cur : # for each arg . ( Used for compatibility with old versions of postgresql AND NOT att.attisdropped elif arg_modes : typ.typname type_name p.proargnames , self.arg_types = tuple ( arg_types ) p.proiswindow is_window , p.proretset is_set_returning yield FunctionMetadata ( * row ) ON n.oid = p.pronamespace ORDER BY 1 , 2 sql = cur.mogrify ( self.columns_query , [ kinds ] ) p.proisagg is_aggregate , p.proargmodes , ON att.attrelid = cls.oid p.proname func_name , false is_window , _logger.debug ( 'Functions Query . sql : % r ' , query ) p.proargnames , if self.conn.server_version > 90000 : WHERE cls.relkind = ANY ( % s ) INNER JOIN pg_catalog.pg_namespace n AND att.attnum > 0 prorettype : :regtype : :text , p.proargmodes , INNER JOIN pg_catalog.pg_namespace nsp ON n.oid = p.pronamespace ON cls.relnamespace = nsp.oid FROM pg_catalog.pg_proc p else : INNER JOIN pg_catalog.pg_namespace n query = `` ' ON att.attrelid = cls.oid cls.relname table_name , cur.execute ( query ) ON typ.oid = att.atttypid ORDER BY 1 , 2 , att.attnum '' ' self.arg_modes = tuple ( arg_modes ) if arg_modes else None self.arg_types = tuple ( [ None ] * len ( arg_modes ) ) INNER JOIN pg_catalog.pg_class cls columns_query = `` ' cur.execute ( query ) FROM pg_catalog.pg_attribute att FROM pg_catalog.pg_attribute att WHERE p.prorettype : :regtype ! = 'trigger ' : :regtype ' '' att.atttypid : :regtype : :text type_name # Be flexible in not requiring arg_types -- use None as a placeholder INNER JOIN pg_catalog.pg_namespace nsp p.proname func_name , prorettype : :regtype : :text return_type , prorettype : :regtype : :text return_type , WHERE cls.relkind = ANY ( % s ) elif self.conn.server_version > = 80400 : _logger.debug ( 'Functions Query . sql : % r ' , query )","['pgcli/packages/function_metadata.py', 'pgcli/pgexecute.py']",Merge pull request # 539 from dbcli/darikg/fix-old-columns-query
299,f77dafd17bf11d505d4afd120added2c7b242880,2016-06-29 21:36:05-07:00,"with mock.patch.object ( PGCli , 'connect ' ) as mock_connect : def test_port_db_uri ( tmpdir ) : mock_connect.assert_called_with ( 'testdb ' , 'baz.com ' , 'bar ' , '2543 ' , 'foo ' ) self.connect ( * list ( map ( lambda p : unquote ( p ) if p else p , arguments ) ) ) self.connect ( * list ( map ( lambda p : unquote ( str ( p ) ) if p else p , arguments ) ) ) cli = PGCli ( pgclirc_file=str ( tmpdir.join ( `` rcfile '' ) ) )","['pgcli/main.py', 'tests/test_main.py']",Merge pull request # 538 from eswald/issue-536
300,68f8f429390b50ddd33d503aa6bff8dd9cc6eb5d,2016-06-28 19:59:12-07:00,.. _ ` Anže Pečar ` : https : //github.com/Smotko .. _ ` Ari Summer ` : Ari Summer 0.20.0 * Add support for ` \dx ` meta command to list the installed extensions . ( Thanks : ` Darik Gamble ` _ ) .. _ ` Anthony Lai ` : https : //github.com/ajlai * Fix multi-way joins in auto-completion . ( Thanks : ` Darik Gamble ` _ ) * Add support for ` \o ` command to redirect query output to a file . ( Thanks : ` Tim Sanders ` _ ) . .. _ ` Stuart Quin ` : https : //github.com/stuartquin * Joakim Koljonen .. _ ` Tim Sanders ` : https : //github.com/Gollum999 Bugs : 1.0.0 .. _ ` gtxx ` : gtxx .. _ ` Irina Truong ` : https : //github.com/j-bennet * Add support for Amazon Redshift . ( Thanks : ` Timothy Cleaver ` _ ) . * Concat and return all available notices . ( Thanks : ` Stuart Quin ` _ ) . * Update pgspecial dependency to 1.4.0 . * Added humanized time display . Connect # 396 . ( Thanks : ` Irina Truong ` _ ) . .. _ ` Rodrigo Ramírez Norambuena ` : https : //github.com/roramirez * Do n't error when completing parameter-less functions . ( Thanks : ` David Szotten ` _ ) . * Lots of tests for pgcompleter . ( Thanks : ` Darik Gamble ` _ ) . * Add support for ` \copy ` command . ( Thanks : ` Catherine Devlin ` _ ) * Pager is selected from config file or else from environment variable . ( Thanks : ` Fernando Mora ` _ ) . .. _ ` Amjith Ramanujam ` : https : //github.com/amjith * Amjith Ramanujam .. _ ` Jonathan Slenders ` : https : //github.com/jonathanslenders Internal Changes : * Upgrade sqlparse requirement to version 0.1.19 . ( Thanks : ` Fernando L. Canizo ` _ ) . 0.20.1 * Add ` \i ` path completion . ( Thanks : ` Anthony Lai ` _ ) . .. _ ` Joakim Koljonen ` : https : //github.com/koljonen .. _ ` Fernando L. Canizo ` : Fernando L. Canizo * Upgrade to prompt-toolkit 1.0.0 . ( Thanks : ` Jonathan Slenders ` _ ) . * Handle unicode in record type . ( Thanks : ` Amjith Ramanujam ` _ ) . * Handle dates that fall in the B.C . range . ( Thanks : ` Stuart Quin ` _ ) . .. _ ` Catherine Devlin ` : https : //github.com/catherinedevlin * Explicitly add wcwidth as a dependency . ( Thanks : ` Amjith Ramanujam ` _ ) . * Add a limit to the warning about too many rows . This is controlled by a new config value in ~/.config/pgcli/config . ( Thanks : ` Anže Pečar ` _ ) * Added sdist upload to release script . ( Thanks : ` Irina Truong ` _ ) . Features : * Filter out trigger implemented functions from the suggestion list . ( Thanks : ` Daniel Rocco ` _ ) * Robust support for Postgres version less than 9.x . ( Thanks : ` Darik Gamble ` _ ) * Add support for Postgres 8.x . ( Thanks : ` Timothy Cleaver ` _ and ` Darik Gamble ` _ ) ===== .. _ ` James Munson ` : https : //github.com/jmunson .. _ ` Timothy Cleaver ` : Timothy Cleaver * Fix the bug in auto-expand mode when there are no rows to display . ( Thanks : ` Amjith Ramanujam ` _ ) . * State of the art JOIN clause completions that suggest entire conditions . ( Thanks : ` Joakim Koljonen ` _ ) .. _ ` Fernando Mora ` : https : //github.com/fernandomora * Column suggestions after the COLUMN keyword . ( Thanks : ` Darik Gamble ` _ ) * Add tests for the format_output . ( Thanks : ` Amjith Ramanujam ` _ ) . * Suggest fully formed JOIN clauses based on Foreign Key relations . ( Thanks : ` Joakim Koljonen ` _ ) * Sort completions based on most recently used . ( Thanks : ` Darik Gamble ` ) .. _ ` David Szotten ` : David Szotten * Connect to a dsn saved in config file . ( Thanks : ` Rodrigo Ramírez Norambuena ` _ ) . * Add EXPLAIN keyword to the completion list . ( Thanks : ` Amjith Ramanujam ` _ ) . * Stuart Quin * Fix lexical ordering bug . ( Thanks : ` Anthony Lai ` _ ) . * Update config file location in README . ( Thanks : ` Ari Summer ` _ ) . * Improved argument list in function parameter completions . ( Thanks : ` Joakim Koljonen ` _ ) * Use lexical order to break ties when fuzzy matching . ( Thanks : ` Daniel Rocco ` _ ) . * Expand ' * ' into column list during completion . This can be triggered by hitting ` < tab > ` after the ' * ' character in the sql while typing . ( Thanks : ` Joakim Koljonen ` _ ) * Ensure target dir exists when copying config . ( Thanks : ` David Szotten ` _ ) . * Stuart Quin * Fix bug where config writing would leave a '~ ' dir . ( Thanks : ` James Munson ` _ ) . * Fix auto-completion breaking for table names with caps . ( Thanks : ` Anthony Lai ` _ ) . * Display null values as < null > in expanded output . ( Thanks : ` Amjith Ramanujam ` _ ) . * Add timestamptz to DATE custom extension . ( Thanks : ` Fernando Mora ` _ ) . * Fix broken ` \i ` after # 395 . ( Thanks : ` David Szotten ` _ ) .,"['AUTHORS', 'changelog.rst']",Merge pull request # 494 from dbcli/amjith/release-1.0
301,17790dc2c426c4cad9b886d4d62c6721373d166c,2016-06-24 06:43:06-07:00,"# cumulatively summing statement lengths to find the one that bounds the text = stmt.text_before_cursor + stmt.word_before_cursor if filteredtables and _allow_join_condition ( stmt.parsed ) : tables = extract_tables ( full_text ) def _split_multiple_statements ( full_text , text_before_cursor , parsed ) : identifier = parse_partial_identifier ( word_before_cursor ) def suggest_based_on_last_token ( token , text_before_cursor , full_text , def reduce_to_prev_keyword ( self ) : tables = extract_tables ( stmt.text_before_cursor ) full_text = _strip_named_query ( full_text ) if schema and identifier.value [ 0 ] ! = ' '' ' : prev_keyword , _ = find_prev_keyword ( text_before_cursor ) return ( Column ( tables=extract_tables ( stmt.full_text ) ) , ) schema = ( identifier and identifier.get_parent_name ( ) ) or None if statement : ' \ns zzz SELECT * FROM abc ' - > 'SELECT * FROM abc ' self.full_text = full_text # Check for special commands and handle those separately def __init__ ( self , full_text , text_before_cursor ) : p = sqlparse.parse ( stmt.text_before_cursor ) [ 0 ] parsed = sqlparse.parse ( text_before_cursor ) return suggest_based_on_last_token ( 'type ' , text_before_cursor , text_before_cursor = strip_named_query ( text_before_cursor ) # string . In that case we want to remove the partially typed string before text_before_cursor = _strip_named_query ( text_before_cursor ) include='many_punctuations ' ) return txt # If we 've partially typed a word then word_before_cursor wo n't be an return ( Column ( tables=extract_tables ( full_text ) ) , ) parent = ( identifier and identifier.get_parent_name ( ) ) or None return ( Column ( tables=extract_tables ( stmt.text_before_cursor ) ) , ) self.last_token = parsed and parsed.token_prev ( len ( parsed.tokens ) ) or `` This will strip `` save named query '' command in the beginning of the line : tables = extract_tables ( text_before_cursor ) # [ ( schema , table , alias ) , ... ] # string before sending it to the sqlparser . Otherwise the last token # statement , but the statement wo n't have a first token return suggest_based_on_last_token ( last_token = statement and statement.token_prev ( len ( statement.tokens ) ) or `` if tok1 and tok1.value == '\\ ' : parent = ( stmt.identifier and stmt.identifier.get_parent_name ( ) ) or None self.identifier = parse_partial_identifier ( word_before_cursor ) # Be careful here because trivial whitespace is parsed as a statement , _split_multiple_statements ( full_text , text_before_cursor , parsed ) return suggest_special ( text ) parent = ( identifier and identifier.get_parent_name ( ) ) or [ ] column_suggestions = suggest_based_on_last_token ( if _allow_join_condition ( stmt.parsed ) : ' \ns zzz SELECT * FROM abc ' - > 'SELECT * FROM abc ' if last_word ( stmt.text_before_cursor , and _allow_join ( stmt.parsed ) ) : tables = extract_tables ( stmt.full_text ) self.text_before_cursor = text_before_cursor # sending it to the sqlparser . Otherwise the last token will always be the return suggest_based_on_last_token ( full_text , identifier , parsed_statement ) text_before_cursor , include='many_punctuations ' ) # Be careful here because trivial whitespace is parsed as a self.identifier = None parent=filteredtables [ -1 ] ) ) txt = named_query_regex.sub ( `` , txt ) identifier = None '\ns zzz SELECT * FROM abc ' - > 'SELECT * FROM abc ' column_suggestions = suggest_based_on_last_token ( 'where ' , stmt ) # the current position # but the statement wo n't have a first token schema = stmt.get_identifier_schema ( ) parsed = sqlparse.parse ( text_before_cursor ) # Check for special commands and handle those separately return suggest_based_on_last_token ( prev_keyword , text_before_cursor , self.parsed = parsed prev_keyword = stmt.reduce_to_prev_keyword ( ) # empty string . In that case we want to remove the partially typed if tok1 and tok1.value == '\\ ' : schema = schema.lower ( ) prev_keyword , _ = find_prev_keyword ( stmt.text_before_cursor ) tables = extract_tables ( stmt.text_before_cursor ) # [ ( schema , table , alias ) , ... ] schema = schema.lower ( ) return ( Column ( tables=extract_tables ( stmt.full_text ) ) , if named_query_regex.match ( txt ) : if filteredtables and _allow_join_condition ( parsed_statement ) : if word_before_cursor : `` `` '' pattern = re.compile ( r'^\s * \\ns\s+ [ A-z0-9\-_ ] +\s+ ' ) This will strip `` save named query '' command in the beginning of the line : parsed_statement ) self.text_before_cursor_including_last_word = text_before_cursor # cumulatively summing statement lengths to find the one that bounds # If schema name is unquoted , lower-case it p = sqlparse.parse ( text_before_cursor ) [ 0 ] txt = pattern.sub ( `` , txt ) identifier , parsed_statement=None ) : # current position full_text , text_before_cursor , parsed = \ else : if stmt.parsed : stmt = SqlStatement ( full_text , text_before_cursor ) # keywords as completion . tables = extract_tables ( text_before_cursor ) tok1 = stmt.parsed.token_first ( ) if word_before_cursor [ -1 ] == ' ( ' or word_before_cursor [ 0 ] == '\\ ' : if schema and self.identifier.value [ 0 ] ! = ' '' ' : text_before_cursor = text_before_cursor [ : -len ( word_before_cursor ) ] # If we 've partially typed a word then word_before_cursor wo n't be an empty full_text = strip_named_query ( full_text ) parent=filteredtables [ -1 ] ) ) return prev_keyword if pattern.match ( txt ) : if self.word_before_cursor : else : text_before_cursor_including_last_word = text_before_cursor if last_word ( text_before_cursor , schema = ( self.identifier and self.identifier.get_parent_name ( ) ) or None def suggest_based_on_last_token ( token , stmt ) : text_before_cursor = text_before_cursor [ : -len ( word_before_cursor ) ] '\ns zzz SELECT * FROM abc ' - > 'SELECT * FROM abc ' def _strip_named_query ( txt ) : # completion useless because it will always return the list of prev_keyword , text_before_cursor = find_prev_keyword ( text_before_cursor ) # If schema name is unquoted , lower-case it # it will always return the list of keywords as completion . 'where ' , text_before_cursor , full_text , identifier , class SqlStatement ( object ) : self.word_before_cursor = word_before_cursor = last_word ( prev_keyword , self.text_before_cursor = \ word_before_cursor = last_word ( text_before_cursor , def get_identifier_schema ( self ) : parsed_statement=statement ) return ( Column ( tables=extract_tables ( full_text ) ) , parsed = sqlparse.parse ( text_before_cursor ) parent = ( stmt.identifier and stmt.identifier.get_parent_name ( ) ) or [ ] prev_keyword , text_before_cursor , full_text , identifier , tok1 = statement.token_first ( ) return suggest_based_on_last_token ( 'type ' , stmt ) last_token = parsed_statement named_query_regex = re.compile ( r'^\s * \\ns\s+ [ A-z0-9\-_ ] +\s+ ' ) return suggest_special ( text_before_cursor_including_last_word ) find_prev_keyword ( self.text_before_cursor ) last_token , text_before_cursor , full_text , identifier , else : return schema return ( Column ( tables=extract_tables ( text_before_cursor ) ) , ) full_text , identifier , parsed_statement ) # will always be the partially typed string which renders the smart parsed = sqlparse.parse ( text_before_cursor ) else : and _allow_join ( parsed_statement ) ) : def strip_named_query ( txt ) : return full_text , text_before_cursor , statement if word_before_cursor [ -1 ] == ' ( ' or word_before_cursor [ 0 ] == '\\ ' : if _allow_join_condition ( parsed_statement ) : return suggest_based_on_last_token ( prev_keyword , stmt ) return suggest_based_on_last_token ( stmt.last_token , stmt ) return txt `` `` '' # partially typed string which renders the smart completion useless because return suggest_based_on_last_token ( prev_keyword , stmt )",['pgcli/packages/sqlcompletion.py'],Merge pull request # 532 from dbcli/darikg/doc-object
302,33eade861e9aea83ca7fda262026312d2873f302,2016-06-20 12:28:46-04:00,"def schemas ( self , pos=0 ) : kw = keyword ( 'SELECT ' , -1 ) comp.extend_columns ( tbl_cols , kind='tables ' ) alias ( ' y ' ) ] ) 'Custom ' : [ Completion ( text='projects ' , start_position=start_pos , display_meta='table ' ) Completion ( text='typ3 ' , display_meta='datatype ' ) , join ( 'users users2 ON users2.parentid = users.id ' ) , testdata.views ( ) + [ assert set ( result ) == set ( testdata.schemas ( ) + testdata.tables ( ) + [ # views testdata.views ( ) + testdata.functions ( ) ) 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , expected = [ Completion ( text=cols , start_position=-1 , fk_join ( 'u2.userid = u.id ' ) ] ) Completion ( text='shipments.user_id = users.id ' , start_position=0 , display_meta='fk join ' ) ] ) False ] , ( 'public ' , 'users ' , 'id ' , 'public ' , 'users ' , 'parentid ' ) , return [ schema ( escape ( s ) , pos=pos ) for s in schemas ] Completion ( text='phone_number ' , start_position=0 , display_meta='column ' ) , Completion ( text= ' '' Users '' ' , start_position=0 , display_meta='table ' ) , 'custom ' : { assert set ( result ) == set ( testdata.columns ( 'users ' , 'custom ' ) ] , function ( 'custom_func2 ' , -2 ) ] ) } , def builtin_datatypes ( self , pos=0 ) : fun = [ x for x in self.metadata [ typ ] [ schema ] if x [ 0 ] == parent ] [ 0 ] return [ function ( f , pos ) for f in self.completer.functions ] alias ( 'users ' ) , metadata = dict ( ( k , { 'public ' : v } ) for k , v in metadata.items ( ) ) Completion ( text='func1 ' , start_position=0 , display_meta='function ' ) , testdata.functions ( 'custom ' , start_pos ) ) 'tables ' : { 'functions ' : { from pgcli.packages.function_metadata import FunctionMetadata , ForeignKey 'custom ' : [ tables.append ( ( 'public ' , table ) ) for x in self.metadata.get ( 'datatypes ' , { } ) .get ( schema , [ ] ) ] Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) , [ 'set_returning_func ' , [ ' x ' , ' y ' ] , [ 'integer ' , 'integer ' ] , 'custom ' : [ alias ( ' o ' ) ] ) 'tables ' : { column ( 'email ' ) , fk_join ( 'u2.userid = users.id ' ) , Completion ( text='orders.email = users.email ' , start_position=0 , display_meta='name join ' ) , 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] } , columns.extend ( [ ( 'public ' , view , col , 'text ' ) for col in cols ] ) name_join ( 'shipments.id = users.id ' ) , 'functions ' : [ Completion ( text='custom ' , start_position=0 , display_meta='schema ' ) , function ( 'custom_func1 ' , -2 ) , name_join ( ' o.email = u.email ' ) , Completion ( text=join , start_position=0 , display_meta='join ' ) , expected = [ Completion ( text=expected , start_position=-1 , display_meta='keyword ' ) ] ) for view , cols in metadata [ 'views ' ] .items ( ) : functions = [ FunctionMetadata ( 'public ' , * func_meta ) join = 'custom.shipments ON shipments.user_id = { 0 } .id'.format ( tbl ) alias ( 'u2 ' ) , join ( 'public.users ON users.id = `` Users '' .userid ' ) , # and so on 'datatypes ' : [ 'custom_type1 ' , 'custom_type2 ' ] , function , wildcard_expansion ) return [ view ( escape ( x ) , pos ) datatypes = [ ( 'public ' , typ ) for typ in metadata [ 'datatypes ' ] ] import pgcli.pgcompleter as pgcompleter from prompt_toolkit.completion import Completion testdata.columns ( 'set_returning_func ' , typ='functions ' ) assert set ( result ) == set ( testdata.columns ( 'users ' ) name_join ( ' y.price = x.price ' ) , ] } , expected = Completion ( text='users ON users.id = u.userid ' , from functools import partial 'public ' : [ 'typ1 ' , 'typ2 ' ] , columns.extend ( [ ( 'public ' , table , col , 'text ' ) for col in cols ] ) def functions ( self , schema='public ' , pos=0 ) : 'Users ' : [ 'userid ' , 'username ' ] , testdata.functions ( ) # types Completion ( text='func1 ' , start_position=0 , display_meta='function ' ) , for func_meta in funcs ] assert completions.index ( col ) < completions.index ( kw ) testdata = MetaData ( metadata ) Completion ( text= ' '' Custom '' ' , start_position=0 , display_meta='schema ' ) , assert set ( result ) == set ( testdata.tables ( 'custom ' , start_pos ) display= ' * ' , display_meta='columns ' ) ] keyword ( 'CURRENT ' , -2 ) , comp.extend_datatypes ( datatypes ) Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) ] } , # Let all columns be text columns False ] ] , 'datatypes ' : [ 'custom_type1 ' , 'custom_type2 ' ] , escape = lambda name : ( ' '' ' + name + ' '' ' if not name.islower ( ) or name in ( Completion ( text='orders.id = users.id ' , start_position=0 , display_meta='name join ' ) , schemata , tables , tbl_cols , views , view_cols = [ ] , [ ] , [ ] , [ ] , [ ] datatypes = [ ( schema , datatype ) [ 'custom_func1 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , Completion ( text='custom_type2 ' , start_position=0 , display_meta='datatype ' ) , assert set ( result ) == set ( testdata.schemas ( ) + testdata.tables ( ) 'datatypes ' : { return testdata.completer testdata.functions ( ) class MetaData ( object ) : Completion ( text='CURRENT ' , start_position=-2 , display_meta='keyword ' ) , Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) 'select ' , 'insert ' ) else name ) comp = pgcompleter.PGCompleter ( smart_completion=True ) fk_join ( 'u2.userid = u.id ' ) , comp.extend_relations ( tables , kind='tables ' ) tbl_cols.extend ( [ ( schema , table , col , 'text ' ) for col in cols ] ) assert set ( result ) == set ( testdata.datatypes ( 'custom ' ) comp.extend_functions ( functions ) 'public ' : [ 'typ1 ' , 'typ2 ' ] , [ 'func2 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] , [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] expected = table ( ' '' select '' ' , -5 ) for table , cols in tbls.items ( ) : join ( 'custom.shipments ON shipments.user_id = { 0 } .id'.format ( tbl ) ) , assert set ( result ) == set ( testdata.columns ( 'users ' ) + testdata.functions ( ) Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) , Completion ( text= ' o.email = u.email ' , start_position=0 , display_meta='name join ' ) , alias ( ' y ' ) , 'datatypes ' : { for display_meta in ( 'schema ' , 'table ' , 'view ' , 'function ' , 'column ' , [ 'custom_func2 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , comp.extend_schemata ( schemata ) testdata.tables ( 'Custom ' , start_pos ) ) def tables ( self , schema='public ' , pos=0 ) : for schema , funcs in metadata [ 'functions ' ] .items ( ) for datatype in datatypes ] Completion ( text='users ' , start_position=0 , display_meta='table ' ) , Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) ] ) Completion ( text='price ' , start_position=0 , display_meta='column ' ) ] ) Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] schemata = [ 'public ' ] # Let all columns be text columns Completion ( text='public.users ON users.id = `` Users '' .userid ' , start_position=0 , display_meta='join ' ) , metadata = self.metadata schema , table , view , function , column , keyword , datatype , alias , name_join , \ ( 'public ' , 'users ' , 'id ' , 'custom ' , 'shipments ' , 'user_id ' ) 'projects ' : [ 'projectid ' , 'name ' ] schemas = set ( sch for schs in self.metadata.values ( ) for sch in schs ) for view , cols in tbls.items ( ) : comp.extend_datatypes ( datatypes ) from metadata import ( MetaData , alias , name_join , fk_join , join , keyword , Completion ( text= ' y.price = x.price ' , start_position=0 , display_meta='name join ' ) , Completion ( text='users users2 ON users2.parentid = users.id ' , start_position=0 , display_meta='join ' ) , 'users ' : [ 'id ' , 'phone_number ' ] , Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) , 'foreignkeys ' : { list ( map ( lambda x : Completion ( x , display_meta='keyword ' ) , completer.keywords ) ) ) ] ) 'tables ' : { comp.extend_columns ( columns , kind='views ' ) table , function , column , wildcard_expansion ) join ( ' '' Users '' ON `` Users '' .userid = users.id ' ) , return comp views.append ( ( 'public ' , view ) ) Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) name_join ( 'orders.email = users.email ' ) , comp.extend_columns ( view_cols , kind='views ' ) Completion ( text='orders ' , start_position=0 , display_meta='table ' ) , for schema , tbls in metadata [ 'tables ' ] .items ( ) : assert set ( result ) == set ( [ keyword ( 'SELECT ' , -3 ) ] ) Completion ( text= ' o ' , start_position=0 , display_meta='table alias ' ) ] ) assert set ( testdata.keywords ( ) ) == result 'Users ' : [ 'userid ' , 'username ' ] , expected = [ wildcard_expansion ( 'id , ordered_date , status ' ) ] tables.append ( ( schema , table ) ) Completion ( text='public ' , start_position=0 , display_meta='schema ' ) , Completion ( text= ' '' ABC '' ' , start_position=0 , display_meta='column ' ) , [ 'func3 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , [ 'set_returning_func ' , [ ' x ' ] , [ 'integer ' ] , [ ' o ' ] , assert set ( result ) == set ( testdata.columns ( 'set_returning_func ' , typ='functions ' ) ) 'keyword ' , 'datatype ' , 'table alias ' , 'name join ' , 'fk join ' , 'join ' ) ] Completion ( text= ' y.id = x.id ' , start_position=0 , display_meta='name join ' ) ] ) Completion ( text='public ' , start_position=0 , display_meta='schema ' ) , alias ( 'orders ' ) ] ) comp.extend_foreignkeys ( foreignkeys ) Completion ( text='phone_number ' , start_position=0 , display_meta='column ' ) ] ) Completion ( text='u2 ' , start_position=0 , display_meta='table alias ' ) , assert set ( result ) == set ( [ join ( 'users users2 ON users2.id = users.parentid ' ) , } cols = self.metadata [ typ ] [ schema ] [ parent ] assert completions.index ( column ) < completions.index ( keyword ) Completion ( text='custom_type1 ' , start_position=0 , display_meta='datatype ' ) , Completion ( text='last_name ' , start_position=0 , display_meta='column ' ) , assert ( column ( 'id ' ) in [ 'func2 ' , [ ] , [ ] , [ ] , `` , False , False , datatypes = [ ( schema , datatype ) } } , col = column ( 'status ' , -1 ) testdata.columns ( 'set_returning_func ' , 'custom ' , 'functions ' ) ) Completion ( text='parentid ' , start_position=0 , display_meta='column ' ) , alias ( 'shipments ' ) , Completion ( text='u2.username = `` Users '' .username ' , start_position=0 , display_meta='name join ' ) , Completion ( text= ' x = f2.x ' , start_position=0 , display_meta='name join ' ) , for schema , funcs in metadata [ 'functions ' ] .items ( ) [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] if typ == 'functions ' : name_join ( 'u2.username = `` Users '' .username ' ) , views , columns = [ ] , [ ] 'public ' : { alias ( 'users ' ) ] tables , columns = [ ] , [ ] 'views ' : { assert set ( result ) == set ( testdata.schemas ( ) + testdata.functions ( ) + testdata.tables ( ) ) False ] , 'shipments ' : [ 'id ' , 'address ' , 'user_id ' ] for schema , datatypes in metadata [ 'datatypes ' ] .items ( ) Completion ( text='custom_func2 ' , start_position=-2 , display_meta='function ' ) , 'public ' : [ testdata.tables ( ) + list ( testdata.builtin_datatypes ( ) ) ) # def schema ( text , pos=0 ) : ( 'public ' , 'users ' , 'id ' , 'custom ' , 'shipments ' , 'user_id ' ) 'products ' : [ 'id ' , 'product_name ' , 'price ' ] , expected = [ Completion ( text='id , ordered_date , status ' , start_position=-1 , expected = join ( 'users ON users.id = u.userid ' , -len ( last_word ) ) Completion ( text='func3 ' , start_position=start_pos , display_meta='function ' ) , assert set ( result ) == set ( [ Completion ( text='SELECT ' , start_position=-3 , 'users ' : [ 'id ' , 'parentid ' , 'email ' , 'first_name ' , 'last_name ' ] , testdata.tables ( 'custom ' ) ) comp.set_search_path ( [ 'public ' ] ) return [ keyword ( kw , pos ) for kw in self.completer.keywords ] Completion ( text= ' '' Custom '' ' , start_position=0 , display_meta='schema ' ) , cols = fun [ 1 ] expected = [ wildcard_expansion ( expected ) ] Completion ( text=ref , start_position=0 , display_meta='table alias ' ) ] ) 'Users ' : [ 'userid ' , 'username ' ] , Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) , fk_join ( 'shipments.user_id = users.id ' ) ] ) 'custom ' : [ 'typ3 ' , 'typ4 ' ] , assert set ( result ) == set ( testdata.columns ( 'users ' ) ) comp.extend_columns ( columns , kind='tables ' ) } , Completion ( text= ' o.id = u.id ' , start_position=0 , display_meta='name join ' ) , Completion ( text='shipments.id = users.id ' , start_position=0 , display_meta='name join ' ) , 'public ' : { assert set ( result ) == set ( testdata.schemas ( ) + testdata.datatypes ( ) Completion ( text= ' '' Users '' ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='first_name ' , start_position=0 , display_meta='column ' ) , schemata.append ( schema ) [ 'custom_func1 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , functions = [ FunctionMetadata ( schema , * func_meta ) Completion ( text='custom_func1 ' , start_position=0 , display_meta='function ' ) , Completion ( text='last_name ' , start_position=0 , display_meta='column ' ) ] ) # functions name_join ( 'u2.userid = `` Users '' .userid ' ) , assert set ( map ( lambda x : Completion ( x , display_meta='keyword ' ) , # The code below is quivalent to 'custom ' : { assert set ( result ) == set ( testdata.columns ( 'users ' , 'custom ' ) ) [ ' o ' , ' o ' ] , `` , False , False , True ] ] , [ ' o ' , ' o ' ] , `` , False , False , True ] ] , import pgcli.pgcompleter as pgcompleter Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] ) Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) , [ 'custom_func2 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , comp.extend_schemata ( schemata ) comp.extend_relations ( tables , kind='tables ' ) Completion ( text= ' '' Users '' ' , start_position=start_pos , display_meta='table ' ) , name_join ( ' y.id = x.id ' ) ] ) assert set ( result ) == set ( testdata.columns ( 'select ' ) ) return Completion ( cols , start_position=pos , display_meta='columns ' , for schema , datatypes in metadata [ 'datatypes ' ] .items ( ) Completion ( text='username ' , start_position=0 , display_meta='column ' ) ] ) assert set ( result ) == set ( testdata.schemas ( ) view_cols.extend ( [ ( schema , view , col , 'text ' ) for col in cols ] ) } testdata.views ( ) + testdata.tables ( ) + testdata.functions ( ) ) assert set ( result ) == set ( testdata.columns ( 'products ' , 'custom ' ) ) def keywords ( self , pos=0 ) : 'integer ' , False , False , True ] ] , # Let all columns be text columns for fk in fks ] 'Custom ' : { functions = [ FunctionMetadata ( schema , * func_meta ) foreignkeys = [ ForeignKey ( * fk ) for fk in metadata [ 'foreignkeys ' ] ] users = Completion ( text='users ' , start_position=0 , display_meta='table ' ) 'users ' : [ 'id ' , 'phone_number ' ] , def __init__ ( self , metadata ) : 'functions ' : [ Completion ( text= ' y ' , start_position=0 , display_meta='table alias ' ) ] ) from prompt_toolkit.completion import Completion for x in self.metadata.get ( 'tables ' , { } ) .get ( schema , [ ] ) ] Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) , start_position=-len ( last_word ) , display_meta='join ' ) testdata.columns ( 'set_returning_func ' , typ='functions ' ) ) assert set ( result ) == set ( testdata.columns ( 'products ' , 'custom ' ) + testdata.functions ( ) Completion ( text= ' x ' , start_position=0 , display_meta='table alias ' ) , from metadata import ( MetaData , alias , name_join , fk_join , join , Completion ( text='u2.userid = u.id ' , start_position=0 , display_meta='fk join ' ) , else : 'users ' : [ 'id ' , 'parentid ' , 'email ' , 'first_name ' , 'last_name ' ] , testdata.keywords ( ) ) ) 'custom ' : [ 'typ3 ' , 'typ4 ' ] , for datatype in datatypes ] name_join ( ' y.product_name = x.product_name ' ) , 'user_emails ' : [ 'id ' , 'email ' ] } , columns.extend ( [ ( schema , table , col , 'text ' ) for col in cols ] ) Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) ] function ( 'set_returning_func ' , -len ( 'func ' ) ) ] ) Completion ( text= ' u ' , start_position=0 , display_meta='table alias ' ) , foreignkeys = [ ForeignKey ( * fk ) for fks in metadata [ 'foreignkeys ' ] .values ( ) comp.extend_relations ( views , kind='views ' ) display = ' * ' ) for func_meta in funcs ] for table , cols in metadata [ 'tables ' ] .items ( ) : assert set ( result ) == set ( testdata.columns ( 'select ' ) + [ def completer ( self ) : list ( map ( lambda f : Completion ( f , display_meta='datatype ' ) , completer.datatypes ) ) ) Completion ( text= ' y.product_name = x.product_name ' , start_position=0 , display_meta='name join ' ) , for table , cols in tbls.items ( ) : expected = [ Completion ( text=col_list , start_position=-1 , 'shipments ' : [ 'id ' , 'address ' , 'user_id ' ] Completion ( text='products ' , display_meta='table ' ) , Completion ( text='users users2 ON users2.id = users.parentid ' , start_position=0 , display_meta='join ' ) , assert set ( result ) == set ( testdata.functions ( 'Custom ' , start_pos ) assert set ( result ) == set ( ( 'public ' , 'users ' , 'id ' , 'public ' , 'Users ' , 'userid ' ) 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , Completion ( text='product_name ' , start_position=0 , display_meta='column ' ) , Completion ( text='users ' , start_position=0 , display_meta='table ' ) , Completion ( text='set_returning_func ' , start_position=-len ( 'func ' ) , display_meta='function ' ) ] ) list ( map ( lambda x : Completion ( x , display_meta='keyword ' ) , completer.keywords ) ) list ( map ( lambda f : Completion ( f , display_meta='function ' ) , completer.functions ) ) 'Custom ' : [ alias ( ' '' Users '' ' ) , ] , name_join ( ' x = f2.x ' ) , orders = table ( 'orders ' ) Completion ( text='func4 ' , start_position=start_pos , display_meta='function ' ) , list ( testdata.builtin_functions ( ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] } , def completion ( display_meta , text , pos=0 ) : name_join ( ' y = f2.y ' ) , Completion ( text= ' '' Users '' ' , display_meta='table ' ) , Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] Completion ( text='userid ' , start_position=0 , display_meta='column ' ) , def wildcard_expansion ( cols , pos=-1 ) : 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] 'functions ' : { alias ( ' u ' ) , for schema , tbls in metadata.get ( 'views ' , { } ) .items ( ) : Completion ( text='custom_func1 ' , start_position=0 , display_meta='function ' ) ] ) assert set ( result ) == set ( testdata.columns ( 'Users ' ) ) keyword = Completion ( text='SELECT ' , start_position=-1 , display_meta='keyword ' ) [ 'func1 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , Completion ( text='custom_func2 ' , start_position=-2 , display_meta='function ' ) ] ) 'foreignkeys ' : [ 'views ' : { Completion ( text='price ' , start_position=0 , display_meta='column ' ) , return Completion ( text , start_position=pos , comp.extend_relations ( views , kind='views ' ) 'integer ' , False , False , True ] ] , Completion ( text='shipments ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='orders ' , start_position=0 , display_meta='table ' ) ] ) completer.keywords ) ) == result ( 'public ' , 'users ' , 'id ' , 'public ' , 'Users ' , 'userid ' ) Completion ( text= ' '' Users '' ON `` Users '' .userid = users.id ' , start_position=0 , display_meta='join ' ) , assert set ( result ) == set ( [ function ( 'MAX ' , -2 ) , comp.extend_foreignkeys ( foreignkeys ) display_meta=display_meta ) column = Completion ( text='status ' , start_position=-1 , display_meta='column ' ) comp = pgcompleter.PGCompleter ( smart_completion=True ) Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] [ 'set_returning_func ' , [ ' x ' , ' y ' ] , [ 'integer ' , 'integer ' ] , Completion ( text='u2.userid = `` Users '' .userid ' , start_position=0 , display_meta='name join ' ) , tables.append ( ( schema , table ) ) Completion ( text='custom ' , start_position=0 , display_meta='schema ' ) , # return completion ( 'schema ' , text , pos ) name_join ( 'orders.id = users.id ' ) , return [ column ( escape ( col ) , pos ) for col in cols ] 'projects ' : [ 'projectid ' , 'name ' ] expected = [ wildcard_expansion ( cols ) ] Completion ( text='orders ' , start_position=0 , display_meta='table alias ' ) ] ) return [ datatype ( dt , pos ) for dt in self.completer.datatypes ] orders = Completion ( text='orders ' , start_position=0 , display_meta='table ' ) assert set ( result ) == set ( [ Completion ( text='MAX ' , start_position=-2 , display_meta='function ' ) , assert set ( result ) == set ( testdata.columns ( 'products ' , 'custom ' ) [ 'set_returning_func ' , [ ' x ' ] , [ 'integer ' ] , [ ' o ' ] , for x in self.metadata.get ( 'functions ' , { } ) .get ( schema , [ ] ) ] views.append ( ( schema , view ) ) Completion ( text='users ' , display_meta='table ' ) , 'public ' : [ display= ' * ' , display_meta='columns ' ) ] Completion ( text='MAXEXTENTS ' , start_position=-2 , display_meta='keyword ' ) , Completion ( text='typ4 ' , display_meta='datatype ' ) , Completion ( text='set_returning_func ' , start_position=start_pos , display_meta='function ' ) , def datatypes ( self , schema='public ' , pos=0 ) : fk_join , join = [ partial ( completion , display_meta ) return [ table ( escape ( x ) , pos ) assert ( Completion ( text='id ' , start_position=0 , display_meta='column ' ) in expected = [ wildcard_expansion ( col_list ) ] Completion ( text='users ' , start_position=0 , display_meta='table alias ' ) , return [ function ( escape ( x [ 0 ] ) , pos ) Completion ( text='id ' , start_position=0 , display_meta='column ' ) , column ( 'id ' ) , Completion ( text= ' '' insert '' ' , start_position=0 , display_meta='column ' ) , 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' , 'email ' ] , testdata.functions ( ) ) ] + testdata.functions ( ) ) } } , return comp 'user_emails ' : [ 'id ' , 'email ' ] } , [ 'func3 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , Completion ( text= ' y = f2.y ' , start_position=0 , display_meta='name join ' ) , # tables } , ] + testdata.functions ( ) def views ( self , schema='public ' , pos=0 ) : name_join ( ' o.id = u.id ' ) , ] + testdata.columns ( 'set_returning_func ' , typ='functions ' ) ) Completion ( text='custom_func1 ' , start_position=-2 , display_meta='function ' ) , Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) keyword ( 'MAXEXTENTS ' , -2 ) , 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) , schemata.append ( schema ) def columns ( self , parent , schema='public ' , typ='tables ' , pos=0 ) : Completion ( text='users ' , start_position=start_pos , display_meta='table ' ) , assert set ( result ) == set ( testdata.columns ( 'Users ' , 'custom ' ) ) Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) ] ) ] ) for x in self.metadata.get ( 'views ' , { } ) .get ( schema , [ ] ) ] self.metadata = metadata schemata , tables , columns = [ ] , [ ] , [ ] return [ datatype ( escape ( x ) , pos ) comp.set_search_path ( [ 'public ' ] ) for func_meta in metadata [ 'functions ' ] ] Completion ( text='func3 ' , start_position=-len ( 'func ' ) , display_meta='function ' ) , 'Users ' : [ 'userid ' , 'username ' ] , Completion ( text='u2.userid = u.id ' , start_position=0 , display_meta='fk join ' ) ] ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] comp.extend_functions ( functions ) users = table ( 'users ' ) def builtin_functions ( self , pos=0 ) : Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) , function ( 'func3 ' , -len ( 'func ' ) ) , Completion ( text='products ' , start_position=start_pos , display_meta='table ' ) , [ 'func1 ' , [ ] , [ ] , [ ] , `` , False , False , ( 'public ' , 'users ' , 'id ' , 'public ' , 'users ' , 'parentid ' ) , False ] , list ( map ( lambda f : Completion ( f , display_meta='function ' ) , completer.functions ) ) Completion ( text= ' y ' , start_position=0 , display_meta='table alias ' ) , function ( 'custom_func2 ' , -2 ) , list ( testdata.builtin_functions ( ) Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) , testdata.keywords ( ) ) Completion ( text='shipments ' , start_position=start_pos , display_meta='table ' ) , assert set ( result ) == set ( [ alias ( 'users ' ) , alias ( ref ) ] ) 'Custom ' : { expected = Completion ( text= ' '' select '' ' , start_position=-5 , display_meta='table ' ) Completion ( text='email ' , start_position=0 , display_meta='column ' ) , for schema , tbls in metadata [ 'tables ' ] .items ( ) : 'products ' : [ 'id ' , 'product_name ' , 'price ' ] , Completion ( text='users ' , start_position=0 , display_meta='table alias ' ) ] 'foreignkeys ' : [ 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' , 'email ' ] , 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , Completion ( text='shipments ' , display_meta='table ' ) , alias ( ' x ' ) , Completion ( text='user_emails ' , start_position=0 , display_meta='view ' ) , Completion ( text='u2.userid = users.id ' , start_position=0 , display_meta='fk join ' ) , # fks","['tests/metadata.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 529 from dbcli/koljonen/simplify_smart_completion_tests
303,fc31362f0ee2e1ef807408c53d6a0cce478b6240,2016-06-19 20:35:29-07:00,"'DEBUG ' : logging.DEBUG print ( 'Version : ' , __version__ ) handler = logging.FileHandler ( os.path.expanduser ( log_file ) ) less_chatty = False # Disable logging if value is NONE by switching to a no-op handler . print ( 'Goodbye ! ' ) if not self.less_chatty : # and `` DEBUG '' . `` NONE '' disables logging . handler = logging.FileHandler ( os.path.expanduser ( log_file ) ) self.less_chatty = c [ 'main ' ] .as_bool ( 'less_chatty ' ) print ( 'Home : http : //pgcli.com ' ) 'DEBUG ' : logging.DEBUG , def emit ( self , record ) : if not self.less_chatty : print ( 'Home : http : //pgcli.com ' ) # no-op logging handler print ( 'Goodbye ! ' ) print ( 'Version : ' , __version__ ) handler = NullHandler ( ) print ( 'Mail : https : //groups.google.com/forum/ # ! forum/pgcli ' ) print ( 'Mail : https : //groups.google.com/forum/ # ! forum/pgcli ' ) pass class NullHandler ( logging.Handler ) : if log_level.upper ( ) == 'NONE ' : 'NONE ' : logging.CRITICAL # Set log level to a high value so it does n't even waste cycles getting called . print ( 'Chat : https : //gitter.im/dbcli/pgcli ' ) # Skip intro on startup and goodbye on exit print ( 'Chat : https : //gitter.im/dbcli/pgcli ' ) # and `` DEBUG '' . else :","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 530 from dbcli/feature/j-bennet/less-chatty
304,7ce6df95ab9a6aeab8e3d0c268568063624849b3,2016-06-16 18:15:39-04:00,"CROSS JOIN `` Users '' if _allow_join_condition_suggestion ( parsed_statement ) : conds.append ( ( cond , 'fk join ' , prio ) ) d [ pair [ 0 ] ] .append ( pair [ 1 ] ) Completion ( text= ' u ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='u2.userid = `` Users '' .userid ' , start_position=0 , display_meta='name join ' ) , except IndexError : # The user typed an incorrect table qualifier if cond not in found_conds : Completion ( text='u2.userid = users.id ' , start_position=0 , display_meta='fk join ' ) , def _allow_join ( statement ) : for t in scoped_cols.keys ( ) : def _allow_join_condition ( statement ) : 'integer ' , 'bigint ' , 'smallint ' ) ' '' coldict = list_dict ( ( ( t.schema , t.name , c.name ) , t ) complete_event ) ) if rtbl and rtbl.ref ! = lefttable.ref : complete_event ) found = set ( cnd [ 0 ] for cnd in conds ) lref = ( suggestion.parent or suggestion.tables [ -1 ] ) .ref fks = ( ( fk , lcol.name ) for lcol in lcols for fk in lcol.foreignkeys ) ( 'SELECT * FROM users JOIN nontable nt on ' , 'nt ' ) for pair in pairs : if rtbl.ref ! = lefttable.ref : def test_suggested_column_names_from_shadowed_visible_table ( completer , complete_event , text ) : def list_dict ( pairs ) : # Turns [ ( a , b ) , ( a , c ) ] into { a : [ b , c ] } def add_cond ( lcol , rcol , rref , meta , prio ) : JOIN `` Users '' u2 ON refprio = dict ( ( tbl.ref , num ) for num , tbl assert result == [ col = namedtuple ( 'col ' , 'schema tbl col ' ) prio = 2000 + refprio [ rtbl.ref ] conds.append ( ( cond , meta , prio + ref_prio [ rref ] ) ) conds , found_conds = [ ] , set ( ) conds = [ ] Document ( text=text , cursor_position=position ) , scoped_cols = self.populate_scoped_cols ( suggestion.tables ) def _allow_join_condition_suggestion ( statement ) : def test_suggested_column_names_from_shadowed_visible_table ( completer , complete_event , table ) : Completion ( text='users ' , start_position=0 , display_meta='table alias ' ) ] for fk , lcol in fks : if filteredtables and _allow_join_condition ( parsed_statement ) : try : for t , c in cols if t.ref ! = lref ) aliases = tuple ( t.ref for t in tables ) prio = ( 1000 if c.datatype and c.datatype in ( ' '' SELECT * and _allow_join_suggestion ( parsed_statement ) ) : Completion ( text='users ' , start_position=0 , display_meta='table alias ' ) , lefttable = suggestion.parent or suggestion.tables [ -1 ] aliases = tuple ( t.alias or t.name for t in tables ) def test_suggested_join_conditions_with_same_table_twice ( completer , complete_event , text ) : ' '' users '' ' , return [ ] conds.append ( ( cond , 'name join ' , prio ) ) for rtbl in ( t for t in col_table [ c ] if t.ref ! = ltbl.ref ) : for c in ( coltyp ( c.name , c.datatype ) for c in lcols ) : position = len ( text ) text = 'SELECT FROM ' + table tbls = self.populate_scoped_cols ( suggestion.tables ) .items for c in refcols.get ( lefttable.ref , [ ] ) : 'users ' , ( 'SELECT * FROM users JOIN NonTable on ' , 'NonTable ' ) , col_table [ ( col.name , col.datatype ) ] .append ( tbl ) ltbl , lcols = [ ( t , cs ) for ( t , cs ) in tbls ( ) if t.ref == lref ] [ -1 ] 'SELECT FROM `` users '' ' , FROM users else 0 + refprio [ rtbl.ref ] ) col_table = list_dict ( ( coltyp ( c.name , c.datatype ) , t ) for t , c in cols ) if not conds : cond = make_cond ( lefttable.ref , rtbl.ref , c.name , c.name ) assert set ( result ) == set ( [ 'SELECT * FROM users JOIN users u2 on foo . ' prefix = `` if suggestion.parent else tbl1 + ' . ' cond = make_cond ( lefttable.ref , rtbl.ref , if cond not in found : tbldict = defaultdict ( list ) ] ) def test_suggested_join_conditions_with_invalid_table ( completer , complete_event , text , ref ) : for tbl , col in ( ( t , c ) for t , cs in scoped_cols.items ( ) for c in cs ) : result = completer.get_completions ( # Map ( schema , tablename ) to tables and ref to columns for rcol in ( ( fk.parentschema , fk.parenttable , ref_prio = dict ( ( tbl.ref , num ) for num , tbl Completion ( text='u2.userid = u.id ' , start_position=0 , display_meta='fk join ' ) , coltyp = namedtuple ( 'coltyp ' , 'name datatype ' ) conds , metas , prios = zip ( * conds ) if conds else ( [ ] , [ ] , [ ] ) 'SELECT FROM users ' , for rtbl in coldict [ right ] : left = col ( ltbl.schema , ltbl.name , lcol ) result = set ( completer.get_completions ( Completion ( text='u2 ' , start_position=0 , display_meta='table alias ' ) , if c.datatype in ( 'integer ' , 'bigint ' , 'smallint ' ) else 0 ) add_cond ( left.col , right.col , rtbl.ref , 'fk join ' , 2000 ) if _allow_join_condition ( parsed_statement ) : return d return prefix + case ( col1 ) + ' = ' + tbl2 + ' . ' + case ( col2 ) lcol.name , rcol [ 2 ] ) Completion ( text='u2.username = `` Users '' .username ' , start_position=0 , display_meta='name join ' ) , tbldict [ ( t.schema , t.name ) ] .append ( t ) def test_suggested_join_conditions_with_invalid_qualifier ( completer , complete_event , text ) : d = defaultdict ( list ) par = col ( fk.parentschema , fk.parenttable , fk.parentcolumn ) refcols = dict ( ( t.ref , cs ) for t , cs in scoped_cols.items ( ) ) fk.childcolumn ) ) : assert set ( result ) == set ( ) NATURAL JOIN users u # Map ( schema , table , col ) to tables col_table = defaultdict ( lambda : [ ] ) for rtbl in col_table [ ( c.name , c.datatype ) ] : for rtbl in tbldict [ ( rcol [ 0 ] , rcol [ 1 ] ) ] : left , right = ( child , par ) if left == child else ( par , child ) def _allow_join_suggestion ( statement ) : cond = prefix + case ( lcol ) + ' = ' + rref + ' . ' + case ( rcol ) cols = [ ( t , c ) for t , cs in tbls ( ) for c in cs ] fk.parentcolumn ) , ( fk.childschema , fk.childtable , return [ ] found_conds.add ( cond ) for fk in lcol.foreignkeys : and _allow_join ( parsed_statement ) ) : Completion ( text=ref , start_position=0 , display_meta='table alias ' ) ] ) Completion ( text= ' '' Users '' ' , start_position=0 , display_meta='table alias ' ) , child = col ( fk.childschema , fk.childtable , fk.childcolumn ) conds , metas , prios = zip ( * conds ) @ pytest.mark.parametrize ( 'text ' , [ add_cond ( c.name , c.name , rtbl.ref , 'name join ' , 1000 for lcol in refcols.get ( lefttable.ref , [ ] ) : prefix = `` if suggestion.parent else ltbl.ref + ' . ' def make_cond ( tbl1 , tbl2 , col1 , col2 ) :","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 528 from dbcli/koljonen/join_condition_fixes
305,9e98896bb3557b9a3cd21b4d8369d5427b66b770,2016-06-16 08:18:01-04:00,"# fks Completion ( text= ' u ' , start_position=0 , display_meta='table alias ' ) , 'SELECT * FROM foo JOIN bar USING ( barid ) JOIN ' right = col ( rtbl.schema , rtbl.name , rcol.name ) FROM { 0 } 'SELECT * FROM public . { 0 } RIGHT OUTER JOIN ' , fks = ( ( fk , rtbl , rcol ) for rtbl , rcols in cols.items ( ) def _allow_join_suggestion ( statement ) : last_word = text.split ( ) [ -1 ] Schema ( ) , Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) , `` `` '' and last_tok.value.lower ( ) not in ( 'cross join ' , 'natural join ' ) ) return False if name and not name_quoted and not name.islower ( ) : ' u.id , u.parentid , u.email , u.first_name , u.last_name ' ) def test_simple_select_single_table_schema_qualified_quoted_table ( sql ) : Join ( ( ( None , 'foo ' , None , False ) , ) , 'sch ' ) , 'foreignkeys ' : [ result = set ( completer.get_completions ( # Set up some data structures for efficient access Function ( schema=None ) , ] , tbls - set of table refs already in use , normalized with normalize_ref result = completer.get_completions ( Completion ( text='shipments.user_id = users.id ' , start_position=0 , display_meta='fk join ' ) ] ) ) , ( 'users ' , ' '' users '' ' , 'Users ' ) ) ) join = left.schema + ' . ' + join JOIN `` ' parent = col ( fk.parentschema , fk.parenttable , fk.parentcolumn ) ' '' return tuple ( i for i in identifiers if i.name ) We need this to avoid bad suggestions when entering e.g . complete_event ) ) complete_event ) FULL OUTER JOIN `` Users '' u2 ON Table ( schema='sch ' ) , Column ( tables= ( ( None , 'tabl ' , ' '' tabl '' ' , False ) , ) ) , # Schema-qualify if ( 1 ) new table in same schema as old , and old 'id , Users.email , Users.first_name , Users.last_name ' ) , Schema ( ) complete_event ) ) View ( schema='sch ' ) , LEFT JOIN `` ' 'SELECT * FROM `` Users '' u JOIN u ' , select * from tbl1 a join tbl2 b < cursor > else ' '' ' + self.name + ' '' ' ) ) Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) ] ) def test_suggested_join_conditions ( completer , complete_event , text ) : Join : get_join_matches , return next ( a for a in aliases if normalize_ref ( a ) not in tbls ) left = child if parent == right else parent 'SELECT * FROM USERS u right JOIN `` Users '' u2 ON ' , aliases = ( ' '' ' + tbl [ 1 : -1 ] + str ( i ) + ' '' ' for i in itertools.count ( 2 ) ) text = query.format ( tbl ) ref_prio = dict ( ( normalize_ref ( t.ref ) , n ) for n , t in enumerate ( tbls ) ) Completion ( text='orders ' , start_position=0 , display_meta='table ' ) , or left.schema not in ( right.schema , 'public ' ) ) : def test_suggest_qualified_tables_views_and_functions ( expression ) : def test_suggested_joins ( completer , complete_event , text ) : Join ( ( ( None , 'foo ' , None , False ) , ( None , 'bar ' , None , False ) ) , None ) , lref = self.generate_alias ( left.tbl , refs ) Function , Datatype , Alias , JoinCondition , Join ) 'select * from abc . `` def '' ' , 0 if ( left.schema , left.tbl ) in other_tbls else 1 ) ) from pgcli.packages.function_metadata import FunctionMetadata tables = extract_tables ( sql ) 'id , users.email , users.first_name , users.last_name ' ) , def test_extract_no_tables ( text ) : 'id , users.parentid , users.email , users.first_name , users.last_name ' ) , : return : boolean and left.schema == right.schema position = len ( 'SELECT * FROM ' ) 'SELECT * FROM foo JOIN bar ' col = namedtuple ( 'col ' , 'schema tbl col ' ) tables = extract_tables ( text_before_cursor ) def test_where_suggests_columns_functions_quoted_table ( expression ) : ( 'public ' , 'users ' , 'id ' , 'public ' , 'Users ' , 'userid ' ) So check that the preceding token is a JOIN keyword Completion ( text= ' '' Users '' ON `` Users '' .userid = users.id ' , start_position=0 , display_meta='join ' ) , TableReference.ref = property ( lambda self : self.alias or ( Document ( text=text , cursor_position=position ) , Document ( text=text , cursor_position=position ) , join = ' { 0 } ON { 0 } . { 1 } = { 2 } . { 3 } '.format ( if name and not name_quoted and name ! = name.lower ( ) : if not statement or not statement.tokens : # Joins are suggested after JOIN , e.g . 'foo ON foo.barid = bar.barid ' def test_suggested_joins_quoted_schema_qualified_table ( completer , complete_event , text ) : 'SELECT * FROM `` tabl '' WHERE ' , Table ( schema=None ) , from pgcli.packages.function_metadata import FunctionMetadata , ForeignKey 'id , Users.parentid , Users.email , Users.first_name , Users.last_name ' ) , 'SELECT * FROM users natural join ' cols = self.populate_scoped_cols ( tbls ) 'SELECT * FROM users u LEFT JOIN `` Users '' u2 ON ' , `` `` '' Generate a unique table alias Completion ( text='shipments.id = users.id ' , start_position=0 , display_meta='name join ' ) , if alias_quoted or name_quoted and not alias and name.islower ( ) : parsed = sqlparse.parse ( import itertools suggest.append ( Join ( tables=tables , schema=schema ) ) ' '' SELECT * def test_suggest_after_join_with_two_tables ( expression ) : priority_collection=prios , type_priority=100 ) parsed = sqlparse.parse ( text_before_cursor ) return ( last_tok.value.lower ( ) .endswith ( 'join ' ) Completion ( text='users ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='users users2 ON users2.parentid = users.id ' , start_position=0 , display_meta='join ' ) , alias_quoted = alias and item.value [ -1 ] == ' '' ' 'select * from `` abc '' . `` def '' ' , refs = set ( normalize_ref ( t.ref ) for t in tbls ) def test_suggested_joins ( completer , complete_event , query , tbl ) : def test_suggest_after_join_with_one_table ( expression ) : assert set ( suggestions ) == set ( [ col_list = 'id , parentid , email , first_name , last_name ' tbls = suggestion.tables : param statement : an sqlparse.sql.Statement self.name if self.name.islower ( ) or self.name [ 0 ] == ' '' ' Completion ( text='public ' , start_position=0 , display_meta='schema ' ) , FROM users u return suggest_special ( text_before_cursor ) complete_event ) Completion ( text='users users2 ON users2.id = users.parentid ' , start_position=0 , display_meta='join ' ) , 'SELECT * FROM public . `` Users '' JOIN ' , def test_table_names_after_from ( completer , complete_event , text ) : joins , prios = [ ] , [ ] position = len ( text ) 'SELECT * FROM `` Users '' u JOIN id ' , def test_suggest_qualified_tables_views_and_set_returning_functions ( expression ) : INNER JOIN `` ' Completion ( text='users ' , start_position=0 , display_meta='table ' ) , def get_join_matches ( self , suggestion , word_before_cursor ) : def test_table_names_after_from_are_lexical_ordered_by_text ( completer , complete_event ) : 'SELECT * FROM users JOIN ' , text_before_cursor = text_before_cursor [ : -len ( word_before_cursor ) ] FROM public . `` Users '' tbl - name of the table to alias , quoted if it needs to be `` `` '' normalize_ref = lambda ref : ref if ref [ 0 ] == ' '' ' else ' '' ' + ref.lower ( ) + ' '' ' ( 'public ' , 'users ' , 'id ' , 'public ' , 'users ' , 'parentid ' ) , FROM users 'SELECT * FROM `` tabl '' WHERE ' , join = ' { 0 } { 4 } ON { 4 } . { 1 } = { 2 } . { 3 } '.format ( col_list = 'id , u.email , u.first_name , u.last_name ' JOIN custom.shipments ON `` ' assert set ( result ) == set ( [ View ( schema=None ) , 'select * from `` abc '' . `` def '' ' , text_before_cursor_including_last_word = text_before_cursor Completion ( text= ' '' Custom '' ' , start_position=0 , display_meta='schema ' ) , Completion ( text='u2.userid = u.id ' , start_position=0 , display_meta='fk join ' ) ] ) Completion ( text='custom_func1 ' , start_position=0 , display_meta='function ' ) ] ) # In the case 'sche. < cursor > ' , we get an empty TableReference ; remove that Completion ( text='shipments ' , start_position=0 , display_meta='table alias ' ) , if _allow_join_suggestion ( parsed_statement ) : ] ) for rcol in rcols for fk in rcol.foreignkeys ) if normalize_ref ( left.tbl ) in refs : return tuple ( identifiers ) col_list = 'id , email , first_name , last_name ' result = completer.get_completions ( c = self.case else : # JoinConditions are suggested after ON , e.g . 'foo.barid = bar.barid ' 'SELECT * FROM users u INNER join `` Users '' u2 ON ' , Keyword ( ) , Completion ( text='parentid ' , start_position=0 , display_meta='column ' ) , text = 'SELECT * FROM ' 'SELECT * FROM `` Users '' u JOIN userid ' , Function ( schema='sch ' , filter='for_from_clause ' ) , ] ) Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) , join = 'custom.shipments ON shipments.user_id = { 0 } .id'.format ( tbl ) c ( left.tbl ) , c ( left.col ) , rtbl.ref , c ( right.col ) ) 'SELECT * FROM users u right outer join `` Users '' u2 ON ' , def test_suggested_joins_fuzzy ( completer , complete_event , text ) : other_tbls = set ( ( t.schema , t.name ) if _allow_join_condition_suggestion ( parsed_statement ) : Keyword , NamedQuery , Datatype , Alias , Path , JoinCondition ) def _allow_join_condition_suggestion ( statement ) : Join ( ( ( None , 'abc ' , tbl_alias if tbl_alias else None , False ) , ) , None ) , 'SELECT * FROM users u FULL OUTER JOIN `` Users '' u2 ON ' , text_before_cursor [ : -len ( word_before_cursor ) ] ) if ( token_v.endswith ( 'join ' ) and token.is_keyword else : assert tables == tuple ( ) def test_suggest_tables_views_schemas_and_set_returning_functions ( expression ) : result = set ( completer.get_completions ( joins.append ( join ) aliases = ( self.case ( tbl ) + str ( i ) for i in itertools.count ( 2 ) ) ( 'public ' , 'users ' , 'id ' , 'custom ' , 'shipments ' , 'user_id ' ) 'SELECT * FROM users u JOIN `` Users '' u2 ON ' , suggestions = suggest_type ( expression , expression ) if suggestion.schema and left.schema ! = suggestion.schema : last_tok = statement.token_prev ( len ( statement.tokens ) ) and _allow_join_suggestion ( parsed_statement ) ) : Completion ( text='u2 ' , start_position=0 , display_meta='table alias ' ) , 'SELECT * FROM Users u FULL JOIN `` Users '' u2 ON ' , Completion ( text=join , start_position=0 , display_meta='join ' ) , Completion ( text= ' '' Users '' ' , start_position=0 , display_meta='table ' ) , # Iterate over FKs in existing tables to find potential joins 'SELECT * FROM users CROSS JOIN ' , col_list = 'id , u.parentid , u.email , u.first_name , u.last_name ' Join ( ( ( None , 'foo ' , None , False ) , ) , None ) , Completion ( text='public.users ON users.id = `` Users '' .userid ' , start_position=0 , display_meta='join ' ) , alias = ' '' ' + ( alias or name ) + ' '' ' Completion ( text='custom ' , start_position=0 , display_meta='schema ' ) , # is schema-qualified , or ( 2 ) new in other schema , except public Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) , 'SELECT * FROM ' , start_position=-len ( last_word ) , display_meta='join ' ) expected = Completion ( text='users ON users.id = u.userid ' , return suggest_special ( text_before_cursor_including_last_word ) 'SELECT * FROM `` Users '' u JOIN uid ' , 'SELECT * FROM public . `` Users '' RIGHT OUTER JOIN ' , 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , if tbl [ 0 ] == ' '' ' : 'SELECT * FROM users JOIN custom.shipments ON ' , qualified = dict ( ( normalize_ref ( t.ref ) , t.schema ) for t in tbls ) def test_suggest_tables_views_schemas_and_functions ( expression ) : def generate_alias ( self , tbl , tbls ) : assert tables == ( ( 'abc ' , 'def ' , ' '' def '' ' , False ) , ) continue comp.extend_foreignkeys ( foreignkeys ) assert expected in result ' u.id , u.email , u.first_name , u.last_name ' ) for fk , rtbl , rcol in fks : Join = namedtuple ( 'Join ' , [ 'tables ' , 'schema ' ] ) 'SELECT * FROM foo JOIN bar on bar.barid = foo.barid JOIN ' , def _allow_join_suggestion ( statement ) : for t in list ( cols ) [ : -1 ] ) if not suggestion.schema and ( qualified [ normalize_ref ( rtbl.ref ) ] foreignkeys = [ ForeignKey ( * fk ) for fk in metadata [ 'foreignkeys ' ] ] FROM public.users prios.append ( ref_prio [ normalize_ref ( rtbl.ref ) ] * 2 + ( Function , Datatype , Alias , JoinCondition ) TableReference.ref = property ( lambda self : self.alias or self.name ) def test_table_names_after_from ( completer , complete_event ) : Completion ( text='func1 ' , start_position=0 , display_meta='function ' ) , Keyword , NamedQuery , Datatype , Alias , Path , JoinCondition , Join ) Function ( schema=None , filter='for_from_clause ' ) , child = col ( fk.childschema , fk.childtable , fk.childcolumn ) def test_suggest_qualified_tables_views_functions_and_joins ( expression ) : 'select * from abc . `` def '' ' , Tests if a join should be suggested 'SELECT * FROM Users u LEFT OUTER JOIN `` Users '' u2 ON ' , c ( left.tbl ) , c ( left.col ) , rtbl.ref , c ( right.col ) , lref ) tables = extract_tables ( text ) return self.find_matches ( word_before_cursor , joins , meta='join ' , 'users ' : [ 'id ' , 'parentid ' , 'email ' , 'first_name ' , 'last_name ' ] , Completion ( text='user_emails ' , start_position=0 , display_meta='view ' ) ,","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_parseutils.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 527 from dbcli/koljonen/suggest_joins
306,3029ca6f67460a53a0d3ea62c35dbaec10749fa9,2016-06-07 14:28:44-07:00,"suggestions = suggest_type ( sql , sql ) ] ) elif token_v == 'column ' : return ( Column ( tables=extract_tables ( text_before_cursor ) ) , ) 'ALTER TABLE foo ALTER COLUMN bar ' , # E.g . 'ALTER TABLE foo ALTER COLUMN bar Column ( tables= ( ( None , 'foo ' , None , False ) , ) ) , assert set ( suggestions ) == set ( [ 'ALTER TABLE foo ALTER COLUMN ' , 'ALTER TABLE foo DROP COLUMN bar ' , 'ALTER TABLE foo DROP COLUMN ' , ] ) def test_column_keyword_suggests_columns ( sql ) :","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 525 from dbcli/darikg/alter-column
307,7a93f649a7c4e5f3bdba7285a8c47a1854c323af,2016-06-07 14:28:04-07:00,pgspecial_logger.addHandler ( handler ) log_level = level_map [ log_level.upper ( ) ] pgspecial_logger = logging.getLogger ( 'pgspecial ' ) root_logger.setLevel ( level_map [ log_level.upper ( ) ] ) pgspecial_logger.setLevel ( log_level ) root_logger.setLevel ( log_level ),['pgcli/main.py'],Merge pull request # 524 from dbcli/darikg/pgspecial_logging
308,92cc469b7b49984026c15778e3045513cb1da202,2016-06-06 17:21:32-04:00,"'types ' , 'databases ' , 'casing ' ] FROM pg_catalog.pg_proc P WHERE L.lanname IN ( 'sql ' , 'plpgsql ' ) ) collist = sep.join ( self.case ( c ) for c in flat_cols ) with open ( casing_file , ' w ' ) as f : OrderWords AS ( for t , cs in colit ( ) for c in cs ) self.asterisk_column_order = ( settings or { } ) .get ( casing_file = config_location ( ) + 'casing ' casing_file = completer.casing_file generate_casing_file = False self.casing = dict ( ( word.lower ( ) , word ) for word in words ) FROM OrderWords self.casing_file = settings.get ( 'casing_file ' ) WHERE Word ~ * '. * [ a-z ] . * ' package_root = os.path.dirname ( package_root ) SELECT proname return UNION -- Function names SELECT typname settings = { 'asterisk_column_order ' : return prefix + col1 + ' = ' + tbl2 + ' . ' + col2 Names AS ( f.write ( casing_prefs ) SELECT Word ) , # casing_file location . collist = ' , '.join ( self.case ( c ) for c in flat_cols ) return casing_file settings - dict of settings for completer object `` `` '' extend casing data SELECT Word , settings = { 'casing_file ' : get_casing_file ( c ) , : return : item = self.case ( item ) 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , c = self.config = load_config ( pgclirc_file , default_config ) with self.conn.cursor ( ) as cur : def get_casing_file ( config ) : ) SELECT nspname 'generate_casing_file ' : c [ 'main ' ] .as_bool ( 'generate_casing_file ' ) , def case ( self , word ) : collist = sep.join ( c for c in flat_cols ) # In Unix/Linux : ~/.config/pgcli/casing collist = ' , '.join ( t.ref + ' . ' + c.name for t , cs in colit ( ) FROM Words from .config import ( load_config , config_location , ensure_dir_exists , get_config ) # % USERPROFILE % is typically C : \Users\ { username } for row in cur : AND N.nspname NOT IN ( 'pg_catalog ' , 'information_schema ' ) FROM pg_catalog.pg_class generate_casing_file = completer.generate_casing_file Column names with open ( casing_file , ' r ' ) as f : from .config import ( get_casing_file , collist = ' , '.join ( c for c in flat_cols ) 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] } JOIN pg_catalog.pg_namespace N ON N.oid = P.pronamespace FROM pg_catalog.pg_proc if not casing_file : if casing_file == 'default ' : # casing should be a dict { lowercasename : PreferredCasingName } return prefix + case ( col1 ) + ' = ' + tbl2 + ' . ' + case ( col2 ) yield row [ 0 ] UNION -- Type names for c in cs ) FROM pg_catalog.pg_type WHERE LOWER ( Word ) IN ( SELECT Name FROM Names ) self.casing = { } WITH Words AS ( JOIN pg_catalog.pg_language L ON L.oid = P.prolang # location , one will be generated based on usage in SQL/PLPGSQL functions . GROUP BY Word from pgcli import __file__ as package_root ROW_NUMBER ( ) OVER ( PARTITION BY LOWER ( Word ) ORDER BY Count DESC ) settings = settings or { } def casing ( self ) : SELECT regexp_split_to_table ( prosrc , '\W+ ' ) AS Word , COUNT ( 1 ) case = self.case FROM pg_catalog.pg_namespace `` `` '' Yields the most common casing for names used in db functions '' '' '' FROM pg_catalog.pg_attribute casing_prefs = '\n'.join ( executor.casing ( ) ) # If generate_casing_file is set to True and there is no file in the above if os.path.isfile ( casing_file ) : UNION -- Schema names import os return self.casing.get ( word , word ) query = `` ' pgclirc_file = pgclirc_file or ' % sconfig ' % config_location ( ) completer.extend_casing ( [ line.strip ( ) for line in f ] ) if generate_casing_file and not os.path.isfile ( casing_file ) : SELECT relname SELECT attname AS Name ' '' 'types ' , 'databases ' ] UNION -- Table/view names self.config [ 'main ' ] [ 'asterisk_column_order ' ] } def refresh_casing ( completer , executor ) : c = self.config cur.execute ( query ) settings = { def extend_casing ( self , words ) : AND Row_Number = 1 ; casing_file = config [ 'main ' ] [ 'casing_file ' ] # In Windows : % USERPROFILE % \AppData\Local\dbcli\pgcli\casing _logger.debug ( 'Casing Query . sql : % r ' , query ) default_config = os.path.join ( package_root , 'pgclirc ' ) self.generate_casing_file = settings.get ( 'generate_casing_file ' ) casing_file = default write_default_config , load_config , config_location , ensure_dir_exists , self.asterisk_column_order = settings.get ( collist = ' , '.join ( t.ref + ' . ' + self.case ( c.name ) write_default_config ( default_config , pgclirc_file ) `` `` '' c = self.config = get_config ( pgclirc_file )","['pgcli/completion_refresher.py', 'pgcli/config.py', 'pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_completion_refresher.py']",Merge pull request # 512 from koljonen/casing
309,163b2e208712d1d463fa7475499c9f86f0301b6b,2016-06-05 14:50:39-07:00,"DEFAULT = PGCli ( ) .row_limit `` `` '' returns True if limit prompt should be shown , False otherwise . '' '' '' def _should_show_limit_prompt ( self , status , cur ) : elif ( os_environ_pager ) : from mock import Mock threshold = 1000 pgcli = PGCli ( prompt_passwd , never_prompt , pgclirc_file=pgclirc , self.row_limit = row_limit result = cli._should_show_limit_prompt ( stmt , None ) cli = PGCli ( row_limit=0 ) over_limit = Mock ( ) assert result is True assert result is False if ( is_select ( status ) and result = cli._should_show_limit_prompt ( stmt , low_count ) return False def test_default_row_limit ( ) : pgexecute=None , pgclirc_file=None ) : self.row_limit = c [ 'main ' ] .as_int ( 'row_limit ' ) low_count.configure_mock ( rowcount=1 ) over_default.configure_mock ( rowcount=DEFAULT + 10 ) threshold = self.row_limit from pgcli.main import PGCli username , version , pgclirc , dsn ) : LIMIT = DEFAULT + 1000 result = cli._should_show_limit_prompt ( stmt , over_limit ) return self.row_limit > 0 and cur and cur.rowcount > self.row_limit row_limit=row_limit ) stmt = `` SELECT * FROM students '' elif os_environ_pager : row_limit = 1000 cli = PGCli ( ) def test_set_row_limit ( ) : result = cli._should_show_limit_prompt ( stmt , over_default ) def test_no_limit ( ) : help='Set threshold for row limit prompt . Use 0 to disable prompt . ' ) cli = PGCli ( row_limit=LIMIT ) def test_row_limit_on_non_select ( ) : low_count = Mock ( ) # Set threshold for row limit prompt . Use 0 to disable prompt . over_default = Mock ( ) over_limit.configure_mock ( rowcount=LIMIT + 10 ) if not is_select ( status ) : if row_limit is not None : else : pgcli = PGCli ( prompt_passwd , never_prompt , pgclirc_file=pgclirc ) stmt = `` UPDATE students set name='Boby ' '' cur and cur.rowcount > threshold ) : if self._should_show_limit_prompt ( status , cur ) : pgexecute=None , pgclirc_file=None , row_limit=None ) : username , version , pgclirc , dsn , row_limit ) :","['pgcli/main.py', 'pgcli/pgclirc', 'tests/test_rowlimit.py']",Merge pull request # 521 from Smotko/configure-row-limit
310,52bac9af854f3e0222ee0569b4206acd3bdaa804,2016-06-04 07:34:35-04:00,"package_root = os.path.dirname ( package_root ) flat_cols = list ( itertools.chain ( * ( ( c.name for c in cols ) pgclirc_file = pgclirc_file or ' % sconfig ' % config_location ( ) def get_config ( pgclirc_file=None ) : self.completion_refresher.refresh ( def __init__ ( self , smart_completion=True , pgspecial=None , settings=None ) : from .config import load_config , config_location , get_config def __init__ ( self , smart_completion=True , pgspecial=None ) : for cols in scoped_cols.values ( ) : settings = { 'asterisk_column_order ' : def _bg_refresh ( self , pgexecute , special , callbacks , history=None ) : bg_refresh.assert_called_with ( pgexecute , special , callbacks , None , # Possible values : `` table_order '' and `` alphabetic '' # Custom colors for the completion menu , toolbar , etc . bg_refresh.assert_called_with ( pgexecute , special , callbacks , None ) args= ( executor , special , callbacks , history ) , for t , cols in colit ( ) ) ) ) ORDER BY 1 , 2 , att.attnum '' ' 'asterisk_column_order ' , 'table_order ' ) def refresh ( self , executor , special , callbacks , history=None ) : settings=settings ) def _bg_refresh ( self , pgexecute , special , callbacks , history=None , default_config = os.path.join ( package_root , 'pgclirc ' ) write_default_config ( default_config , pgclirc_file ) return load_config ( pgclirc_file , default_config ) for t , cols in colit ( ) ) ) args= ( executor , special , callbacks , history , settings ) , self.config [ 'main ' ] [ 'asterisk_column_order ' ] } completer = PGCompleter ( smart_completion=True , pgspecial=special , self.pgexecute , self.pgspecial , callback , history=history ) callback , history=history , settings=settings ) asterisk_column_order = table_order settings = { self.completion_refresher.refresh ( self.pgexecute , self.pgspecial , settings=None ) : None ) ORDER BY 1 , 2 , 3 '' ' 'asterisk_column_order ' : c [ 'main ' ] [ 'asterisk_column_order ' ] } completer = PGCompleter ( smart_completion=True , pgspecial=special ) flat_cols.sort ( ) # Keybindings : flat_cols = itertools.chain ( * ( ( c.name for c in cols ) if self.asterisk_column_order == 'alphabetic ' : # Order of columns when expanding * to column list completer = PGCompleter ( smart_completion , pgspecial=self.pgspecial , cols.sort ( key=operator.attrgetter ( 'name ' ) ) completer = PGCompleter ( smart_completion , pgspecial=self.pgspecial ) self.asterisk_column_order = ( settings or { } ) .get ( def refresh ( self , executor , special , callbacks , history=None , # Keybindings : from pgcli import __file__ as package_root # Custom colors for the completion menu , toolbar , etc . from .config import load_config , config_location","['pgcli/completion_refresher.py', 'pgcli/config.py', 'pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_completion_refresher.py']",Merge pull request # 513 from koljonen/order_columns_by_db_column_order
311,71b01cedd00a9a6c9a5b835025f110e567a13c8c,2016-06-02 20:17:45-07:00,Integration tests use ` behave package http : //pythonhosted.org/behave/ ` _ . Integration tests use ` behave package http : //pythonhosted.org/behave/ ` _ and $ py.test pytest .,['DEVELOP.rst'],Merge pull request # 523 from Smotko/fix-develop-documentation
312,6b29ad862ca292cf1482236934c111783bcdc9d5,2016-06-02 17:31:36-04:00,"[ 'integer ' , 'integer ' ] , [ 't ' , 't ' ] , 'record ' , False , False , True ) , ( 'public ' , 'd ' , ' e ' , 'int4 ' ) ] ) unknown A list of tokens not assigned to type or default continue if mode in ( ' o ' , ' b ' , 't ' ) ] # OUT , INOUT , TABLE field , parse_state = TypedFieldMetadata ( ) , 'type ' p.proargmodes , [ 'func2 ' , `` , `` , False , False , False ] ] , mode_names = set ( ( 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' ) ) f1 = FunctionMetadata ( 's ' , ' f ' , ' x int ' , 'int ' , False , False , False ) self.name = None [ ' o ' , ' o ' ] , `` , False , False , True ] ] , parse_state = 'default ' 'TABLE ( x integer , y integer ) ' , False , False , True ) , # their names oidvectortypes ( p.proargtypes ) proargtypes , `` `` '' Parses a argument/column list , yielding TypedFieldMetadata objects field.mode = tok.value.upper ( ) COALESCE ( proallargtypes : :regtype [ ] , proargtypes : :regtype [ ] ) : :text [ ] , _logger.debug ( arg_list ) return [ ColumnMetadata ( self.func_name , self.return_type , [ ] ) ] f3 = FunctionMetadata ( 's ' , ' g ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , 'integer ' , 'bigint ' , 'smallint ' ) sql = `` ' IN a int = 5 , `` `` '' Yields ColumnMetaData namedtuples from a table declaration '' '' '' False , False , True ] ] , return list ( fields ( self.arg_list , mode_filter= ( 'OUT ' , 'INOUT ' ) ) ) if not sql : [ 'custom_func2 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , f1 = FunctionMetadata ( 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , typ.typname type_name prorettype : :regtype : :text return_type , if f.name and ( not mode_filter or f.mode in mode_filter ) : def test_parse_typed_field_list_no_arg_names ( ) : [ 'func4 ' , `` , `` , False , False , False ] FunctionMetadata ( 'public ' , 'func3 ' , [ ' x ' , ' y ' ] , typed_args = [ f [ 0 ] + ' , ' + f [ 1 ] for f in args ] False ] , return hash ( ( self.schema_name , self.func_name , self.arg_list , FunctionMetadata ( 'public ' , 'func4 ' , ' x integer ' , definitions . This function parses a flattened list of sqlparse tokens field.name = tok.value # happens for e.g . parameter-less functions like now ( ) self.default = [ ] parens = 0 for name , typ , mode in zip ( ( 'public ' , 'd ' , ' e ' , 'integer ' ) ] ) self.return_type , self.is_aggregate , self.is_window , field = TypedFieldMetadata ( ) if tok.ttype in Whitespace or tok.ttype in Comment : [ 'set_returning_func ' , [ ' x ' ] , [ 'integer ' ] , [ ' o ' ] , # For functions without output parameters , the function name IN c double precision = 9.99 '' , self.arg_names , self.arg_types , self.arg_modes , return list ( fields ( match.group ( 1 ) , mode_filter=None ) ) for tok in tokens : [ 'func4 ' , [ ] , [ ] , [ ] , `` , False , False , False ] ] x INT , tbl_str = `` ' if tok.value == ' ( ' : 'SETOF integer ' , False , False , True ) , assert ( len ( args ) == 3 ) [ 'custom_func1 ' , [ `` ] , [ `` ] , [ `` ] , `` , False , False , type A list of tokens denoting the type else : import sqlparse yield FunctionMetadata ( row [ 0 ] , row [ 1 ] , arg_list , row [ 4 ] , row [ 5 ] , row [ 6 ] , row [ 7 ] ) ON typ.oid = att.atttypid [ 'func2 ' , [ ] , [ ] , [ ] , `` , False , False , self.arg_list = arg_list.strip ( ) name The name of the argument/column [ 'custom_func1 ' , `` , `` , False , False , False ] , fs = fields ( func_header , mode_filter= [ 'OUT ' , 'INOUT ' ] ) # Final argument wo n't be followed by a comma , so make sure it gets yielded fs = fields ( `` ) [ 'custom_func2 ' , `` , `` , False , False , False ] , arg_modes , return_type , is_aggregate , is_window , is_set_returning ) : # Function may have named output arguments -- find them and return self.return_type , self.is_aggregate , self.is_window , table_def_regex = re.compile ( r'^TABLE\s * \ ( ( .+ ) \ ) $ ' , re.IGNORECASE ) ] self.arg_names = tuple ( arg_names ) if arg_names else None # Function returns a table -- get the column names args = itertools.izip_longest ( names , row [ 3 ] .split ( ' , ' ) , `` ) field [ parse_state ] .append ( tok ) if field.type : 'integer ' , False , False , True ] ] , elif tok.value == ' ) ' : att.atttypid : :regtype : :text type_name # E.g . 'SELECT unnest FROM unnest ( ... ) ; ' prio = ( 1000 if c.datatype and c.datatype in ( self.is_aggregate , self.is_window , self.is_set_returning ) ) return ( ( ' % s ( schema_name= % r , func_name= % r , arg_names= % r , ' self.arg_types = tuple ( arg_types ) self.arg_list , self.return_type , self.is_aggregate , return [ ColumnMetadata ( name , type , [ ] ) sql = ' a int , b int [ ] [ ] , c double precision , d text ' t.typname return_type , y DOUBLE PRECISION , yield ColumnMetadata ( f.name , None , [ ] ) self.is_set_returning ) ) OUT d double precision [ ] `` ' arg_list = ' , '.join ( typed_args ) Attributes are : yield field False , False , True ] ] , self.unknown = [ ] False ] , # note that ` ttype in Name ` would also match Name.Builtin 'is_window= % r , is_set_returning= % r ) ' ) def test_table_column_names ( ) : self.arg_types , self.arg_modes , self.return_type , if parens == 0 and tok.value == ' , ' : _logger.debug ( list ( args ) ) INNER JOIN pg_catalog.pg_type t assert fs == [ ColumnMetadata ( x , None , [ ] ) for x in ( ' x ' , ' y ' , ' z ' ) ] [ 'set_returning_func ' , `` `` '' Describes typed field from a function signature or table definition # Initialize metadata holder for the next field def fields ( sql , mode_filter= ( 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' ) ) : def __init__ ( self , schema_name , func_name , arg_names , arg_types , def __init__ ( self , schema_name , func_name , arg_list , return_type , is_aggregate , import re f3 = FunctionMetadata ( 's ' , ' g ' , ' x int ' , 'int ' , False , False , False ) mode 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' else : if tok.ttype in Keyword : yield field __slots__ = [ 'name ' , 'mode ' , 'type ' , 'default ' , 'unknown ' ] def __init__ ( self ) : names = row [ 2 ] if row [ 2 ] is not None else [ ] from pgcli.pgcompleter import ColumnMetadata [ 'set_returning_func ' , [ ' x ' , ' y ' ] , [ 'integer ' , 'integer ' ] , assert [ arg.mode for arg in args ] == [ 'IN ' , 'IN ' , 'IN ' , 'OUT ' ] parse_state = 'unknown ' args = list ( parse_typed_field_list ( tokens ) ) [ 'func3 ' , `` , `` , False , False , False ] , IN b text default 'abc ' : :text , self.type = [ ] from sqlparse.tokens import Whitespace , Comment , Keyword , Name , Punctuation False ] ] , tokens = sqlparse.parse ( sql ) [ 0 ] .flatten ( ) elif tok.ttype == Name and not field.name : self.mode = 'IN ' fs = list ( fields ( tbl_str , mode_filter=None ) ) class TypedFieldMetadata ( object ) : yield FunctionMetadata ( * row ) elif tok.value.upper ( ) == 'DEFAULT ' : Field/column lists are used in function signatures and table if field.type : prorettype : :regtype : :text , assert list ( fs ) == [ ColumnMetadata ( ' y ' , None , [ ] ) ] elif parens == 0 and tok.value == '= ' : 'arg_types= % r , arg_modes= % r , return_type= % r , is_aggregate= % r , ' # `` ( [ [ argmode ] [ argname ] argtype FunctionMetadata ( 'schema1 ' , 'func2 ' , None , [ ] , [ ] , [ 'func3 ' , [ ] , [ ] , [ ] , `` , False , False , False ] , def __getitem__ ( self , attr ) : if match : return getattr ( self , attr ) pg_catalog.pg_get_function_arguments ( p.oid ) arg_list , def test_empty_arg_list ( ) : for f in parse_typed_field_list ( tokens ) : False , False ) [ 'set_returning_func ' , `` , 'TABLE ( x INT , y INT ) ' , def test_parse_typed_field_list_more_complex ( ) : if not field.name and tok.value.upper ( ) in mode_names : field [ parse_state ] .append ( tok ) elif tok.ttype in Punctuation : 'integer ' , False , False , True ) , FunctionMetadata , parse_typed_field_list , fields ) FunctionMetadata ( 'public ' , 'func1 ' , `` , f2 = FunctionMetadata ( 's ' , ' f ' , [ ' x ' ] , [ 'integer ' ] , [ ] , 'int ' , False , elif not self.arg_modes : sql = 'int , double precision , text ' and yields one metadata argument per argument / column . ' is_aggregate= % r , is_window= % r , is_set_returning= % r ) ' ) # is used as the name of the output column . self.is_set_returning ) ) parens += 1 z TEXT `` ' self.arg_modes = tuple ( arg_modes ) if arg_modes else None def parse_typed_field_list ( tokens ) : 'OUT x INT ' , 'SETOF INT ' , FunctionMetadata ( 'schema1 ' , 'func2 ' , `` , `` `` '' pg_catalog.pg_get_function_result ( p.oid ) return_type , FunctionMetadata ( 'public ' , 'func4 ' , ( ' x ' , ) , ( 'integer ' , ) , [ ] , parse_state = 'type ' FunctionMetadata ( 'public ' , 'func3 ' , `` , # postgres function argument list syntax : [ 'func1 ' , [ ] , [ ] , [ ] , `` , False , False , default A list of tokens denoting the default value parens -= 1 # No other keywords allowed before arg name [ 'func1 ' , `` , `` , False , False , False ] , from pgcli.packages.function_metadata import FunctionMetadata # sql is something like `` x int , y text , ... '' assert list ( fs ) == [ ] self.arg_names , self.arg_types , self.arg_modes ) else : def test_parse_typed_field_list_simple ( ) : ON p.prorettype = t.oid FunctionMetadata ( 'public ' , 'func1 ' , None , [ ] , [ ] , self.is_window , self.is_set_returning ) ) # [ { DEFAULT | = } default_expr ] [ , ... ] ] ) '' INNER JOIN pg_catalog.pg_type typ elif parens == 0 : return return hash ( ( self.schema_name , self.func_name , self.arg_names , p.proargnames , from pgcli.packages.function_metadata import ( # End of the current field specification def test_argument_names ( ) : f2 = FunctionMetadata ( 's ' , ' f ' , ' x int ' , 'int ' , False , False , False ) prio = ( 1000 if c.datatype and c.datatype [ :3 ] == 'int ' match = table_def_regex.match ( self.return_type ) return ( ( ' % s ( schema_name= % r , func_name= % r , arg_list= % r , return_type= % r , ' func_header = 'IN x INT DEFAULT 2 , OUT y DOUBLE PRECISION ' assert [ arg.name for arg in args ] == [ ' a ' , ' b ' , ' c ' , 'd ' ] is_window , is_set_returning ) : parse_state = 'default '","['pgcli/packages/function_metadata.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_function_metadata.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 517 from dbcli/koljonen/simplify_function_metadata
313,f912633d6ded6ed563f8b8ba88525839afa20031,2016-06-01 16:30:06-04:00,"( 'SELECT users . * FROM users ' , ] ) 'id , users.email , users.first_name , users.last_name ' ) , sql = 'SELECT users . * FROM users ' sep = ' , ' + word_before_cursor [ : -1 ] ( 'SELECT Users . * FROM Users ' , expected = [ Completion ( text=expected , start_position=-1 , Document ( text=sql , cursor_position=pos ) , complete_event ) 'id , Users.email , Users.first_name , Users.last_name ' ) , def test_wildcard_column_expansion_with_table_qualifier ( completer , complete_event , text , expected ) : def test_wildcard_column_expansion_with_table_qualifier ( completer , complete_event ) : sep = ' , ' + self.escape_name ( tables [ 0 ] .ref ) + ' . ' col_list = 'id , users.email , users.first_name , users.last_name ' Document ( text=text , cursor_position=pos ) , complete_event ) expected = [ Completion ( text=col_list , start_position=-1 ,","['pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 516 from dbcli/koljonen/fix_another_casing_issue
314,32029e27668dcdc6204bab8d8d64236962ecf973,2016-05-29 17:29:30-04:00,"Completion ( text='projects ' , start_position=start_pos , display_meta='table ' ) text , use_leading_double_quote ) : start_pos = -1 objects = metadata [ schema ] .keys ( ) 'Custom ' : { ] assert set ( result ) == set ( [ 'projects ' : [ 'projectid ' , 'name ' ] if use_leading_double_quote : # If schema name is unquoted , lower-case it objects = metadata [ self.escape_name ( schema ) ] .keys ( ) Completion ( text= ' '' Custom '' ' , start_position=0 , display_meta='schema ' ) , text += ' '' ' start_pos = 0 ] ) schema = self.escape_name ( schema ) result = completer.get_completions ( if schema and identifier.value [ 0 ] ! = ' '' ' : else : ] ) def test_suggested_table_names_with_schema_dot2 ( completer , complete_event , Document ( text=text , cursor_position=position ) , complete_event ) 'SELECT * FROM `` Custom '' . ' , 'SELECT * FROM Custom . ' , 'Custom ' : [ [ 'func4 ' , `` , `` , False , False , False ] Completion ( text='func4 ' , start_position=start_pos , display_meta='function ' ) , } , Completion ( text= ' '' Custom '' ' , start_position=0 , display_meta='schema ' ) , schema = schema.lower ( ) position = len ( text )","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py']",Merge pull request # 514 from koljonen/fix_schema_casing_issue
315,a9c209df7a046846a16930124a865432d7caf2a1,2016-05-25 19:11:07-04:00,"pos = text.index ( ' * ' ) + 1 'INSERT INTO public.Orders ( * ' , expected = [ Completion ( text='id , ordered_date , status ' , start_position=-1 , assert expected == completions 'INSERT INTO public.Orders ( * ) ' , 'INSERT INTO Orders ( * ) ' , completions = completer.get_completions ( def test_wildcard_column_expansion ( completer , complete_event ) : 'INSERT INTO public.orders ( * ' , 'INSERT INTO public.orders ( * ) ' , Document ( text=text , cursor_position=pos ) , complete_event ) 'SELECT * FROM custom.set_returning_func ( ) ' , 'INSERT INTO public.Orders ( * ' , 'INSERT INTO public.Orders ( * ) ' , ] ) 'INSERT INTO orders ( * ) ' , 'SELECT * FROM Custom.Set_Returning_Func ( ) ' schema_name , real_name , alias = parse_identifier ( item ) yield TableReference ( None , real_name , alias , allow_functions ) 'INSERT INTO Orders ( * ' , 'INSERT INTO Orders ( * ' , 'INSERT INTO Orders ( * ) ' 'SELECT * FROM Custom.set_returning_func ( ) ' , sql = 'SELECT * FROM custom.set_returning_func ( ) ' def test_wildcard_column_expansion_with_function ( completer , complete_event , text ) : 'INSERT INTO public.orders ( * ) ' , 'INSERT INTO orders ( * ) ' , def test_wildcard_column_expansion_with_insert ( completer , complete_event , text ) : yield TableReference ( None , item.get_real_name ( ) , item.get_alias ( ) , Document ( text=sql , cursor_position=pos ) , complete_event ) 'INSERT INTO orders ( * ' , 'INSERT INTO orders ( * ' , 'INSERT INTO public.orders ( * ' , display= ' * ' , display_meta='columns ' ) ] allow_functions )","['pgcli/packages/parseutils.py', 'tests/test_smart_completion_multiple_schemata.py']",Merge pull request # 510 from koljonen/fixtablecasingissue2
316,ab91b83723901ea6b9a52be329f258901f612c6b,2016-05-25 18:57:40-04:00,"newcount = _min ( self [ elem ] , other [ elem ] ) def test_suggested_aliases_after_on_right_side ( completer , complete_event , text ) : fk.parentcolumn ) , ( fk.childschema , fk.childtable , position = len ( 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON ' ) else 0 + refprio [ rtbl.ref ] ) assert suggestions == ( Alias ( aliases= ( ' a ' , ' b ' , ) ) , ) If an element 's count has been set to zero or is a negative number , Counter ( { ' y ' : 3 , ' z ' : 2 , ' g ' : 1 } ) def fields ( self ) : [ ' A ' , ' A ' , ' B ' , ' B ' , ' C ' , ' C ' ] : return : dict { TableReference : [ list of column names ] } assert names == [ ' x ' , ' y ' , ' z ' ] Function ( schema=parent ) ] return False ' '' select a.x , b.y newcount = self [ elem ] + other [ elem ] Column = namedtuple ( 'Column ' , [ 'tables ' , 'drop_unique ' ] ) columns.extend ( [ ( 'public ' , table , col , 'text ' ) for col in cols ] ) return nlargest ( n , self.iteritems ( ) , key=itemgetter ( 1 ) ) yield f.name _max = max 4 full_text , identifier , parsed_statement ) ( 'public ' , ' a ' , ' x ' , 'text ' ) , ( 'public ' , ' a ' , ' y ' , 'text ' ) , sugs = [ Column ( tables=filteredtables ) , assert suggestions == ( Alias ( aliases= ( 'abc ' , 'bcd ' , ) ) , ) assert fs == [ ColumnMetadata ( x , None , [ ] ) for x in ( ' x ' , ' y ' , ' z ' ) ] def suggest_based_on_last_token ( token , text_before_cursor , full_text , # Let all columns be text columns ) ) AS childcolumn conds.append ( ( cond , 'fk join ' , prio ) ) Completion ( text='id ' , start_position=0 , display_meta='column ' ) , # parentcolumns , childcolumns # To strip negative and zero counts , add-in an empty counter : parentschema , childschema = e ( [ fk.parentschema , fk.childschema ] ) : return : boolean refprio = dict ( ( tbl.ref , num ) for num , tbl > > > c = Counter ( ) # a new , empty counter 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' , INNER JOIN pg_catalog.pg_type typ ' '' Dict subclass for counting hashable objects . Sometimes called a bag tables = tuple ( t for t in tables if identifies ( parent , t ) ) parent= ( None , 'abc ' , ' a ' , False ) ) prio = ( 1000 if c.datatype and c.datatype [ :3 ] == 'int ' So check that the preceding token is a ON , AND , or OR keyword , instead of Keyword , NamedQuery , Datatype , Alias , Path ) > > > Counter ( 'abbb ' ) & Counter ( 'bcc ' ) for elem , count in self.iteritems ( ) : def suggest_based_on_last_token ( token , text_before_cursor , full_text , identifier ) : from collections import Counter assert list ( names ) == [ ] conds , metas , prios = zip ( * conds ) # suggest only columns that appear in the last table and one more refcols = dict ( ( t.ref , cs ) for t , cs in scoped_cols.items ( ) ) if len ( self ) < len ( other ) : _min = min [ schema , relname , colname ] ) return tuple ( sugs ) are stored as dictionary values . lcol.name , rcol [ 2 ] ) childcolmeta.foreignkeys.append ( ( fk ) ) collist = ' , '.join ( t.ref + ' . ' + c.name for t , cs in colit ( ) JoinCondition = namedtuple ( 'JoinCondition ' , [ 'tables ' , 'parent ' ] ) dict.__delitem__ ( self , elem ) if suggestion.require_last_table : prev_keyword , text_before_cursor , full_text , identifier ) `` `` '' Yields field names from a table declaration '' '' '' Counter ( { ' b ' : 3 , ' c ' : 2 , ' a ' : 1 } ) # For each fk from the left table , generate a join condition if def test_suggested_tables_after_on_right_side ( completer , complete_event ) : return last_tok.value.lower ( ) in ( 'on ' , 'and ' , 'or ' ) JOIN pg_catalog.pg_namespace s_c ON s_c.oid = t_c.relnamespace # the other table is also in the scope if not self : columns.extend ( [ ( 'public ' , view , col ) for col in cols ] ) assert list ( fs ) == [ ] def test_suggested_tables_after_on ( completer , complete_event ) : flat_cols = [ col for ( col , count ) def __and__ ( self , other ) : > > > c.update ( d ) # add elements from another counter on `` ' , typ.typname type_name # ColumnMetadata namedtuple for both the child and parent def elements ( self ) : ltbl = tables [ -1 ] .ref t_p.relname AS parenttable , : return : list of ( schema_name , relation_name , column_name , column_type ) tuples parenttable , childtable = e ( [ fk.parenttable , fk.childtable ] ) ' '' Union is the maximum of value in either of the input counters . 'SELECT * FROM users u1 JOIN users u2 USING ( email ) JOIN user_emails ue USING ( ) ' , else : SELECT s_p.nspname AS parentschema , def test_suggested_tables_after_on ( completer , complete_event , text ) : > > > Counter ( 'abbb ' ) | Counter ( 'bcc ' ) tbldict [ ( t.schema , t.name ) ] .append ( t ) childcolmeta = meta [ childschema ] [ childtable ] [ childcol ] from an input iterable . Or , initialize the count from another mapping if _allow_join_suggestion ( parsed_statement ) : 'where ' , text_before_cursor , full_text , identifier ) # Tables that are closer to the cursor get higher prio # suggest only columns that appear in more than one table self.update ( iterable , * * kwds ) return suggest_based_on_last_token ( prev_keyword , text_before_cursor , return sorted ( self.iteritems ( ) , key=itemgetter ( 1 ) , reverse=True ) self , other = other , self return ( Column ( tables=tables , require_last_table=True ) , ) unnest ( ( if iterable is not None : def __repr__ ( self ) : 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id and ' , [ ( ' a ' , 5 ) , ( ' r ' , 2 ) , ( ' b ' , 2 ) ] return 0 # For name matching , use a { ( colname , coltype ) : TableReference } dict join bcd b raise NotImplementedError ( join bcd b on : return : { TableReference : { colname : ColumnMetaData } } Alias ( aliases= ( 'abc ' , 'bcd ' , ) ) , ) ) run ( executor , `` create schema schema2 '' ) columns.extend ( [ ( schema , table , col ) for col in cols ] ) text = 'SELECT users.name , orders.id FROM users JOIN orders ON ' 'SELECT * FROM users u1 JOIN users u2 USING ( email ) JOIN user_emails ue USING ( ) ' , s_c.nspname AS childschema , full_text , identifier , parsed_statement ) e.g . an equals sign . column = ColumnMetadata ( name=colname , datatype=datatype , fk = ForeignKey ( parentschema , parenttable , parcol , dict.update ( self , iterable ) # fast path when counter is empty # dbmetadata [ 'tables ' ] [ 'schema_name ' ] [ 'table_name ' ] should be a list of Function , Datatype , Alias ) def __or__ ( self , other ) : array_agg ( attname ORDER BY i ) col_table = defaultdict ( lambda : [ ] ) from collections import namedtuple , defaultdict for schema , relname , colname , datatype in column_data : > > > d = Counter ( 'watch ' ) prefix = `` if suggestion.parent else tbl1 + ' . ' 'SELECT users.name , orders.id FROM users JOIN orders ON ' , tables= ( Completion ( text= ' y = f2.y ' , start_position=0 , display_meta='name join ' ) , metadata [ schema ] [ relname ] = OrderedDict ( ) column_data = [ self.escaped_names ( d ) for d in column_data ] 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON ' , > > > Counter ( 'abbbc ' ) - Counter ( 'bccd ' ) parcolmeta.foreignkeys.append ( ( fk ) ) # column names . ' '' Iterator over elements repeating each as many times as its count . if n is None : names = field_names ( func_header , mode_filter= [ 'OUT ' , 'INOUT ' ] ) def test_suggested_aliases_after_on ( completer , complete_event , text ) : select def update ( self , iterable=None , * * kwds ) : if cond not in found : : return : list of ( schema_name , relation_name , column_name ) tuples result [ elem ] = newcount 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id AND ' , from collections import namedtuple def test_foreign_key_query ( executor ) : Tests if a join condition should be suggested ( None , 'bcd ' , ' b ' , False ) ) , names = field_names ( `` ) assert set ( executor.foreignkeys ( ) ) > = set ( [ # require_last_table is used for 'tb11 JOIN tbl2 USING ( ... ' which should fs = fields ( func_header , mode_filter= [ 'OUT ' , 'INOUT ' ] ) for rtbl in col_table [ ( c.name , c.datatype ) ] : def __init__ ( self , iterable=None , * * kwds ) : ( 'public ' , ' a ' ) , ( 'public ' , ' b ' ) , ( 'schema1 ' , ' c ' ) ] ) fk.childcolumn ) ) : # Find all name-match join conditions return ( Column ( tables=tables ) , def fields ( sql , mode_filter= ( 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' ) ) : self.update ( kwds ) parsed_statement=statement ) > > > Counter ( 'abbb ' ) + Counter ( 'bcc ' ) ForeignKey = namedtuple ( 'ForeignKey ' , [ 'parentschema ' , 'parenttable ' , ( schema , relname , colname ) = self.escaped_names ( return self.find_matches ( word_before_cursor , conds , conds.append ( ( cond , 'name join ' , prio ) ) metadata [ schema ] [ relname ] .append ( column ) Document ( text=text , cursor_position=pos ) , complete_event ) ) last_token = parsed_statement > > > c = Counter ( 'ABCABC ' ) ] ) for elem , count in iterable.iteritems ( ) : 'SELECT * FROM users u1 JOIN user_emails ue USING ( ) JOIN users u2 ue USING ( first_name , last_name ) ' , if rtbl.ref ! = lefttable.ref : meta = self.dbmetadata [ 'tables ' ] # and at http : //en.wikipedia.org/wiki/Multiset run ( executor , `` create table schema1.parent ( parentid int PRIMARY KEY ) '' ) 'SELECT users.name , orders.id FROM users JOIN orders ON JOIN orders orders2 ON ' self_get = self.get JoinCondition : get_join_condition_matches , prev_keyword , text_before_cursor , full_text , identifier ) if hasattr ( iterable , 'iteritems ' ) : set ( c.name for t , cs in colit ( ) if t.ref == ltbl for c in cs ) & `` `` '' newcount = self [ elem ] - other [ elem ] ' '' ' '' in Counter ( flat_cols ) .items ( ) Function ( schema=parent ) ) def test_on_suggests_tables_right_side ( sql ) : from .packages.function_metadata import ColumnMetadata , ForeignKey flat_cols = list ( prev_keyword , text_before_cursor , full_text , identifier , 'Like dict.copy ( ) but returns a Counter instance instead of a dict . ' from .packages.function_metadata import FunctionMetadata ' '' List the n most common elements and their counts from the most ( None , 'abc ' , None , False ) , att.attname column_name text = 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = ' return prefix + col1 + ' = ' + tbl2 + ' . ' + col2 `` `` '' Returns a list of output field names '' '' '' for t , cols in colit ( ) ) ) def __sub__ ( self , other ) : if elem in self : > > > c.update ( 'witch ' ) # add elements from another iterable JoinCondition ( tables= ( ( None , 'abc ' , ' a ' , False ) , def test_suggested_tables_after_on_right_side ( completer , complete_event , text ) : 'type ' , text_before_cursor , full_text , identifier ) return list ( fields ( match.group ( 1 ) , mode_filter=None ) ) Completion ( text= ' o.email = u.email ' , start_position=0 , display_meta='name join ' ) , Completion ( text= ' y.price = x.price ' , start_position=0 , display_meta='name join ' ) , for elem in iterable : Completion ( text='orders.email = users.email ' , start_position=0 , display_meta='name join ' ) , 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = JOIN orders o2 ON ' def __add__ ( self , other ) : from itertools import repeat , ifilter return suggest_based_on_last_token ( # Override dict methods where the meaning changes for Counter objects . self.all_completions.add ( column ) return ' % s ( ) ' % self.__class__.__name__ last_tok = statement.token_prev ( len ( statement.tokens ) ) ( None , 'bcd ' , None , False ) ) , for schema , relname , column in column_data : from pgcli.pgcompleter import ColumnMetadata for lcol in refcols.get ( lefttable.ref , [ ] ) : yield ColumnMetadata ( f.name , None , [ ] ) if count > 1 ] ( None , 'bcd ' , None , False ) ) , # assert set ( suggestions ) == set ( ( JoinCondition ( parsed_statement ) ( 'public ' , ' b ' , ' z ' ) , ( 'schema1 ' , ' c ' , ' w ' ) ] ) self [ elem ] = self_get ( elem , 0 ) + count ' '' from for tbl , col in ( ( t , c ) for t , cs in scoped_cols.items ( ) for c in cs ) : text = 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' if newcount > 0 : > > > Counter ( 'abracadabra ' ) .most_common ( 3 ) fs = list ( fields ( tbl_str , mode_filter=None ) ) return result parent=filteredtables [ -1 ] ) ) lefttable = suggestion.parent or suggestion.tables [ -1 ] return [ ] select * from tbl1 a join tbl2 b on a.id = < cursor > tables=tables , parent=None ) ) return ( Alias ( aliases=aliases ) , ) from abc a 'where ' , text_before_cursor , full_text , identifier , def field_names ( sql , mode_filter= ( 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' ) ) : Counter ( { ' b ' : 4 , ' c ' : 2 , ' a ' : 1 } ) tables = extract_tables ( full_text ) def fieldnames ( self ) : for fk in lcol.foreignkeys : text = 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON ' # Let all columns be text columns 'SELECT u.name , o.id FROM users u JOIN orders o ON ' , class Counter ( dict ) : `` `` '' Yields ForeignKey named tuples '' '' '' > > > Counter ( 'zyzygy ' ) ( None , 'abc ' , None , False ) , > > > c = Counter ( 'gallahad ' ) # a new counter from an iterable JOIN pg_catalog.pg_class t_c ON t_c.oid = fk.conrelid sugs.append ( JoinCondition ( tables=tables , Completion ( text= ' o.id = u.id ' , start_position=0 , display_meta='name join ' ) , def test_join_using_suggests_from_last_table ( completer , complete_event , text ) : def most_common ( self , n=None ) : set ( c.name for t , cs in colit ( ) if t.ref ! = ltbl for c in cs ) ) Completion ( text= ' x = f2.x ' , start_position=0 , display_meta='name join ' ) , 'SELECT * FROM users u1 JOIN user_emails ue USING ( ) JOIN users u2 ue USING ( first_name , last_name ) ' , for _ in repeat ( None , count ) : # drop_unique is used for 'tb11 JOIN tbl2 USING ( ... ' which should def __delitem__ ( self , elem ) : columns.extend ( [ ( 'public ' , table , col ) for col in cols ] ) else : tables = extract_tables ( text_before_cursor ) # [ ( schema , table , alias ) , ... ] ( 'public ' , ' b ' , ' z ' , 'text ' ) , ( 'schema1 ' , ' c ' , ' w ' , 'text ' ) ] ) `` `` '' Returns a list of output-field ColumnMetadata namedtuples '' '' '' self.all_completions.add ( colname ) if not statement or not statement.tokens : return list ( field_names ( match.group ( 1 ) , mode_filter=None ) ) meta_collection=metas , type_priority=100 , priority_collection=prios ) for c in refcols.get ( lefttable.ref , [ ] ) : if suggestion.drop_unique : ) , Counter ( { ' b ' : 2 , ' a ' : 1 } ) : param column_data : list of ( schema_name , rel_name , column_name ) tuples # Knuth TAOCP Volume II section 4.6.3 exercise 19 for row in cur : return NotImplemented identifier , parsed_statement=None ) : def __missing__ ( self , key ) : def test_on_suggests_tables_and_join_conditions_right_side ( sql ) : def test_on_suggests_aliases ( sql ) : flat_cols = list ( itertools.chain ( * scoped_cols.values ( ) ) ) cols = cols.values ( ) if not isinstance ( other , Counter ) : Completion ( text='orders.id = users.id ' , start_position=0 , display_meta='name join ' ) , # Outputs guaranteed to only include positive counts . assert list ( fs ) == [ ColumnMetadata ( ' y ' , None , [ ] ) ] t_c.relname AS childtable , parent=None self [ elem ] = self_get ( elem , 0 ) + 1 return ( Column ( tables=tables , drop_unique=True ) , ) from .packages.counter import Counter if rtbl and rtbl.ref ! = lefttable.ref : of elements to their counts . cols = func.fields ( ) 'Counter.fromkeys ( ) is undefined . Use Counter ( iterable ) instead . ' ) except ImportError : tables = extract_tables ( full_text ) # [ ( schema , table , alias ) , ... ] col_table [ ( col.name , col.datatype ) ] .append ( tbl ) FunctionMetadata , parse_typed_field_list , field_names ) run ( executor , `` create schema schema1 '' ) in enumerate ( suggestion.tables ) ) Column = namedtuple ( 'Column ' , [ 'tables ' , 'require_last_table ' ] ) # python 2.6 return suggest_based_on_last_token ( def copy ( self ) : # fk_data is a list of ForeignKey namedtuples , with fields pos = text.index ( ' ( ) ' ) + 1 else : Completion ( text= ' y ' , start_position=0 , display_meta='table alias ' ) ] ) return suggest_based_on_last_token ( 'type ' , text_before_cursor , 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id and ' , def test_suggested_aliases_after_on ( completer , complete_event ) : def foreignkeys ( self ) : JOIN pg_catalog.pg_attribute c USING ( attnum ) metadata [ schema ] [ relname ] [ colname ] = column columns.extend ( [ ( schema , table , col , 'text ' ) for col in cols ] ) for elem in ifilter ( self.__contains__ , other ) : > > > c = Counter ( 'which ' ) from heapq import nlargest ( 'public ' , ' a ' , ' x ' ) , ( 'public ' , ' a ' , ' y ' ) , 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = ' position = len ( text ) assert list ( names ) == [ ' y ' ] for t in scoped_cols.keys ( ) : ( 'public ' , 'd ' , ' e ' , 'int4 ' ) ] ) query = `` ' text = 'SELECT u.name , o.id FROM users u JOIN orders o ON ' return list ( fields ( self.arg_list , mode_filter= ( 'OUT ' , 'INOUT ' ) ) ) FROM pg_catalog.pg_constraint fk for fk in fk_data : # dbmetadata [ 'tables ' ] [ 'schema_name ' ] [ 'table_name ' ] should be an Completion ( text= ' y.product_name = x.product_name ' , start_position=0 , display_meta='name join ' ) , > > > c [ ' h ' ] # four ' h ' in which , witch , and watch cur.execute ( query ) `` `` '' Yields ColumnMetaData namedtuples from a table declaration '' '' '' from .packages.function_metadata import FunctionMetadata , ForeignKey ( 'schema1 ' , 'parent ' , 'parentid ' , 'schema2 ' , 'child ' , 'motherid ' ) ] ) Alias ( aliases= ( ' a ' , ' b ' , ) ) , ) ) prio = 2000 + refprio [ rtbl.ref ] def test_on_suggests_tables_and_join_conditions ( sql ) : ' '' Like dict.update ( ) but add counts instead of replacing them . _logger.debug ( 'Functions Query . sql : % r ' , query ) ' '' Intersection is the minimum of corresponding counts . WHERE c.attrelid = fk.conrelid JOIN pg_catalog.pg_namespace s_p ON s_p.oid = t_p.relnamespace def _allow_join_suggestion ( statement ) : items = ' , '.join ( map ( ' % r : % r'.__mod__ , self.most_common ( ) ) ) return ' % s ( { % s } ) ' % ( self.__class__.__name__ , items ) cols = func.fieldnames ( ) def fromkeys ( cls , iterable , v=None ) : if not conds : att.attname column_name , Source can be an iterable , a dictionary , or another Counter instance . self_get = self.get return list ( field_names ( self.arg_list , mode_filter= ( 'OUT ' , 'INOUT ' ) ) ) tbldict = defaultdict ( list ) ( select unnest ( conkey ) as attnum , generate_subscripts ( conkey , 1 ) as i ) x # Map ( schema , tablename ) to tables and ref to columns > > > c = Counter ( a=4 , b=2 ) # a new counter from keyword args # Multiset-style mathematical operations discussed in : We need this to avoid bad suggestions when entering e.g . @ classmethod found = set ( cnd [ 0 ] for cnd in conds ) yield ForeignKey ( * row ) 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = JOIN orders orders2 ON ' , collist = ' , '.join ( t.ref + ' . ' + c for t , cs in colit ( ) yield elem FunctionMetadata , parse_typed_field_list , fields ) full_text , identifier ) ColumnMetadata = namedtuple ( 'ColumnMetadata ' , [ 'name ' , 'datatype ' , 'foreignkeys ' ] ) # assert tables == ( ( None , 'abc ' , 'abc ' , False ) , ) drop_unique=True ) , # c += Counter ( ) Function , Datatype , Alias , JoinCondition ) # copied from http : //code.activestate.com/recipes/576611-counter-class/ cond = make_cond ( lefttable.ref , rtbl.ref , flat_cols = itertools.chain ( * ( ( c.name for c in cols ) ( 'public ' , ' a ' ) , ( 'public ' , ' b ' ) , ( 'schema1 ' , ' c ' ) ] ) tables = extract_tables ( text_before_cursor ) with self.conn.cursor ( ) as cur : parent=None ) , 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON JOIN public.orders z ON z.id > y.id ' return suggest_based_on_last_token ( if kwds : foreignkeys= [ ] ) scoped_cols = self.populate_scoped_cols ( suggestion.tables ) if self : ' '' Add counts from two counters . columns.extend ( [ ( 'public ' , view , col , 'text ' ) for col in cols ] ) > > > c = Counter ( { ' a ' : 4 , ' b ' : 2 } ) # a new counter from a mapping 'Like dict.__delitem__ ( ) but does not raise KeyError for missing values . ' WHERE fk.contype = ' f ' ; cond = make_cond ( lefttable.ref , rtbl.ref , c.name , c.name ) common to the least . If n is None , then list all element counts . return ( Alias ( aliases=aliases ) , ) childschema , childtable , childcol ) def make_cond ( tbl1 , tbl2 , col1 , col2 ) : for rcol in ( ( fk.parentschema , fk.parenttable , # parentschema , childschema , parenttable , childtable , names = list ( field_names ( tbl_str , mode_filter=None ) ) metadata [ schema ] [ relname ] = [ ] ON typ.oid = att.atttypid ( select unnest ( confkey ) as attnum , generate_subscripts ( confkey , 1 ) as i ) x : param statement : an sqlparse.sql.Statement run ( executor , `` create table schema2.child ( childid int PRIMARY KEY , motherid int REFERENCES schema1.parent ) '' ) from collections import namedtuple ( 'public ' , 'd ' , ' e ' ) ] ) def extend_foreignkeys ( self , fk_data ) : for elem in set ( self ) | set ( other ) : def test_on_suggests_aliases_and_join_conditions ( sql ) : childcol , parcol = e ( [ fk.childcolumn , fk.parentcolumn ] ) require_last_table=True ) , JOIN pg_catalog.pg_class t_p ON t_p.oid = fk.confrelid return Counter ( self ) assert set ( result ) == set ( [ 'SELECT u.name , o.id FROM users u JOIN orders o ON JOIN orders o2 ON ' def test_on_suggests_tables ( sql ) : ] ) def get_join_condition_matches ( self , suggestion , word_before_cursor ) : def test_join_functions_on_suggests_columns ( completer , complete_event ) : for rtbl in tbldict [ ( rcol [ 0 ] , rcol [ 1 ] ) ] : ' '' , def test_join_functions_on_suggests_columns_and_join_conditions ( completer , complete_event ) : 'parentcolumn ' , 'childschema ' , 'childtable ' , 'childcolumn ' ] ) return suggest_based_on_last_token ( last_token , text_before_cursor , WHERE c.attrelid = fk.confrelid last_token , text_before_cursor , full_text , identifier , # assert tables == ( ( None , 'abc ' , None , False ) , ) ( None , 'def ' , 'd ' , False ) ) , : param column_data : list of ( schema_name , rel_name , column_name , column_type ) tuples Completion ( text= ' y.id = x.id ' , start_position=0 , display_meta='name join ' ) ] ) def test_suggested_aliases_after_on_right_side ( completer , complete_event ) : Completion ( text= ' y ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='email ' , start_position=0 , display_meta='column ' ) , result = set ( completer.get_completions ( ' '' Create a new , empty Counter object . And if given , count elements e = self.escaped_names tables= ( ( None , 'abc ' , ' a ' , False ) , try : ) ) AS parentcolumn , Alias ( aliases= ( 'abc ' , 'bcd ' , ) ) , ) ) completer.extend_foreignkeys ( executor.foreignkeys ( ) ) 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id AND ' , > > > sorted ( c.elements ( ) ) parcolmeta = meta [ parentschema ] [ parenttable ] [ parcol ] elements ( ) will ignore it . # These are added as a list of ForeignKey namedtuples to the fs = fields ( `` ) filteredtables = tuple ( t for t in tables if identifies ( parent , t ) ) or multiset . Elements are stored as dictionary keys and their counts assert set ( suggestions ) == set ( ( JoinCondition ( tables= ( return ( Alias ( aliases=aliases ) , JoinCondition ( ' '' Subtract count , but keep only results with positive counts . def test_suggestions_after_on ( completer , complete_event , text ) : Keyword , NamedQuery , Datatype , Alias , Path , JoinCondition ) conds = [ ] newcount = _max ( self [ elem ] , other [ elem ] ) from operator import itemgetter result = Counter ( ) # OrderedDict { column_name : ColumnMetaData } . Counter ( { ' b ' : 1 } )","['pgcli/completion_refresher.py', 'pgcli/packages/counter.py', 'pgcli/packages/function_metadata.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_function_metadata.py', 'tests/test_parseutils.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 496 from koljonen/joinconditions
317,f1b60c2a411c4ae4dcb7377f088f64a99d43be99,2016-05-23 19:46:34-04:00,"# Fallback to meta param if meta_collection param is None type_priority=0 , priority_collection = None ) : meta=None , meta_collection=None ) : collection = zip ( collection , meta_collection ) priority_collection = priority_collection or itertools.repeat ( 0 ) priority = type_priority , prio , sort_key , priority_func ( item ) , lexical_priority # All completions have an identical meta meta=None , meta_collection=None , priority = sort_key , priority_func ( item ) , lexical_priority # Fallback to 0 if priority_collection param is None if meta_collection : for item , meta in collection : else : for item , meta , prio in collection : # meta-display string collection = zip ( collection , itertools.repeat ( meta ) ) meta_collection = meta_collection or itertools.repeat ( meta ) collection = zip ( collection , meta_collection , priority_collection ) # Each possible completion in the collection has a corresponding",['pgcli/pgcompleter.py'],Merge pull request # 507 from koljonen/find_matches_priority_arguments
318,85d0ddb4564b40dc1283428e52c8a51bf0d0990b,2016-05-21 08:55:39-04:00,"Completion ( text='phone_number ' , start_position=0 , display_meta='column ' ) ] ) def test_suggest_columns_from_quoted_table ( completer , complete_event ) : else : name = item.get_name ( ) pos = len ( 'SELECT U . ' ) name = item.get_name ( ) 'SELECT U . FROM USERS U ' , Completion ( text= ' '' Users '' ' , start_position=0 , display_meta='table ' ) , def test_suggest_columns_from_quoted_table ( completer , complete_event , text ) : # We need to do some massaging of the names because postgres is case name_quoted = quote_count > 2 or ( quote_count and not schema_quoted ) Completion ( text= ' '' Users '' ' , start_position=start_pos , display_meta='table ' ) , yield TableReference ( schema_name , real_name , item.get_alias ( ) , schema_name = schema_name.lower ( ) 'SELECT U . FROM Users U ' , name = name.lower ( ) schema_quoted = schema_name and item.value [ 0 ] == ' '' ' is_function ) Completion ( text='email ' , start_position=0 , display_meta='column ' ) , # insensitive and ' '' Foo '' ' is not the same table as 'Foo ' ( while 'foo ' is ) assert set ( result ) == set ( [ 'SELECT U . FROM custom.USERS U ' , if not name : ' '' Users '' ' , alias = alias or name 'SELECT U . FROM `` custom '' .Users U ' , schema_name = item.get_parent_name ( ) text = 'SELECT U . FROM `` Users '' U ' name = item.get_real_name ( ) if real_name : quote_count = item.value.count ( ' '' ' ) 'Users ' : [ 'userid ' , 'username ' ] , 'SELECT U . FROM custom.Users U ' , ] ) complete_event ) 'SELECT U . FROM custom.users U ' , schema_name , real_name , alias = parse_identifier ( item ) Completion ( text='userid ' , start_position=0 , display_meta='column ' ) , if not alias : result = completer.get_completions ( Document ( text=text , cursor_position=pos ) , return schema_name , name , alias if name and not name_quoted and name ! = name.lower ( ) : alias = name 'SELECT U . FROM `` custom '' .USERS U ' , yield TableReference ( schema_name , real_name , alias , is_function ) real_name = item.get_real_name ( ) 'SELECT U . FROM custom . `` Users '' U ' , Completion ( text='first_name ' , start_position=0 , display_meta='column ' ) , 'SELECT U . FROM `` custom '' . `` Users '' U ' schema_name = item.get_parent_name ( ) Completion ( text='last_name ' , start_position=0 , display_meta='column ' ) ] ) def parse_identifier ( item ) : 'Users ' : [ 'userid ' , 'username ' ] , Completion ( text='username ' , start_position=0 , display_meta='column ' ) ] ) if schema_name and not schema_quoted : 'SELECT U . FROM users U ' yield TableReference ( None , name , item.get_alias ( ) or name , Completion ( text= ' '' Users '' ' , display_meta='table ' ) , def test_suggest_columns_from_unquoted_table ( completer , complete_event , text ) : 'SELECT U . FROM `` custom '' .users U ' schema_name = None alias = item.get_alias ( ) Completion ( text='id ' , start_position=0 , display_meta='column ' ) ,","['pgcli/packages/parseutils.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 508 from koljonen/fixtablecasingissue
319,30de80223bb00cc33cf7c97c5afbdac17ab073d5,2016-05-17 19:40:42-04:00,"if count > 1 ] metadata [ schema ] [ relname ] = [ ] # column names . collist = ' , '.join ( c for c in flat_cols ) * [ ] Test passing in a special command . metadata [ schema ] [ relname ] = [ ' * ' ] if count > 1 and col ! = ' * ' ] * [ ] Input SELECT prefix and check if only columns are returned . * [ ] Test passing in a special command . for c in cs if c ! = ' * ' ) collist = sep.join ( c for c in flat_cols ) Completion ( text= ' * ' , start_position=0 , display_meta='column ' ) , collist = ' , '.join ( c for c in flat_cols if c ! = ' * ' ) # column names . Default to an asterisk for c in cs ) collist = sep.join ( c for c in flat_cols if c ! = ' * ' ) * [ ] Input SELECT prefix and check if only columns and ' * ' are returned .","['pgcli/pgcompleter.py', 'tests/test_plan.wiki', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 505 from koljonen/drop_asterisk_column_suggestion
320,d378ddf55951f010092627158d12a3160c752ade,2016-05-17 20:32:10+01:00,"# def test_unicode_notices ( executor ) : services : title = title + self.conn.notices.pop ( ) # sql = `` DO language plpgsql $ $ BEGIN RAISE NOTICE '有人更改 ' ; END $ $ ; '' from .encodingutils import unicode2utf8 , PY2 addons : from .encodingutils import unicode2utf8 , PY2 , utf8tounicode title = title + utf8tounicode ( self.conn.notices.pop ( ) ) on_start : false # default : false # result = list ( executor.run ( sql ) ) on_start : false # default : false postgresql # assert result [ 0 ] [ 0 ] == u'NOTICE : 有人更改\n ' postgresql : `` 9.3 ''","['.travis.yml', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 504 from dbcli/amjith/unicode-notices
321,8d426c2db6391b3e0dea145998aebefee94a5376,2016-05-16 18:44:25-04:00,"assert set ( result ) == set ( [ import sqlparse import pprint Document ( text=text , cursor_position=pos ) , complete_event ) ) INNER JOIN set_returning_func ( ) f2 USING ( `` ' import pytest result = set ( completer.get_completions ( pos = len ( text ) def test_simple_update_table_no_schema ( ) : import stat text = `` 'SELECT * FROM set_returning_func ( ) f1 from prompt_toolkit.completion import Completion from prompt_toolkit.document import Document Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) , def test_join_functions_using_suggests_common_columns ( completer , complete_event ) : def test_simple_update_table ( ) : import pexpect Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) def test_simple_update_table_with_schema ( ) :","['pgcli/main.py', 'pgcli/pgexecute.py', 'tests/features/environment.py', 'tests/test_expanded.py', 'tests/test_fuzzy_completion.py', 'tests/test_main.py', 'tests/test_parseutils.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 502 from koljonen/cleanup
322,087fb1cb7d7c3c11026528f01859b76e35f2205f,2016-05-16 18:36:46-04:00,"# Return column names from a set-returning function # shadowing behavior , we need to check both views and tables for collist = ' , '.join ( c for c in flat_cols if c ! = ' * ' ) in Counter ( scoped_cols ) .items ( ) flat_cols = [ col for ( col , count ) sql = 'SELECT u . * FROM users u ' # We do n't know if schema.relname is a table or view . Since from collections import OrderedDict Document ( text=sql , cursor_position=pos ) , complete_event ) return self.find_matches ( word_before_cursor , flat_cols , meta='column ' ) scoped_cols = [ col for ( col , count ) functions = meta [ 'functions ' ] [ schema ] [ relname ] cols = ( ' '' select '' .id , `` select '' . `` insert '' , `` select '' . `` ABC '' , ' schemas = [ tbl.schema ] if tbl.schema else self.search_path def test_wildcard_column_expansion_with_alias_qualifier ( completer , complete_event ) : cols = meta [ reltype ] .get ( schema , { } ) .get ( relname ) for c in cs if c ! = ' * ' ) : return : dict { TableReference : [ list of column names ] } def addcols ( schema , rel , alias , reltype , cols ) : col_list = 'id , email , first_name , last_name ' 'users.id , users.phone_number ' ) functions = meta [ 'functions ' ] [ schema ] [ relname ] columns.extend ( func.fieldnames ( ) ) columns = [ ] and word_before_cursor [ -len ( lastword ) - 1 ] == ' . ' ) : for func in functions : if tbl not in columns : display= ' * ' , display_meta='columns ' ) ] pos = len ( 'SELECT users . * ' ) else : in Counter ( flat_cols ) .items ( ) for func in functions : # User typed x . * ; replicate `` x . '' for all columns except the assert expected == completions if tbl.schema : # first , which gets the original ( as we only replace the `` * '' '' ) return self.find_matches ( word_before_cursor , scoped_cols , meta='column ' ) : return : list of column names except ImportError : # Table exists , so do n't bother checking for a view # Get an array of FunctionMetadata objects except KeyError : collist = sep.join ( c for c in flat_cols if c ! = ' * ' ) if tbl.is_function : # one at a time flat_cols = list ( itertools.chain ( * scoped_cols.values ( ) ) ) sep = ' , ' + self.escape_name ( tables [ 0 ] .ref ) + ' . ' cols = func.fieldnames ( ) from .packages.parseutils import last_word # No such function name pos = len ( 'SELECT `` select '' . * ' ) schema = self.escape_name ( schema ) columns [ tbl ] = [ ] # Schema not specified , so traverse the search path looking for columns.extend ( meta [ 'views ' ] [ schema ] [ relname ] ) # Get an array of FunctionMetadata objects sql = 'SELECT users . * FROM users ' col_list = 'id , `` select '' . `` insert '' , `` select '' . `` ABC '' ' # a table or view that matches . Note that in order to get proper sql = 'SELECT * FROM users ' pos = len ( 'SELECT u . * ' ) col_list = 'id , u.email , u.first_name , u.last_name ' def test_wildcard_column_expansion_with_two_tables_and_parent ( completer , complete_event ) : for reltype in ( 'tables ' , 'views ' ) : continue lastword = last_word ( word_before_cursor , include='most_punctuations ' ) addcols ( schema , relname , tbl.alias , 'functions ' , cols ) col_list = 'id , p.product_name , p.price ' sql = 'SELECT * FROM `` select '' JOIN users u ON true ' try : columns.extend ( meta [ 'tables ' ] [ schema ] [ relname ] ) pass # Return column names from a set-returning function if cols : # each schema before checking the next schema sql = 'SELECT p. * FROM custom.products p ' sql = 'SELECT * FROM public . `` select '' JOIN custom.users ON true ' elif len ( scoped_cols ) > 1 : expected = [ Completion ( text=cols , start_position=-1 , sql = 'SELECT `` select '' . * FROM public . `` select '' ' display= ' * ' , display_meta='columns ' ) ] completions = completer.get_completions ( def test_wildcard_column_expansion_with_two_tables ( completer , complete_event ) : assert completions == expected # Plain columns columns.extend ( func.fieldnames ( ) ) sql = 'SELECT `` select '' . * FROM public . `` select '' JOIN custom.users u ON true ' # A fully qualified schema.relname reference def test_wildcard_column_expansion_with_table_qualifier ( completer , complete_event ) : expected = [ Completion ( text=col_list , start_position=-1 , Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) ] ) else : display_meta='columns ' , display= ' * ' ) , priority= ( 1,1,1 ) ) ] # func is a FunctionMetadata object else : columns.extend ( meta [ 'tables ' ] [ schema ] [ relname ] ) for schema in schemas : for func in ( functions or [ ] ) : return [ Match ( completion=Completion ( collist , -1 , collist = ' , '.join ( t.ref + ' . ' + c for t , cs in colit ( ) Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) ] ) schema = self.escape_name ( tbl.schema ) # Multiple tables ; qualify all columns pos = len ( 'SELECT p. * ' ) sql = 'SELECT `` select '' . * FROM `` select '' JOIN users u ON true ' pass def test_wildcard_column_expansion ( completer , complete_event ) : columns = OrderedDict ( ) for schema in self.search_path : if ( lastword ! = word_before_cursor and len ( tables ) == 1 col_list = 'id , users.email , users.first_name , users.last_name ' sql = 'SELECT * FROM custom.set_returning_func ( ) ' columns.extend ( meta [ 'views ' ] [ schema ] [ relname ] ) relname = self.escape_name ( tbl.name ) try : addcols ( schema , relname , tbl.alias , reltype , cols ) TableReference.ref = property ( lambda self : self.alias or self.name ) col_list = ' x ' colit = scoped_cols.items pos = len ( 'SELECT * ' ) if lastword == ' * ' : # tables and views can not share the same name , we can check continue functions = meta [ 'functions ' ] .get ( schema , { } ) .get ( relname ) try : tbl = TableReference ( schema , rel , alias , reltype == 'functions ' ) from .packages.parseutils import last_word , TableReference except KeyError : break ' u.id , u.email , u.first_name , u.last_name ' ) from .packages.ordereddict import OrderedDict columns [ tbl ] .extend ( cols )","['pgcli/packages/parseutils.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 492 from koljonen/master
323,5844690138de221c80be35a6b96382c666878a9c,2016-05-15 14:44:15-04:00,"] ) def test_join_using_suggests_columns_after_first_column ( completer , complete_event , text ) : text = 'SELECT * FROM users INNER JOIN orders USING ( ' def test_join_using_suggests_common_columns ( completer , complete_event , text ) : 'SELECT * FROM users INNER JOIN orders USING ( id , ' , def test_join_using_suggests_common_columns ( completer , complete_event ) : if prev_tok and prev_tok.value and prev_tok.value.lower ( ) == 'using ' : text = 'SELECT * FROM users INNER JOIN orders USING ( id , ' 'SELECT * FROM users INNER JOIN orders USING ( ' , 'SELECT * FROM users INNER JOIN orders USING ( id , ' , if ( prev_tok and prev_tok.value and prev_tok.value.lower ( ) .split ( ' ' ) [ -1 ] == 'using ' ) : def test_join_using_suggests_columns_after_first_column ( completer , complete_event ) : 'SELECT * FROM users INNER JOIN orders USING ( ' ,","['pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 501 from koljonen/fixusing
324,30727196ed68a97b7b14b3bfd457337c4a7103ec,2016-05-15 13:01:10-04:00,"'custom_func2 ' , filt = lambda f : not f.is_aggregate and not f.is_window 'custom_func1 ' , Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) , suggest.append ( Function ( schema=schema , filter='is_set_returning ' ) ) Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) , # Only suggest functions allowed in FROM clause Completion ( text='custom_func1 ' , start_position=0 , display_meta='function ' ) , suggest.append ( Function ( schema=schema , filter='for_from_clause ' ) ) Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) , # Only suggest set-returning functions if suggestion.filter == 'is_set_returning ' : Completion ( text='func3 ' , start_position=start_pos , display_meta='function ' ) , if suggestion.filter == 'for_from_clause ' : Function ( schema=None , filter='for_from_clause ' ) , Function ( schema='sch ' , filter='for_from_clause ' ) , Function ( schema=None , filter='is_set_returning ' ) , Function ( schema=None , filter='is_set_returning ' ) , Function ( schema='sch ' , filter='is_set_returning ' ) , Completion ( text='func1 ' , start_position=0 , display_meta='function ' ) , Function ( schema=None , filter='for_from_clause ' ) , filt = operator.attrgetter ( 'is_set_returning ' ) Completion ( text='func1 ' , start_position=0 , display_meta='function ' ) ,","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 497 from koljonen/allownonsetreturningfunctionsinfromclause
325,cd6d1d2f2a2423db74e18b149787b2efcca442a3,2016-05-15 04:35:16-07:00,"mock_connect.assert_called_with ( 'testdb [ ' , 'baz.com ' , 'bar^ ' , None , ' ] foo ' ) # unquote each URI part ( they may be percent encoded ) with mock.patch.object ( PGCli , 'connect ' ) as mock_connect : import mock self.connect ( * list ( map ( lambda p : unquote ( p ) if p else p , arguments ) ) ) from urlparse import urlparse arguments = [ database , uri.hostname , uri.username , uri.port , uri.password ] def test_quoted_db_uri ( tmpdir ) : from urlparse import urlparse , unquote cli = PGCli ( pgclirc_file=str ( tmpdir.join ( `` rcfile '' ) ) ) uri.port , uri.password ) from urllib.parse import urlparse from urllib.parse import urlparse , unquote self.connect ( database , uri.hostname , uri.username ,","['pgcli/main.py', 'tests/test_main.py']",Merge pull request # 488 from asfaltboy/feature/support-quoted-URI
326,c53221c38574711cdbd9e30ab1705967d4e96288,2016-05-09 21:02:49-07:00,"'prompt_toolkit > =1.0.0 , < 1.1.0 ' , from prompt_toolkit.shortcuts import create_prompt_layout enable_abort_and_exit_bindings=True ) from prompt_toolkit.enums import DEFAULT_BUFFER , EditingMode eventloop=self.eventloop ) ignore_case=True , 'prompt_toolkit==0.60 ' , vi_mode = not get_vi_mode_enabled ( ) document = self.cli.run ( ) event.cli.editing_mode = EditingMode.VI if vi_mode else EditingMode.EMACS cli = CommandLineInterface ( application=application , enable_vi_mode=Condition ( lambda cli : get_vi_mode_enabled ( ) ) ) set_vi_mode_enabled ( not get_vi_mode_enabled ( ) ) set_vi_mode_enabled ( vi_mode ) from prompt_toolkit.enums import DEFAULT_BUFFER from prompt_toolkit.enums import EditingMode editing_mode=editing_mode ) document = self.cli.run ( True ) from prompt_toolkit.shortcuts import create_prompt_layout , create_eventloop editing_mode = EditingMode.VI if self.vi_mode else EditingMode.EMACS cli = CommandLineInterface ( application=application ) enable_abort_and_exit_bindings=True , ignore_case=True ) self.eventloop = create_eventloop ( )","['pgcli/key_bindings.py', 'pgcli/main.py', 'setup.py']",Merge pull request # 490 from jonathanslenders/prompt-toolkit-1.0.0
327,64c50cfd35016b24d09f1fcf60e8d6fc2d0685b4,2016-04-26 10:05:23-07:00,"# Always set default set of less recommended options , they are ignored if pager is with open ( self.output_file , ' a ' ) as f : # different than less or is already parameterized with their own arguments # different than less or is already parameterized with their own arguments # Always set default set of less recommended options , they are ignored if pager is with open ( self.output_file , ' a ' , encoding='utf-8 ' ) as f :",['pgcli/main.py'],Merge pull request # 487 from dbcli/amjith/output_file_encoding
328,9c42a8ab29f0727cf82ecbf4946eba3007f4e21c,2016-04-24 16:03:22-07:00,"return [ ( None , None , None , message , `` , False ) ] 'Send all query results to file . ' ) open ( filename , ' w ' ) .close ( ) click.echo ( `` , file=f ) # extra newline return [ ( None , None , None , message , `` , True ) ] try : except IOError as e : click.echo ( '\n'.join ( output ) , file=f ) with open ( self.output_file , ' a ' ) as f : def write_to_file ( self , pattern , * * _ ) : message = str ( e ) + '\nFile output disabled ' self.pgspecial.register ( self.write_to_file , '\\o ' , '\\o [ filename ] ' , self.output_file = None click.echo_via_pager ( '\n'.join ( output ) ) if self.output_file and not document.text.startswith ( ( '\\o ' , '\\ ? ' ) ) : click.secho ( str ( e ) , err=True , fg='red ' ) self.output_file = None message = 'Writing to file `` % s '' ' % self.output_file if not os.path.isfile ( filename ) : return [ ( None , None , None , message , `` , True ) ] click.echo_via_pager ( '\n'.join ( output ) ) filename = os.path.abspath ( os.path.expanduser ( pattern ) ) else : except IOError as e : click.echo ( document.text , file=f ) try : message = 'File output disabled ' if not pattern : self.output_file = None self.output_file = filename",['pgcli/main.py'],Merge pull request # 483 from Gollum999/master
329,2547ac8682f3ec1f95e1ff365f858bad6807de6d,2016-04-04 19:13:42-07:00,"for c in completer.get_completions ( document , None ) : yield Match ( completion=c , priority = None ) document = Document ( text=word_before_cursor , Keyword , NamedQuery , Datatype , Alias , Path ) return ( Path ( ) , ) def get_path_matches ( self , _ , word_before_cursor ) : from prompt_toolkit.contrib.completers import PathCompleter cursor_position=len ( word_before_cursor ) ) completer = PathCompleter ( expanduser=True ) Path : get_path_matches , Keyword , NamedQuery , Datatype , Alias ) from prompt_toolkit.document import Document if full_text.startswith ( '\\i ' ) : Path = namedtuple ( 'Path ' , [ ] )","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py']",Merge pull request # 480 from ajlai/add-i-autocompletion
330,60adc95ef1377f79f9cf7555b0e15762c7dbef70,2016-03-27 20:21:26-07:00,"cfg = load_config ( config_full_path ) pgcli.connect_uri ( dsn_config ) if dsn is not `` : username , version , pgclirc , dsn ) : exit ( 1 ) if ' : // ' in database : 'Please check the `` [ alias_dsn ] '' section in pgclirc . ' , elif ' : // ' in database : # DNS to call by -D option [ alias_dsn ] click.secho ( 'Invalid DSNs found in the config file . '\ try : dsn_config = cfg [ 'alias_dsn ' ] [ dsn ] help='Use DSN configured into the [ alias_dsn ] section of pgclirc file . ' ) err=True , fg='red ' ) username , version , pgclirc ) : except :","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 482 from roramirez/dsn_config
331,96747e44d46d99a91879587d311578ecd4664645,2016-03-23 20:42:34-07:00,"collection = [ 'Foo ' , 'FOO ' , 'fOO ' ] `` `` '' Fuzzy matching should keep matches even if letter casing does n't match . `` `` '' matches = completer.find_matches ( text , collection ) text = 'foo ' r = pat.search ( self.unescape_name ( item ) ) def test_matching_should_be_case_insensitive ( completer ) : r = pat.search ( self.unescape_name ( item.lower ( ) ) ) This test checks that variations of the text which have different casing are still matched . assert len ( matches ) == 3","['pgcli/pgcompleter.py', 'tests/test_fuzzy_completion.py']",Merge pull request # 479 from ajlai/fix-478
332,289d960114ae59f8247f160e15871673b7751b3c,2016-03-22 22:37:13-07:00,"# with the same match group length and start position . In Python , : : up for the first time , then do : or That will create a .deb file and a .rpm file . : : to you . # with 1 to prioritize shorter strings ( ie `` user '' > `` users '' ) . 'public ' , effects of your change . # Lexical order of items in the collection , used for tiebreaking items ' '' select '' ' , Document ( text=text , cursor_position=position ) , assert [ c.text for c in result ] == [ up for the first time , then do : text = 'SELECT * FROM ' That will create a .deb file and a .rpm file . origin master `` to keep your own fork up to date . priority = sort_key , priority_func ( item ) , lexical_order [ item ] ] 'user_emails ' , effects of your change . priority = sort_key , priority_func ( item ) , lexical_priority origin master `` to keep your own fork up to date . or permissions to create and drop test database . Dafault user is `` postgres `` # usual position ranking , hence -position . # Lexical order of items in the collection , used for to you . def test_table_names_after_from_are_lexical_ordered_by_text ( completer , complete_event ) : result = completer.get_completions ( permissions to create and drop test database . Default user is `` postgres `` DEB or RPM package , then you can do : complete_event ) lexical_order = dict ( [ ( name , -position ) for position , name in 'set_returning_func ' , # important , '' we use -ord ( c ) to prioritize `` aa '' > `` ab '' and end enumerate ( sorted ( collection ) ) ] ) DEB or RPM package , then you can do : 'users ' # 'user ' < 'users ' , i.e . the `` lower '' value comes first . Since we use # * higher * priority to mean `` more important , '' we need to flip Python 's # position . Since we use * higher * priority to mean `` more # tiebreaking items with the same match group length and start 'orders ' , lexical_priority = tuple ( -ord ( c ) for c in self.unescape_name ( item ) ) + ( 1 , ) # We also use the unescape_name to make sure quoted names have # the same priority as unquoted names . position = len ( 'SELECT * FROM ' )","['DEVELOP.rst', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 477 from ajlai/fix-lexical-order-tiebreaking
333,c3a7284bc8bbd58b68dd885b5339d8c29685bd6d,2016-03-18 11:37:12-07:00,"'prompt_toolkit==0.60 ' , get_continuation_tokens=get_continuation_tokens , return [ ( Token.Continuation , ' . ' * ( width - 1 ) + ' ' ) ] 'prompt_toolkit==0.57 ' , def get_continuation_tokens ( cli , width ) :","['pgcli/main.py', 'setup.py']",Merge pull request # 476 from jonathanslenders/prompt_toolkit_0.60
334,ccf3693be62dd8a79ced19ed9d69f0708d2b3d6f,2016-02-28 21:53:05-08:00,"timestamptz_oid = cursor.description [ 0 ] [ 1 ] def test_bc_dates ( executor ) : == `` | 00:00:00+14:59 | '' oids = ( date_oid , timestamp_oid ) cursor.execute ( 'SELECT NULL : :timestamptz ' ) assert run ( executor , `` SELECT ( CAST ( '4713-01-01 00:00:00 BC ' AS timestamp ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ assert result.split ( `` \n '' ) [ 3 ] == `` | 0001-01-01 BC | '' run ( executor , `` SET TIME ZONE UTC '' ) oids = ( date_oid , timestamp_oid , timestamptz_oid ) assert run ( executor , `` SELECT ( CAST ( '00:00:00 ' AS time ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ result = run ( executor , `` SELECT d FROM bc_date_test LIMIT 1 '' , join=True ) def test_date_time_types ( executor ) : assert run ( executor , `` SELECT ( CAST ( '00:00:00+14:59 ' AS timetz ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ == `` | 4713-01-01 00:00:00 BC | '' == `` | 00:00:00 | '' == `` | 4713-01-01 00:00:00+00 BC | '' assert run ( executor , `` SELECT ( CAST ( '4713-01-01 00:00:00+00 BC ' AS timestamptz ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ run ( executor , `` insert into bc_date_test ( d ) values ( '0001-01-01 00:00:00 BC ' ) '' ) assert run ( executor , `` SELECT ( CAST ( '-123456789 days 12:23:56 ' AS interval ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ == `` | -123456789 days , 12:23:56 | '' == `` | 4713-01-01 BC | '' assert run ( executor , `` SELECT ( CAST ( '4713-01-01 BC ' AS date ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ run ( executor , `` create table bc_date_test ( d DATE ) '' )","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 470 from fernandomora/master
335,5f4bded5999b0e93097384be029f0e6912425e8a,2016-02-26 16:21:27+01:00,"timestamptz_oid = cursor.description [ 0 ] [ 1 ] def test_bc_dates ( executor ) : == `` | 00:00:00+14:59 | '' oids = ( date_oid , timestamp_oid ) cursor.execute ( 'SELECT NULL : :timestamptz ' ) assert run ( executor , `` SELECT ( CAST ( '4713-01-01 00:00:00 BC ' AS timestamp ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ assert result.split ( `` \n '' ) [ 3 ] == `` | 0001-01-01 BC | '' run ( executor , `` SET TIME ZONE UTC '' ) oids = ( date_oid , timestamp_oid , timestamptz_oid ) def test_bc_timestamps ( executor ) : assert run ( executor , `` SELECT ( CAST ( '00:00:00 ' AS time ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ result = run ( executor , `` SELECT d FROM bc_date_test LIMIT 1 '' , join=True ) assert run ( executor , `` SELECT ( CAST ( '00:00:00+14:59 ' AS timetz ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ == `` | 4713-01-01 00:00:00 BC | '' == `` | 00:00:00 | '' == `` | 4713-01-01 00:00:00+00 BC | '' assert run ( executor , `` SELECT ( CAST ( '4713-01-01 00:00:00+00 BC ' AS timestamptz ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ run ( executor , `` insert into bc_date_test ( d ) values ( '0001-01-01 00:00:00 BC ' ) '' ) assert run ( executor , `` SELECT ( CAST ( '-123456789 days 12:23:56 ' AS interval ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ == `` | -123456789 days , 12:23:56 | '' == `` | 4713-01-01 BC | '' assert run ( executor , `` SELECT ( CAST ( '4713-01-01 BC ' AS date ) ) '' , join=True ) .split ( `` \n '' ) [ 3 ] \ run ( executor , `` create table bc_date_test ( d DATE ) '' )","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Issue # 448 . Add timestamptz to DATE custom extension
336,484108c549c845bdcea263b80979a51b09760663,2016-02-15 07:53:30-08:00,"priority = sort_key , priority_func ( item ) , lexical_order [ item ] text = 'user ' # usual position ranking , hence -position . lexically . `` `` '' enumerate ( sorted ( collection ) ) ] ) The input collections to this test are out of order ; each run checks that # with the same match group length and start position . In Python , [ 'user_group ' , 'user ' ] , search for the text 'user ' should present these tables in this order . assert matches [ 1 ] .priority > matches [ 0 ] .priority When fuzzy matching , if multiple matches have the same match length and [ 'user_group ' , 'user_action ' ] , # * higher * priority to mean `` more important , '' we need to flip Python 's ] ) lexical_order = dict ( [ ( name , -position ) for position , name in [ 'user_action ' , 'user ' ] , the search text 'user ' results in the input tables being reordered start position , present them in lexical ( rather than arbitrary ) order . For priority=priority ) ) # 'user ' < 'users ' , i.e . the `` lower '' value comes first . Since we use example , if we have tables 'user ' , 'user_action ' , and 'user_group ' , a matches = completer.find_matches ( text , collection ) `` `` '' Fuzzy result rank should use lexical order to break ties . priority= ( sort_key , priority_func ( item ) ) ) ) # Lexical order of items in the collection , used for tiebreaking items def test_should_break_ties_using_lexical_order ( completer , collection ) :","['pgcli/pgcompleter.py', 'tests/test_fuzzy_completion.py']",Merge pull request # 461 from drocco007/master
337,18186f645228a73bf90e75f0397e1947fbb6f61b,2016-02-08 07:46:56-05:00,"FROM pg_catalog.pg_proc p ON p.prorettype = t.oid OR ( -- composite type , but not a table databases_query = `` '' '' SELECT d.datname as `` Name '' , INNER JOIN pg_catalog.pg_namespace n WHERE ( t.typrelid = 0 -- non-composite types INNER JOIN pg_catalog.pg_namespace n p.proisagg is_aggregate , yield FunctionMetadata ( * row ) oidvectortypes ( p.proargtypes ) proargtypes , INNER JOIN pg_catalog.pg_namespace n AND n.nspname < > 'pg_catalog ' WHERE ( t.typrelid = 0 -- non-composite types query = `` ' FROM pg_catalog.pg_database d ) p.proretset is_set_returning FROM pg_catalog.pg_type t typed_args = [ f [ 0 ] + ' , ' + f [ 1 ] for f in args ] _logger.debug ( 'Search path query . sql : % r ' , self.search_path_query ) ' '' FROM pg_catalog.pg_type el ORDER BY 1 , 2 p.proname func_name , INNER JOIN pg_catalog.pg_type t _logger.debug ( 'Search path query . sql : % r ' , fallback ) _logger.debug ( arg_list ) pg_catalog.pg_get_userbyid ( d.datdba ) as `` Owner '' , names = row [ 2 ] if row [ 2 ] is not None else [ ] pg_catalog.pg_get_function_arguments ( p.oid ) arg_list , WHERE ( t.typrelid = 0 OR ( SELECT c.relkind = ' c ' FROM pg_catalog.pg_class c WHERE c.oid = t.typrelid ) ) AND NOT EXISTS ( -- ignore array types FROM pg_catalog.pg_type t return cur.fetchone ( ) [ 0 ] WHERE c.oid = t.typrelid args = itertools.izip_longest ( names , row [ 3 ] .split ( ' , ' ) , `` ) FROM pg_catalog.pg_class c except psycopg2.ProgrammingError : return [ x [ 0 ] for x in cur.fetchall ( ) ] FROM pg_catalog.pg_type t try : cur.execute ( fallback ) ) d.datctype as `` Ctype '' , ) if self.conn.server_version > 90000 : pg_catalog.format_type ( t.oid , NULL ) type_name import itertools pg_catalog.pg_encoding_to_char ( d.encoding ) as `` Encoding '' , ON n.oid = t.typnamespace cur.execute ( self.functions_query ) FROM pg_catalog.pg_class c import pprint with self.conn.cursor ( ) as cur : _logger.debug ( 'Search path query . sql : % r ' , self.search_path_query ) AND n.nspname < > 'information_schema ' return [ x [ 0 ] for x in cur.fetchall ( ) ] _logger.debug ( 'Datatypes Query . sql : % r ' , self.datatypes_query ) t.typname type_name WHERE c.relkind = ANY ( % s ) pg_catalog.pg_get_function_result ( p.oid ) return_type , p.proisagg is_aggregate , with self.conn.cursor ( ) as cur : FROM pg_catalog.pg_attribute att cur.execute ( self.search_path_query ) AND pg_catalog.pg_type_is_visible ( t.oid ) yield FunctionMetadata ( row [ 0 ] , row [ 1 ] , arg_list , row [ 4 ] , row [ 5 ] , row [ 6 ] , row [ 7 ] ) functions_query = `` ' d.datcollate as `` Collate '' , _logger.debug ( list ( args ) ) ON n.oid = t.typnamespace SELECT nsp.nspname schema_name , t.typname type_name ORDER BY 1 , 2 '' ' FROM pg_catalog.pg_proc p WHERE c.relkind = ANY ( % s ) FROM pg_catalog.pg_class c ON n.oid = p.pronamespace WHERE el.oid = t.typelem AND el.typarray = t.oid SELECT n.nspname schema_name , SELECT nsp.nspname schema_name , WHERE c.oid = t.typrelid cur.execute ( self.datatypes_query ) for row in cur : SELECT c.relkind = ' c ' ON n.oid = p.pronamespace databases_query = `` ' INNER JOIN pg_catalog.pg_namespace n AND NOT EXISTS ( -- ignore array types p.proiswindow is_window , ORDER BY 1 , 2 ; ) cur.execute ( self.search_path_query ) _logger.debug ( 'Functions Query . sql : % r ' , self.functions_query ) else : ORDER BY 1 , 2 ; ' '' INNER JOIN pg_catalog.pg_namespace n arg_list = ' , '.join ( typed_args ) for row in cur : SELECT n.nspname schema_name , ) FROM pg_catalog.pg_class c AND n.nspname < > 'pg_catalog ' SELECT n.nspname schema_name , yield FunctionMetadata ( * row ) SELECT d.datname ORDER BY 1 ; '' '' '' cur.execute ( query ) fallback = 'SELECT * FROM current_schemas ( true ) ' _logger.debug ( 'Datatypes Query . sql : % r ' , query ) SELECT 1 pg_catalog.array_to_string ( d.datacl , E'\n ' ) AS `` Access privileges '' FROM pg_catalog.pg_type el p.proname func_name , SELECT c.relkind = ' c ' pg_catalog.pg_get_function_arguments ( p.oid ) arg_list , p.proiswindow is_window , ORDER BY 1 '' ' t.typname return_type , FROM pg_catalog.pg_database d LEFT JOIN pg_catalog.pg_namespace n ON n.oid = t.typnamespace AND t.typname ! ~ '^_ ' datatypes_query = `` ' cur.execute ( query ) FROM pg_catalog.pg_attribute att WHERE el.oid = t.typelem AND el.typarray = t.oid ) ' '' _logger.debug ( 'Functions Query . sql : % r ' , query ) SELECT n.nspname schema_name , false is_window , SELECT 1 AND n.nspname < > 'information_schema ' p.proretset is_set_returning WHERE cls.relkind = ANY ( % s ) OR ( -- composite type , but not a table p.proargnames , WHERE cls.relkind = ANY ( % s ) pg_catalog.pg_get_function_result ( p.oid ) return_type , ON n.oid = p.pronamespace",['pgcli/pgexecute.py'],Merge pull request # 451 from timcleaver/master
338,fea50b59dbc49b2f0c1ee6b963f71d19cfa846b3,2016-02-03 19:23:22-08:00,"timestamp_oid = cursor.description [ 0 ] [ 1 ] Casts date and timestamp values to string , resolves issues with out of def cast_date ( value , cursor ) : `` `` '' run ( executor , `` create table bc_date_test ( d DATE ) '' ) result = run ( executor , `` SELECT d FROM bc_date_test LIMIT 1 '' , join=True ) run ( executor , `` insert into bc_date_test ( d ) values ( '0001-01-01 00:00:00 BC ' ) '' ) cursor = connection.cursor ( ) def register_date_typecasters ( connection ) : return value oids = ( date_oid , timestamp_oid ) def test_bc_dates ( executor ) : psycopg2.extensions.register_type ( new_type ) assert result.split ( `` \n '' ) [ 3 ] == `` | 0001-01-01 BC | '' register_date_typecasters ( conn ) cursor.execute ( 'SELECT NULL : :date ' ) range dates ( e.g . BC ) which psycopg2 ca n't handle cursor.execute ( 'SELECT NULL : :timestamp ' ) new_type = psycopg2.extensions.new_type ( oids , 'DATE ' , cast_date ) date_oid = cursor.description [ 0 ] [ 1 ]","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 457 from dbcli/stuartquin/cast-bc-dates
339,becd32cc4bf4424dcfaf4b9a495ad0ea97d29886,2016-02-03 19:21:29-08:00,"from .config import write_default_config , load_config , config_location import platform def test_ensure_existing_dir ( tmpdir ) : PGCli ( pgclirc_file=rcfile ) except OSError as exc : # trigger an oserror that is n't `` directory already exists '' ) ensure_dir_exists ( destination ) pgclirc_file=rcfile , import stat from pgcli.config import config_location rcfile = str ( tmpdir.join ( `` subdir '' ) .join ( `` rcfile '' ) ) rcfile = subdir.join ( `` rcfile '' ) write_default_config , load_config , config_location , ensure_dir_exists , from .config import ( def test_ensure_file_parent ( tmpdir ) : pgclirc_file=config_location ( ) , ensure_dir_exists ( log_file ) with pytest.raises ( OSError ) : ensure_dir_exists ( str ( rcfile ) ) import errno # should just not raise from pgcli.config import ensure_dir_exists raise from os.path import expanduser , exists , dirname def test_missing_rc_dir ( tmpdir ) : rcfile = str ( tmpdir.join ( `` rcfile '' ) ) parent_dir = dirname ( path ) def ensure_dir_exists ( path ) : def test_ensure_other_create_error ( tmpdir ) : rcfile = str ( tmpdir.mkdir ( `` subdir '' ) .join ( `` rcfile '' ) ) import pytest assert os.path.exists ( rcfile ) from os.path import expanduser , exists ensure_dir_exists ( str ( rcfile ) ) os.makedirs ( parent_dir ) # ignore existing destination ( py2 has no exist_ok arg to makedirs ) ensure_dir_exists ( rcfile ) subdir = tmpdir.join ( `` subdir '' ) os.chmod ( str ( tmpdir ) , stat.S_IREAD ) statement = r '' \i { } '' .format ( sqlfile ) import platform statement = r '' \i { 0 } '' .format ( sqlfile ) try : if exc.errno ! = errno.EEXIST : import os","['pgcli/config.py', 'pgcli/main.py', 'tests/test_config.py', 'tests/test_main.py']",Merge pull request # 458 from davidszotten/ensure_config_targetdir
340,cd678d9756c88c2bc27ccde09136b76edadd2920,2016-02-03 09:07:50-05:00,"return [ ( None , None , None , message ) ] return [ ( None , None , None , message , `` , False ) ] return [ ( None , None , None , str ( e ) , `` , False ) ] return [ ( None , None , None , str ( e ) ) ]",['pgcli/main.py'],Merge pull request # 453 from dbcli/amjith/execute_from_file_corner_case
341,37c10e45c8fea5753f1a412f052e840cf53b8833,2016-02-03 10:57:36+00:00,"timestamp_oid = cursor.description [ 0 ] [ 1 ] Casts date and timestamp values to string , resolves issues with out of def cast_date ( value , cursor ) : `` `` '' run ( executor , `` create table bc_date_test ( d DATE ) '' ) result = run ( executor , `` SELECT d FROM bc_date_test LIMIT 1 '' , join=True ) run ( executor , `` insert into bc_date_test ( d ) values ( '0001-01-01 00:00:00 BC ' ) '' ) cursor = connection.cursor ( ) def register_date_typecasters ( connection ) : return value oids = ( date_oid , timestamp_oid ) def test_bc_dates ( executor ) : psycopg2.extensions.register_type ( new_type ) assert result.split ( `` \n '' ) [ 3 ] == `` | 0001-01-01 BC | '' register_date_typecasters ( conn ) cursor.execute ( 'SELECT NULL : :date ' ) range dates ( e.g . BC ) which psycopg2 ca n't handle cursor.execute ( 'SELECT NULL : :timestamp ' ) new_type = psycopg2.extensions.new_type ( oids , 'DATE ' , cast_date ) date_oid = cursor.description [ 0 ] [ 1 ]","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Issue # 448 extension for BC dates
342,1fc381a84316bbbd9cb938e09bb9290d52a5bc85,2016-02-02 22:47:35-08:00,"self.logger = logging.getLogger ( __name__ ) configured_pager = config [ 'main ' ] .get ( 'pager ' ) os.environ [ 'LESS ' ] = '-SRXF ' elif ( os_environ_pager ) : c = self.config = load_config ( pgclirc_file , default_config ) original_less_opts = self.adjust_less_opts ( ) c = self.config = load_config ( pgclirc_file , default_config ) finally : # Reset the less opts back to original . self.set_default_pager ( c ) # Default pager . class PGCli ( object ) : self.logger = logging.getLogger ( __name__ ) self.logger.info ( 'Default pager found in config file : ' + '\ '' + configured_pager + '\ '' ) # By default 'PAGER ' environment variable is used os.environ [ 'LESS ' ] = '-SRXF ' def adjust_less_opts ( self ) : # pager = less -SRXF class PGCli ( object ) : def set_default_pager ( self , config ) : self.logger.info ( 'No default pager found in environment . Using os default pager ' ) self.initialize_logging ( ) self.logger.info ( 'Default pager found in PAGER environment variable : ' + '\ '' + os_environ_pager + '\ '' ) os.environ [ 'LESS ' ] = original_less_opts # different than less or is already parameterized with their own arguments os_environ_pager = os.environ.get ( 'PAGER ' ) if configured_pager : # Load config . os.environ [ 'PAGER ' ] = os_environ_pager return less_opts self.logger.debug ( 'Original value for LESS env var : % r ' , less_opts ) os.environ [ 'PAGER ' ] = configured_pager # Load config . # Always set default set of less recommended options , they are ignored if pager is self.initialize_logging ( ) less_opts = os.environ.get ( 'LESS ' , `` ) logger.debug ( 'Restoring env var LESS to % r . ' , original_less_opts ) else :","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 452 from fernandomora/default-pager-on-pgclirc
343,bc21511c5cce21aebae0e432ec52b963be180ab0,2016-02-02 18:55:16-08:00,"cli = PGCli ( from pgcli.main import obfuscate_process_password , format_output , PGCli from pgcli.main import obfuscate_process_password , format_output sqlfile.write ( `` SELECT NOW ( ) '' ) statement = r '' \i { } '' .format ( sqlfile ) from pgcli.config import config_location def test_i_works ( tmpdir , executor ) : pgexecute=executor , ) run ( executor , statement , pgspecial=cli.pgspecial ) from utils import dbtest , run pgclirc_file=config_location ( ) , sqlfile = tmpdir.join ( `` test.sql '' )",['tests/test_main.py'],Merge pull request # 456 from davidszotten/test_execute_from_file
344,f8ba5c6f54ae44aa5bf74b6ef6a3d9cb871ec524,2016-02-01 21:23:58-08:00,"yield result + ( sql , True ) return self.pgexecute.run ( query , self.pgspecial , on_error=self.on_error ) yield result + ( sql , True ) query , self.pgspecial , on_error_resume=on_error_resume else : return self.pgexecute.run ( # e.g . execute_from_file already appends these on_error_resume = ( self.on_error == 'RESUME ' ) if len ( result ) < 6 : yield result )","['pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 449 from davidszotten/fix_execute_from_file
345,02987e27ccc411e020156bd8e9cff794f6bbeba9,2016-01-25 19:10:02+00:00,"yield result + ( sql , True ) return self.pgexecute.run ( query , self.pgspecial , on_error=self.on_error ) yield result + ( sql , True ) query , self.pgspecial , on_error_resume=on_error_resume else : return self.pgexecute.run ( # e.g . execute_from_file already appends these on_error_resume = ( self.on_error == 'RESUME ' ) if len ( result ) < 6 : yield result )","['pgcli/main.py', 'pgcli/pgexecute.py']",fix execute_from_file after # 395
346,9d87e8fd6ffa4c0ab66dd6c399ee3a276302942a,2016-01-18 07:22:05-08:00,"from prompt_toolkit.buffer import AcceptAction layout = create_prompt_layout ( pygments_style_cls=style ) lexer=PostgresLexer , on_abort=AbortAction.RETRY , enable_abort_and_exit_bindings=True , cli = CommandLineInterface ( from prompt_toolkit.styles import default_style_extensions from prompt_toolkit.layout.lexers import PygmentsLexer if cli.buffers [ DEFAULT_BUFFER ] .always_multiline : if cli.buffers [ DEFAULT_BUFFER ] .completer.smart_completion : custom_styles = dict ( [ ( string_to_tokentype ( x ) , y ) from prompt_toolkit.shortcuts import create_prompt_layout for x , y in cli_style.items ( ) ] ) reserve_space_for_menu=True , for x , y in cli_style.items ( ) ] ) custom_styles = dict ( [ ( string_to_tokentype ( x ) , y ) if cli.buffers [ 'default ' ] .always_multiline : styles.update ( style.styles ) from prompt_toolkit.shortcuts import create_default_layout , create_eventloop from prompt_toolkit.enums import DEFAULT_BUFFER cli = CommandLineInterface ( application=application ) styles.update ( default_style_extensions ) eventloop=create_eventloop ( ) ) from pygments.style import Style return PGStyle lexer=PygmentsLexer ( PostgresLexer ) , reserve_space_for_menu=4 , class PGStyle ( Style ) : return PygmentsStyle.from_defaults ( style_dict=custom_styles , 'prompt_toolkit==0.46 ' , styles = { } if cli.buffers [ 'default ' ] .completer.smart_completion : layout = create_default_layout ( application=application , styles.update ( custom_styles ) complete_while_typing=Always ( ) ) from prompt_toolkit.styles import PygmentsStyle accept_action=AcceptAction.RETURN_DOCUMENT ) complete_while_typing=Always ( ) , 'prompt_toolkit==0.57 ' , enable_search=True ,","['pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgstyle.py', 'pgcli/pgtoolbar.py', 'setup.py']",Merge pull request # 442 from jonathanslenders/prompt-toolkit-0.57
347,a27fe8f0508bd441c1af87015bddf6450ade9168,2016-01-13 10:12:44-08:00,"assert u'日本語 ' in run ( executor , `` SELECT * FROM person '' , join=True ) run ( executor , `` CREATE TABLE person ( name TEXT , current_mood mood ) '' ) def test_unicode_support_in_enum_type ( executor ) : run ( executor , `` INSERT INTO person VALUES ( 'Moe ' , '日本語 ' ) '' ) run ( executor , `` CREATE TYPE mood AS ENUM ( 'sad ' , 'ok ' , 'happy ' , '日本語 ' ) '' )",['tests/test_pgexecute.py'],Merge pull request # 441 from dbcli/amjith/unicode-enum
348,a6b8436c50103660ab61cdf73cb5e57b2b1e6699,2016-01-12 04:49:53-08:00,"plain_text = '\n'.join ( [ '\t'.join ( map ( _text_type_encode , headers ) ) ] + \ from .. encodingutils import utf8tounicode return _text_type ( val , `` utf-8 '' ) [ '\t'.join ( map ( _text_type , row ) ) for row in list_of_lists ] ) _text_type_encode = lambda x : _text_type ( utf8tounicode ( x ) ) [ '\t'.join ( map ( _text_type_encode , row ) ) for row in list_of_lists ] ) plain_text = '\n'.join ( [ '\t'.join ( map ( _text_type , headers ) ) ] + \ return _text_type ( val , `` ascii '' )",['pgcli/packages/tabulate.py'],Merge pull request # 438 from GTxx/enum_type_unicode
349,e14e97e4cd45445400322b270b631ebb4424e7bb,2016-01-06 14:38:44-08:00,"`` NOTICE '' , `` NOT '' , `` REPLACE '' , `` NOT '' , `` VARCHAR '' `` RAISE '' , `` VOID '' `` VARCHAR '' , `` RENAME '' , `` RENAME '' ,",['pgcli/packages/pgliterals/pgliterals.json'],Merge pull request # 436 from dbcli/amjith/keywords
350,cb65d2ca4a70ad9b387b1402e8f87909332abf9d,2016-01-06 16:35:00+08:00,"plain_text = '\n'.join ( [ '\t'.join ( map ( _text_type_encode , headers ) ) ] + \ from .. encodingutils import utf8tounicode return _text_type ( val , `` utf-8 '' ) [ '\t'.join ( map ( _text_type , row ) ) for row in list_of_lists ] ) _text_type_encode = lambda x : _text_type ( utf8tounicode ( x ) ) [ '\t'.join ( map ( _text_type_encode , row ) ) for row in list_of_lists ] ) plain_text = '\n'.join ( [ '\t'.join ( map ( _text_type , headers ) ) ] + \ return _text_type ( val , `` ascii '' )",['pgcli/packages/tabulate.py'],convert enum type to unicode in tabulate . # 437
351,f74e2f520f79f279807c122075aee3ccb8fcc6cb,2016-01-05 19:46:57-05:00,if not sql : # happens for e.g . parameter-less functions like now ( ) assert list ( names ) == [ ] def test_empty_arg_list ( ) : names = field_names ( `` ) return,"['pgcli/packages/function_metadata.py', 'tests/test_function_metadata.py']",Merge pull request # 435 from davidszotten/field_names_noparams
352,a54830fb654c3c415f20886f317e8a6443131368,2015-12-06 08:11:30-08:00,"title = title + self.conn.notices.pop ( ) # conn.notices persist between queies , we use pop to clear out the list except IndexError : title = None title = self.conn.notices.pop ( ) while len ( self.conn.notices ) > 0 : title = `` try :",['pgcli/pgexecute.py'],Merge pull request # 429 from dbcli/stuartquin/output-all-notices
353,218689dc20097d6ca275f3dc44caaf853fc3062e,2015-11-28 17:20:58-08:00,"sql = 'SELECT * FROM orders WHERE s ' Document ( text=sql , cursor_position=len ( sql ) ) , complete_event ) completions = completer.get_completions ( # Use negative infinity in second element to force keywords return -float ( 'Infinity ' ) , -match_point # Use negative infinity to force keywords to sort after all def test_columns_before_keywords ( completer , complete_event ) : # fuzzy matches assert completions.index ( column ) < completions.index ( keyword ) column = Completion ( text='status ' , start_position=-1 , display_meta='column ' ) # to sort after all fuzzy matches return -match_point , -float ( 'Infinity ' ) keyword = Completion ( text='SELECT ' , start_position=-1 , display_meta='keyword ' )","['pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 425 from dbcli/darikg/sort-kw-after-columns
354,afcec9536b0853e89cffdedeb41b526f4029965d,2015-11-28 17:16:10-08:00,"import humanize print ( 'Time : % 0.03fs ' % query.total_time ) humanize.time.naturaldelta ( query.total_time ) ) ) if query.total_time > 1 : print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , # Only add humanized time display if > 1 second print ( 'Time : % 0.03fs ' % query.total_time ) 'humanize > = 0.5.1 ' , else :","['pgcli/main.py', 'setup.py']",Merge pull request # 422 from dbcli/j-bennet/humanize-time
355,29d47ebf343547f1c0f0c7f4850c4113409e2844,2015-11-25 19:03:50-08:00,"assert tables == ( ( None , 'abc ' , None , False ) , ) item.value.upper ( ) in ( 'COPY ' , 'FROM ' , 'INTO ' , 'UPDATE ' , 'TABLE ' , 'JOIN ' , ) ) : tables = extract_tables ( sql ) item_val.endswith ( 'JOIN ' ) ) : t1.id = t2.t1_id def test_suggest_columns_after_three_way_join ( completer , complete_event ) : item_val = item.value.upper ( ) raise StopIteration assert Column ( tables= ( ( None , 't3 ' , None , False ) , ) ) in set ( suggestions ) suggestions = suggest_type ( sql , sql ) def test_incomplete_join_clause ( ) : ( None , 't1 ' , None , False ) , ( None , 'bcd ' , ' b ' , False ) ) assert ( Completion ( text='id ' , start_position=0 , display_meta='column ' ) in INNER JOIN users u3 ON u2.id = u3 . ' '' def test_multiple_joins ( ) : from abc a join bcd b tbl_prefix_seen = True t2.id = t3 . ' '' set ( result ) ) result = completer.get_completions ( assert tables == ( ( None , 't2 ' , None , False ) , def test_suggest_columns_after_multiple_joins ( ) : sql = `` 'select a.x , b.y text = `` 'SELECT * FROM users u1 assert tables == ( ( None , 'abc ' , ' a ' , False ) , ( None , 't3 ' , None , False ) ) elif ( ( item.ttype is Keyword or item.ttype is Keyword.DML ) and def test_subselect_tables ( ) : if ( item_val in ( 'COPY ' , 'FROM ' , 'INTO ' , 'UPDATE ' , 'TABLE ' ) or inner join t2 ON sql = 'SELECT * FROM ( SELECT FROM abc ' Document ( text=text , cursor_position=position ) , complete_event ) INNER JOIN users u2 ON u1.id = u2.id tbl_prefix_seen = True on a.id = `` ' inner join t3 ON sql = `` 'select * from t1 tbl_prefix_seen = False position = len ( text ) elif item.ttype is Keyword or item.ttype is Keyword.DML :","['pgcli/packages/parseutils.py', 'tests/test_parseutils.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 423 from dbcli/darikg/fix-multiple-joins
356,1f6f0186d363d73d26e81c84245715246d57e8b6,2015-11-24 12:56:31-08:00,"import humanize print ( 'Time : % 0.03fs ' % query.total_time ) print ( 'Time : % 0.03fs ( % s ) ' % ( query.total_time , humanize.time.naturaldelta ( query.total_time ) ) ) 'humanize > = 0.5.1 ' ,","['pgcli/main.py', 'setup.py']",Added humanized time display . Connect # 396 .
357,5dde125d9399296ae91eff7267651af7e70b4063,2015-11-24 11:17:31-08:00,"# An unmatched double quote , e.g . ' '' foo ' , 'foo . `` ' , or 'foo . `` bar ' if n_tok == 1 and isinstance ( p.tokens [ 0 ] , Identifier ) : ' '' foo * bar ' Completion ( text='set_returning_func ' , start_position=start_pos , display_meta='function ' ) , start_pos = -1 def test_allow_leading_double_quote_in_last_word ( completer , complete_event ) : p = sqlparse.parse ( word_before_cursor ) [ 0 ] # word_before_cursor may include a schema qualification , like 'SELECT * FROM `` sch '' . ' , Completion ( text='shipments ' , start_position=start_pos , display_meta='table ' ) , assert Table ( schema=None ) in set ( suggestions ) return None `` `` '' Attempt to parse a ( partially typed ) word as an identifier tables = extract_tables ( 'select * from abc.def ' ) Document ( text=text , cursor_position=position ) , complete_event ) def test_simple_select_single_table_schema_qualified ( sql ) : Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) , Completion ( text='users ' , start_position=0 , display_meta='table ' ) , tables = extract_tables ( sql ) 'select * from `` foo ' , completion=Completion ( item , -text_len , display_meta=meta ) , from .parseutils import ( 'SELECT * FROM sch . `` foo ' , word may include a schema qualification , like ` schema_name.partial_name ` 'SELECT * FROM `` sch '' . `` ' , if use_leading_double_quote : from sqlparse.tokens import Keyword , DML , Punctuation , Token , Error text += ' '' ' # text starts with double quote ; user is manually escaping a name Completion ( text='users ' , start_position=start_pos , display_meta='table ' ) , 'select * from `` abc '' . `` def '' ' , text = 'SELECT from users ' # Completion.position value is correct else : from .parseutils import last_word , extract_tables , find_prev_keyword Completion ( text='shipments ' , start_position=0 , display_meta='table ' ) , def test_simple_select_single_table_schema_qualified ( ) : > > > last_word ( ' '' foo * bar ' , include='most_punctuations ' ) or ` schema_name. ` There may also be unclosed quotation marks , like 'select * from abc.def ' , ` `` schema ` , or ` schema . `` partial_name ` text = 'SELECT * from `` sele ' position = len ( text ) text_len = len ( text ) 'SELECT * FROM `` custom '' . ' , # separately def test_suggested_column_names_from_shadowed_visible_table ( completer , complete_event ) : Completion ( text='products ' , start_position=0 , display_meta='table ' ) , `` `` '' 'SELECT * FROM `` tabl '' WHERE ' , # Close the double quote , then reparse 'SELECT FROM users ' , text = text [ 1 : ] 'select * from `` abc '' .def ' , Completion ( text='products ' , start_position=start_pos , display_meta='table ' ) , p = sqlparse.parse ( word ) [ 0 ] ] ) return p.tokens [ 0 ] result = completer.get_completions ( last_word , extract_tables , find_prev_keyword , parse_partial_identifier ) text_before_cursor [ : -len ( word_before_cursor ) ] ) # `` schema_name.partial_name '' or `` schema_name . `` , so parse it 'SELECT * FROM custom . ' , def test_simple_select_with_cols_multiple_qualified_tables ( ) : ] ) def test_suggested_table_names_with_schema_dot ( completer , complete_event ) : return parse_partial_identifier ( word + ' '' ' ) : return : sqlparse.sql.Identifier , or None def test_suggested_table_names_with_schema_dot ( completer , complete_event , 'select * from `` ' , identifier = parse_partial_identifier ( word_before_cursor ) text = 'SELECT * FROM custom . ' 'SELECT * FROM sch . `` ' , completion=Completion ( item , -len ( text ) , display_meta=meta ) , text , use_leading_double_quote ) : def test_simple_select_with_cols_multiple_tables ( ) : n_tok = len ( p.tokens ) def parse_partial_identifier ( word ) : suggestions = suggest_type ( sql , sql ) # Match on everything that follows the double-quote . Note that elif p.token_next_match ( 0 , Error , ' '' ' ) : assert expected in set ( result ) : param word : string representing a ( partially complete ) identifier def test_suggested_column_names_from_shadowed_visible_table ( completer , complete_event , text ) : from sqlparse.tokens import Keyword , DML , Punctuation , Token text_before_cursor [ : -len ( word_before_cursor ) ] ) start_pos = 0 # text_len is calculated before removing the quote , so the expected = Completion ( text= ' '' select '' ' , start_position=-5 , display_meta='table ' ) 'SELECT FROM `` users '' ' , if text and text [ 0 ] == ' '' ' : if p.tokens and isinstance ( p.tokens [ 0 ] , Identifier ) : def test_ignore_leading_double_quotes ( sql ) : 'select * from abc . `` def '' ' , identifier = p.tokens [ 0 ]","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_parseutils.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 421 from dbcli/darikg/support-leading-double-quote
358,a05e9a571ded0b6ec3161112446524355c141d6a,2015-11-22 22:13:13-08:00,"expected = [ 'Title ' , '+ -- -- -- -- -+ -- -- -- -- -+\n| head1 | head2 |\n| -- -- -- -- -+ -- -- -- -- -|\n| abc | def |\n+ -- -- -- -- -+ -- -- -- -- -+ ' , 'test status ' ] assert results == expected self.refresh_completions ( history=history , from pgcli.main import obfuscate_process_password 'test status ' , 'psql ' ) if ( max_width and if ( max_width and rows and def test_format_output ( ) : max_width=1 ) expanded = [ 'Title ' , u'- [ RECORD 0 ] -- -- -- -- -- -- -- -- -- -- -- -- -\nhead1 | abc\nhead2 | def\n ' , 'test status ' ] self.refresh_completions ( history=history , def test_format_output_auto_expand ( ) : from pgcli.main import obfuscate_process_password , format_output max_width=100 ) results = format_output ( 'Title ' , [ ( 'abc ' , 'def ' ) ] , [ 'head1 ' , 'head2 ' ] , [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , table = [ 'Title ' , '+ -- -- -- -- -+ -- -- -- -- -+\n| head1 | head2 |\n| -- -- -- -- -+ -- -- -- -- -|\n| abc | def |\n+ -- -- -- -- -+ -- -- -- -- -+ ' , 'test status ' ] assert expanded_results == expanded table_results = format_output ( 'Title ' , [ ( 'abc ' , 'def ' ) ] , [ 'head1 ' , 'head2 ' ] , 'test status ' , 'psql ' , assert table_results == table expanded_results = format_output ( 'Title ' , [ ( 'abc ' , 'def ' ) ] ,","['pgcli/main.py', 'tests/test_main.py']",Merge pull request # 419 from dbcli/amjith/fix-auto-expand-bug
359,171da8fd4a99b1919712dd2e6691a4add429cc04,2015-11-17 21:36:32-08:00,"views = self.populate_schema_objects ( suggestion.schema , 'views ' ) Keyword ( ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'def ' , 'd ' , False ) ] } , 'dv ' : View , assert tables == [ ( None , 'foo ' , None , True ) ] { 'type ' : 'function ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) return ( Column ( tables=tables ) , Column ( tables= ( ( None , 'def ' , 'd ' , False ) , ) ) , suggestions = [ { 'type ' : 'datatype ' , 'schema ' : schema } , 'function ' : get_function_matches , return ( ) `` `` '' input is a list of dicts '' '' '' View ( schema='myschema ' ) , suggest_type , Special , Database , Schema , Table , View , Function , Datatype ) Function ( schema=None ) , assert tables == [ ] 'datatype ' : get_datatype_matches , return suggest_based_on_last_token ( 'type ' , text_before_cursor , ( 'ghi ' , 'jkl ' , ' y ' , False ) ] tables = self.populate_schema_objects ( suggestion.schema , 'tables ' ) Datatype ( schema=None ) , Function ( schema='sch ' , filter='is_set_returning ' ) , { 'type ' : 'view ' , 'schema ' : schema } ] Table ( schema='sch ' ) , { 'type ' : 'table ' , 'schema ' : 'd ' } , Function ( schema=parent ) , ) View ( schema= ' a ' ) , return ( Keyword ( ) , Special ( ) ) { 'type ' : 'table ' , 'schema ' : 't ' } , { 'type ' : 'table ' , 'schema ' : [ ] } , schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] Special = namedtuple ( 'Special ' , [ ] ) { 'type ' : 'view ' , 'schema ' : ' f ' } , { 'type ' : 'view ' , 'schema ' : [ ] } ] sorted_dicts ( [ { 'type ' : 'keyword ' } , { 'type ' : 'special ' } ] ) assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'schema_name ' } ] Alias : get_alias_matches , column_suggestions = suggest_based_on_last_token ( 'where ' , suggestion [ 'schema ' ] , 'functions ' ) ] ) assert tables == [ ( None , 'my_table ' , 'm ' , False ) ] { 'type ' : 'datatype ' , 'schema ' : [ ] } , Function ( schema='t2 ' ) , return ( Keyword ( ) , ) { 'type ' : 'function ' , 'schema ' : 't1 ' } @ pytest.mark.parametrize ( 'join_type ' , [ `` , 'INNER ' , 'LEFT ' , 'RIGHT OUTER ' ] ) View ( schema='t2 ' ) , 'table ' : get_table_matches , matcher = self.suggestion_matchers [ suggestion [ 'type ' ] ] { 'type ' : 'function ' , 'schema ' : [ ] , 'filter ' : 'is_set_returning ' } , Table ( schema='myschema ' ) , Database : get_database_matches , Column ( tables= ( ( None , ' a ' , None , False ) , ) ) , assert tables == [ ( 'abc ' , 'def ' , ' x ' , False ) , 'special ' : get_special_matches , { 'type ' : 'table ' , 'schema ' : [ ] } , assert set ( tables ) == set ( [ ( 'abc ' , 'def ' , None , False ) , if suggestion.filter == 'is_set_returning ' : ( None , 'Def ' , None , False ) ] Table ( schema=None ) , { 'type ' : 'column ' , 'tables ' : [ ] } , return [ ] assert tables == ( ( None , 'Abc ' , ' a ' , False ) , ) NamedQuery : get_namedquery_matches , { 'type ' : 'schema ' } , View : get_view_matches , 'type ' , text_before_cursor , full_text , identifier ) return [ ] Table : get_table_matches , return ( ) suggestion.schema , 'functions ' ) Schema : get_schema_matches , NamedQuery = namedtuple ( 'NamedQuery ' , [ ] ) Function ( schema='d ' ) , assert suggestions == ( Schema ( ) , ) Function = namedtuple ( 'Function ' , [ 'schema ' , 'filter ' ] ) return ( Table ( schema=schema ) , parent = ( identifier and identifier.get_parent_name ( ) ) or None assert suggestions == ( Table ( schema='schema_name ' ) , ) { 'type ' : 'view ' , 'schema ' : 't2 ' } , drop_unique=True ) , Table ( schema=schema ) ] return ( Column ( tables=extract_tables ( full_text ) ) , ) Keyword ( ) , { 'type ' : 'table ' , 'schema ' : [ ] } , 'dT ' : Datatype , Function ( schema= ' f ' ) , _logger.debug ( 'Suggestion type : % r ' , suggestion [ 'type ' ] ) tables = [ t for t in tables if identifies ( parent , t ) ] suggestions.append ( { 'type ' : 'schema ' } ) Schema ( ) ] ) 'tables ' : [ ( None , 'abc ' , None , False ) ] } ] Function ( schema= ' a ' ) , return ( Keyword ( ) , ) { 'type ' : 'schema ' } ] ) ( None , 'Def ' , None , False ) ] ) assert tables == [ ( None , 'Abc ' , ' a ' , False ) , 'namedquery ' : get_namedquery_matches , return [ { 'type ' : rel_type , 'schema ' : schema } ] suggestions = [ Datatype ( schema=schema ) , if not suggestion.schema : assert set ( tables ) == set ( [ ( 'foo ' , 'bar ' , 'baz ' , False ) , return ( Schema ( ) , ( None , 'bar ' , None , True ) ] assert tables == [ ( 'foo ' , 'bar ' , 'baz ' , False ) , return [ { 'type ' : 'column ' , 'tables ' : tables , 'drop_unique ' : True } ] 'all_punctuations ' ) .startswith ( ' ( ' ) : Column ( tables= ( ( None , 'tabl ' , 't ' , False ) , ) ) , 'schema ' : get_schema_matches , Table ( schema='t2 ' ) , return ( Column ( tables=tables , drop_unique=True ) , ) { 'schema ' : [ ] , 'type ' : 'function ' } , { 'type ' : 'view ' , 'schema ' : 't1 ' } , assert sorted_dicts ( suggestion ) == sorted_dicts ( [ suggest.append ( { 'type ' : 'function ' , 'schema ' : schema , Table ( schema=parent ) , assert set ( tables ) == set ( [ ( 'abc ' , 'def ' , ' x ' , False ) , return suggest assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'sch ' } , { 'type ' : 'function ' , 'schema ' : 'tabl ' } ] ) assert sorted ( tables ) == [ ( None , 'abc ' , ' a ' , False ) , if not suggestion [ 'schema ' ] and 'filter ' not in suggestion : View = namedtuple ( 'View ' , [ 'schema ' ] ) if not suggestion.schema and not suggestion.filter : from pgcli.packages.sqlcompletion import suggest_type View ( schema= ' f ' ) , aliases = [ t.alias or t.name for t in tables ] { 'type ' : 'function ' , 'schema ' : 't1 ' } ] ) assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'myschema ' } , assert tables == ( ( None , 'my_table ' , 'm ' , False ) , ) from test_sqlcompletion import sorted_dicts 'drop_unique ' : True } ] Table ( schema= ' f ' ) , assert set ( suggestions ) == set ( ( Database ( ) , ) ) 'df ' : Function , { 'type ' : 'table ' , 'schema ' : 'tabl ' } , 'df ' : 'function ' , ] 'dT ' : 'datatype ' , { 'type ' : 'table ' , 'schema ' : ' f ' } , [ { 'type ' : 'schema ' } , Function ( schema='t1 ' ) { 'type ' : 'function ' , 'schema ' : ' f ' } ] Keyword ( ) , from .packages.sqlcompletion import suggest_type assert tables == [ ( None , 'foo ' , 'bar ' , True ) ] Column ( tables= ( ) ) , { 'type ' : 'function ' , 'schema ' : [ ] , 'filter ' : 'is_set_returning ' } , { 'type ' : 'keyword ' } ] ( None , 'def ' , None , False ) ] ) { 'type ' : 'table ' , 'schema ' : 'bar ' } ] ) { 'type ' : 'column ' , 'tables ' : [ ( 'sch ' , 'tabl ' , None , False ) ] } , Column ( tables= ( ( None , 'tbl ' , None , False ) , ) ) , parent = ( identifier and identifier.get_parent_name ( ) ) or [ ] Datatype : get_datatype_matches , { 'type ' : 'schema ' } , Alias = namedtuple ( 'Alias ' , [ 'aliases ' ] ) matcher = self.suggestion_matchers [ suggestion_type ] assert suggestions == [ { 'type ' : 'column ' , 'tables ' : [ ] } ] { 'type ' : 'function ' , 'schema ' : [ ] } , Table ( schema=None ) , assert tables == [ ( 'abc ' , 'def ' , None , False ) ] ( None , 'def ' , None , False ) ) , return tuple ( suggest ) Table ( schema='t1 ' ) , { 'type ' : 'schema ' } ] ) return suggest_based_on_last_token ( prev_keyword , text_before_cursor , 'keyword ' : get_keyword_matches , { 'type ' : 'column ' , 'tables ' : [ ( None , ' a ' , None , False ) ] } , { 'type ' : 'function ' , 'schema ' : parent } ] if suggestion.get ( 'filter ' ) == 'is_set_returning ' : { 'type ' : 'view ' , 'schema ' : 'd ' } , Function ( schema='tabl ' ) , return ( Column ( tables=extract_tables ( full_text ) ) , Function ( schema='t ' ) , return [ { 'type ' : 'table ' , 'schema ' : schema } , Column ( tables= ( ( None , 'foo ' , None , False ) , ) ) , return [ { 'type ' : 'column ' , 'tables ' : tables } , assert suggestions == ( Alias ( aliases= ( 'abc ' , 'bcd ' , ) ) , ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'func ' , None , True ) ] } , return ( NamedQuery ( ) , ) Column ( tables= ( ( None , 'abc ' , None , False ) , assert tables == [ ( None , 'Abc ' , None , False ) , { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None , False ) ] } , assert suggestions == ( Datatype ( schema='foo ' ) , ) assert suggestions == ( Column ( tables= ( ( None , 'abc ' , None , False ) , ) ) , ) Function ( schema=None ) , assert tables == [ ( None , 'abc ' , None , False ) ] ( None , 'tabl2 ' , 't2 ' , False ) ] ) assert suggestions == [ { 'type ' : 'database ' } ] views = self.populate_schema_objects ( suggestion [ 'schema ' ] , 'views ' ) _logger.debug ( 'Suggestion type : % r ' , suggestion_type ) return ( Keyword ( ) , ) 'database ' : get_database_matches , 'view ' : get_view_matches , @ pytest.mark.parametrize ( 'col_list ' , [ `` , 'col1 , ' ] ) Table ( schema='bar ' ) ] ) assert sorted_dicts ( suggest_type ( q , q ) ) == sorted_dicts ( [ assert set ( tables ) == set ( [ ( None , 'foo ' , None , False ) , types = self.populate_schema_objects ( suggestion.schema , 'datatypes ' ) ( None , 'def ' , None , False ) ] assert suggestions == [ { 'type ' : 'schema ' } ] assert set ( suggestions ) == set ( text_before_cursor , full_text , identifier ) return ( Database ( ) , ) return [ { 'type ' : 'keyword ' } , { 'type ' : 'special ' } ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , None , False ) ] } , prev_keyword , text_before_cursor , full_text , identifier ) Special : get_special_matches , Function ( schema=None , filter='is_set_returning ' ) , assert suggestion == [ assert suggestion == ( Keyword ( ) , ) @ pytest.mark.parametrize ( 'tbl_alias ' , [ `` , 'foo ' ] ) ( None , 'def ' , 'd ' , False ) ] Column ( tables= ( ( None , 'tabl2 ' , 't2 ' , False ) , ) ) , assert tables == ( ( 'abc ' , 'def ' , None , False ) , ) suggest.insert ( 0 , { 'type ' : 'schema ' } ) aliases = suggestion [ 'aliases ' ] [ Special ( ) ] ) Function ( schema='t1 ' ) , assert suggestions == ( Keyword ( ) , ) full_text , identifier ) Function ( schema=None , filter='is_set_returning ' ) , return tuple ( suggestions ) assert sorted ( tables ) == [ ( None , 'abc ' , None , False ) , { 'type ' : 'view ' , 'schema ' : [ ] } , Keyword : get_keyword_matches , Column ( tables= ( ( None , ' b ' , None , False ) , ) ) , return ( Alias ( aliases=aliases ) , ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None , False ) ] } , View ( schema='tabl ' ) , return [ { 'type ' : 'keyword ' } ] # assert tables == [ ( None , 'abc ' , None , False ) ] { 'type ' : 'view ' , 'schema ' : 'myschema ' } ] Schema ( ) , return [ { 'type ' : 'schema ' } , { 'type ' : rel_type , 'schema ' : [ ] } ] ( None , 'def ' , 'd ' , False ) ] ) suggest_type , Special , Database , Schema , Table , Function , Column , View , return ( rel_type ( schema=schema ) , ) ( None , 'bar ' , None , True ) ] ) types = self.populate_schema_objects ( suggestion [ 'schema ' ] , 'datatypes ' ) assert set ( tables ) == set ( [ ( None , 'tabl1 ' , 't1 ' , False ) , { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , 't ' , False ) ] } , rel_type = { 'table ' : Table , 'view ' : View , 'function ' : Function } [ token_v ] assert set ( expected ) == set ( suggestions ) assert set ( suggest_type ( text , text ) ) == set ( [ Column.__new__.__defaults__ = ( None , None ) assert sorted_dicts ( suggest_type ( text , text ) ) == sorted_dicts ( [ View ( schema='sch ' ) , Column ( tables= ( ( None , 'func ' , None , True ) , ) ) , tables = suggestion [ 'tables ' ] 'filter ' : 'is_set_returning ' } ) { 'type ' : 'function ' , 'schema ' : 't ' } ] ) return list ( identifiers ) assert sorted_dicts ( expected ) == sorted_dicts ( suggestions ) if suggestion.drop_unique : return suggest_based_on_last_token ( assert tables == [ ( None , 'foo ' , None , False ) , Function : get_function_matches , def sorted_dicts ( dicts ) : tables = suggestion.tables 'tables ' : [ ( None , 'abc ' , None , False ) , ( None , 'def ' , None , False ) ] , rel_type = { 'dt ' : Table , { 'type ' : 'table ' , 'schema ' : [ ] } , aliases = suggestion.aliases Keyword , NamedQuery , Datatype , Alias ) assert tables == ( ( 'foo ' , 'bar ' , None , True ) , ) ( '\\ns abc SELECT foo ' , 'SELECT foo ' , [ { 'type ' : 'keyword ' } ] ) , { 'type ' : 'view ' , 'schema ' : [ ] } , [ { 'type ' : 'datatype ' , 'schema ' : 'foo ' } ] ) { 'type ' : 'table ' , 'schema ' : ' a ' } , { 'type ' : 'table ' , 'schema ' : 't2 ' } , assert set ( tables ) == set ( [ ( None , 'Abc ' , ' a ' , False ) , # For convenience , do n't require the ` filter ` argument in Function constructor { 'type ' : 'function ' , 'schema ' : 't2 ' } ] ) assert tables == [ ( None , 'abc ' , 'abc ' , False ) ] suggest.insert ( 0 , Schema ( ) ) Column ( tables= ( ( None , 'foo ' , ' f ' , False ) , ) ) , assert sorted_dicts ( suggestions ) == sorted_dicts ( Schema = namedtuple ( 'Schema ' , [ ] ) { 'type ' : 'keyword ' } , assert sorted_dicts ( suggestions ) == sorted_dicts ( [ assert tables == ( ) assert tables == ( ( None , 'foo ' , None , True ) , ) assert tables == [ ( 'foo ' , 'bar ' , None , True ) ] return [ { 'type ' : 'namedquery ' } ] assert set ( suggestions ) == set ( [ { 'type ' : 'keyword ' } assert suggestions == ( Function ( schema='myschema ' ) , ) if suggestion.get ( 'drop_unique ' ) : 'tables ' : [ ( None , 'foo ' , None , False ) ] } , View ( schema='t1 ' ) , tables = self.populate_schema_objects ( suggestion [ 'schema ' ] , 'tables ' ) View ( schema=None ) , ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None , False ) ] } ] ( 'bar ' , 'qux ' , 'quux ' , True ) ] ) 'column ' : get_column_matches , 'dv ' : 'view ' , Keyword = namedtuple ( 'Keyword ' , [ ] ) assert suggestions == [ { 'type ' : 'column ' , { 'type ' : 'column ' , 'tables ' : [ ] } , Keyword ( ) , ) { 'type ' : rel_type , 'schema ' : [ ] } ] View ( schema=None ) , funcs = self.populate_functions ( suggestion [ 'schema ' ] , filt ) View ( schema=None ) , { 'type ' : 'keyword ' } Keyword ( ) return sorted ( tuple ( x.items ( ) ) for x in dicts ) View ( schema=schema ) , ) Column ( tables= ( ( None , 'abc ' , ' a ' , False ) , ) ) , assert sorted ( tables ) == [ ( 'abc ' , 'def ' , None , False ) , from pgcli.packages.sqlcompletion import ( ] ) { 'type ' : 'view ' , 'schema ' : 't ' } , { 'type ' : 'column ' , 'tables ' : [ ( None , ' b ' , None , False ) ] } , return ( Schema ( ) , ) from .packages.sqlcompletion import ( Column ( tables= ( ( None , 'tbl ' , None , False ) , ) ) ] ) if not suggestion.schema and ( Function ( schema=parent ) ) assert set ( suggest_type ( q , q ) ) == set ( [ if not suggestion [ 'schema ' ] : @ pytest.mark.parametrize ( 'text ' , [ ' , ' , ' , ' , 'sel , ' ] ) Table ( schema='t ' ) , { 'type ' : 'table ' , 'schema ' : parent } , { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , ' a ' , False ) ] } , return [ { 'type ' : 'keyword ' } ] ( 'ghi ' , 'jkl ' , None , False ) ] ) Function ( schema=None ) , Column ( tables= ( ) ) , assert set ( tables ) == set ( [ ( None , 'Abc ' , None , False ) , return suggestions 'alias ' : get_alias_matches , tables = tuple ( t for t in tables if identifies ( parent , t ) ) ( '\\ns abc SELECT foo ' , 'SELECT foo ' , ( Keyword ( ) , ) ) , Function , Datatype , Alias ) assert suggestions == ( Column ( tables= ( ) ) , ) Column ( tables= ( ( None , 'tabl1 ' , 't1 ' , False ) , ) ) , assert set ( suggestion ) == set ( [ assert tables == ( ( None , 'abc ' , None , False ) , ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' , False ) ] } , return ( Special ( ) , ) return [ { 'type ' : 'database ' } ] { 'type ' : 'function ' , 'schema ' : [ ] } , return [ { 'type ' : 'schema ' } , Column ( tables= ( ( 'sch ' , 'tabl ' , None , False ) , ) ) , ( None , 'Def ' , 'd ' , False ) ] ) assert suggestion == [ { 'type ' : 'keyword ' } ] funcs = self.populate_functions ( suggestion.schema , filt ) suggest = [ { 'type ' : 'table ' , 'schema ' : schema } ] Table = namedtuple ( 'Table ' , [ 'schema ' ] ) assert tables == ( ( None , 'abc ' , 'abc ' , False ) , ) Table ( schema='tabl ' ) , suggest = [ Table ( schema=schema ) ] Function ( schema=None ) , [ { 'type ' : 'special ' } ] ) assert suggestions == [ { 'type ' : 'alias ' , 'aliases ' : [ ' a ' , ' b ' ] } ] rel_type = { 'dt ' : 'table ' , Column ( tables= ( ( None , 'tabl ' , None , False ) , ) ) , assert tables == ( ( None , 'foo ' , 'bar ' , True ) , ) return ( Schema ( ) , rel_type ( schema=None ) ) ] ) if not suggestion [ 'schema ' ] and ( assert suggestion == ( Keyword ( ) , ) schema = ( identifier and identifier.get_parent_name ( ) ) or None assert tables == [ ( None , 'Abc ' , ' a ' , False ) ] ( None , 'tabl2 ' , 't2 ' , False ) ] @ pytest.mark.parametrize ( 'initial_text ' , [ `` , ' ' , '\t \t ' ] ) assert suggest_type ( sql , sql ) == ( Schema ( ) , ) return ( Schema ( ) , rel_type ( schema=schema ) ) assert tables == ( ( None , 'Abc ' , None , False ) , ) { 'type ' : 'view ' , 'schema ' : 'tabl ' } , aliases = tuple ( t.alias or t.name for t in tables ) Table ( schema=None ) , rel_type = token_v return [ { 'type ' : 'column ' , 'tables ' : extract_tables ( full_text ) } , Column : get_column_matches , suggestion_type = type ( suggestion ) return [ { 'type ' : 'keyword ' } , { 'type ' : 'special ' } ] { 'type ' : 'keyword ' } ] ) assert suggestions == [ { 'type ' : 'function ' , 'schema ' : 'myschema ' } ] 'all_punctuations ' ) .startswith ( ' ( ' ) : return [ { 'type ' : 'special ' } ] assert suggestions == [ { 'type ' : 'alias ' , 'aliases ' : [ 'abc ' , 'bcd ' ] } ] suggest.append ( { 'type ' : 'view ' , 'schema ' : schema } ) ( 'bar ' , 'qux ' , 'quux ' , True ) ] return tuple ( identifiers ) assert suggest_type ( sql , sql ) == [ { 'type ' : 'schema ' } ] { 'type ' : 'function ' , 'schema ' : [ ] } , 'where ' , text_before_cursor , full_text , identifier ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl2 ' , 't2 ' , False ) ] } , Database = namedtuple ( 'Database ' , [ ] ) from collections import namedtuple ( 'def ' , 'ghi ' , None , False ) ] ) assert suggest_type ( text , text ) == [ assert set ( suggestions ) == \ { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None , False ) ] } , { 'type ' : 'function ' , 'schema ' : 'sch ' , 'filter ' : 'is_set_returning ' } , { 'type ' : 'function ' , 'schema ' : ' a ' } ] ) Column ( tables= ( ( None , 'abc ' , None , False ) , ) ) , suggest.append ( View ( schema=schema ) ) View ( schema='d ' ) , Table ( schema='d ' ) , { 'type ' : 'keyword ' } column_suggestions = suggest_based_on_last_token ( assert sorted ( tables ) == [ ( None , 'tabl1 ' , 't1 ' , False ) , { 'type ' : 'table ' , 'schema ' : schema } ] View ( schema='t ' ) , return [ { 'type ' : 'column ' , 'tables ' : extract_tables ( full_text ) } ] ( 'ghi ' , 'jkl ' , ' y ' , False ) ] ) assert sorted_dicts ( suggestions ) == sorted_dicts ( [ { 'type ' : 'database ' } ] ) { 'type ' : 'datatype ' , 'schema ' : 'bar ' } , assert suggestions == [ { 'type ' : 'keyword ' } ] set ( [ Keyword ( ) , Special ( ) ] ) Function.__new__.__defaults__ = ( None , None ) assert sorted_dicts ( suggestions ) == \ ] ) Schema ( ) , assert suggestions == ( Alias ( aliases= ( ' a ' , ' b ' , ) ) , ) { 'type ' : 'column ' , { 'type ' : 'datatype ' , 'schema ' : [ ] } , assert set ( tables ) == set ( [ ( None , 'abc ' , ' a ' , False ) , { 'type ' : 'table ' , 'schema ' : 't1 ' } , # assert tables == ( ( None , 'abc ' , None , False ) , ) { 'type ' : 'view ' , 'schema ' : 'sch ' } , return [ { 'type ' : 'keyword ' } ] Column = namedtuple ( 'Column ' , [ 'tables ' , 'drop_unique ' ] ) return suggest_based_on_last_token ( return [ { 'type ' : 'alias ' , 'aliases ' : aliases } ] suggest_type , Special , Database , Schema , Table , Column , View , Keyword , suggestions.append ( Schema ( ) ) { 'type ' : 'function ' , 'schema ' : [ ] } , Datatype ( schema='bar ' ) , { 'type ' : 'table ' , 'schema ' : 'sch ' } ] ) Table ( schema='sch ' ) ] ) assert set ( tables ) == set ( [ ( None , 'abc ' , None , False ) , return ( Keyword ( ) , Special ( ) ) Datatype = namedtuple ( 'Datatype ' , [ 'schema ' ] ) { 'type ' : 'view ' , 'schema ' : ' a ' } , { 'type ' : 'function ' , 'schema ' : 'd ' } ] ) assert suggestions == ( Database ( ) , ) Table ( schema= ' a ' ) , { 'type ' : 'view ' , 'schema ' : parent } , return [ { 'type ' : 'schema ' } ] View ( schema=parent ) , { 'type ' : 'column ' , 'tables ' : [ ( None , 'foo ' , ' f ' , False ) ] } , { 'type ' : 'view ' , 'schema ' : [ ] } ] ) ( None , 'Def ' , 'd ' , False ) ] ( 'def ' , 'ghi ' , None , False ) ] suggest.append ( Function ( schema=schema , filter='is_set_returning ' ) ) ( 'ghi ' , 'jkl ' , None , False ) ] assert tables == [ ( None , 'Abc ' , None , False ) ]","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_parseutils.py', 'tests/test_pgspecial.py', 'tests/test_sqlcompletion.py']",Merge pull request # 413 from dbcli/darikg/immutable-suggestions
360,f4bb154cedd5068447725a87769f0b494da007a8,2015-11-12 18:51:55-08:00,"upload_source_tarball ( ) def upload_source_tarball ( ) : run_step ( 'python ' , 'setup.py ' , 'sdist ' , 'upload ' )",['release.py'],Merge pull request # 411 from dbcli/j-bennet/add-upload-to-release-script
361,7ee8a9035821466640ba2700cf2de019a577cb31,2015-11-09 19:55:31-08:00,"match_end_limit = len ( text ) if start_only else None load keyword and identifier preferences def get_alias_matches ( self , suggestion , word_before_cursor ) : types = self.populate_schema_objects ( self._completer_thread = threading.Thread ( if token.ttype in Name : if history : self.refresh_completions ( persist_priorities='all ' ) 'schema ' : get_schema_matches , ` mode ` can be either 'fuzzy ' , or 'strict ' if not word_before_cursor.startswith ( 'pg_ ' ) : self.keyword_counts [ keyword ] += 1 return self.find_matches ( word_before_cursor , schema_names , meta='schema ' ) scoped_cols = self.populate_scoped_cols ( tables ) assert kw_counts == expected self.functions , self.cli = self._build_cli ( ) completions.extend ( types ) # Unless we 're sure the user really wants them , hide schema names tables = [ t for t in tables if not t.startswith ( 'pg_ ' ) ] if not suggestion [ 'schema ' ] and 'filter ' not in suggestion : cols = self.find_matches ( word_before_cursor , scoped_cols , meta='view ' ) # pg_catalog tables that are implicitly on the search path matches = completer.find_matches ( text , collection ) bg_refresh.assert_called_with ( pgexecute , special , callbacks , None ) completions.extend ( funcs ) # names starting with pg_ , which are mostly temporary schemas # to sort after all fuzzy matches if not s.startswith ( 'pg_ ' ) ] funcs = self.populate_schema_objects ( def test_learn_table_names ( completer , complete_event ) : def test_prevalence_counter ( ) : # also suggest hardcoded functions using startswith matching 'table ' : get_table_matches , self.refresh_completions ( ) return len ( r.group ( ) ) , r.start ( ) elif suggestion [ 'type ' ] == 'special ' : def _compile_regex ( keyword ) : completer.extend_query_history ( history ) self.update_names ( text ) return match_point , 0 # database agnostic `` `` '' Refresh outdated completions meta='table alias ' ) self.datatypes , start_only=True , self.prioritizer.update_keywords ( text ) in Counter ( scoped_cols ) .items ( ) self.pgspecial.register ( # also suggest hardcoded functions using startswith n_recent = 100 fuzzy = True # Sort matches so highest priorities are first return -match_point , -float ( 'Infinity ' ) # ` users ` should be higher priority than ` orders ` ( used more often ) if not word_before_cursor.startswith ( 'pg_ ' ) : funcs = set ( funcs ) history=FileHistory ( os.path.expanduser ( history_file ) ) , funcs = self.populate_functions ( suggestion [ 'schema ' ] , filt ) tables = suggestion [ 'tables ' ] def refresh_completions ( self , history=None , persist_priorities='all ' ) : views = [ v for v in views if not v.startswith ( 'pg_ ' ) ] def _build_cli ( self , history ) : def update_keywords ( self , text ) : completions.extend ( queries ) Match = namedtuple ( 'Match ' , [ 'completion ' , 'priority ' ] ) cmd_names = commands.keys ( ) if suggestion.get ( 'drop_unique ' ) : assert counter.keyword_count ( 'NOSUCHKEYWORD ' ) == 0 self.name_counts [ token.value ] += 1 'datatype ' : get_datatype_matches , matches = self.find_matches ( word_before_cursor , self.all_completions , else : assert completions [ 0 ] .text == 'VIEW ' if not self.pgspecial : history = FileHistory ( os.path.expanduser ( history_file ) ) schema_names = [ s for s in schema_names mode='strict ' , meta='datatype ' ) ) self.keyword_counts = defaultdict ( int ) _logger.debug ( `` Completion column scope : % r '' , tables ) _logger.debug ( 'Suggestion type : % r ' , suggestion [ 'type ' ] ) elif persist_priorities == 'keywords ' : def get_database_matches ( self , _ , word_before_cursor ) : 'namedquery ' : get_namedquery_matches , if reset : def _swap_completer_objects ( self , new_completer ) : self.refresh_completions ( reset=False ) # should suggest only columns that appear in more than one tables = self.populate_schema_objects ( if history_file == 'default ' : elif suggestion [ 'type ' ] == 'function ' : self.completer.reset_completions ( ) funcs = self.populate_schema_objects ( history_file = config_location ( ) + 'history ' completions.extend ( cols ) refresh_callback = lambda : self.refresh_completions ( return self.find_matches ( word_before_cursor , scoped_cols , meta='column ' ) # suggest custom datatypes from pgcli.packages.prioritization import PrevalenceCounter suggestion_matchers = { persist_priorities=persist_priorities ) elif suggestion [ 'type ' ] == 'keyword ' : schema_names = self.find_matches ( word_before_cursor , if suggestion.get ( 'drop_unique ' ) : Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) start_only=True , fuzzy=False ) completions = [ m.completion for m in matches ] scoped_cols = self.populate_scoped_cols ( tables ) # Leave the new prioritizer as is 'view ' : get_view_matches , return matches views = self.populate_schema_objects ( suggestion [ 'schema ' ] , 'views ' ) self.prioritizer.update ( text ) def refresh ( self , executor , special , callbacks ) : args= ( executor , special , callbacks ) , meta='function ' ) self.refresh_completions ( persist_priorities='keywords ' ) # Map suggestion type to method # drop_unique is used for 'tb11 JOIN tbl2 USING ( ... ' which 'keywords ' - The new prioritizer is updated with old keyword def _swap_completer_objects ( self , new_completer , persist_priorities ) : white_space_regex = re.compile ( '\\s+ ' , re.MULTILINE ) persist_priorities is a string specifying how the old completer 's args= ( executor , special , callbacks , history ) , def _bg_refresh ( self , pgexecute , special , callbacks ) : queries = self.find_matches ( name='completion_refresh ' ) for _ in regex.finditer ( text ) : for parsed in sqlparse.parse ( text ) : # Function overloading means we way have multiple functions aliases = self.find_matches ( word_before_cursor , aliases , return self.find_matches ( word_before_cursor , self.databases , return self.find_matches ( word_before_cursor , views , meta='view ' ) from collections import defaultdict if is_init : meta_collection=desc ) fuzzy=False , self.completer.extend_query_history ( document.text ) self._swap_completer_objects ( new_completer , persist_priorities ) start_only=True , return self.keyword_counts [ keyword ] continue completions.extend ( schema_names ) funcs = self.find_matches ( word_before_cursor , funcs , word_before_cursor , self.functions , mode='strict ' , def get_namedquery_matches ( self , _ , word_before_cursor ) : history_file = self.config [ 'main ' ] [ 'history_file ' ] completions.extend ( views ) matches = [ ] meta='datatype ' ) # table def name_count ( self , name ) : tables = self.find_matches ( word_before_cursor , tables , self.change_db , '\\c ' , '\\c [ onnect ] database_name ' , if not suggestion [ 'schema ' ] and ( # drop_unique is used for 'tb11 JOIN tbl2 USING ( ... ' which should with self._completer_lock : users = Completion ( text='users ' , start_position=0 , display_meta='table ' ) # Unless we 're sure the user really wants them , hide schema 'column ' : get_column_matches , 'Refresh auto-completions . ' , arg_type=NO_QUERY ) commands = self.pgspecial.commands def refresh_completions ( self , reset=False ) : completions.extend ( tables ) in Counter ( scoped_cols ) .items ( ) assert completions.index ( users ) < completions.index ( orders ) funcs = self.find_matches ( word_before_cursor , funcs , meta='function ' ) if count > 1 and col ! = ' * ' ] # Load history into pgcompleter so it can learn user preferences # Now that we 've used ` VIEW ` once , it should be suggested ahead of other return self.find_matches ( word_before_cursor , self.keywords , completions.extend ( keywords ) completer.extend_query_history ( sql ) new_completer.prioritizer.clear_names ( ) if not self.pgspecial : filt = operator.attrgetter ( 'is_set_returning ' ) return self.find_matches ( word_before_cursor , cmd_names , mode='strict ' , start_only=True , callback = functools.partial ( self._on_completions_refreshed , history=history , # with whitespace wildcards def clear_names ( self ) : return self.find_matches ( fuzzy = False # suggest only columns that appear in more than one table completions.extend ( predefined_funcs ) '\\c [ onnect ] database_name ' , tables = suggestion [ 'tables ' ] : param history : A prompt_toolkit.history.FileHistory object . Used to views = [ v for v in views if not v.startswith ( 'pg_ ' ) ] funcs.extend ( predefined_funcs ) # starting with pg_ , which are mostly temporary schemas 'function ' : get_function_matches , reverse=True ) suggestion [ 'schema ' ] , 'tables ' ) scoped_cols = [ col for ( col , count ) for keyword , regex in keyword_regexs.items ( ) : matcher = self.suggestion_matchers [ suggestion [ 'type ' ] ] sql = 'SELECT * FROM ' Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) names = [ 'foo ' , 'bar ' , 'baz ' ] self.pgspecial.register ( self.change_db , '\\c ' , # During completer initialization , only load keyword preferences , from sqlparse.tokens import Name meta_collection=desc ) # Only suggest set-returning functions return [ ] history_file = self.config [ 'main ' ] [ 'history_file ' ] sql = 'create v ' def keyword_count ( self , keyword ) : 'all ' - The new prioritizer is updated to exactly reflect # Also suggest hardcoded types not word_before_cursor.startswith ( 'pg_ ' ) ) : 'database ' : get_database_matches , 'Change to a new database . ' , priority= ( sort_key , priority_func ( item ) ) ) ) schema_names = self.dbmetadata [ 'tables ' ] .keys ( ) counter.update ( sql ) return re.compile ( pattern , re.MULTILINE | re.IGNORECASE ) completions.extend ( dbs ) # e.g . 'table ' - > self.get_table_matches predefined_funcs = self.find_matches ( word_before_cursor , # Function overloading means we way have multiple functions of the same self.prioritizer = PrevalenceCounter ( ) fuzzy=False , meta='datatype ' ) suggestion [ 'schema ' ] , 'functions ' ) schema_names = [ s for s in schema_names if not s.startswith ( 'pg_ ' ) ] # Swap over the entire prioritizer , but clear name priorities , if suggestion [ 'type ' ] == 'column ' : dbs = self.find_matches ( word_before_cursor , self.databases , persist_priorities='none ' ) elif suggestion [ 'type ' ] == 'alias ' : self.completion_refresher.refresh ( self.pgexecute , self.pgspecial , the old one from .packages.prioritization import PrevalenceCounter target=self._bg_refresh , matches.extend ( self.find_matches ( word_before_cursor , self.datatypes , suggestion [ 'schema ' ] , 'datatypes ' ) kw_counts = [ counter.keyword_count ( x ) for x in keywords ] meta='table ' ) for recent in history [ -n_recent : ] : 'special ' : get_special_matches , matches = sorted ( matches , key=operator.attrgetter ( 'priority ' ) , assert len ( matches ) == 2 pattern = '\\b ' + re.sub ( white_space_regex , '\\s+ ' , keyword ) + '\\b ' meta='database ' ) for sort_key , item , meta in sorted ( completions ) ] self.pgexecute , self.pgspecial , callback , history=history ) considered a match if the text appears anywhere within it . # Count keywords . Ca n't rely for sqlparse for this , because it 's mode='strict ' , meta='keyword ' ) self.update_keywords ( text ) return funcs desc = [ commands [ cmd ] .description for cmd in cmd_names ] def get_table_matches ( self , suggestion , word_before_cursor ) : # Use negative infinity in second element to force keywords assert result == [ ' '' user '' ' , 'user_action ' ] cmd_names = commands.keys ( ) pass return self.name_counts [ name ] schema_names = self.dbmetadata [ 'tables ' ] .keys ( ) assert name_counts == [ 3 , 2 , 2 ] 'Execute commands from file . ' ) import re def _build_cli ( self ) : filt = operator.attrgetter ( 'is_set_returning ' ) history_file = config_location ( ) + 'history ' # suggest custom datatypes completer.extend_query_history ( recent , is_init=True ) self.pgspecial.register ( self.refresh_completions , '\\refresh ' , '\\refresh ' , # Surround the keyword with word boundaries and replace interior whitespace result = [ match.text for match in completer.find_matches ( text , collection ) ] 'Change to a new database . ' , aliases= ( 'use ' , '\\connect ' , 'USE ' ) ) # leaving learned keyword priorities alone def __init__ ( self ) : def test_learn_keywords ( completer , complete_event ) : BY baz '' ' types = self.find_matches ( word_before_cursor , types , elif suggestion [ 'type ' ] == 'namedquery ' : _logger.debug ( 'Suggestion type : % r ' , suggestion [ 'type ' ] ) if count > 1 and col ! = ' * ' ] start_only=False , fuzzy=True , meta='named query ' ) # keywords starting with v . def find_matches ( self , text , collection , mode='fuzzy ' , types = self.find_matches ( word_before_cursor , funcs = set ( funcs ) else : priorities , but not any other . completion=Completion ( item , -len ( text ) , display_meta=meta ) , views = self.find_matches ( word_before_cursor , views , If ` start_only ` is True , the text will match an available if mode == 'fuzzy ' : history = 'SELECT * FROM users ; SELECT * FROM orders ; SELECT * FROM users ' self.pgspecial.register ( self.refresh_completions , '\\ # ' , '\\ # ' , if suggestion.get ( 'filter ' ) == 'is_set_returning ' : 'fuzzy ' : fuzzy matching , ties broken by name prevalance assert matches [ 1 ] .priority > matches [ 0 ] .priority self.completion_refresher.refresh ( mode='strict ' ) elif suggestion [ 'type ' ] == 'schema ' : Document ( text=sql , cursor_position=len ( sql ) ) , complete_event ) old_completer = self.completer # Unless we 're sure the user really wants them , do n't suggest completions.extend ( types ) priority_func = self.prioritizer.name_count def update ( self , text ) : return [ m.completion for m in matches ] select * from foo ; if not suggestion [ 'schema ' ] and 'filter ' not in suggestion : tables = self.populate_schema_objects ( suggestion [ 'schema ' ] , 'tables ' ) def get_function_matches ( self , suggestion , word_before_cursor ) : persist_priorities='all ' ) schema_names , views = self.populate_schema_objects ( matches.append ( Match ( self._on_completions_refreshed ) } completions.extend ( special ) funcs = self.populate_functions ( suggestion [ 'schema ' ] , filt ) def get_datatype_matches ( self , suggestion , word_before_cursor ) : SELECT * FROM foo WHERE bar GROUP for token in parsed.flatten ( ) : types = self.populate_schema_objects ( suggestion [ 'schema ' ] , 'datatypes ' ) elif suggestion [ 'type ' ] == 'table ' : return self.find_matches ( word_before_cursor , tables , meta='table ' ) meta='table alias ' ) self._swap_completer_objects ( new_completer ) new_completer.prioritizer = old_completer.prioritizer completion only at the beginning . Otherwise , a completion is elif suggestion [ 'type ' ] == 'database ' : if not suggestion [ 'schema ' ] : predefined_funcs = self.find_matches ( if history_file == 'default ' : meta='function ' ) aliases = suggestion [ 'aliases ' ] if not suggestion [ 'schema ' ] and ( # Allow PGCompleter to learn user 's preferred keywords , etc . priority_func = self.prioritizer.keyword_count # Just swap over the entire prioritizer desc = [ commands [ cmd ] .description for cmd in cmd_names ] keywords = self.find_matches ( word_before_cursor , self.keywords , self.completer.reset_completions ( ) def get_special_matches ( self , _ , word_before_cursor ) : def find_matches ( self , text , collection , start_only=False , fuzzy=True , word_before_cursor , NamedQueries.instance.list ( ) , fuzzy=False , # Also suggest hardcoded types orders = Completion ( text='orders ' , start_position=0 , display_meta='table ' ) meta='function ' ) keyword_regexs = dict ( ( kw , _compile_regex ( kw ) ) for kw in keywords ) self.pgspecial.register ( refresh_callback , '\\ # ' , '\\ # ' , meta='keyword ' ) # signs to flip the direction of the tuple meta='schema ' ) keywords = [ 'SELECT ' , 'FROM ' , 'GROUP BY ' ] : param persist_priorities : 'all ' or 'keywords ' 'Refresh auto-completions . ' , arg_type=NO_QUERY ) return [ Completion ( item , -len ( text ) , display_meta=meta ) def get_keyword_matches ( self , _ , word_before_cursor ) : def update_names ( self , text ) : def get_column_matches ( self , suggestion , word_before_cursor ) : def extend_query_history ( self , text , is_init=False ) : return sorted ( completions , key=operator.attrgetter ( 'text ' ) ) # Only suggest set-returning functions self.refresh_completions ( reset=True ) from collections import namedtuple import functools matches = self.find_matches ( word_before_cursor , types , meta='datatype ' ) match_end_limit = len ( text ) # matching def _bg_refresh ( self , pgexecute , special , callbacks , history=None ) : # name at this point , so keep unique names only self.name_counts = defaultdict ( int ) matches.extend ( matcher ( self , suggestion , word_before_cursor ) ) self.pgspecial.register ( refresh_callback , '\\refresh ' , '\\refresh ' , 'none ' - The new prioritizer is left in a new/clean state completions.extend ( aliases ) sql = 'CREATE VIEW v AS SELECT 1 ' keywords = get_literals ( 'keywords ' ) return completions return self.find_matches ( word_before_cursor , self.all_completions , tables = [ t for t in tables if not t.startswith ( 'pg_ ' ) ] # the pg_catalog tables that are implicitly on the search path start_only=True , completions = completer.get_completions ( suggestion [ 'schema ' ] , 'functions ' ) expected = [ 3 , 3 , 2 ] name='completion_refresh ' ) class PrevalenceCounter ( object ) : _logger.debug ( `` Completion column scope : % r '' , tables ) return self.find_matches ( word_before_cursor , aliases , with self._completer_lock : # of the same name at this point , so keep unique names only name_counts = [ counter.name_count ( x ) for x in names ] if persist_priorities == 'all ' : self.cli = self._build_cli ( history ) def _on_completions_refreshed ( self , new_completer , persist_priorities ) : special = self.find_matches ( word_before_cursor , cmd_names , return -len ( r.group ( ) ) , -r.start ( ) bg_refresh.assert_called_with ( pgexecute , special , callbacks ) scoped_cols = [ col for ( col , count ) assert result == [ 'user_group ' , 'api_user ' ] suggestion [ 'schema ' ] , 'views ' ) ` keyword ` : start only matching , ties broken by keyword prevalance if not suggestion [ 'schema ' ] : not word_before_cursor.startswith ( 'pg_ ' ) ) : def refresh ( self , executor , special , callbacks , history=None ) : elif persist_priorities == 'none ' : meta='database ' ) learned prioritizer should be transferred to the new completer . counter = PrevalenceCounter ( ) def get_schema_matches ( self , _ , word_before_cursor ) : aliases = suggestion [ 'aliases ' ] self.refresh_completions ( history=history , def _on_completions_refreshed ( self , new_completer ) : commands = self.pgspecial.commands self._completer_thread = threading.Thread ( target=self._bg_refresh , completions.append ( ( sort_key , item , meta ) ) # Unless we 're sure the user really wants them , do n't suggest the aliases= ( 'use ' , '\\connect ' , 'USE ' ) ) elif suggestion [ 'type ' ] == 'datatype ' : 'alias ' : get_alias_matches , fuzzy=False , if suggestion.get ( 'filter ' ) == 'is_set_returning ' : from .pgliterals.main import get_literals 'Execute commands from file . ' ) # Note : higher priority values mean more important , so use negative import sqlparse meta='column ' ) word_before_cursor , NamedQueries.instance.list ( ) , meta='named query ' ) 'keyword ' : get_keyword_matches , sql = `` 'SELECT * FROM foo WHERE bar GROUP BY baz ; # not names completions = [ ] `` `` '' elif suggestion [ 'type ' ] == 'view ' : with self._completer_lock : def get_view_matches ( self , suggestion , word_before_cursor ) :","['pgcli/completion_refresher.py', 'pgcli/main.py', 'pgcli/packages/prioritization.py', 'pgcli/pgcompleter.py', 'tests/test_completion_refresher.py', 'tests/test_fuzzy_completion.py', 'tests/test_prioritization.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 379 from dbcli/darikg/learn-keyword-prefs
362,f7aef6ecacd0dc4c1343d3aab534c12aa50cd51d,2015-11-07 16:39:42-05:00,"====== * Fixed logging in Windows by switching the location of log and history file based on OS . ( Thanks : Amjith , ` Darik Gamble ` _ , ` Iryna Cherniavska ` _ ) . __version__ = ' 0.20.0 ' Bug Fixes : 0.20.0 __version__ = ' 0.20.1 '","['changelog.rst', 'pgcli/__init__.py']",Merge pull request # 408 from dbcli/j-bennet/release-0.20.1
363,f0b8c71f66dad8a06e3d5e9d4a379d955fc879f9,2015-11-06 06:37:12-05:00,"load_config ( config_location ( ) + 'config ' ) ) log_file = ~/.config/pgcli/log return expanduser ( '~/.config/pgcli/ ' ) return expanduser ( '~/.config/pgcli/config ' ) history_file = config_location ( ) + 'history ' history_file = default from .config import load_config , config_location # In Windows : % USERPROFILE % \AppData\Local\dbcli\pgcli\log if log_file == 'default ' : # In Unix/Linux : ~/.config/pgcli/log if not os.path.exists ( config_full_path ) : return os.getenv ( 'USERPROFILE ' ) + '\\AppData\\Local\\dbcli\\pgcli\\ ' if history_file == 'default ' : log_file = default print ( 'Config file is now located at ' , config_full_path ) # % USERPROFILE % is typically C : \Users\ { username } # In Windows : % USERPROFILE % \AppData\Local\dbcli\pgcli\history log_file = config_location ( ) + 'log ' NamedQueries.instance = NamedQueries.from_config ( load_config ( '~/.pgclirc ' ) ) if not os.path.exists ( config_location ( ) ) : return os.getenv ( 'USERPROFILE ' ) + '\AppData\Local\dbcli\pgcli\config ' from .config import load_config config_full_path ) NamedQueries.instance = NamedQueries.from_config ( @ click.option ( ' -- pgclirc ' , default=config_location ( ) , envvar='PGCLIRC ' , envvar='PGCLIRC ' , help='Location of pgclirc file . ' ) config_full_path = config_location ( ) + 'config ' shutil.move ( os.path.expanduser ( '~/.pgclirc ' ) , config_location ( ) ) config_location ( ) ) shutil.move ( os.path.expanduser ( '~/.pgclirc ' ) , config_full_path ) print ( 'Config file is now located at ' , config_location ( ) ) # In Unix/Linux : ~/.config/pgcli/history help='Location of pgclirc file . ' ) history_file = ~/.config/pgcli/history","['pgcli/config.py', 'pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgcompleter.py']",Merge pull request # 407 from dbcli/amjith/fix_log_file_windows
364,c6668bc23572855a9cbc22ddda20c106b3a87b90,2015-10-31 21:33:59-07:00,".. _ ` inkn ` : inkn * inkn .. _ ` Stuart Quin ` : https : //github.com/stuartquin * Add support for `` \x auto `` . ( Thanks : ` Stuart Quin ` _ ) . * Fix completion refresh in multiple query scenario . ( Thanks : ` Darik Gamble ` _ ) . * Jay Zeng * Eric Workman * Dhaivat Pandit * Only show expanded layout if valid list of headers provided . ( Thanks : ` Stuart Quin ` _ ) . * Jacob Magnusson 0.20.0 * Fix PyPI badge . ( Thanks : ` Artur Dryomov ` _ ) . * Dionysis Grigoropoulos * Do n't hide functions from pg_catalog . ( Thanks : ` Darik Gamble ` _ ) . * Çağatay Yüksel Functions that return table like results will now be suggested in places of tables . * Make `` enter '' key behave as `` tab '' key when the completion menu is displayed . ( Thanks : ` Matheus Rosa ` _ ) . .. _ ` Johannes Hoff ` : Johannes Hoff * Artur Dryomov * TamasNo1 Internal Changes : * Johannes Hoff * Fix suggestions in compound join clauses . ( Thanks : ` Darik Gamble ` _ ) . * Fix the removal of whitespaces in the output . ( Thanks : ` Jacek Wielemborek ` _ ) * Eric Workman * Çağatay Yüksel * xa * Dhaivat Pandit than the display window . When `` on_error = STOP `` in the config file , pgcli will abort execution if one of the queries results in an error . * Michael Kaminsky * Add `` CONCURRENTLY `` to keyword completion . ( Thanks : ` Johannes Hoff ` _ ) . Features : Improvements : .. _ ` Artur Dryomov ` : https : //github.com/ming13 * Dionysis Grigoropoulos background thread . This means large databases with thousands of tables are .. _ ` Matheus Rosa ` : Matheus Rosa When the auto-completion entries are refreshed , the update now happens in a * Jacek Wielemborek * Improvements to integration tests to make it more robust . ( Thanks : ` Iryna Cherniavska ` _ ) . * Fix the broken timing information . * Using `` pgspecial `` as a separate module . ( Thanks : ` Iryna Cherniavska ` _ ) . * vinotheassassin * Fix the ordering bug in ` \\d+ ` display , this bug was displaying the wrong table name in the reference . ( Thanks : ` Tamas Boros ` _ ) . * xa ====== .. _ ` Tamas Boros ` : https : //github.com/TamasNo1 * Suggest fields from functions used as tables . ( Thanks : ` Darik Gamble ` _ ) . * Hide the password displayed in the process name in `` ps `` . ( Thanks : ` Stuart Quin ` _ ) * Support different error-handling options when running multiple queries . ( Thanks : ` Darik Gamble ` _ ) . * Matheus Rosa * Move literal definitions to standalone JSON files . ( Thanks : ` Darik Gamble ` _ ) . .. _ ` Jacek Wielemborek ` : https : //github.com/d33tah * Jacob Magnusson handled without blocking . Bug Fixes : * Perform auto-completion refresh in background . ( Thanks : Amjith , ` Darik Gamble ` _ , ` Iryna Cherniavska ` _ ) . * Michael Kaminsky `` \\x auto `` will automatically switch to expanded mode if the output is wider * Move config file to ` ~/.config/pgcli/config ` instead of ` ~/.pgclirc ` ( Thanks : ` inkn ` _ ) . * Jay Zeng * Suggest set-returning functions as tables . ( Thanks : ` Darik Gamble ` _ ) .","['AUTHORS', 'changelog.rst']",Merge pull request # 405 from dbcli/amjith/release-0.20.0
365,00df5b44c9f0291cfadcc0e8e101e8208578350a,2015-10-28 12:42:52-07:00,"buffer=buf , with self._completer_lock : if query.db_changed : # first , load the sql magic if it is n't already loaded def test_raises_with_no_formatter ( executor , sql ) : logger.debug ( `` rows : % r '' , cur ) reconnect = click.prompt ( 'Connection reset . Reconnect ( Y/n ) ' , # register our own magic # Highlight matching brackets while editing . return False # I ca n't figure out how to get the underylying psycopg2 connection processor=HighlightMatchingBracketProcessor ( chars= ' [ ] ( ) { } ' ) , multiline=True , formatted = format_output ( title , cur , headers , status , if ( is_select ( status ) and for title , rows , headers , status , sql , success in results : # first , load the sql magic if it is n't already loaded self.on_error = on_error_modes [ c [ 'main ' ] [ 'on_error ' ] .upper ( ) ] reconnect = click.prompt ( print ( 'Time : % 0.03fs ' % query.total_time ) def need_search_path_refresh ( sql ) : from .encodingutils import unicode2utf8 , PY2 , utf8tounicode def _build_cli ( self ) : with self._completer_lock : get_vi_mode_enabled=lambda : self.vi_mode , max_width = None ON_ERROR_STOP = 2 result = list ( executor.run ( sql , on_error_resume=True , result = [ ] if not on_error_resume : logger.debug ( `` rows : % r '' , cur ) res = self.pgexecute.run ( text , self.pgspecial , ( Puts the E in REPL ) start the completion refresh for the new database . self.refresh_completions ( need_completion_reset ( document.text ) ) processor=HighlightMatchingBracketProcessor ( chars= ' [ ] ( ) { } ' ) , def run ( executor , sql , join=False , expanded=False , pgspecial=None ) : first_token = query.split ( ) [ 0 ] set_vi_mode_enabled=set_vi_mode ) mutating = set ( [ 'insert ' , 'update ' , 'delete ' ] ) if self.pgspecial.auto_expand : act as a query result . If an exception_formatter is not supplied , history=FileHistory ( os.path.expanduser ( history_file ) ) , from .encodingutils import unicode2utf8 , PY2 if q.successful : click.secho ( 'Reconnected ! \nTry the command again . ' , fg='green ' ) self._handle_server_closed_connection ( ) logger = self.logger query = MetaQuery ( query=document.text , successful=False ) multiline=True , exception_formatter=exception_formatter ) ) def run ( executor , sql , join=False , expanded=False , pgspecial=None , `` `` '' Returns tuple ( title , rows , headers , status ) '' '' '' # of a multi-statement query , the overall query is considered show_default=False , type=bool , default=True ) drop_tables ) 'Query ' , path_changed = path_changed or has_change_path_cmd ( sql ) filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , all_success = False def test_on_error_raises ( executor , sql ) : on_error=self.on_error ) def test_invalid_column_name ( executor , exception_formatter ) : successful = True yield result logger.debug ( `` status : % r '' , status ) _logger.debug ( 'Unsuccessful query - ignoring ' ) # new connection def exception_formatter ( e ) : result = click.style ( utf8tounicode ( str ( e ) ) , fg='red ' ) key_binding_manager = pgcli_bindings ( logger.debug ( `` headers : % r '' , headers ) _logger.debug ( 'Mutating query detected -- ignoring ' ) def has_change_path_cmd ( sql ) : click.secho ( `` Aborted ! `` , err=True , fg='red ' ) max_width = self.cli.output.get_size ( ) .columns def exception_formatter ( ) : # Keep track of whether or not the query is mutating . In case yield ( None , None , None , None ) return False def test_multiple_queries_same_line_syntaxerror ( executor , exception_formatter ) : self.cli = self._build_cli ( ) logger.debug ( 'Search path : % r ' , logger.debug ( 'Search path : % r ' , self.completer.search_path ) def test_invalid_column_name ( executor ) : # mutating if any one of the component statements is mutating def need_completion_reset ( queries ) : layout = create_default_layout ( lexer=PostgresLexer , threshold = 1000 def prompt_tokens ( _ ) : 'DROP TABLE foo ' , % threshold , fg='red ' ) logger.debug ( 'sql : % r ' , text ) pgexecute.connect ( ) if reconnect : if first_token.lower ( ) in ( 'use ' , '\\c ' , '\\connect ' ) : : param exception_formatter : A callable that accepts an Exception and self.refresh_completions ( reset=False ) MetaQuery = namedtuple ( reserve_space_for_menu=True , 'query ' , # The entire text of the command self.vi_mode = value : param on_error_resume : Bool . If true , queries following an exception title , cur , headers , status , self.table_format , total = 0 print ( 'Time : % 0.03fs ' % total ) ConditionalProcessor ( yield ( None , None , None , None , statement , False ) @ pytest.mark.parametrize ( 'sql ' , [ # A corresponding pgcli object already exists result = list ( executor.run ( sql , on_error=ON_ERROR_RESUME ) ) except Exception : except OperationalError as e : `` `` '' Determines if the statement is a database switch such as 'use ' or '\\c ' '' '' '' application = Application ( style=style_factory ( self.syntax_style , self.cli_style ) , key_bindings_registry=key_binding_manager.registry , from .pgexecute import PGExecute cur and cur.rowcount > threshold ) : db_changed = db_changed or has_change_db_cmd ( sql ) res = pgexecute.run ( document.text , self.pgspecial , if on_error == ON_ERROR_STOP : statement is an alter , create , or drop '' '' '' click.secho ( str ( e ) , err=True , fg='red ' ) def _handle_server_closed_connection ( self ) : return lambda e : str ( e ) pgexecute = self.pgexecute always_multiline=self.multi_line , % threshold , fg='red ' ) layout=layout , or on_error == ON_ERROR_RAISE ) : 'mutated ' , # True if any subquery executed insert/update/delete def test_invalid_syntax ( executor ) : history_file = self.config [ 'main ' ] [ 'history_file ' ] on_error_resume=False ) : from pgcli.pgexecute import ( ON_ERROR_STOP , ON_ERROR_RAISE , ON_ERROR_RESUME ) click.secho ( `` Aborted ! `` , err=True , fg='red ' ) : return : Generator yielding tuples containing for title , rows , headers , status in executor.run ( sql , pgspecial ) : eventloop=create_eventloop ( ) ) '\\connect ' , 'drop ' ) : : return : List of tuples containing ( title , rows , headers , status ) key_binding_manager = pgcli_bindings ( complete_while_typing=Always ( ) ) def run ( self , statement , pgspecial=None , exception_formatter=None , else : self.pgexecute.search_path ( ) ) # This is called via the ipython command ' % load_ext pgcli.magic ' 'meta_changed ' , # True if any subquery executed create/alter/drop elif query.meta_changed : statement is an alter , create , drop or change db . '' '' '' if first_token.lower ( ) in ( 'use ' , '\\c ' , '\\connect ' ) : logger.debug ( 'sql : % r ' , document.text ) `` `` '' Used to run a command entered by the user during CLI operation ConditionalProcessor ( all_success = True buf = PGBuffer ( yield None , None , None , result 'successful ' , # True If all subqueries were successful or not exception_formatter ) : lambda : self.vi_mode , self.completion_refresher.is_refreshing ) result.extend ( format_output ( title , rows , headers , status , 'psql ' , self.vi_mode = value if not click.confirm ( 'Do you want to continue ? ' ) : formatted = [ ] self.completer.search_path ) self.on_error = c [ 'main ' ] [ 'on_error ' ] .upper ( ) logger.debug ( `` status : % r '' , status ) max_width = None self.cli = CommandLineInterface ( application=application , # Keep track of whether any of the queries are mutating or changing ] ) except Exception : [ history=FileHistory ( os.path.expanduser ( history_file ) ) , returns a formatted ( title , rows , headers , status ) tuple that can exception_formatter , on_error_resume ) When a database is changed the existing completions must be reset before we def need_completion_refresh ( queries ) : elif query.path_changed : `` `` '' return click.style ( utf8tounicode ( str ( e ) ) , fg='red ' ) threshold = 1000 if q.meta_changed or q.db_changed or q.path_changed : # Highlight matching brackets while editing . style=style_factory ( self.syntax_style , self.cli_style ) , `` `` '' Determines if the statement is a database switch such as 'use ' or '\\c ' . def test_need_completion_refresh ( sql ) : end = time ( ) self.pgexecute.connect ( ) get_prompt_tokens=prompt_tokens , history_file = self.config [ 'main ' ] [ 'history_file ' ] # register our own magic list ( executor.run ( sql , on_error=ON_ERROR_RAISE ) ) def _evaluate_command ( self , text ) : result = list ( executor.run ( sql , on_error_resume=False , reconnect = True def test_on_error_resume ( executor , exception_formatter ) : try : output.extend ( formatted ) key_bindings_registry=key_binding_manager.registry , path_changed = False # For convenience , print the connection alias def test_invalid_syntax ( executor , exception_formatter ) : from pgcli.main import obfuscate_process_password meta_changed = False # CREATE , ALTER , DROP , etc extra_input_processors= [ return formatted result = '\n'.join ( result ) application = Application ( return drop_tables ) mutating = False `` `` '' This is called via the ipython command ' % load_ext pgcli.magic ' '' '' '' if ( is_select ( status ) and cur and cur.rowcount > threshold ) : start = time ( ) result = run ( executor , u '' select 'fooé ' ; invalid syntax é '' ) if not click.confirm ( 'Do you want to continue ? ' ) : # Refresh the table names and column names if necessary . total = 0 if ( 'server closed the connection ' in utf8tounicode ( e.args [ 0 ] ) ) : `` `` '' Used during CLI execution '' '' '' def test_on_error_stop ( executor , exception_formatter ) : return ipython.run_cell_magic ( 'sql ' , line , q.query ) output.extend ( formatted ) # finally clause to fail . if success : # Run the query . # if an exception occurs in pgexecute.run ( ) . Which causes from .pgexecute import PGExecute , ON_ERROR_RESUME , ON_ERROR_STOP def prompt_tokens ( cli ) : 'Connection reset . Reconnect ( Y/n ) ' , def set_vi_mode ( value ) : ignore_case=True ) ( title , rows , headers , status , query , success ) ignore_case=True ) if reconnect : total += end - start lexer=PostgresLexer , self.table_format , layout = create_default_layout ( show_default=False , type=bool , default=True ) pgexecute.connect ( ) self.pgexecute.connect ( ) output = [ ] return True completer=self.completer , Query = namedtuple ( 'Query ' , [ 'query ' , 'successful ' , 'mutating ' ] ) self.completer.set_search_path ( pgexecute.search_path ( ) ) except OperationalError as e : return True result = run ( executor , u '' select 'fooé ' ; invalid syntax é '' , # to least drastic changes self.completion_refresher.is_refreshing ) complete_while_typing=Always ( ) ) self.refresh_completions ( reset=True ) 'path_changed ' , # True if any subquery changed the search path self.pgspecial.expanded_output , # from the sqlalchemy connection , so just grab the url and make a try : def has_meta_cmd ( query ) : on_exit=AbortAction.RAISE_EXCEPTION , from pgcli.main import need_completion_refresh , obfuscate_process_password else : # from the sqlalchemy connection , so just grab the url and make a if need_search_path_refresh ( document.text ) : # Check if we need to update completions , in order of most assert need_completion_refresh ( sql ) ] ) def run ( self , statement , pgspecial=None , on_error=ON_ERROR_RESUME ) : import click output , query = self._evaluate_command ( document.text ) logger.debug ( `` headers : % r '' , headers ) click.secho ( 'The result set has more than % s rows . ' for title , cur , headers , status , sql , success in res : def test_multiple_queries_same_line_syntaxerror ( executor ) : break list ( executor.run ( sql ) ) eventloop=create_eventloop ( ) ) filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , db_changed = False expanded=expanded ) ) return False ON_ERROR_RAISE = 0 mutating = set ( [ 'insert ' , 'update ' , 'delete ' , 'alter ' , 'create ' , 'drop ' ] ) on_exit=AbortAction.RAISE_EXCEPTION , ipython = get_ipython ( ) get_bottom_toolbar_tokens=get_toolbar_tokens , buf = PGBuffer ( always_multiline=self.multi_line , completer=self.completer , set_vi_mode_enabled=set_vi_mode ) mutated = False # INSERT , DELETE , etc # Run the query . returns ( results , MetaQuery ) ] ) for title , cur , headers , status in res : exception_formatter=None ) : click.secho ( 'The result set has more than % s rows . ' exception_formatter=exception_formatter ) result = run ( executor , 'select invalid command ' , click.secho ( str ( e ) , err=True , fg='red ' ) on_error_resume = self.on_error == 'RESUME ' ] ) yield None , None , None , exception_formatter ( e ) , sql , False display_completions_in_columns=self.wider_completion_menu , in utf8tounicode ( e.args [ 0 ] ) ) : 'total_time ' , # Time elapsed executing the query self.completer.set_search_path ( result = run ( executor , 'select invalid command ' ) reserve_space_for_menu=True , # Refresh search_path to set default schema . def test_on_error_resume ( executor ) : # I ca n't figure out how to get the underylying psycopg2 connection res = [ ] if ( 'server closed the connection ' def set_vi_mode ( value ) : ( assuming exception_formatter has been supplied ) continue to result = run ( executor , 'invalid syntax ! ' ) max_width = self.cli.output.get_size ( ) .columns if need_completion_refresh ( document.text ) : # Initialize default metaquery in case execution fails application=application , ipython = get_ipython ( ) successful = False query = Query ( document.text , successful , mutating ) max_width ) yield result + ( sql , True ) cli = CommandLineInterface ( result = run ( executor , 'invalid syntax ! ' , # A corresponding pgcli object already exists return ipython.run_cell_magic ( 'sql ' , line , q.query ) # For convenience , print the connection alias click.secho ( 'Reconnected ! \nTry the command again . ' , fg='green ' ) return [ ( Token.Prompt , ' % s > ' % pgexecute.dbname ) ] for query in sqlparse.split ( queries ) : formatted = format_output ( if first_token.lower ( ) in ( 'alter ' , 'create ' , 'drop ' ) : get_vi_mode_enabled=lambda : self.vi_mode , try : if not q.successful : display_completions_in_columns=self.wider_completion_menu , ON_ERROR_RESUME = 1 return result meta_query = MetaQuery ( text , all_success , total , meta_changed , return [ ( Token.Prompt , ' % s > ' % self.pgexecute.dbname ) ] try : if self.pgspecial.auto_expand : # new connection on_error_modes = { 'STOP ' : ON_ERROR_STOP , 'RESUME ' : ON_ERROR_RESUME } psycopg2 exceptions are always raised . return output , meta_query formatted = '\n'.join ( formatted ) mutating = mutating or is_mutating ( status ) results = executor.run ( sql , pgspecial , exception_formatter ) self.pgspecial.expanded_output , max_width ) meta_changed = meta_changed or has_meta_cmd ( sql ) execute . def has_change_db_cmd ( query ) : expanded=expanded ) ) db_changed , path_changed , mutated ) 'db_changed ' , # True if any subquery changed the database start = time ( ) # the database get_toolbar_tokens = create_toolbar_tokens_func ( if q.mutating : if first_token.lower ( ) in ( 'alter ' , 'create ' , 'use ' , '\\c ' , def test_on_error_stop ( executor ) : _logger.debug ( 'Dangerous query detected -- ignoring ' ) MetaQuery.__new__.__defaults__ = ( `` , False , 0 , False , False , False , False ) yield self.execute_normal_sql ( sql ) + ( sql , True ) return cli result = list ( executor.run ( sql , on_error=ON_ERROR_STOP ) ) first_token = query.split ( ) [ 0 ] 'SELECT * FROM foo ; DROP TABLE foo ' , layout=layout , buffer=buf , formatted.extend ( format_output ( title , rows , headers , status , 'psql ' , get_bottom_toolbar_tokens=get_toolbar_tokens , break mutated = mutated or is_mutating ( status ) get_toolbar_tokens = create_toolbar_tokens_func ( lambda : self.vi_mode , total += end - start output = [ ] end = time ( ) # Initialized to [ ] because res might never get initialized get_prompt_tokens=prompt_tokens , extra_input_processors= [ yield self.execute_normal_sql ( sql ) `` `` ''","['pgcli/magic.py', 'pgcli/main.py', 'pgcli/pgexecute.py', 'tests/conftest.py', 'tests/test_main.py', 'tests/test_pgexecute.py', 'tests/utils.py']",Merge pull request # 395 from dbcli/darikg/refactor-on-error-options
366,a5cf7d9ba273854d9ad5dfba8a3d3a57ded651fe,2015-10-27 03:50:01-07:00,reason='setproctitle not available ' ) try : setproctitle = None import setproctitle import setproctitle except ImportError :,['tests/test_main.py'],Merge pull request # 400 from dbcli/j-bennet/safeguard-setproctitle
367,203c1e939e40fe2da6dbfde3d0f3e92f750315a7,2015-10-25 19:57:35-07:00,"from textwrap import dedent headers = [ 'xyz ' ] from pgcli.packages.tabulate import tabulate | -- -- -- -- -| def test_dont_strip_leading_whitespace ( ) : | abc | | xyz | ' '' ) .strip ( ) tbl , _ = tabulate ( data , headers , tablefmt='psql ' ) strings = [ s.strip ( ) for s in strings ] data = [ [ ' abc ' ] ] assert tbl == dedent ( `` '","['pgcli/packages/tabulate.py', 'tests/test_tabulate.py']",Merge pull request # 398 from d33tah/master
368,d7b1e5eb91b65d3807fbf921ae51898ce3973b14,2015-10-23 08:55:37-04:00,"# so we 'll only install it if we 're not in Windows . import platform # But this is not necessary in Windows since the password is never shown in the 'psycopg2 > = 2.5.4 ' , process_title = re.sub ( r '' password= ( .+ ? ) ( ( \s [ a-zA-Z ] += ) | $ ) '' , r '' password=xxxx\2 '' , process_title ) 'sqlparse == 0.1.16 ' , except ImportError : install_requires= [ process_title = re.sub ( r '' password= ( .+ ? ) ( ( \s [ a-zA-Z ] += ) | $ ) '' , r '' password=xxxx\2 '' , process_title ) 'configobj > = 5.0.6 ' , import setproctitle 'sqlparse == 0.1.16 ' , install_requirements.append ( 'setproctitle > = 1.1.9 ' ) try : setproctitle = None 'click > = 4.1 ' , 'pgspecial > =1.1.0 ' , ] , if platform.system ( ) ! = 'Windows ' : obfuscate_process_password ( ) 'prompt_toolkit==0.46 ' , install_requires=install_requirements , 'click > = 4.1 ' , 'setproctitle > = 1.1.9 ' ] 'prompt_toolkit==0.46 ' , # setproctitle is used to mask the password when running ` ps ` in command line . obfuscate_process_password ( ) install_requirements = [ reason='Not applicable in windows ' ) # task manager . Also setproctitle is a hard dependency to install in Windows , 'Pygments > = 2.0 ' , # Pygments has to be Capitalcased . WTF ? 'Pygments > = 2.0 ' , # Pygments has to be Capitalcased . WTF ? import setproctitle if setproctitle : 'configobj > = 5.0.6 ' , 'psycopg2 > = 2.5.4 ' , 'pgspecial > =1.1.0 ' ,","['pgcli/main.py', 'setup.py', 'tests/test_main.py']",Merge pull request # 397 from dbcli/amjith/optional-setproctitle
369,d9c62b0925023ce3f255113dd22d615c94a71a05,2015-10-20 09:15:36-07:00,"def need_completion_reset ( queries ) : if need_search_path_refresh ( document.text ) : lambda : self.completion_refresher.is_refreshing ( ) ) successful = True # Refresh search_path to set default schema . with self._completer_lock : self.refresh_completions ( need_completion_reset ( document.text ) ) When a database is changed the existing completions must be reset before we `` `` '' def refresh_completions ( self , reset=False ) : # Refresh the table names and column names if necessary . self.completer.reset_completions ( ) # Refresh the table names and column names if necessary . self.completer.set_search_path ( pgexecute.search_path ( ) ) return False if reset : logger.debug ( 'Search path : % r ' , self.completer.search_path ) try : self.completer.set_search_path ( pgexecute.search_path ( ) ) logger.debug ( 'Search path : % r ' , self.completer.search_path ) with self._completer_lock : logger.debug ( 'Refreshing search path ' ) return True def refresh_completions ( self ) : except Exception : with self._completer_lock : self.refresh_completions ( ) if need_completion_refresh ( document.text ) : successful = True if first_token.lower ( ) in ( 'use ' , '\\c ' , '\\connect ' ) : for query in sqlparse.split ( queries ) : start the completion refresh for the new database . if need_search_path_refresh ( document.text ) : `` `` '' Determines if the statement is a database switch such as 'use ' or '\\c ' . logger.debug ( 'Refreshing search path ' ) first_token = query.split ( ) [ 0 ] self.completion_refresher.is_refreshing ) # Refresh search_path to set default schema . if need_completion_refresh ( document.text ) :",['pgcli/main.py'],Merge pull request # 388 from dbcli/amjith/completion-refresh-cornercase
370,eded7675dd4046ac64a95a1425e86eaa046bc705,2015-10-19 11:54:46-07:00,"setproctitle.setproctitle ( `` pgcli user=root password=top secret host=localhost '' ) from pgcli.main import need_completion_refresh , obfuscate_process_password def test_obfuscate_process_password ( ) : import re setproctitle.setproctitle ( `` pgcli user=root password=secret host=localhost '' ) obfuscate_process_password ( ) setproctitle.setproctitle ( `` pgcli user=root password=top secret '' ) def obfuscate_process_password ( ) : 'configobj > = 5.0.6 ' , elif `` = '' in process_title : 'configobj > = 5.0.6 ' process_title = re.sub ( r '' password= ( .+ ? ) ( ( \s [ a-zA-Z ] += ) | $ ) '' , r '' password=xxxx\2 '' , process_title ) expected = `` pgcli user=root password=xxxx host=localhost '' if ' : // ' in process_title : from pgcli.main import need_completion_refresh setproctitle.setproctitle ( original_title ) assert title == expected process_title = setproctitle.getproctitle ( ) title = setproctitle.getproctitle ( ) assert need_completion_refresh ( sql ) expected = `` pgcli user=root password=xxxx '' original_title = setproctitle.getproctitle ( ) 'setproctitle > = 1.1.9 ' assert need_completion_refresh ( sql ) import setproctitle import setproctitle setproctitle.setproctitle ( process_title )","['pgcli/main.py', 'setup.py', 'tests/test_main.py']",Merge pull request # 387 from dbcli/stuartquin/hide-commandline-password
371,6bb6e90f83929d26b3412e5859399dcfb72d4a62,2015-10-19 18:45:43+01:00,"content_exceeds_width ( rows [ 0 ] , max_width ) and if max_width and content_exceeds_width ( rows [ 0 ] , max_width ) : headers ) : if ( max_width and",['pgcli/main.py'],Merge pull request # 391 from dbcli/amjith/x-auto-headers
372,748fcb76778b618d232b1c829f72d4ef65392441,2015-10-18 21:56:52+01:00,"def obscure_process_password ( ) : import re setproctitle.setproctitle ( `` pgcli user=root password=secret host=localhost '' ) def test_obscure_process_password ( ) : obscure_process_password ( ) 'configobj > = 5.0.6 ' , elif `` = '' in process_title : 'configobj > = 5.0.6 ' expected = `` pgcli user=root password=xxxx host=localhost '' if ' : // ' in process_title : process_title = re.sub ( r '' password=\S+ '' , `` password=xxxx '' , process_title ) from pgcli.main import need_completion_refresh setproctitle.setproctitle ( original_title ) assert title == expected process_title = setproctitle.getproctitle ( ) title = setproctitle.getproctitle ( ) assert need_completion_refresh ( sql ) from pgcli.main import need_completion_refresh , obscure_process_password original_title = setproctitle.getproctitle ( ) 'setproctitle > = 1.1.9 ' assert need_completion_refresh ( sql ) import setproctitle import setproctitle setproctitle.setproctitle ( process_title )","['pgcli/main.py', 'setup.py', 'tests/test_main.py']",Issue # 355 Use setproctitle to hide command line passwords
373,b3e109d5185381f3a000fa8397c55c5f38a7bda0,2015-10-14 04:30:43-07:00,"if on_error == ON_ERROR_STOP : with pytest.raises ( psycopg2.ProgrammingError ) : continue on_error_modes = { 'STOP ' : ON_ERROR_STOP , 'RESUME ' : ON_ERROR_RESUME } try : assert len ( result ) == 3 raise result = list ( executor.run ( sql , on_error=ON_ERROR_RESUME ) ) import psycopg2 result = list ( executor.run ( sql , on_error=ON_ERROR_STOP ) ) return ( None , None , None , click.style ( utf8tounicode ( str ( e ) ) , fg='red ' ) ) # Always raise operational errors , regardless of on_error self.on_error = on_error_modes [ c [ 'main ' ] [ 'on_error ' ] .upper ( ) ] yield result ON_ERROR_STOP = 2 except psycopg2.DatabaseError as e : def test_on_error_resume ( executor ) : sql = 'select 1 ; error ; select 1 ; ' 'invalid sql ' , result = click.style ( utf8tounicode ( str ( e ) ) , fg='red ' ) # specification # Not a special command , so execute as normal sql # Error handling if pgspecial : list ( executor.run ( sql , on_error=ON_ERROR_RAISE ) ) assert len ( result ) == 2 except psycopg2.ProgrammingError as e : return title , cur , headers , cur.statusmessage for result in pgspecial.execute ( cur , sql ) : # First try to run each query as special def test_on_error_raises ( executor , sql ) : if ( isinstance ( e , psycopg2.OperationalError ) return title , None , None , cur.statusmessage from .pgexecute import PGExecute try : if pgspecial : try : yield self.execute_normal_sql ( sql ) # First try to run each query as special res = pgexecute.run ( document.text , self.pgspecial , # continue executing the remaining statements , or stopping def run ( self , statement , pgspecial=None , on_error=ON_ERROR_RESUME ) : return self.pgexecute.run ( query , self.pgspecial ) try : from .pgexecute import PGExecute , ON_ERROR_RESUME , ON_ERROR_STOP or on_error == ON_ERROR_RAISE ) : except special.CommandNotFound : ] ) return self.pgexecute.run ( query , self.pgspecial , on_error=self.on_error ) # Possible values `` STOP '' or `` RESUME '' ON_ERROR_RAISE = 0 def run ( self , statement , pgspecial=None ) : _logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) _logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) pass return # When one of multiple SQL statements causes an error , choose to either from pgcli.pgexecute import ( ON_ERROR_STOP , ON_ERROR_RAISE , ON_ERROR_RESUME ) return ( title , None , None , cur.statusmessage ) cur.execute ( split_sql ) ON_ERROR_RESUME = 1 def test_on_error_stop ( executor ) : _logger.error ( `` sql : % r , error : % r '' , sql , e ) return ( title , cur , headers , cur.statusmessage ) on_error=self.on_error ) res = pgexecute.run ( document.text , self.pgspecial ) break cur.execute ( split_sql ) on_error = RESUME yield None , None , None , result for result in pgspecial.execute ( cur , sql ) : yield result pass yield self.execute_normal_sql ( sql ) _logger.error ( `` sql : % r , error : % r '' , split_sql , e ) except special.CommandNotFound : 'SELECT 1 ; select error ; ' ,","['pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 382 from dbcli/darikg/on-error-options
374,8ba1efb9218e96788a7ac692c58292303256f4c3,2015-10-11 20:40:36-07:00,|Build Status| |PyPI| |Gitter| |Build Status| |PyPI| |Gitter| .. |PyPI| image : : https : //img.shields.io/pypi/v/pgcli.svg .. |PyPI| image : : https : //pypip.in/version/pgcli/badge.svg,['README.rst'],Merge pull request # 383 from ming13/readme-formatting
375,4e9fe6ad1c36bffd01aae4722cbf7609d230efe3,2015-10-10 09:31:03-04:00,"return `` HasSelectedCompletion ( ) '' Makes the enter key work as the tab key only when showing the menu . def __call__ ( self , cli ) : def __repr__ ( self ) : `` `` '' _logger.debug ( 'Detected < C-J > key . ' ) b = event.cli.current_buffer event.current_buffer.complete_state = None class HasSelectedCompletion ( Filter ) : return ( complete_state is not None and from .filters import HasSelectedCompletion def _ ( event ) : complete_state.current_completion is not None ) b.complete_state = None from prompt_toolkit.filters import Filter complete_state = cli.current_buffer.complete_state `` `` '' Enable when the current buffer has a selected completion . '' '' ''","['pgcli/filters.py', 'pgcli/key_bindings.py']",Merge pull request # 381 from mdsrosa/enter_key_as_tab_key
376,c7ac5d248308f1379c0e5fbb03587532457116b2,2015-10-09 19:08:41+01:00,duration = time ( ) - start print ( 'Format Time : % 0.03fs ' % total ) # Run the query . print ( 'Time : % 0.03fs ' % total ) start = time ( ) # Run the query . print ( 'Command Time : % 0.03fs ' % duration ),['pgcli/main.py'],Merge pull request # 380 from dbcli/amjith/timing
377,54acaed24f4600f999d823568f13ca146fc60e1b,2015-10-06 08:39:03+01:00,* Stuart Quin * Stuart Quin,['AUTHORS'],Merge pull request # 376 from dbcli/amjith/authors_update
378,f074a4c6c05dd61d0ed625b507f671214542e477,2015-10-05 22:03:02-07:00,"`` LEN '' , `` ANY '' , from .packages.pgliterals.main import get_literals 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , `` THEN '' , `` FLOAT '' , `` CURRENT '' , `` INSERT INTO '' , `` TRIGGER '' , `` CREATE '' , 'FULL ' , 'FUNCTION ' , 'GRANT ' , 'GROUP BY ' , 'HAVING ' , 'HEADER ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , `` CASE '' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , `` INITIAL '' , `` PCTFREE '' , `` NUMERIC '' , `` FIRST '' , `` RENAME '' , `` FREEZE '' , `` JOIN '' , `` VALIDATE '' , `` EXTENSION '' , `` CHECK '' , `` RETURNS '' , root = os.path.dirname ( __file__ ) `` BY '' , `` MID '' , `` UCASE '' `` TOP '' , `` ROUND '' , `` ENCODING '' , `` VARCHAR2 '' , `` UPDATE '' , `` INT '' , `` ELSE '' , `` GROUP BY '' , `` ESCAPE '' , `` FROM '' , `` INTEGER '' , `` COMPRESS '' , `` SHARE '' , import json `` SYSDATE '' , keywords = get_literals ( 'keywords ' ) `` START '' , 'MAX ' , 'MIN ' , 'MID ' , 'NOW ' , 'ROUND ' , 'SUM ' , 'TOP ' , 'UCASE ' ] `` SELECT '' , `` COUNT '' , literals = json.load ( f ) 'CONNECT ' , 'COPY ' , 'CREATE ' , 'CURRENT ' , 'DATABASE ' , 'DATE ' , { 'DESCRIBE ' , 'DISTINCT ' , 'DROP ' , 'ELSE ' , 'ENCODING ' , 'ESCAPE ' , `` DEFAULT '' , `` INCREMENT '' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , `` VARCHAR '' , `` ASC '' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'USING ' , 'VALIDATE ' , 'VALUES ' , `` MAX '' , `` INTERVAL '' , `` AS '' , `` FORCE_NOT_NULL '' , 'IDENTIFIED ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , 'INDEX ' , 'INITIAL ' , `` PRIOR '' , `` DISTINCT '' , `` COLUMN '' , `` MODIFY '' , `` datatypes '' : [ `` HEADER '' , `` WHERE '' , `` UID '' , `` BIGINT '' , `` FULL '' , `` OUTER '' , `` SIZE '' , `` ROWID '' , `` DESCRIBE '' , `` WHENEVER '' , `` NUMBER '' , `` TEXT '' , `` CHAR '' , `` DELIMITER '' , `` IS '' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' ] `` LANGUAGE '' , `` AND '' , `` SUCCESSFUL '' , `` OR '' , `` FUNCTION '' , `` VIEW '' , `` EXCLUSIVE '' , `` keywords '' : [ `` DATABASE '' , `` INTO '' , `` OWNER '' , `` OFFLINE '' , `` NOW '' , 'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'QUOTE ' , `` REAL '' , package_data= { 'pgcli ' : [ 'pgclirc ' ] } , `` MINUS '' , `` functions '' : [ `` HAVING '' , `` MAXEXTENTS '' , 'CLUSTER ' , 'COLUMN ' , 'COMMENT ' , 'COMPRESS ' , 'CONCURRENTLY ' , `` TRUNCATE '' , `` SMALLINT '' , `` WHEN '' , } `` LAST '' , `` ALL '' , `` CONCURRENTLY '' , `` LIMIT '' , `` IDENTIFIED '' , `` EXISTS '' , `` INDEX '' , `` LOCK '' , `` USER '' , `` SET '' , 'DECIMAL ' , 'DEFAULT ' , 'DELETE FROM ' , 'DELIMITER ' , 'DESC ' , `` ROWNUM '' , `` PRIVILEGES '' , 'INTEGER ' , 'NUMERIC ' , 'REAL ' , 'TEXT ' , 'VARCHAR ' ] with open ( literal_file ) as f : `` VARCHAR '' `` ORDER BY '' , `` RAW '' , def get_literals ( literal_type ) : `` DELETE FROM '' , returns a tuple of literal values of that type '' '' '' `` ADD '' , `` AUDIT '' , `` BETWEEN '' , `` NOCOMPRESS '' , `` DROP '' , `` USING '' , `` ONLINE '' , `` ACCESS '' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , `` SESSION '' , 'ASC ' , 'AUDIT ' , 'BETWEEN ' , 'BY ' , 'CASE ' , 'CHAR ' , 'CHECK ' , 'packages/pgliterals/pgliterals.json ' ] } , `` ROW '' , 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'TRUNCATE ' , 'UID ' , 'UNION ' , `` INTERSECT '' , `` CONNECT '' , `` RESOURCE '' , `` FORMAT '' , `` TABLE '' , `` FORCE_QUOTE '' , functions = get_literals ( 'functions ' ) import os 'FORMAT ' , 'FORCE_QUOTE ' , 'FORCE_NOT_NULL ' , 'FREEZE ' , 'FROM ' , `` ROWS '' , `` VALUES '' , `` DOUBLE PRECISION '' , `` LEVEL '' , `` TEMPLATE '' , keywords = [ 'ACCESS ' , 'ADD ' , 'ALL ' , 'ALTER TABLE ' , 'AND ' , 'ANY ' , 'AS ' , `` RIGHT '' , 'EXCLUSIVE ' , 'EXISTS ' , 'EXTENSION ' , 'FILE ' , 'FLOAT ' , 'FOR ' , `` DATE '' , `` NOWAIT '' , `` FOR '' , `` IMMEDIATE '' , datatypes = get_literals ( 'datatypes ' ) `` LIKE '' , datatypes = [ 'BIGINT ' , 'BOOLEAN ' , 'CHAR ' , 'DATE ' , 'DOUBLE PRECISION ' , 'INT ' , `` QUOTE '' , `` MIN '' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , `` ON '' , return tuple ( literals [ literal_type ] ) literal_file = os.path.join ( root , 'pgliterals.json ' ) `` USE '' , `` ALTER TABLE '' , `` IN '' , `` DESC '' , `` LONG '' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'INTERVAL ' , 'INTO ' , 'IS ' , `` BOOLEAN '' , `` OF '' , package_data= { 'pgcli ' : [ 'pgclirc ' , `` LCASE '' , `` COPY '' , `` NOAUDIT '' , `` NOT '' , `` SYNONYM '' , `` COMMENT '' , `` CLUSTER '' , functions = [ 'AVG ' , 'COUNT ' , 'FIRST ' , 'FORMAT ' , 'LAST ' , 'LCASE ' , 'LEN ' , `` FILE '' , `` UNION '' , `` PRIMARY '' , `` MODE '' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OIDS ' , 'OF ' , `` GRANT '' , `` TO '' , ] `` REVOKE '' , `` DECIMAL '' , `` OPTION '' , ] , `` SUM '' , `` AVG '' , `` WITH '' `` UNIQUE '' , `` OIDS '' , `` MLSLABEL '' , `` `` '' Where ` literal_type ` is one of 'keywords ' , 'functions ' , 'datatypes ' , `` NULL '' , `` LEFT '' ,","['pgcli/packages/pgliterals/__init__.py', 'pgcli/packages/pgliterals/main.py', 'pgcli/packages/pgliterals/pgliterals.json', 'pgcli/pgcompleter.py', 'setup.py']",Merge pull request # 374 from dbcli/darikg/pgliterals
379,396eb2fdcab07a89d5f5f58f80b04526f16bf343,2015-10-05 18:10:20-04:00,"# Send Ctrl + D into cli actual = re.sub ( '\x1b\ [ ( . * ) ? . { 1 } ' , `` , actual ) pgspecial pip install . pytest mock codecov behave pexpect==3.3 actual = re.sub ( r'\x1b\ [ ( [ 0-9A-Za-z ; ? ] ) + [ m|K ] ? ' , `` , context.cli.before ) context.cli.sendline ( '\\connect postgres ' ) context.cli.sendline ( '\\connect { 0 } '.format ( db_name ) ) context.cli.sendcontrol ( 'd ' ) context.cli.sendline ( '\connect postgres ' ) # Terminate nicely . context.cli.terminate ( ) pip install . pytest mock codecov behave pexpect pexpect==3.3 context.cli.sendline ( '\connect { 0 } '.format ( db_name ) ) actual = re.sub ( '\x1b\ [ [ 0-9 ; ] * m ' , `` , context.cli.before ) context.cli.expect ( pexpect.EOF , timeout=5 ) pexpect > =3.3","['.travis.yml', 'requirements-dev.txt', 'tests/features/environment.py', 'tests/features/steps/step_definitions.py', 'tox.ini']",Merge pull request # 375 from dbcli/j-bennet/integration-tests
380,4055b726cca8d3c698968a96111050fade53995e,2015-10-04 09:31:11-04:00,"f3 = FunctionMetadata ( 's ' , ' g ' , ' x int ' , 'int ' , False , False , False ) pg_catalog.pg_get_function_result ( p.oid ) result , { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None ) ] } , tables = [ t for t in tables if identifies ( parent , * t ) ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None , False ) ] } , def test_join_functions_on_suggests_columns ( completer , complete_event ) : # func is a FunctionMetadata object False , False , True ] ] , if tbl.schema : def field_names ( sql , mode_filter= ( 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' ) ) : { 'type ' : 'column ' , 'tables ' : [ ( 'sch ' , 'tabl ' , None ) ] } , list ( map ( lambda x : Completion ( x , display_meta='keyword ' ) , completer.keywords ) ) ) self.schema_name = schema_name self.mode = 'IN ' except KeyError : def test_parse_typed_field_list_simple ( ) : def __ne__ ( self , other ) : assert sorted ( tables ) == [ ( 'abc ' , 'def ' , None , False ) , assert sorted ( tables ) == [ ( None , 'tabl1 ' , 't1 ' , False ) , assert suggestions == [ { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , None ) ] } ] assert f1 == f2 { 'type ' : 'column ' , 'tables ' : [ ( None , 'foo ' , ' f ' ) ] } , columns.extend ( func.fieldnames ( ) ) sql = `` ' IN a int = 5 , yield f.name parens -= 1 self.arg_list , self.return_type , self.is_aggregate , 'tables ' : [ ( None , 'abc ' , None ) , ( None , 'def ' , None ) ] , # Schema not specified , so traverse the search path looking for class TypedFieldMetadata ( object ) : def test_simple_schema_qualified_function_as_table ( arg_list ) : return hash ( ( self.schema_name , self.func_name , self.arg_list , parens += 1 OUT d double precision [ ] `` ' False , False , True ] ] , else : def test_simple_table_and_function ( ) : { 'type ' : 'column ' , 'tables ' : [ ( None , ' b ' , None , False ) ] } , assert not ( f1 ! = f2 ) self.default = [ ] assert [ arg.name for arg in args ] == [ ' a ' , ' b ' , ' c ' , 'd ' ] self.unknown = [ ] assert tables == [ ( None , 'Abc ' , None ) , ( None , 'Def ' , None ) ] { 'type ' : 'function ' , 'schema ' : [ ] } , # End of the current field specification return ( isinstance ( other , self.__class__ ) # ( bar , baz ) . So do n't allow any identifiers in insert statements assert tables == [ ( None , 'abc ' , 'abc ' ) ] # at a time tables = extract_tables ( 'SELECT * FROM foo ( { 0 } ) bar'.format ( arg_list ) ) # one at a time tables = extract_tables ( 'SELECT * FROM foo JOIN bar ( ) ' ) return id == alias or id == table or ( columns.extend ( meta [ 'tables ' ] [ schema ] [ relname ] ) columns.extend ( func.fieldnames ( ) ) from pgcli.pgexecute import FunctionMetadata else : yield ( schema_name , real_name , item.get_alias ( ) ) `` `` '' Returns a list of output field names '' '' '' def __repr__ ( self ) : # each schema before checking the next schema y DOUBLE PRECISION , columns.extend ( meta [ 'views ' ] [ schema ] [ relname ] ) def test_suggest_columns_from_set_returning_function ( completer , complete_event ) : complete_event ) ' is_aggregate= % r , is_window= % r , is_set_returning= % r ) ' ) columns.extend ( meta [ 'tables ' ] [ schema ] [ relname ] ) # We do n't know if schema.relname is a table or view . Since if field.type : from sqlparse.tokens import Whitespace , Comment , Keyword , Name , Punctuation INNER JOIN set_returning_func ( ) f2 ON f1 . ' '' elif parens == 0 and tok.value == '= ' : assert sorted ( tables ) == [ ( None , 'abc ' , ' a ' ) , ( None , 'def ' , 'd ' ) ] pos = len ( 'select f . ' ) def test_argument_names ( ) : self.type = [ ] assert tables == [ ( None , 'abc ' , None , False ) ] tokens = sqlparse.parse ( sql ) [ 0 ] .flatten ( ) assert tables == [ ( None , 'Abc ' , None ) ] if self.return_type.lower ( ) == 'void ' : for tok in tokens : assert tables == [ ( None , 'abc ' , 'abc ' , False ) ] assert [ arg.mode for arg in args ] == [ 'IN ' , 'IN ' , 'IN ' , 'OUT ' ] field = TypedFieldMetadata ( ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None ) ] } , assert sorted ( tables ) == [ ( None , 'abc ' , None , False ) , return id == ref.alias or id == ref.name or ( aliases = [ t [ 2 ] or t [ 1 ] for t in tables ] pos = len ( text ) # their names assert tables == [ ( None , 'my_table ' , 'm ' ) ] identifiers = extract_table_identifiers ( stream , if tbl.is_function : _identifier_is_function ( identifier ) ) ( None , 'bar ' , None , True ) ] assert f1 ! = f3 continue field [ parse_state ] .append ( tok ) # `` insert into foo ( bar , baz ) '' as a function call to foo with arguments parse_state = 'type ' yield ( schema_name , real_name , identifier.get_alias ( ) ) try : { 'type ' : 'keyword ' } schema and ( id == schema + ' . ' + table ) ) TableReference = namedtuple ( 'TableReference ' , [ 'schema ' , 'name ' , 'alias ' , 'is_function ' ] ) self.func_name = func_name assert sorted ( tables ) == [ ( None , 'abc ' , None ) , ( None , 'def ' , None ) ] yield field { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None , False ) ] } , assert tables == [ ( None , 'foo ' , 'bar ' , True ) ] def test_complex_table_and_function ( ) : assert sorted ( tables ) == [ ( None , 'tabl1 ' , 't1 ' ) , ( None , 'tabl2 ' , 't2 ' ) ] ( None , 'tabl2 ' , 't2 ' , False ) ] yield ( None , item.get_name ( ) , item.get_name ( ) ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl2 ' , 't2 ' , False ) ] } , parens = 0 break relname = self.escape_name ( tbl.name ) def identifies ( id , ref ) : from collections import namedtuple # `` ( [ [ argmode ] [ argname ] argtype continue assert not ( f1 == f3 ) functions = meta [ 'functions ' ] [ schema ] [ relname ] 'tables ' : [ ( None , 'abc ' , None , False ) , ( None , 'def ' , None , False ) ] , relname = self.escape_name ( tbl [ 1 ] ) schema = self.escape_name ( tbl.schema ) from pgcli.packages.function_metadata import ( Completion ( text='custom_func1 ' , start_position=0 , display_meta='function ' ) , yield TableReference ( None , item.get_real_name ( ) , item.get_alias ( ) , from .packages.function_metadata import FunctionMetadata assert tables == [ ( 'abc ' , 'def ' , ' x ' ) , ( 'ghi ' , 'jkl ' , ' y ' ) ] pg_catalog.pg_get_function_result ( p.oid ) return_type , assert hash ( f1 ) ! = hash ( f3 ) assert tables == [ ( 'abc ' , 'def ' , ' x ' , False ) , assert tables == [ ( None , 'Abc ' , ' a ' ) ] ( None , 'Def ' , 'd ' , False ) ] sql = 'int , double precision , text ' Document ( text=text , cursor_position=pos ) , complete_event ) ) list ( map ( lambda f : Completion ( f , display_meta='function ' ) , completer.functions ) ) pos = len ( 'select ' ) # Final argument wo n't be followed by a comma , so make sure it gets yielded try : mode_names = set ( ( 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' ) ) x INT , for func in functions : [ 'set_returning_func ' , self.is_set_returning ) ) tbl_str = `` ' `` `` '' # a table or view that matches . Note that in order to get proper if tok.value == ' ( ' : # Return column names from a set-returning function Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) , { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , 't ' ) ] } , for schema in self.search_path : { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' , False ) ] } , __slots__ = [ 'name ' , 'mode ' , 'type ' , 'default ' , 'unknown ' ] self.is_aggregate = is_aggregate assert tables == [ ( None , 'Abc ' , ' a ' ) , ( None , 'Def ' , 'd ' ) ] IN c double precision = 9.99 '' , INNER JOIN set_returning_func ( ) f2 USING ( `` ' elif tok.value == ' ) ' : { 'type ' : 'column ' , 'tables ' : [ ( None , ' a ' , None ) ] } , if tok.ttype in Whitespace or tok.ttype in Comment : # Kludge : sqlparse mistakenly identifies insert statements as { 'type ' : 'column ' , 'tables ' : [ ( None , 'def ' , 'd ' , False ) ] } , self.is_window , self.is_set_returning ) ) def test_suggest_columns_from_aliased_set_returning_function ( completer , complete_event ) : # assert tables == [ ( None , 'abc ' , None ) ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl2 ' , 't2 ' ) ] } , for schema in self.search_path : `` `` '' Yields field names from a table declaration '' '' '' 'tables ' : [ ( None , 'abc ' , None , False ) ] } ] mode 'IN ' , 'OUT ' , 'INOUT ' , 'VARIADIC ' return getattr ( self , attr ) return list ( field_names ( match.group ( 1 ) , mode_filter=None ) ) assert tables == [ ( None , 'Abc ' , None , False ) , except KeyError : if f.name and ( not mode_filter or f.mode in mode_filter ) : Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) def extract_table_identifiers ( token_stream ) : assert tables == [ ( None , 'abc ' , None ) ] def __init__ ( self , schema_name , func_name , arg_list , return_type , is_aggregate , def test_parse_typed_field_list_no_arg_names ( ) : unknown A list of tokens not assigned to type or default from pgcli.packages.function_metadata import FunctionMetadata return [ ] elif tok.value.upper ( ) == 'DEFAULT ' : and self.__dict__ == other.__dict__ ) # postgres function argument list syntax : def test_function_metadata_eq ( ) : return list ( extract_table_identifiers ( stream ) ) Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) , result = completer.get_completions ( Document ( text=sql , cursor_position=pos ) , # shadowing behavior , we need to check both views and tables for Field/column lists are used in function signatures and table { 'type ' : 'column ' , 'tables ' : [ ( None , ' a ' , None , False ) ] } , for f in parse_typed_field_list ( tokens ) : self.is_set_returning = is_set_returning def __eq__ ( self , other ) : [ 'set_returning_func ' , `` , `` , False , False , True ] ] , yield TableReference ( None , name , item.get_alias ( ) or name , # Function may have named output arguments -- find them and return functions = meta [ 'functions ' ] [ schema ] [ relname ] { 'type ' : 'column ' , 'tables ' : [ ( None , ' b ' , None ) ] } , match = table_def_regex.match ( self.return_type ) name The name of the argument/column Attributes are : # sql is something like `` x int , y text , ... '' def _identifier_is_function ( identifier ) : { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , None ) ] } , f1 = FunctionMetadata ( 's ' , ' f ' , ' x int ' , 'int ' , False , False , False ) elif tok.ttype == Name and not field.name : relname = self.escape_name ( tbl.name ) def test_simple_function_as_table ( arg_list ) : yield TableReference ( schema_name , real_name , item.get_alias ( ) , yield ( None , name , item.get_alias ( ) or name ) assert sorted ( tables ) == [ ( 'abc ' , 'def ' , None ) , ( 'ghi ' , 'jkl ' , None ) ] Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] else : parse_state = 'default ' names = field_names ( func_header , mode_filter= [ 'OUT ' , 'INOUT ' ] ) sql = 'select f. from custom.set_returning_func ( ) f ' `` `` '' Parses a argument/column list , yielding TypedFieldMetadata objects def parse_typed_field_list ( tokens ) : { 'type ' : 'column ' , 'tables ' : [ ( 'sch ' , 'tabl ' , None , False ) ] } , except KeyError : ( 'def ' , 'ghi ' , None , False ) ] ( 'bar ' , 'qux ' , 'quux ' , True ) ] def test_join_functions_using_suggests_common_columns ( completer , complete_event ) : def test_simple_aliased_function_as_table ( arg_list ) : text = `` 'SELECT * FROM set_returning_func ( ) f1 { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None ) ] } ] def test_select_suggests_fields_from_function ( ) : if tok.ttype in Keyword : def extract_table_identifiers ( token_stream , allow_functions=True ) : assert hash ( f1 ) == hash ( f2 ) `` `` '' Returns true if string ` id ` matches TableReference ` ref ` `` '' '' assert tables == [ ( None , 'Abc ' , ' a ' , False ) ] def test_parse_typed_field_list_more_complex ( ) : ( None , 'Def ' , None , False ) ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , ' a ' ) ] } , is_window , is_set_returning ) : self.return_type , self.is_aggregate , self.is_window , self.return_type = return_type.strip ( ) import re `` `` '' yields tuples of TableReference namedtuples '' '' '' # No such function name # tables and views can not share the same name , we can check one Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) , Returns a list of ( schema , table , alias ) tuples def test_table_column_names ( ) : pass yield field allow_functions=not insert_stmt ) def __init__ ( self ) : def identifies ( id , schema , table , alias ) : columns.extend ( meta [ 'views ' ] [ schema ] [ relname ] ) if field.type : else : f2 = FunctionMetadata ( 's ' , ' f ' , ' x int ' , 'int ' , False , False , False ) def __hash__ ( self ) : # tables and views can not share the same name , we can check : param scoped_tbls : list of ( schema , table , alias ) tuples sql = ' a int , b int [ ] [ ] , c double precision , d text ' is_function ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'foo ' , ' f ' , False ) ] } , # shadowing behavior , we need to check both views and tables for pass tables = extract_tables ( `` 'SELECT * FROM foo.bar baz else : IN b text default 'abc ' : :text , # [ { DEFAULT | = } default_expr ] [ , ... ] ] ) '' # AND mistakenly identifies the field list as # We do n't know if schema.relname is a table or view . Since self.name = None # function calls due to the parenthesized column list , e.g . interprets { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , 't ' , False ) ] } , z TEXT `` ' for func in functions : # assert tables == [ ( None , 'abc ' , None , False ) ] schema = self.escape_name ( tbl [ 0 ] ) return not self.__eq__ ( other ) # Table exists , so do n't bother checking for a view if tbl.is_function : return ( ( ' % s ( schema_name= % r , func_name= % r , arg_list= % r , return_type= % r , ' tables = extract_tables ( 'SELECT * FROM foo.bar ( { 0 } ) '.format ( arg_list ) ) # Initialize metadata holder for the next field JOIN bar.qux ( x , y , z ) quux '' ' ) if parens == 0 and tok.value == ' , ' : Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] [ 'set_returning_func ' , `` , 'TABLE ( x INT , y INT ) ' , field.name = tok.value allow_functions ) ] ) FunctionMetadata = namedtuple ( 'FunctionMetadata ' , field , parse_state = TypedFieldMetadata ( ) , 'type ' `` `` '' Describes typed field from a function signature or table definition assert tables == [ ( 'foo ' , 'bar ' , None , True ) ] Returns a list of TableReference namedtuples names = list ( field_names ( tbl_str , mode_filter=None ) ) is_function = ( allow_functions and assert tables == [ ( None , 'foo ' , None , False ) , return list ( field_names ( self.arg_list , mode_filter= ( 'OUT ' , 'INOUT ' ) ) ) identifier.get_alias ( ) , is_function ) field.mode = tok.value.upper ( ) table_def_regex = re.compile ( r'^TABLE\s * \ ( ( .+ ) \ ) $ ' , re.IGNORECASE ) elif parens == 0 : assert tables == [ ( None , 'Abc ' , ' a ' , False ) , definitions . This function parses a flattened list of sqlparse tokens return any ( isinstance ( t , Function ) for t in identifier.tokens ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None , False ) ] } ] continue default A list of tokens denoting the default value ( None , 'def ' , 'd ' , False ) ] class FunctionMetadata ( object ) : assert sorted ( tables ) == [ ( 'abc ' , 'def ' , None ) , ( 'def ' , 'ghi ' , None ) ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'func ' , None , True ) ] } , # func is a FunctionMetadata object # note that ` ttype in Name ` would also match Name.Builtin [ 'schema_name ' , 'func_name ' , 'arg_list ' , 'result ' , assert names == [ ' x ' , ' y ' , ' z ' ] assert tables == [ ( None , 'Abc ' , None , False ) ] 'is_aggregate ' , 'is_window ' , 'is_set_returning ' ] ) ( 'ghi ' , 'jkl ' , None , False ) ] 'OUT x INT ' , 'SETOF INT ' , assert tables == [ ( None , 'my_table ' , 'm ' , False ) ] % ( self.__class__.__name__ , self.schema_name , self.func_name , assert ( len ( args ) == 3 ) elif tok.ttype in Punctuation : Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] sql = 'select from set_returning_func ( ) ' tables = extract_tables ( 'SELECT * FROM foo ( { 0 } ) '.format ( arg_list ) ) assert list ( names ) == [ ' y ' ] try : aliases = [ t.alias or t.name for t in tables ] continue # Schema not specified , so traverse the search path looking for func_header = 'IN x INT DEFAULT 2 , OUT y DOUBLE PRECISION ' suggestions = suggest_type ( 'SELECT FROM func ( ) ' , 'SELECT ' ) # a table or view that matches . Note that in order to get proper : param scoped_tbls : list of TableReference namedtuples from collections import namedtuple # each schema before checking the next schema { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } , ref.schema and ( id == ref.schema + ' . ' + ref.name ) ) # Function returns a table -- get the column names is_function = allow_functions and _identifier_is_function ( item ) FunctionMetadata , parse_typed_field_list , field_names ) assert sorted ( tables ) == [ ( None , 'abc ' , ' a ' , False ) , def __getitem__ ( self , attr ) : assert tables == [ ( 'foo ' , 'bar ' , 'baz ' , False ) , assert set ( result ) == set ( [ def fieldnames ( self ) : if not field.name and tok.value.upper ( ) in mode_names : if tbl [ 0 ] : yield TableReference ( schema_name , real_name , # No other keywords allowed before arg name args = list ( parse_typed_field_list ( tokens ) ) ( 'ghi ' , 'jkl ' , ' y ' , False ) ] [ 'set_returning_func ' , `` , `` , False , False , True ] ] , { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , ' a ' , False ) ] } , Completion ( text= ' x ' , start_position=0 , display_meta='column ' ) ] ) parse_state = 'unknown ' field [ parse_state ] .append ( tok ) relname = self.escape_name ( tbl [ 1 ] ) assert sorted_dicts ( suggestions ) == sorted_dicts ( [ `` `` '' Class for describing a postgresql function '' '' '' result = set ( completer.get_completions ( assert suggestions == [ { 'type ' : 'column ' , { 'type ' : 'column ' , 'tables ' : [ ( None , 'def ' , 'd ' ) ] } , sql = 'select f. from set_returning_func ( ) f ' # Get an array of FunctionMetadata objects Completion ( text= ' y ' , start_position=0 , display_meta='column ' ) ] ) assert tables == [ ( None , 'foo ' , None , True ) ] # to have is_function=True Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) , assert tables == [ ( 'abc ' , 'def ' , None ) ] # Table exists , so do n't bother checking for a view { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None , False ) ] } , self.is_window = is_window tables = [ t for t in tables if identifies ( parent , t ) ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , None , False ) ] } , break return list ( identifiers ) self.arg_list = arg_list.strip ( ) assert suggestions == [ { 'tables ' : [ ( None , 'foo ' , None ) ] , 'type ' : 'column ' } , import sqlparse assert tables == [ ( 'abc ' , 'def ' , None , False ) ] type A list of tokens denoting the type 'tables ' : [ ( None , 'foo ' , None , False ) ] } , and yields one metadata argument per argument / column . `` `` '' yields tuples of ( schema_name , table_name , table_alias ) '' '' '' if match : parse_state = 'default ' ( None , 'def ' , None , False ) ] { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None ) ] } ,","['pgcli/packages/function_metadata.py', 'pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_function_metadata.py', 'tests/test_parseutils.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 368 from dbcli/darikg/suggest-columns-from-functions
381,12207f39fef560f60e51ffe2815eea843fe19850,2015-10-03 14:48:16-07:00,"] ) assert need_completion_refresh ( sql ) return True if first_token.lower ( ) in ( 'alter ' , 'create ' , 'use ' , '\\c ' , '\\connect ' , 'drop ' ) '\\connect ' , 'drop ' ) : return first_token.lower ( ) in ( 'alter ' , 'create ' , 'use ' , '\\c ' , return False def test_need_completion_refresh ( sql ) : import pytest 'SELECT * FROM foo ; DROP TABLE foo ' , 'DROP TABLE foo ' , from pgcli.main import need_completion_refresh","['pgcli/main.py', 'tests/test_main.py']",Merge pull request # 373 from dbcli/darikg/fix-need_completion_refresh
382,5e54956b7c1d597b6c83b2c7f54839e62f7c4b3b,2015-10-03 14:45:23-07:00,"'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id and ' , def test_join_alias_dot_suggests_cols2 ( sql ) : suggestions = suggest_type ( def test_on_suggests_aliases ( ) : 'select a.x , b.y from abc a join bcd b on a.id = ' , def test_join_alias_dot_suggests_cols1 ( sql ) : def test_on_suggests_tables ( sql ) : suggestions = suggest_type ( sql , sql ) suggestions = suggest_type ( 'SELECT * FROM abc a JOIN def d ON a . ' , 'SELECT * FROM abc a JOIN def d ON a . ' , 'select abc.x , bcd.y from abc join bcd on ' , def test_on_suggests_tables_right_side ( ) : 'select a.x , b.y from abc a join bcd b on ' , 'select a.x , b.y from abc a join bcd b on a.id = b.id OR ' , ] ) 'SELECT * FROM abc a JOIN def d ON a.id = d.id AND a . ' , elif token_v.endswith ( ' , ' ) or token_v == '= ' : 'select a.x , b.y from abc a join bcd b on a.id = ' ) 'select abc.x , bcd.y from abc join bcd on ' ) 'select abc.x , bcd.y from abc join bcd on ' , 'SELECT * FROM abc a JOIN def d ON a.id = d. ' , 'SELECT * FROM abc a JOIN def d ON a.id = d.id AND a.id2 = d. ' , def test_on_suggests_tables_right_side ( sql ) : def test_on_suggests_aliases_right_side ( sql ) : 'select a.x , b.y from abc a join bcd b on a.id = b.id AND a.id2 = ' , def test_on_suggests_aliases_right_side ( ) : def test_join_alias_dot_suggests_cols1 ( ) : 'select a.x , b.y from abc a join bcd b on a.id = ' , def test_on_suggests_tables ( ) : def test_on_suggests_aliases ( sql ) : 'SELECT * FROM abc a JOIN def d ON a . ' ) elif token_v.endswith ( ' , ' ) or token_v in ( '= ' , 'and ' , 'or ' ) : 'select a.x , b.y from abc a join bcd b on ' ) suggestion = suggest_type ( 'SELECT * FROM abc a JOIN def d ON a . ' , 'select a.x , b.y from abc a join bcd b on ' , def test_join_alias_dot_suggests_cols2 ( ) : 'SELECT * FROM abc a JOIN def d ON a.id = d . ' ) 'select abc.x , bcd.y from abc join bcd on abc.id = bcd.id AND ' , suggestion = suggest_type ( sql , sql )","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 371 from dbcli/darikg/fix-compound-join-clauses
383,9f2fced17bb01ce1f8170aecf4f87a0c3ab229dc,2015-09-28 22:07:11-07:00,"# via the special_command decorator and stored in default_commands with a short name . Think of them as favorites . PARSED_QUERY = 1 command_dict [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , register_special_command ( wrapped , command , syntax , description , commands = self.commands os.environ.pop ( 'PAGER ' , None ) return special_cmd.handler ( cur=cur , query=sql ) self.pager = os.environ.get ( 'PAGER ' , `` ) def toggle_timing ( self ) : ╞════════╪════════╡ return self.config.get ( self.section_name , { } ) .get ( name , None ) hidden , case_sensitive ) if special_cmd.arg_type == NO_QUERY : return ' % s : Not Found . ' % name def content_exceeds_width ( row , width ) : def delete ( self , name ) : # - * - coding : utf-8 - * log = logging.getLogger ( __name__ ) command_dict [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , if not pattern : register_special_command ( * args , command_dict=self.commands , * * kwargs ) self.config [ self.section_name ] = { } # Delete a named query . NO_QUERY = 0 self.expanded_output = False command , verbose , pattern = parse_special_command ( sql ) self.config [ self.section_name ] [ name ] = query self.config.write ( ) ╒════════╤════════╕ import os self.register ( self.set_pager , '\\pager ' , '\\pager [ command ] ' , RAW_QUERY = 2 hidden=False , case_sensitive=True , aliases= ( ) ) : separator_space = ( len ( row ) * 3 ) def place_holder ( ) : from collections import namedtuple command = command.strip ( ) .replace ( '+ ' , `` ) 'Toggle timing of commands . ' , arg_type=NO_QUERY ) return [ ( None , None , None , msg ) ] self.auto_expand = True else : msg = 'Pager reset to system default . ' arg_type=NO_QUERY ) command_dict=None ) : # Account for 3 characters between each column raise RuntimeError hidden=True ) default_commands = { } if special_cmd.case_sensitive : return wrapped msg = 'Reset pager back to default . Default : % s ' % self.pager 'Set PAGER . Pring the query results via PAGER . ' , select * from django_migrations ; os.environ [ 'PAGER ' ] = pattern special_cmd = commands [ command.lower ( ) ] class CommandNotFound ( Exception ) : message += `` on . '' if self.timing_enabled else `` off . '' case_sensitive=case_sensitive , verbose = '+ ' in command ╞════════╪═══════════════════════════════════════╡ def register ( self , * args , * * kwargs ) : return ' % s : Deleted ' % name @ special_command ( '\\e ' , '\\e [ file ] ' , 'Edit the query with external editor . ' , arg_type=NO_QUERY ) def wrapper ( wrapped ) : self.register ( self.toggle_timing , '\\timing ' , '\\timing ' , def register_special_command ( handler , command , syntax , description , SpecialCommand = namedtuple ( 'SpecialCommand ' , > \\ns simple select * from abc where a is not Null ; # Add 2 columns for a bit of buffer elif flag == `` on '' : # Default static commands that do n't rely on PGSpecial state are registered self.commands = self.default_commands.copy ( ) arg_type , hidden , case_sensitive , aliases , Examples : if not value.hidden : if ( command not in commands ) and ( command.lower ( ) not in commands ) : ╘════════╧════════╛ select * FROM abc command_dict=PGSpecial.default_commands ) class NamedQueries ( object ) : message = u '' Expanded display is `` self.auto_expand = self.expanded_output from . import export def parse_special_command ( sql ) : │ Name │ Query │ self.timing_enabled = False @ special_command ( '\\sf ' , '\\sf [ + ] FUNCNAME ' , 'Show a function\ 's definition . ' , arg_type=NO_QUERY , hidden=True ) ╒════════╤═══════════════════════════════════════╕ ╘════════╧═══════════════════════════════════════╛ try : result.append ( ( value.syntax , value.description ) ) `` `` '' A decorator used internally for static special commands '' '' '' self.timing_enabled = True usage = u '' 'Named Queries are a way to save frequently used queries elif flag == `` off '' : pass raise CommandNotFound @ export message = `` Timing is `` namedqueries = NamedQueries ( load_config ( '~/.config/pgcli/config ' ) ) if not self.pager : def __init__ ( self ) : raise CommandNotFound ( 'Command not found : % s ' % command ) msg = 'PAGER set to % s . ' % pattern return special_cmd.handler ( ) def execute ( self , cur , sql ) : del self.config [ self.section_name ] [ name ] arg_type=PARSED_QUERY , hidden=False , case_sensitive=True , aliases= ( ) , line_len = sum ( [ len ( x ) for x in row ] ) + separator_space + 2 > \\n simple return [ ( None , result , headers , None ) ] def set_pager ( self , pattern , * * _ ) : > \\nd simple arg_type=PARSED_QUERY ) return ( command , verbose , arg.strip ( ) ) return special_cmd.handler ( cur=cur , pattern=pattern , verbose=verbose ) for alias in aliases : cmd = alias.lower ( ) if not case_sensitive else alias self.timing_enabled = not self.timing_enabled self.expanded_output = False def get ( self , name ) : flag = pattern.strip ( ) message += u '' on . '' if self.expanded_output else u '' off . '' self.expanded_output = True section_name = 'named queries ' @ special_command ( '\\ef ' , '\\ef [ funcname [ line ] ] ' , 'Edit the contents of the query buffer . ' , arg_type=NO_QUERY , hidden=True ) for _ , value in sorted ( self.commands.items ( ) ) : [ 'handler ' , 'syntax ' , 'description ' , 'arg_type ' , 'hidden ' , 'case_sensitive ' ] ) cmd = command.lower ( ) if not case_sensitive else command 'Toggle expanded output . ' , arg_type=PARSED_QUERY ) import logging return line_len > width elif special_cmd.arg_type == PARSED_QUERY : else : def __init__ ( self , config ) : self.expanded_output = not ( self.expanded_output or self.auto_expand ) elif special_cmd.arg_type == RAW_QUERY : if flag == `` auto '' : │ 日本語 │ 日本語 │ def doc_only ( ) : def toggle_expanded_output ( self , pattern , * * _ ) : │ simple │ SELECT * FROM abc where a is not NULL │ self.auto_expand = False from ... config import load_config # Run a named query . @ special_command ( '\\z ' , '\\z [ pattern ] ' , 'Same as \\dp . ' , arg_type=NO_QUERY , hidden=True ) special_cmd = commands [ command ] command , _ , arg = sql.partition ( ' ' ) def list ( self ) : namedqueries = NamedQueries ( load_config ( '~/.pgclirc ' ) ) self.register ( self.show_help , '\\ ? ' , '\\ ? ' , 'Show Help . ' , @ special_command ( '\\dp ' , '\\dp [ pattern ] ' , 'List table , view , and sequence access privileges . ' , arg_type=NO_QUERY , hidden=True ) os.environ [ 'PAGER ' ] = self.pager class PGSpecial ( object ) : │ a │ b │ return [ ( None , None , None , u '' Expanded display is used automatically . '' ) ] self.config = config if os.path.isfile ( '~/.config/pgcli/config ' ) : # List all named queries . return wrapper self.register ( self.toggle_expanded_output , '\\x ' , '\\x ' , ' '' else : def save ( self , name , query ) : except KeyError : def special_command ( command , syntax , description , arg_type=PARSED_QUERY , def show_help ( self ) : simple : Deleted > \\n result = [ ] raise NotImplementedError return self.config.get ( self.section_name , [ ] ) if self.section_name not in self.config : headers = [ 'Command ' , 'Description ' ] # Save a new named query . return [ ( None , None , None , message ) ] @ special_command ( '\\do ' , '\\do [ S ] [ pattern ] ' , 'List operators . ' , arg_type=NO_QUERY , hidden=True )","['pgcli/packages/pgspecial/main.py', 'pgcli/packages/pgspecial/namedqueries.py', 'pgcli/packages/pgspecial/tmp.sql']",Merge pull request # 367 from dbcli/j-bennet/pgspecial-merge-cleanup
384,981f3aadc79a301ccd391e805f3213ad47bab4cd,2015-09-27 22:38:51-07:00,"import pgcli.packages.pgspecial as special elif category == 1 and row [ 2 ] == 'D ' : WHEN ' f ' THEN 'foreign table ' END `` `` '' Save a new named query . # Get column info ORDER BY e.enumsortorder status.append ( `` Rules firing always : '' ) schema , relname = sql_name_pattern ( pattern ) have_heading = True if not rows : # / * untranslated contraint name and def * / def cursor ( connection ) : c.relname as `` Name '' , modifier = `` headers.append ( `` FDW Options '' ) def list_roles ( cur , pattern , verbose ) : # * disabled triggers and the two special ALWAYS and REPLICA `` array_to_string ( ARRAY ( SELECT `` status.append ( `` Triggers : '' ) schema1.s1_tbl1 '' ' ) return ( None , cells , headers , `` '' .join ( status ) ) # / * Print the category heading once * / params.append ( relname ) if ( ( tableinfo.relkind == ' v ' or tableinfo.relkind == 'm ' ) and verbose ) : import psycopg2.extras LEFT JOIN pg_catalog.pg_namespace n condeferrable , ( NOT i.indimmediate ) AND EXISTS ( SELECT 1 FROM return defn # * / # * If we get no rows back , do n't show anything ( obviously ) . We should sql += `` '' '' , NULL AS attfdwoptions '' '' '' sql = `` '' '' SELECT c.oid , n.nspname , c.relname # / * Footer information about a view * / if row [ 7 ] == `` u '' : if func_pattern : # / * OIDs , if verbose and not a materialized view * / @ special_command ( 'describe ' , 'DESCRIBE [ pattern ] ' , `` , hidden=True , case_sensitive=False ) return [ ( title , None , None , cur.statusmessage ) ] schema = '^ ( ' + schema + ' ) $ ' if cur.description : if relname : `` pg_catalog.pg_index i\n '' ) params.append ( schema ) def connection ( ) : r.rolcreaterole , r.rolcreatedb , r.rolcanlogin , headers = [ 'Schema ' , 'Name ' , 'Description ' ] if pattern == `` : row = cur.fetchone ( ) ( indisunique , indisprimary , indisclustered , indisvalid , message = 'Error reading file : % s . ' % filename % s , if cur.description : # / * Everything after `` CREATE RULE '' is echoed verbatim * / params = [ relkinds ] 'pgspecial > =1.1.0 ' , AND el.typarray = t.oid ) `` ' l.lanname as `` Language '' , # placeholder comment . status.append ( `` UNIQUE , '' ) ( 'schema1 ' , 'postgres ' ) , 'relpersistence ' ] ) elif not inquotes and c == ' . ' : where = [ ] def teardown_db ( conn ) : CASE if row [ 3 ] : SELECT e.enumlabel `` \n AND d.objid= % s \n AND d.deptype= ' a ' '' % oid ) # * Print triggers next , if any ( but only user-defined triggers ) . This pg_catalog.obj_description ( p.oid , 'pg_proc ' ) as `` Description '' `` ' if table_pattern : # / * untranslated constraint name and def * / sql = `` '' '' SELECT i.indisunique , i.indisprimary , i.indisclustered , status.append ( `` Disabled triggers : '' ) ruledef = row [ 1 ] @ special_command ( '\\n ' , '\\n [ + ] [ name ] ' , 'List or execute named queries . ' ) sql = sql.strip ( ) deferrable , deferred , indamname , indtable , indpred ) = cur.fetchone ( ) spacer = `` view_def = `` message = `` No named query : { } '' .format ( pattern ) AS `` Description '' ' '' as `` Result data type '' , `` \n a.attnum=d.refobjsubid ) '' a.attcollation AND t.oid = a.atttypid AND a.attcollation < > 'toast . ' || x from pg_catalog.unnest ( tc.reloptions ) x ) , ' , ' ) '' '' '' def get_filename ( sql ) : DROP SCHEMA IF EXISTS schema2 CASCADE '' ' ) cells.append ( cell ) elif category ==1 : return [ ( None , cur , headers , cur.statusmessage ) ] ' '' + verbose_columns + `` ' # Create a namedtuple called tableinfo and match what 's in describe.c # views cur.execute ( 'create view vw1 as select * from tbl1 ' ) return list_objects ( cur , pattern , verbose , [ ' v ' , 's ' , `` ] ) status.append ( '\n ' ) @ special_command ( '\\df ' , '\\df [ + ] [ pattern ] ' , 'List functions . ' ) if ( verbose and tableinfo.relkind ! = 'm ' ) : if tableinfo.relkind == 'S ' : if c == ' '' ' : END as `` Type '' `` ' + verbose_columns + `` ' return [ ( None , None , None , 'Did not find any relation named % s . ' % pattern ) ] `` WHERE r.conrelid = ' % s ' AND r.contype = ' c'\n '' # / * Add these for all cases * / rows = [ ( 'public ' , 'func1 ' , 'integer ' , `` , 'normal ' ) ] suffix = `` '' '' if indisclustered : # Do n't return None for the caller to deal with . usage = 'Syntax : \\ns name query.\n\n ' + namedqueries.usage spacer = ' ' * len ( 'Inherits ' ) `` ev_enabled\n '' `` WHERE f.ftrelid = % s AND s.oid = f.ftserver ; '' % oid ) `` pg_catalog.pg_foreign_server s\n '' elif not inquotes and c.isupper ( ) : schema_pattern , type_pattern = sql_name_pattern ( pattern ) tableinfo.relkind == 'm ' or tableinfo.relkind == ' f ' or WHERE m.member = r.oid ) as memberof '' ' + ( `` ' , cur.execute ( query ) status.append ( `` % s : % s , \n '' % ( spacer , row ) ) sql = ( `` SELECT r.conname , `` CASE status.append ( `` Rules : '' ) # Execute the sql , get the results and call describe_one_table_details on each table . AND n.nspname < > 'information_schema ' `` ' relname += '\\ ' if not ( schema_pattern or func_pattern ) : a.attnum AND a.atthasdef ) , a.attnotnull , a.attnum , ( SELECT c.collname pg_catalog.pg_constraint WHERE conrelid = i.indrelid AND conindid = CASE WHEN c.reloftype = 0 THEN `` attfdwoptions '' '' '' relkinds is a list of strings to filter pg_class.relkind globals ( ) [ defn.__name__ ] = defn sql += `` '' '' , CASE WHEN a.attstattarget=-1 THEN NULL ELSE def list_databases ( cur , * * _ ) : spacer = ' ' * len ( 'Child tables ' ) sql = cur.mogrify ( sql + ' ORDER BY 1 , 2 , 4 ' , params ) schema_pattern , table_pattern = sql_name_pattern ( pattern ) : return : list with one tuple , query as first element . headers = [ 'Name ' , 'Owner ' ] status.append ( '\n ' ) status.append ( `` % s : % s , \n '' % ( spacer , row ) ) sql = `` 'SELECT r.rolname , r.rolsuper , r.rolinherit , if pattern : import re # / * print incoming foreign-key references ( none if no triggers ) * / else : headers.append ( `` Description '' ) sql = cur.mogrify ( sql + `` ORDER BY 1 '' , params ) ORDER BY 2,3 '' '' '' elif indisunique : # / * If exclusion constraint , print the constraintdef * / status.append ( `` Owned by : % s '' % result [ 0 ] ) yield connection WHERE ( t.typrelid = 0 OR # Prepare the cells of the table to print . `` \n a.attrelid=c.oid AND '' with connection.cursor ( ) as cur : # for both conditions . if ( tableinfo.hastriggers ) : sql += 'WHERE r.rolname ~ % s ' from .packages.pgspecial.main import ( PGSpecial , NO_QUERY , content_exceeds_width ) def list_tables ( cur , pattern , verbose ) : dbtest = pytest.mark.skipif ( status.append ( `` \ '' % s\ '' % s '' % row ) headers.append ( 'Modifiers ' ) for row in cur : # add_tablespace_footer ( & cont , tableinfo.relkind , tableinfo.tablespace , WHEN 'S ' THEN 'sequence ' WHEN 's ' THEN 'special ' elif category ==3 : FROM pg_catalog.pg_class c params.append ( schema_pattern ) `` FROM pg_catalog.pg_constraint r\n '' @ special_command ( '\\du ' , '\\du [ + ] [ pattern ] ' , 'List roles . ' ) if not verbose : return [ ( None , None , None , `` Saved . '' ) ] verbose_table = `` ' LEFT JOIN pg_catalog.pg_language l sql += '~ % s ' status.append ( `` Foreign-key constraints : \n '' ) expected = [ title , rows , headers , status ] AND n.nspname < > 'pg_catalog ' i = 0 ARRAY ( FROM pg_catalog.pg_class c ELSE c.reloftype : :pg_catalog.regtype : :pg_catalog.text sql += `` ! ~ '^pg_ ' AND n.nspname < > 'information_schema ' '' `` WHERE r.ev_class = ' % s ' ORDER BY 1 ; '' % # * / # tableinfo.tablespace , true ) ; from . import iocommands c.reltablespace , as `` Argument data types '' , status.append ( `` % s \n '' % view_def ) cell.append ( row [ 10 ] ) results = executor ( '\d ' ) with conn.cursor ( ) as cur : inquotes = False `` t.tgenabled\n '' # / * reloptions , if verbose * / # / * Print per-table FDW options , if any * / # / * print foreign-key constraints ( there are none if no triggers ) * / status.append ( `` % s '' % indexdef ) `` quote_literal ( option_value ) FROM `` AND c.oid = ' % s ' AND c.relam = a.oid AND i.indrelid = c2.oid ; '' '' '' % oid status.append ( `` DEFERRABLE '' ) status = 'SELECT 2 ' if ( usingpos > = 0 ) : show_modifiers = False `` c.oid : :pg_catalog.regclass : :pg_catalog.text ; '' % oid ) cell.append ( 'external ' ) # * do n't print anything . if ( tableinfo.relkind == 'S ' ) : a.attnum > 0 AND NOT a.attisdropped ORDER BY a.attnum ; `` '' '' % oid # / * Everything after `` TRIGGER '' is echoed verbatim * / ( SELECT substring ( pg_catalog.pg_get_expr ( d.adbin , d.adrelid ) for 128 ) res = cur.fetchall ( ) # Set the column names . THEN CAST ( 'var ' AS pg_catalog.text ) status = namedqueries.usage pg_catalog.pg_class c2 , pg_catalog.pg_am a WHERE i.indexrelid = c.oid CAN_CONNECT_TO_DB = False if not pattern : if sql.strip ( ) .startswith ( '\\e ' ) : def list_named_queries ( verbose ) : # printTableAddFooter ( & cont , buf.data ) ; continue ; rows = [ [ r , namedqueries.get ( r ) ] for r in namedqueries.list ( ) ] except : sql += `` pg_catalog.pg_get_indexdef ( i.indexrelid , 0 , true ) , \n `` sql += `` ' FROM pg_catalog.pg_type t if tableinfo.relkind == ' i ' : cell.append ( row [ 9 ] ) WHEN 'S ' THEN 'sequence ' connection.close ( ) # Do stuff here . # / * print rules * / END AS `` Size '' , view_def = cur.fetchone ( ) storage = row [ 8 ] > > > sql_name_pattern ( 'foo * . `` b '' '' $ ar * '' ' ) if deferrable : sql += `` ' AND n.nspname < > 'pg_catalog ' c.relpersistence # / * print child tables * / # / * query = query.split ( MARKER , 1 ) [ 0 ] .rstrip ( '\n ' ) if category ==0 : condeferred , a.amname , c2.relname , pg_catalog.pg_get_expr ( i.indpred , headers.append ( `` Storage '' ) pg_catalog.obj_description ( n.oid , 'pg_namespace ' ) AS `` Description '' ' '' if verbose else `` ) + `` '' '' meta='named query ' ) FROM pg_catalog.pg_namespace n WHERE n.nspname `` '' '' sql += `` , c2.reltablespace '' cell = [ ] pg_catalog.pg_get_function_arguments ( p.oid ) i.indisvalid , ( NOT i.indimmediate ) AND EXISTS ( SELECT 1 FROM if ( tableinfo.hasindex ) : def test_slash_dn ( executor ) : a.attnum ) '' '' '' have_heading = True return [ ( None , cur , headers , cur.statusmessage ) ] `` FROM pg_catalog.pg_constraint r\n '' sql += `` ' Open external editor , wait for the user to type in his query , if not list_rule : CASE c.relkind headers.append ( `` Stats target '' ) if ( tableinfo.relkind == ' r ' or tableinfo.relkind == ' v ' or if ( tgenabled == ' A ' ) : OR pg_catalog.format_type ( t.oid , NULL ) ~ % s ) `` ' # datatype as `` Description '' `` ' # / * print table ( and column ) check constraints * / if ( tgenabled == ' O ' or tgenabled == True ) : for oid , nspname , relname in cur.fetchall ( ) : def export ( defn ) : with io.open ( expanduser ( path ) , encoding='utf-8 ' ) as f : if tableinfo.relkind == ' f ' : array_to_string ( ARRAY ( SELECT quote_ident ( option_name ) || ' ' verbose_columns = `` sql += ' pg_catalog.pg_function_is_visible ( p.oid ) ' tableinfo.relkind == ' c ' or tableinfo.relkind == ' f ' ) : return list_named_queries ( True ) sql = ( `` SELECT c.oid : :pg_catalog.regclass FROM pg_catalog.pg_class c , `` sql = ( `` SELECT s.srvname , \n '' rows = [ ( 'public ' , 'postgres ' ) , queries = self.find_matches ( word_before_cursor , namedqueries.list ( ) , status.append ( `` Typed table of type : % s\n '' % tableinfo.reloftype ) status.append ( `` TABLE \ '' % s\ '' CONSTRAINT \ '' % s\ '' % s\n '' % row ) if tableinfo.relkind == ' f ' : headers = [ `` Name '' , `` Query '' ] show_modifiers = True status.append ( 'Child tables ' ) conn.autocommit = True # add_tablespace_footer ( & cont , tableinfo.relkind , usage + 'Err : Both name and query are required . ' ) ] headers = [ x [ 0 ] for x in cur.description ] WHERE e.enumtypid = t.oid `` \n AND d.refclassid='pg_catalog.pg_class ' : :pg_catalog.regclass '' c.relhasrules , c.relhastriggers , c.relhasoids , relname += c status.append ( `` \ '' % s\ '' % s\n '' % row ) elif ( tableinfo.relkind == ' r ' or tableinfo.relkind == 'm ' or @ dbtest from collections import namedtuple status.append ( `` Inherits '' ) sql = ( `` SELECT r.rulename , trim ( trailing ' ; ' from pg_catalog.pg_get_ruledef ( r.oid , true ) ) , `` rows = [ ( 'public ' , 'foo ' , None ) ] assert results == expected oid ) status = `` i.indexrelid AND contype IN ( ' p ' , ' u ' , ' x ' ) AND condeferrable ) AS WHEN p.provolatile = ' i ' THEN 'immutable ' `` pg_catalog.pg_get_constraintdef ( r.oid , true ) \n '' def test_slash_d ( executor ) : indexdef = row [ 5 ] def query_runner ( sql ) : # / * Footer information about an index * / for category in range ( 4 ) : t.typcollation ) AS attcollation '' '' '' WHERE el.oid = t.typelem except : for row in cur : i.indexrelid AND contype IN ( ' p ' , ' u ' , ' x ' ) AND condeferred ) AS # / * Everything after `` CREATE RULE '' is echoed verbatim * / # / * Tablespace info * / query = namedqueries.get ( pattern ) `` `` '' Delete an existing named query . sql = ( `` SELECT t.tgname , `` results = executor ( '\df ' ) # / * `` WHERE c.confrelid = ' % s ' AND c.contype = ' f ' ORDER BY 1 ; '' % where.append ( ' c.relname ~ % s ' ) def list_objects ( cur , pattern , verbose , relkinds ) : log.debug ( sql ) for category in range ( 4 ) : status.append ( `` Options : % s\n '' % tableinfo.reloptions ) status.append ( `` Rules : \n '' ) start_only=False , fuzzy=True , meta='named query ' ) for i , row in enumerate ( res ) : headers.append ( `` Value '' ) setup_db ( connection ) END as `` Volatility '' , indexdef = indexdef [ ( usingpos + 7 ) : ] seq_values = cur.fetchone ( ) SERVER_VERSION = 0 ( 'public ' , 'vw1 ' , 'view ' , 'postgres ' ) ] for row in cur : cell.append ( row [ 0 ] ) # Column def create_db ( dbname ) : status.append ( '\n ' ) schema = relname status.append ( row [ 6 ] ) LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace headers = [ 'Column ' , 'Type ' ] pg_catalog.array_to_string ( t.typacl , E'\n ' ) tgdef = row [ 1 ] if list_trigger == False : modifier += ' not null ' _logger = logging.getLogger ( __name__ ) import io status.append ( `` Server : % s\n '' % row [ 0 ] ) else : # Index column tableinfo.relkind == ' f ' ) : ( '^ ( foo . * ) $ ' , '^ ( b '' \\\\ $ ar\\\\ * ) $ ' ) `` \nINNER JOIN pg_catalog.pg_attribute a ON ( `` if ( tableinfo.relkind == ' r ' or tableinfo.relkind == ' v ' or # * split the output into 4 different categories . Enabled triggers , return conn database=dbname ) if ( verbose ) : WHEN t.typrelid ! = 0 # * / p.prosrc as `` Source code '' , # / * Footer information about foreign table * / status.append ( `` , deferrable '' ) from pgspecial.namedqueries import NamedQueries import pytest inquotes = not inquotes status.append ( `` , invalid '' ) ELSE 'normal ' where.append ( 'pg_catalog.pg_table_is_visible ( c.oid ) ' ) if category == 3 : status.append ( `` Rules firing on replica only : '' ) WHEN p.prorettype = 'pg_catalog.trigger ' : :pg_catalog.regtype def list_datatypes ( cur , pattern , verbose ) : sql += `` LEFT JOIN pg_catalog.pg_constraint con ON ( conrelid = i.indrelid AND conindid = i.indexrelid AND contype IN ( ' p ' , ' u ' , ' x ' ) ) \n '' usingpos = indexdef.find ( `` USING `` ) FROM pg_catalog.pg_class c sql += ' AND n.nspname ~ % s ' from .namedqueries import namedqueries p.proname as `` Name '' , if ( tableinfo.checks ) : status.append ( `` Has OIDs : % s\n '' % while pattern.search ( sql ) : `` \nINNER JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace '' def list_sequences ( cur , pattern , verbose ) : tableinfo.relkind == ' c ' or tableinfo.relkind == ' f ' ) : status = 'SELECT 1 ' tableinfo.relkind == ' c ' ) : return query_runner results.extend ( ( title , list ( rows ) , headers , status ) ) # schemas def db_connection ( dbname=None ) : if row [ 1 ] : if inquotes and i + 1 < pattern_len and pattern [ i + 1 ] == ' '' ' : sql += `` '' '' , pg_catalog.pg_get_indexdef ( a.attrelid , a.attnum , TRUE ) @ special_command ( '\\dn ' , '\\dn [ + ] [ pattern ] ' , 'List schemas . ' ) WHERE c.oid = ' % s ' '' '' '' % ( suffix , oid ) log.debug ( sql ) if indpred : `` pg_options_to_table ( ftoptions ) ) , ' , ' ) `` from .main import special_command status.append ( `` Triggers firing always : '' ) def describe_table_details ( cur , pattern , verbose ) : WHEN p.provolatile = ' v ' THEN 'volatile ' def save_named_query ( pattern , * * _ ) : relname += ' . ' `` FROM pg_catalog.pg_rewrite r\n '' def describe_one_table_details ( cur , schema_name , relation_name , oid , verbose ) : # atooid ( PQgetvalue ( result , i , 10 ) ) , : param command : string pattern_len = len ( pattern ) elif row [ 2 ] : `` `` '' ' '' + verbose_table + `` ' def open_external_editor ( filename=None , sql= '' ) : def executor ( connection ) : THEN 'trigger ' have_heading = False headers = [ 'Schema ' , 'Name ' , 'Type ' , 'Owner ' ] status.append ( `` INVALID '' ) DROP SCHEMA public CASCADE ; if indisvalid : pg_catalog.obj_description ( c.oid , 'pg_class ' ) as `` Description '' `` ' params.extend ( 2 * [ type_pattern ] ) `` pg_catalog.pg_get_triggerdef ( t.oid , true ) , `` cur.execute ( `` 'create function func1 ( ) returns int language sql as status.append ( `` , clustered '' ) FROM pg_catalog.pg_class c sql = cur.mogrify ( sql , params ) results.append ( describe_one_table_details ( cur , nspname , relname , oid , verbose ) ) ARRAY ( SELECT b.rolname ) , E'\n ' ) AS `` Elements '' , # / * Print tablespace of the index on the same line * / # Populate the editor buffer with the partial sql ( if available ) and a else : # Dollar is always quoted , whether inside quotes or not . WHEN ' v ' THEN 'view ' i += 1 ( SELECT c.relkind = ' c ' continue cur.execute ( 'create schema schema2 ' ) `` `` '' List all datatypes . '' '' '' addopts= -- capture=sys -- showlocals relname += ' '' ' headers = [ 'Schema ' , 'Name ' , 'Result data type ' , 'Argument data types ' , sql += ' AND p.proname ~ % s ' `` i.inhrelid = ' % s ' ORDER BY inhseqno ; '' % oid ) # * Check if this trigger falls into the current category 'hasrules ' , 'hastriggers ' , 'hasoids ' , 'tablespace ' , 'reloptions ' , 'reloftype ' , elif storage [ 0 ] == ' x ' : Returns ( title , rows , headers , status ) '' '' '' i.indrelid , true ) FROM pg_catalog.pg_index i , pg_catalog.pg_class c , if triggerpos > = 0 : SELECT 1 `` them . ) \n '' % cur.rowcount ) cur.execute ( sql ) # / * Check if table is a view or materialized view * / cur.execute ( sql ) # Ex : `` select * from style\e '' - > `` select * from styl '' . cell.append ( row [ 6 ] ) # * never get more than one row back , but if we do , just ignore it and if c == ' $ ' or inquotes and c in '| * + ? ( ) [ ] { } .^\\ ' : `` FROM pg_catalog.pg_foreign_table f , \n '' `` i.inhparent = ' % s ' ORDER BY '' pg_catalog.pg_get_userbyid ( p.proowner ) as `` Owner '' , # functions if show_modifiers : sql = `` SELECT c2.relname , i.indisprimary , i.indisunique , i.indisclustered , `` tableinfo.relkind == ' c ' ) : WHEN 'm ' THEN 'materialized view ' WHEN ' i ' THEN 'index ' AS indexdef '' '' '' @ special_command ( '\\ns ' , '\\ns name query ' , 'Save a named query . ' ) pg_catalog.pg_get_function_result ( p.oid ) from .config import load_config pgspecial = PGSpecial ( ) if category == 0 : # * configurations . `` \nWHERE d.classid='pg_catalog.pg_class ' : :pg_catalog.regclass '' CREATE SCHEMA public ; relname = `` @ pytest.fixture 'Type ' ] if not verbose : `` \n pg_catalog.quote_ident ( attname ) '' if ( tableinfo.relkind == ' f ' ) : if category == 1 : # / * Need these for deferrable PK/UNIQUE indexes * / as `` Type '' , status.append ( `` primary key , `` ) NamedQueries.instance = NamedQueries.from_config ( load_config ( '~/.pgclirc ' ) ) @ pytest.yield_fixture ( scope='module ' ) if not have_heading : `` pg_catalog.pg_inherits i WHERE c.oid=i.inhparent AND `` if ( tableinfo.relkind == ' r ' or tableinfo.relkind == 'm ' or filename = filename.strip ( ) .split ( ' ' , 1 ) [ 0 ] if filename else None modifier += ' default % s ' % row [ 2 ] for title , rows , headers , status in pgspecial.execute ( cur=cur , sql=sql ) : tableinfo.relkind == 'm ' or return list_objects ( cur , pattern , verbose , [ ' r ' , `` ] ) if verbose else `` ) + `` '' '' , r.rolreplication ELSE CAST ( t.typlen AS pg_catalog.text ) FROM pg_catalog.pg_collation c , pg_catalog.pg_type t WHERE c.oid = tableinfo.relkind == ' f ' ) : status = namedqueries.delete ( pattern ) WHERE c.relkind IN ( ' r ' , ' v ' , 'm ' , 'S ' , ' f ' , '' ) `` contype , condeferrable , condeferred '' ) _ , schema = sql_name_pattern ( pattern ) cur.execute ( `` 'CREATE DATABASE _test_db '' ' ) sql += `` '' '' , CASE WHEN attfdwoptions IS NULL THEN `` ELSE ' ( ' || # Sequence elif category ==2 : # add_tablespace_footer ( & cont , ' i ' , if row [ 2 ] : else : if ( tableinfo.relkind == ' i ' ) : suffix = `` '' '' pg_catalog.array_to_string ( c.reloptions || array ( select from .pgspecial import parse_special_command sql = ( `` SELECT c.oid : :pg_catalog.regclass FROM pg_catalog.pg_class c , '' query = read_from_file ( filename ) schema = None for row in cur : # Empty string is ok . pg_options_to_table ( attfdwoptions ) ) , ' , ' ) || ' ) ' END AS query = 'SELECT datname FROM pg_database ; ' from os.path import expanduser WHEN t.typlen < 0 || quote_literal ( option_value ) FROM WHERE c.relkind = ANY ( % s ) `` ' AND n.nspname < > 'information_schema ' if not ( cur.rowcount > 0 ) : WHEN 's ' THEN 'special ' return ( None , None , None , 'Something went wrong . ' ) # The reason we ca n't simply do .strip ( '\e ' ) is that it strips characters , , pg_catalog.pg_size_pretty ( pg_catalog.pg_table_size ( c.oid ) ) as `` Size '' , conn = db_connection ( ) rows = [ ( 'public ' , 'tbl1 ' , 'table ' , 'postgres ' ) , cur.execute ( 'create table tbl1 ( id1 integer , txt1 text ) ' ) title = None FROM pg_catalog.pg_auth_members m status.append ( `` View definition : \n '' ) status.append ( 'for table `` % s. % s '' ' % ( schema_name , indtable ) ) if not row [ 4 ] : status.append ( `` Disabled rules : '' ) elif storage [ 0 ] == ' e ' : `` \n pg_catalog.quote_ident ( relname ) || ' . ' || '' verbose_columns = `` ' status.append ( `` unique , `` ) results = executor ( '\dn ' ) # TODO : should this be somehow be divined from environment ? AND n.nspname ! ~ '^pg_toast ' sql += `` '' '' , pg_catalog.col_description ( a.attrelid , # This is a \d < tablename > command . A royal pain in the ass . from .packages.pgspecial.namedqueries import namedqueries [ pytest ] cell.append ( seq_values [ i ] ) ON l.oid = p.prolang '' ' LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace sql = `` ' AND pg_catalog.pg_table_is_visible ( c.oid ) results = executor ( '\dT ' ) c = pattern [ i ] `` ORDER BY i.indisprimary DESC , i.indisunique DESC , c2.relname ; '' ) % oid FROM pg_catalog.pg_attrdef d WHERE d.adrelid = a.attrelid AND d.adnum = return [ ( None , None , None , cur.statusmessage ) ] if verbose : if not have_heading : have_heading = False ; `` WHERE r.ev_class = ' % s ' AND r.rulename ! = '_RETURN ' ORDER BY 1 ; '' % oid ) from dbutils import ( create_db , db_connection , setup_db , teardown_db ) TableInfo = namedtuple ( `` TableInfo '' , [ 'checks ' , 'relkind ' , 'hasindex ' , # / * print inherited tables * / # not a substring . So it 'll strip `` e '' in the end of the sql also ! # / * we assume here that index and table are in same schema * / # Column comments , if the relkind supports this feature . * / # It is possible to have ` \e filename ` or ` SELECT * FROM \e ` . So we check status.append ( `` INITIALLY DEFERRED '' ) sql += r '' ' t.typname AS `` Internal name '' , triggerpos = tgdef.find ( `` TRIGGER `` ) if tableinfo.relkind == 'S ' : message = None if ( tableinfo.relkind == ' r ' or tableinfo.relkind == ' v ' or results = executor ( '\dt ' ) elif category == 1 : AS `` Access privileges '' , r.rolconnlimit , r.rolvaliduntil , `` FROM pg_catalog.pg_rewrite r\n '' cur.execute ( `` 'create view schema1.s1_vw1 as select * from return cur # / * Footer information about a sequence * / tgdef = triggerpos + 9 ; used in a WHERE clause . cur.execute ( 'create table tbl2 ( id2 integer , txt2 text ) ' ) `` `` '' List all tables in public schema . '' '' '' status.append ( '\n ' ) if query is not None : headers.append ( `` Definition '' ) LEFT JOIN pg_catalog.pg_class tc ON ( c.reltoastrelid = tc.oid ) headers = [ x [ 0 ] for x in cur.description ] start_only=False , fuzzy=True , tableinfo.relkind == 'm ' or tableinfo.relkind == ' f ' or # Found schema/name separator , move current pattern to schema elif storage [ 0 ] == 'm ' : status.append ( `` % s\n '' % ruledef ) @ special_command ( '\\nd ' , '\\nd [ name ] ' , 'Delete a named query . ' ) elif category == 2 and row [ 2 ] == ' A ' : ruledef = row [ 1 ] sql += `` '' '' , NULL AS indexdef '' '' '' `` WHERE r.conrelid = ' % s ' AND r.contype = ' f ' ORDER BY 1 ; '' % import click sql += `` '' '' FROM pg_catalog.pg_attribute a WHERE a.attrelid = ' % s ' AND # / * Footer information about a table * / queries = self.find_matches ( sql = `` 'SELECT n.nspname as `` Schema '' , cur.execute ( 'create table schema1.s1_tbl1 ( id1 integer , txt1 text ) ' ) return list_objects ( cur , pattern , verbose , [ ' i ' , 's ' , `` ] ) sql += ' AND n.nspname ~ % s ' return results `` `` '' Decorator to explicitly mark functions that are exposed in a lib . '' '' '' status.append ( `` , predicate ( % s ) '' % indpred ) `` FROM pg_catalog.pg_constraint c\n '' AND n.nspname ! ~ '^pg_toast ' return contents title = ' > { } '.format ( query ) def list_schemas ( cur , pattern , verbose ) : WHERE c.oid = t.typrelid ) ) import logging if deferred : a.attstattarget END AS attstattarget '' '' '' result = cur.execute ( sql ) Returns : schema_pattern , table_pattern if ( tgenabled == ' R ' ) : return ( None , None , None , 'Did not find any relation with OID % s . ' % oid ) ON n.oid = c.relnamespace # If it 's a seq , fetch it 's value and store it for later . def read_from_file ( path ) : Is this an external editor command ? if cur.rowcount > 0 : `` `` '' List of all named queries . cell.append ( 'main ' ) status.append ( `` Number of child tables : % d ( Use \d+ to list '' , CASE # / * untranslated index name * / results = [ ] pg_catalog.obj_description ( t.oid , 'pg_type ' ) not CAN_CONNECT_TO_DB , `` pg_catalog.pg_get_constraintdef ( c.oid , true ) as condef\n '' ORDER BY 1,2 `` '' '' if tableinfo.hasrules : def test_slash_df ( executor ) : sql = ( `` SELECT r.rulename , trim ( trailing ' ; ' from pg_catalog.pg_get_ruledef ( r.oid , true ) ) \n '' oid ) sql += `` NOT t.tgisinternal '' sql = ( `` SELECT conname , \n '' $ $ select 1 $ $ ' '' ) if schema : @ special_command ( '\\ds ' , '\\ds [ + ] [ pattern ] ' , 'List sequences . ' ) word_before_cursor , NamedQueries.instance.list ( ) , return filename.strip ( ) or None extension='.sql ' ) FROM pg_catalog.pg_roles r `` '' '' except IOError : pattern = re.compile ( ' ( ^\\\e|\\\e $ ) ' ) from dbutils import dbtest else : return [ ( `` , rows , headers , status ) ] pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' pg_catalog.array_to_string ( # / * Everything after `` USING '' is echoed verbatim * / JOIN pg_catalog.pg_roles b ON ( m.roleid = b.oid ) cur.execute ( 'create type foo AS ( a int , b text ) ' ) verbose_columns = verbose_table = `` list_trigger = False ; pg_catalog.format_type ( t.oid , NULL ) AS `` Name '' , `` ' if ( cur.rowcount > 0 ) : sql += ' AND pg_catalog.pg_type_is_visible ( t.oid ) ' status.append ( `` FDW Options : ( % s ) \n '' % ftoptions ) import psycopg2 # / * Table type * / if ( tgenabled == 'D ' or tgenabled == False ) : result = cur.fetchone ( ) if category == 0 and row [ 2 ] == ' O ' : @ special_command ( '\\di ' , '\\di [ + ] [ pattern ] ' , 'List indexes . ' ) status.append ( `` Indexes : \n '' ) WHEN 'm ' THEN 'materialized view ' elif not inquotes and c == ' * ' : select * from django_migrations ; # / * if row [ 7 ] == `` x '' : @ special_command ( '\\dT ' , '\\dT [ S+ ] [ pattern ] ' , 'List data types ' ) POSTGRES_USER , POSTGRES_HOST = 'postgres ' , 'localhost ' return schema , relname if ( not name ) or ( not query ) : # / * Column comments , if the relkind supports this feature . * / params.append ( func_pattern ) tableinfo.relkind == ' f ' ) : status.append ( `` Triggers firing on replica only : '' ) elif category == 3 : @ special_command ( '\\l ' , '\\l ' , 'List databases . ' , arg_type=RAW_QUERY ) if ( tableinfo.relkind == ' r ' or tableinfo.relkind == 'm ' or params = [ ] elif category == 3 and row [ 2 ] == ' R ' : if category == 0 : relname += c.lower ( ) sql += `` i.indisvalid , `` `` \nINNER JOIN pg_catalog.pg_depend d ON c.oid=d.refobjid '' # / * display the list of child tables * / `` pg_catalog.pg_get_constraintdef ( r.oid , true ) as condef\n '' cur = connection.cursor ( ) __all__.append ( defn.__name__ ) WHEN ' f ' THEN 'foreign table ' if ( row [ 1 ] ) : return results log = logging.getLogger ( __name__ ) cell.append ( row [ 7 ] ) if ( verbose and tableinfo.reloptions ) : WHEN ' i ' THEN 'index ' from .packages import pgspecial as special modifier += ' collate % s ' % row [ 5 ] from pgspecial.main import PGSpecial headers = [ `` Name '' ] CASE c.relkind WHEN ' r ' THEN 'table ' cur.execute ( `` 'create function schema1.s1_func1 ( ) returns int language if row [ 5 ] : cell.append ( modifier ) schema_pattern , func_pattern = sql_name_pattern ( pattern ) sql = `` 'SELECT n.nspname AS `` Name '' , sql += `` \nORDER BY 1 ; '' log.debug ( sql ) sql += ( `` WHERE c.oid = ' % s ' AND c.oid = i.indrelid AND i.indexrelid = c2.oid\n '' select * FROM abc sql = pattern.sub ( `` , sql ) def list_functions ( cur , pattern , verbose ) : cur.execute ( 'create schema schema1 ' ) `` WHERE t.tgrelid = ' % s ' AND `` % oid ) ; pg_catalog.shobj_description ( r.oid , 'pg_authid ' ) AS description '' ' if verbose : elif category == 2 : if ( tableinfo.reloftype ) : if ( tableinfo.relkind == ' r ' or tableinfo.relkind == 'm ' or from pgspecial.main import ( PGSpecial , NO_QUERY , content_exceeds_width ) from pgspecial.main import parse_special_command usage = 'Syntax : \\nd name.\n\n ' + namedqueries.usage from pgcli.packages.pgspecial import PGSpecial # / * Print server name * / # tables title = ( tableinfo.relkind , schema_name , relation_name ) def editor_command ( command ) : name , _ , query = pattern.partition ( ' ' ) return [ ( title , cur , headers , cur.statusmessage ) ] relname = `` conn = psycopg2.connect ( user=POSTGRES_USER , host=POSTGRES_HOST , cell.append ( row [ 1 ] ) # Type if row [ 9 ] : sql += ( `` \nFROM pg_catalog.pg_class c , pg_catalog.pg_class c2 , `` teardown_db ( connection ) # This is a simple \d command . No table name to follow . if ( cur.rowcount > 0 ) : elif not inquotes and c == ' ? ' : def execute_named_query ( cur , pattern , * * _ ) : WHEN p.provolatile = 's ' THEN 'stable ' import pgspecial as special Returns ( title , rows , header , status ) sql = `` '' '' SELECT pg_catalog.pg_get_viewdef ( ' % s ' : :pg_catalog.oid , true ) '' '' '' % oid `` `` '' List all schemas . '' '' '' relname += ' . * ' Takes a wildcard-pattern and converts to an appropriate SQL pattern to be results = [ ] command , _ , filename = sql.partition ( ' ' ) rows = [ [ r ] for r in namedqueries.list ( ) ] return command.strip ( ) .endswith ( '\\e ' ) or command.strip ( ) .startswith ( '\\e ' ) tableinfo = TableInfo._make ( cur.fetchone ( ) ) @ special_command ( '\\dv ' , '\\dv [ + ] [ pattern ] ' , 'List views . ' ) # / * FDW options for foreign table column , only for 9.2 or later * / WHERE `` ' pg_catalog.pg_get_userbyid ( n.nspowner ) AS `` Owner '' ' '' + ( `` ' , @ special_command ( '\\dt ' , '\\dt [ + ] [ pattern ] ' , 'List tables . ' ) if storage [ 0 ] == ' p ' : if row [ 3 ] : if row [ 8 ] : ( 'public ' , 'tbl2 ' , 'table ' , 'postgres ' ) ] # false ) ; def list_indexes ( cur , pattern , verbose ) : # If either name or query is missing then print the usage and complain . if tableinfo.hastriggers : END as `` Type '' , sql += `` ' pg_catalog.obj_description ( t.oid , 'pg_type ' ) FROM pg_catalog.pg_class c `` pg_catalog.pg_inherits i WHERE c.oid=i.inhrelid AND '' if schema_pattern : cell.append ( ' ? ? ? ' ) query = sql pass `` quote_ident ( option_name ) || ' ' || `` query = click.edit ( sql + '\n\n ' + MARKER , filename=filename , status.append ( `` Referenced by : \n '' ) # true ) ; AND n.nspname < > 'pg_catalog ' FROM pg_catalog.pg_enum e END , if query is None : pg_catalog.array_to_string ( n.nspacl , E'\\n ' ) AS `` Access privileges '' , sql += `` ' AND ( t.typname ~ % s # / * Get the column that owns this sequence * / oid ) def sql_name_pattern ( pattern ) : LEFT JOIN pg_catalog.pg_namespace n sql = ( `` SELECT conrelid : :pg_catalog.regclass , conname , \n '' connection = db_connection ( '_test_db ' ) status.append ( `` CLUSTER '' ) assert True if category == 2 : tableinfo.relkind == 'm ' or THEN CAST ( 'tuple ' AS pg_catalog.text ) DROP SCHEMA IF EXISTS schema1 CASCADE ; status = 'SELECT 3 ' status.append ( `` % s '' % ruledef ) relname = '^ ( ' + relname + ' ) $ ' from . import export sql += `` '' '' , a.attstorage '' '' '' sql = '' '' '' SELECT c.relchecks , c.relkind , c.relhasindex , try : elif tableinfo.relkind == 'S ' : if ( tableinfo.hasrules and tableinfo.relkind ! = 'm ' ) : i += 1 if TableInfo.relkind == ' i ' : sql as $ $ select 2 $ $ ' '' ) # * / @ export `` FROM pg_catalog.pg_trigger t\n '' cells = [ ] status.append ( ' `` % s '' ' % row [ 0 ] ) # / * print the number of child tables , if any * / SELECT n.nspname as `` Schema '' , # / * Label as primary key or unique ( but not both ) * / `` `` '' Returns ( title , rows , headers , status ) '' '' '' __all__ = [ ] if indisprimary : list_trigger = True contents = f.read ( ) if not ( schema_pattern or type_pattern ) : if not ( cur.rowcount > 0 ) : status.append ( `` Check constraints : \n '' ) spacer = `` FROM pg_catalog.pg_proc p status.append ( `` % s\n '' % row [ 1 ] [ tgdef : ] ) WHEN ' r ' THEN 'table ' WHEN ' v ' THEN 'view ' SERVER_VERSION = conn.server_version sql = `` '' '' SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , AND pg_catalog.pg_table_is_visible ( c.oid ) `` ' WHEN p.proiswindow THEN 'window ' AND n.nspname < > 'information_schema ' from . import dbcommands # * / cur.execute ( sql ) def setup_db ( conn ) : ( 'public ' , 'tbl2 ' , 'table ' , 'postgres ' ) , tgenabled = row [ 2 ] sql = ( `` SELECT pg_catalog.quote_ident ( nspname ) || ' . ' || '' Returns ( title , rows , headers , status ) status = [ ] params.append ( table_pattern ) `` `` '' + ( 'WHERE ' + ' AND '.join ( where ) if where else `` ) + `` '' '' WHEN p.proisagg THEN 'agg ' def test_slash_dT ( executor ) : if result : status.append ( `` UNIQUE CONSTRAINT , '' ) if ( view_def ) : sql = `` 'SELECT * FROM `` % s '' . `` % s '' ' '' % ( schema_name , relation_name ) CAN_CONNECT_TO_DB = True status.append ( `` % s , `` % indamname ) if type_pattern : def list_views ( cur , pattern , verbose ) : cell.append ( 'extended ' ) try : This method is used by list_tables , list_views , and list_indexes sql += ( `` pg_catalog.pg_get_constraintdef ( con.oid , true ) , `` return [ ( None , None , None , status ) ] # / * create_db ( '_test_db ' ) sql += ' n.nspname ~ % s ' def delete_named_query ( pattern , * * _ ) : where.append ( ' n.nspname ~ % s ' ) sql += ' AND c.relname ~ % s ' sql = `` '' '' SELECT a.attname , pg_catalog.format_type ( a.atttypid , a.atttypmod ) , # * could apply to either a table or a view . ( `` yes '' if tableinfo.hasoids else `` no '' ) ) def test_slash_dt ( executor ) : # / * print foreign server name * / if ( cur.rowcount > 0 ) : if filename : status.append ( `` PRIMARY KEY , '' ) return list_objects ( cur , pattern , verbose , [ 'S ' , 's ' , `` ] ) ON n.oid = t.typnamespace FROM pg_catalog.pg_type el AND NOT EXISTS ( return ( query , message ) return [ ( None , None , None , # * Finish printing the footer information about a table . LEFT JOIN pg_catalog.pg_namespace n ON n.oid = p.pronamespace from .main import special_command , RAW_QUERY return the query . with db_connection ( ) .cursor ( ) as cur : sql = cur.mogrify ( sql + ' ORDER BY 1 , 2 ' , params ) status.append ( `` , initially deferred '' ) ( 'schema2 ' , 'postgres ' ) ] list_rule = True `` \nFROM pg_catalog.pg_class c '' while i < pattern_len : namedqueries.save ( name , query ) @ special_command ( '\\d ' , '\\d [ pattern ] ' , 'List or describe tables , views and sequences . ' ) # Make Footers return [ ( None , None , None , usage ) ] # / * print rules * / cell.append ( 'plain ' ) `` ORDER BY 1 ; '' % oid ) MARKER = ' # Type your query above this line.\n ' reason= '' Need a postgres instance at localhost accessible by user 'postgres ' '' ) return [ ( None , None , None , message ) ] cur.execute ( `` '","['pgcli/main.py', 'pgcli/packages/pgspecial/__init__.py', 'pgcli/packages/pgspecial/dbcommands.py', 'pgcli/packages/pgspecial/iocommands.py', 'pgcli/packages/pgspecial/tests/conftest.py', 'pgcli/packages/pgspecial/tests/dbutils.py', 'pgcli/packages/pgspecial/tests/pytest.ini', 'pgcli/packages/pgspecial/tests/test_specials.py', 'pgcli/packages/pgspecial/tmp.sql', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'setup.py', 'tests/test_pgexecute.py']",Merge pull request # 363 from dbcli/j-bennet/extract-pgspecial
385,1be884e83e6d9d4a90e8b0c7923df31728f0f628,2015-09-25 20:35:13-07:00,"global CONFIRM_STEPS def skip_step ( ) : parser = OptionParser ( ) cmd = [ 'git ' , 'add ' , version_file ] if skip_step ( ) : : return : boolean print ( ' '.join ( cmd ) ) print ( ' -- - Pretending to run ... ' ) `` `` '' cmd = [ 'python ' , 'setup.py ' , 'register ' ] print ( ' -- - Skipping ... ' ) cmd = args CONFIRM_STEPS = popts.confirm_steps return True Asks for user 's response whether to run a step . Default is yes . DRY_RUN = popts.dry_run run_step ( 'git ' , 'push ' , 'origin ' , 'master ' ) elif DRY_RUN : subprocess.check_output ( cmd ) run_step ( 'git ' , 'tag ' , tag_name ) cmd = [ 'git ' , 'commit ' , ' -- message ' , 'Releasing version % s ' % ver ] run_step ( 'git ' , 'push ' , ' -- tags ' , 'origin ' ) : param args : list of strings ( command and args ) cmd = [ 'git ' , 'reset ' ] default=False , help= '' Print out , but not actually run any steps . '' If yes ( default ) , runs it . run_step ( 'git ' , 'reset ' ) return False popts , pargs = parser.parse_args ( ) run_step ( 'python ' , 'setup.py ' , 'register ' ) run_step ( 'git ' , 'add ' , version_file ) DRY_RUN = False run_step ( 'python ' , 'setup.py ' , 'sdist ' ) subprocess.check_output ( cmd ) parser.add_option ( cmd = [ 'python ' , 'setup.py ' , 'sdist ' ] print ( ' '.join ( cmd ) ) if choice.lower ( ) == ' n ' : `` confirmed , it will be skipped . '' ) default=False , help= ( `` Confirm every step . If the step is not `` if CONFIRM_STEPS : def run_step ( * args ) : from optparse import OptionParser run_step ( 'git ' , 'commit ' , ' -- message ' , 'Releasing version % s ' % ver ) cmd = [ 'git ' , 'tag ' , tag_name ] else : cmd = [ 'git ' , 'push ' , 'origin ' , 'master ' ] CONFIRM_STEPS = False `` -d '' , `` -- dry-run '' , action= '' store_true '' , dest= '' dry_run '' , choice = raw_input ( `` -- - Confirm step ? ( y/N ) [ y ] `` ) `` -c '' , `` -- confirm-steps '' , action= '' store_true '' , dest= '' confirm_steps '' , choice = raw_input ( 'Are you sure ? ( y/N ) ' ) choice = raw_input ( 'Are you sure ? ( y/N ) [ n ] ' ) cmd = [ 'git ' , 'push ' , ' -- tags ' , 'origin ' ] ) global DRY_RUN Prints out the command and asks if it should be run .",['release.py'],Merge pull request # 364 from dbcli/j-bennet/release-script-update
386,764f69a47bc242383e992502491a1ae0012f13a0,2015-09-24 22:35:40-07:00,"{ 'type ' : 'function ' , 'schema ' : 'sch ' , 'filter ' : 'is_set_returning ' } , and returns a boolean indicating whether that function should be for ( func , metas ) in metadata [ schema ] .items ( ) # suggest user-defined functions using substring matching metadata = self.dbmetadata [ 'functions ' ] metadata [ schema ] [ func ] = [ f ] completions.extend ( funcs ) Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) , from pgcli.pgexecute import FunctionMetadata funcs = self.populate_schema_objects ( 'integer ' , False , False , False ) , completions.extend ( user_funcs ) 'functions ' : [ Completion ( text='shipments ' , start_position=0 , display_meta='table ' ) ] ) except KeyError : { 'type ' : 'function ' , 'schema ' : [ ] , 'filter ' : 'is_set_returning ' } , p.proname func_name n.nspname schema_name , # Because of multiple dispatch , we can have multiple functions { 'type ' : 'keyword ' } , filt = operator.attrgetter ( 'is_set_returning ' ) 'SELECT * FROM sch . ' , Completion ( text='set_returning_func ' , start_position=-len ( 'func ' ) , display_meta='function ' ) ] ) FunctionMetadata ( 'public ' , 'func3 ' , `` , [ 'schema_name ' , 'func_name ' , 'arg_list ' , 'result ' , 'filter ' : 'is_set_returning ' } ) if filter_func ( meta ) ] Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] ) assert funcs > = set ( [ ( 'public ' , 'func1 ' ) , ( 'schema1 ' , 'func2 ' ) ] ) { 'type ' : 'view ' , 'schema ' : 'sch ' } , if token_v == 'from ' or ( token_v.endswith ( 'join ' ) and token.is_keyword ) : # Function overloading means we way have multiple functions for meta in metas FunctionMetadata ( 'schema1 ' , 'func2 ' , `` , funcs = self.populate_schema_objects ( Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) def test_expression_suggests_qualified_tables_views_and_schemas ( expression ) : { 'type ' : 'table ' , 'schema ' : [ ] } , Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] SELECT DISTINCT -- multiple dispatch means possible duplicates 'public ' : [ 'func1 ' , 'func2 ' ] , return [ func for ( func , metas ) in metadata [ schema ] .items ( ) as $ $ select generate_series ( 1,5 ) $ $ ; ' '' ) as $ $ select 1 , 2 from generate_series ( 1,5 ) $ $ ; ' '' ) run ( executor , `` 'create function func4 ( x int ) returns setof int language sql Completion ( text='set_returning_func ' , start_position=0 , display_meta='function ' ) ] def test_suggest_qualified_tables_and_views ( expression ) : assert funcs > = set ( [ # dbmetadata [ 'schema_name ' ] [ 'functions ' ] [ 'function_name ' ] should return run ( executor , `` 'create function func3 ( ) # Only suggest set-returning functions pg_catalog.pg_get_function_result ( p.oid ) result , for func_meta in metadata [ 'functions ' ] ] Completion ( text='func4 ' , start_position=-len ( 'func ' ) , display_meta='function ' ) ] ) def populate_functions ( self , schema , filter_func ) : if suggestion.get ( 'filter ' ) == 'is_set_returning ' : 'SELECT * FROM ' , yield FunctionMetadata ( * row ) # the function metadata namedtuple for the corresponding function # func_data is a list of function metadata namedtuples [ 'custom_func1 ' , `` , `` , False , False , False ] , schema , func = self.escaped_names ( [ f.schema_name , f.func_name ] ) from collections import namedtuple return [ ] yield row funcs = self.populate_functions ( suggestion [ 'schema ' ] , filt ) funcs = set ( funcs ) try : Completion ( text='shipments ' , start_position=0 , display_meta='table ' ) , { 'type ' : 'table ' , 'schema ' : 'sch ' } , p.proretset is_set_returning # is_aggregate , is_window , is_set_returning 'is_aggregate ' , 'is_window ' , 'is_set_returning ' ] ) functions = [ ( schema , func ) return [ func for schema in self.search_path # dbmetadata [ 'functions ' ] [ 'schema_name ' ] [ 'function_name ' ] should return kept or discarded [ 'set_returning_func ' , `` , `` , False , False , True ] ] , funcs = self.find_matches ( word_before_cursor , funcs , def test_suggest_qualified_tables_views_and_set_returning_functions ( expression ) : else : # func_data is an iterator of ( schema_name , function_name ) 'custom ' : [ { 'type ' : 'function ' , 'schema ' : [ ] , 'filter ' : 'is_set_returning ' } , p.proiswindow is_window , # Suggest set-returning functions in the FROM clause schema , func = self.escaped_names ( f ) # with fields schema_name , func_name , arg_list , result , suggestion [ 'schema ' ] , 'functions ' ) if not suggestion [ 'schema ' ] and 'filter ' not in suggestion : user_funcs = self.find_matches ( word_before_cursor , funcs , 'SETOF integer ' , False , False , True ) , returns table ( x int , y int ) language sql pg_catalog.pg_get_function_arguments ( p.oid ) arg_list , ] ) else : metadata [ schema ] [ func ] .append ( f ) `` `` '' Yields tuples of ( schema_name , function_name ) '' '' '' # function metadata -- right now we 're not storing any further metadata [ 'func1 ' , `` , `` , False , False , False ] , suggestion [ 'schema ' ] , 'functions ' ) ] ) [ 'custom_func2 ' , `` , `` , False , False , False ] , { 'type ' : 'schema ' } , functions = [ FunctionMetadata ( 'public ' , * func_meta ) FunctionMetadata = namedtuple ( 'FunctionMetadata ' , else : assert sorted_dicts ( suggestions ) == sorted_dicts ( [ suggest.append ( { 'type ' : 'function ' , 'schema ' : schema , if not suggestion [ 'schema ' ] : { 'type ' : 'schema ' } ] ) ] ) { 'type ' : 'view ' , 'schema ' : [ ] } , # with the same name , which is why ` for meta in metas ` is necessary FunctionMetadata ( 'public ' , 'func4 ' , ' x integer ' , p.proisagg is_aggregate , suggestions = suggest_type ( expression , expression ) 'public ' : [ def test_suggests_tables_views_and_schemas ( expression ) : functions = [ ( 'public ' , func ) for func in metadata [ 'functions ' ] ] meta='function ' ) # of the same name at this point , so keep unique names only meta='function ' ) Completion ( text='user_emails ' , start_position=0 , display_meta='view ' ) ] ) functions = [ FunctionMetadata ( schema , * func_meta ) Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) , FunctionMetadata ( 'public ' , 'func1 ' , `` , 'SELECT * FROM ' , `` `` '' Yields FunctionMetadata named tuples '' '' '' filter_func is a function that accepts a FunctionMetadata namedtuple def test_expression_suggests_tables_views_and_schemas ( expression ) : metadata [ schema ] [ func ] = None # in the comprehensions below [ 'func2 ' , `` , `` , False , False , False ] ] , 'custom ' : [ 'func3 ' , 'func4 ' ] , for func_meta in funcs ] p.proname func_name , def test_suggest_tables_views_schemas_and_set_returning_functions ( expression ) : 'TABLE ( x integer , y integer ) ' , False , False , True ) , [ 'func3 ' , `` , `` , False , False , False ] , if func in metadata [ schema ] : { 'type ' : 'keyword ' } # so just default to None as a placeholder 'SELECT * FROM sch . ' , 'functions ' : [ 'custom_func1 ' , 'custom_func2 ' ] , SELECT n.nspname schema_name , { 'type ' : 'view ' , 'schema ' : 'sch ' } ] ) Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) ] import operator if schema : [ 'set_returning_func ' , `` , `` , False , False , True ] ] , `` `` '' `` `` '' Returns a list of function names for func in funcs ] Completion ( text='user_emails ' , start_position=0 , display_meta='view ' ) ,","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 361 from dbcli/darikg/suggest-functions-as-tables
387,6166291c3e0a9eb97303ee5b5f06e2168c858dd6,2015-09-23 22:51:55-04:00,"config_location ( ) ) import platform from .config import write_default_config , load_config import shutil else : def config_location ( ) : config_dir = os.path.dirname ( config_location ( ) ) log_file = ~/.config/pgcli/log if os.path.exists ( os.path.expanduser ( '~/.pgclirc ' ) ) : if platform.system ( ) == 'Windows ' : shutil.move ( os.path.expanduser ( '~/.pgclirc ' ) , config_location ( ) ) if not os.path.exists ( config_location ( ) ) : namedqueries = NamedQueries ( load_config ( '~/.config/pgcli/config ' ) ) history_file = ~/.config/pgcli/history if os.path.isfile ( '~/.config/pgcli/config ' ) : log_file = ~/.pgcli.log print ( 'Config file ( ~/.pgclirc ) moved to new location ' , os.makedirs ( config_dir ) return os.getenv ( 'USERPROFILE ' ) + '\AppData\Local\dbcli\pgcli\config ' # Migrate the config file from old location . from .config import write_default_config , load_config , config_location namedqueries = NamedQueries ( load_config ( '~/.pgclirc ' ) ) @ click.option ( ' -- pgclirc ' , default='~/.pgclirc ' , envvar='PGCLIRC ' , help='Location of pgclirc file . ' ) cfg.write ( ) print ( 'Config file is now located at ' , config_location ( ) ) help='Location of .pgclirc file . ' ) return expanduser ( '~/.config/pgcli/config ' ) if not os.path.exists ( config_dir ) : else : cfg = load_config ( config , def_config ) print ( 'Please move the existing config file ~/.pgclirc to ' , def upgrade_config ( config , def_config ) : history_file = ~/.pgcli-history namedqueries = NamedQueries ( load_config ( '~/.pgclirc ' ) ) import os else :","['pgcli/config.py', 'pgcli/main.py', 'pgcli/packages/pgspecial/namedqueries.py', 'pgcli/pgclirc']",Merge pull request # 356 from dbcli/amjith/new-config-file
388,e08c54dafb6941bea4465f94b46f2cfaff3f9497,2015-09-23 09:21:16-07:00,"def format_output ( title , cur , headers , status , table_format , expanded=False ) : self.auto_expand = True self.pgspecial.expanded_output , missingval= ' < null > ' ) ) if self.pgspecial.auto_expand : if flag == `` auto '' : separator_space = ( len ( row ) * 3 ) row_result.append ( ( u '' % s '' % header ) + `` `` + ( u '' % s '' % value ) .strip ( ) ) self.expanded_output = False flag = pattern.strip ( ) return _format_table ( tablefmt , headers , rows , minwidths , aligns ) def toggle_expanded_output ( self , pattern , * * _ ) : self.expanded_output = not ( self.expanded_output or self.auto_expand ) max_width ) Also returns a tuple of the raw rows pulled from tabular_data missingval= ' < null > ' ) return [ ( None , None , None , u '' Expanded display is used automatically . '' ) ] 'Toggle expanded output . ' , arg_type=PARSED_QUERY ) # Add 2 columns for a bit of buffer return _format_table ( tablefmt , headers , rows , minwidths , aligns ) , rows max_width = None elif flag == `` off '' : def toggle_expanded_output ( self ) : max_width = self.cli.output.get_size ( ) .columns self.auto_expand = False self.expanded_output = not self.expanded_output line_len = sum ( [ len ( x ) for x in row ] ) + separator_space + 2 return line_len > width else : from .packages.pgspecial.main import ( PGSpecial , NO_QUERY ) if max_width and content_exceeds_width ( rows [ 0 ] , max_width ) : row_result.append ( u '' % s % s '' % ( header , value ) ) self.expanded_output = True def content_exceeds_width ( row , width ) : output.append ( tabulated ) self.auto_expand = self.expanded_output output.append ( expanded_table ( rows , headers ) ) else : # Account for 3 characters between each column self.pgspecial.expanded_output ) def format_output ( title , cur , headers , status , table_format , expanded=False , max_width=None ) : elif flag == `` on '' : output.append ( tabulate ( cur , headers , tablefmt=table_format , tabulated , rows = tabulate ( cur , headers , tablefmt=table_format , from .packages.pgspecial.main import ( PGSpecial , NO_QUERY , content_exceeds_width ) 'Toggle expanded output . ' , arg_type=NO_QUERY ) else :","['pgcli/main.py', 'pgcli/packages/expanded.py', 'pgcli/packages/pgspecial/main.py', 'pgcli/packages/tabulate.py']",Merge pull request # 359 from stuartquin/feature/auto-expand
389,c9b86b225598e8899e2a0b96c9dd462f40fb8b1a,2015-09-22 21:29:14-07:00,"assert funcs > = set ( [ ( 'public ' , 'func1 ' ) , ( 'schema1 ' , 'func2 ' ) ] ) funcs = set ( executor.functions ( ) ) WHERE n.nspname NOT IN ( 'pg_catalog ' , 'information_schema ' ) assert funcs == [ ( 'public ' , 'func1 ' ) , ( 'schema1 ' , 'func2 ' ) ] funcs = list ( executor.functions ( ) )","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 357 from dbcli/darikg/suggest-all-functions
390,0f69f8cd232f27edd8795fc8c215ba01c414c109,2015-09-22 21:22:28-07:00,"'CLUSTER ' , 'COLUMN ' , 'COMMENT ' , 'COMPRESS ' , 'CONCURRENTLY ' , 'DESCRIBE ' , 'DISTINCT ' , 'DROP ' , 'ELSE ' , 'ENCODING ' , 'ESCAPE ' , 'NUMBER ' , 'OIDS ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'IDENTIFIED ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , 'INDEX ' , 'INITIAL ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'USING ' , 'VALIDATE ' , 'VALUES ' , 'INDEX ' , 'INITIAL ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'ORDER BY ' , 'OUTER ' , 'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' ] 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'EXCLUSIVE ' , 'EXISTS ' , 'EXTENSION ' , 'FILE ' , 'FLOAT ' , 'FOR ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , 'DECIMAL ' , 'DEFAULT ' , 'DELETE FROM ' , 'DELIMITER ' , 'DESC ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OIDS ' , 'OF ' , 'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'QUOTE ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'CREATE ' , 'CURRENT ' , 'DATABASE ' , 'DATE ' , 'DECIMAL ' , 'DEFAULT ' , 'FULL ' , 'FUNCTION ' , 'GRANT ' , 'GROUP BY ' , 'HAVING ' , 'HEADER ' , 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'HAVING ' , 'HEADER ' , 'IDENTIFIED ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , 'FILE ' , 'FLOAT ' , 'FOR ' , 'FORMAT ' , 'FORCE_QUOTE ' , 'FORCE_NOT_NULL ' , 'PRIVILEGES ' , 'QUOTE ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , 'ELSE ' , 'ENCODING ' , 'ESCAPE ' , 'EXCLUSIVE ' , 'EXISTS ' , 'EXTENSION ' , 'CLUSTER ' , 'COLUMN ' , 'COMMENT ' , 'COMPRESS ' , 'CONNECT ' , 'COPY ' , 'USING ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'DELETE FROM ' , 'DELIMITER ' , 'DESC ' , 'DESCRIBE ' , 'DISTINCT ' , 'DROP ' , 'FREEZE ' , 'FROM ' , 'FULL ' , 'FUNCTION ' , 'GRANT ' , 'GROUP BY ' , 'TRUNCATE ' , 'UID ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' ] 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'TRUNCATE ' , 'UID ' , 'UNION ' , 'INTERVAL ' , 'INTO ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'INTERVAL ' , 'INTO ' , 'IS ' , 'CONNECT ' , 'COPY ' , 'CREATE ' , 'CURRENT ' , 'DATABASE ' , 'DATE ' , 'FORMAT ' , 'FORCE_QUOTE ' , 'FORCE_NOT_NULL ' , 'FREEZE ' , 'FROM ' ,",['pgcli/pgcompleter.py'],Merge pull request # 360 from johshoff/complete_concurrently
391,687a8054818fa6869fb666adc62729eb82069208,2015-09-22 22:21:02+01:00,"def ioctl_GWINSZ ( fd ) : cr = ioctl_GWINSZ ( fd ) cr = ioctl_GWINSZ ( 0 ) or ioctl_GWINSZ ( 1 ) or ioctl_GWINSZ ( 2 ) def format_output ( title , cur , headers , status , table_format , expanded=False ) : self.pgspecial.auto_expand ) self.auto_expand = True message = u '' Expanded display is `` self.auto_expand = self.expanded_output self.pgspecial.expanded_output , missingval= ' < null > ' ) ) return line_len > get_terminal_width ( ) - 4 env = os.environ return _format_table ( tablefmt , headers , rows , minwidths , aligns ) self.expanded_output = False def toggle_expanded_output ( self , pattern , * * _ ) : # From http : //stackoverflow.com/questions/566746/how-to-get-console-window-width-in-python self.expanded_output = not ( self.expanded_output or self.auto_expand ) Also returns a tuple of the raw rows pulled from tabular_data os.close ( fd ) missingval= ' < null > ' ) def is_wider_than_terminal ( row ) : import fcntl , termios , struct , os from .packages.pgspecial.main import ( PGSpecial , NO_QUERY , is_wider_than_terminal ) if pattern.strip ( ) == `` auto '' : try : 'Toggle expanded output . ' , arg_type=PARSED_QUERY ) def get_terminal_width ( ) : return cr def format_output ( title , cur , headers , status , table_format , expanded=False , auto_expand=False ) : return _format_table ( tablefmt , headers , rows , minwidths , aligns ) , rows import os def toggle_expanded_output ( self ) : pass self.auto_expand = False message = u '' Expanded display is used automatically . '' self.expanded_output = not self.expanded_output else : from .packages.pgspecial.main import ( PGSpecial , NO_QUERY ) cr = ( env.get ( 'LINES ' , 25 ) , env.get ( 'COLUMNS ' , 80 ) ) cr = struct.unpack ( 'hh ' , fcntl.ioctl ( fd , termios.TIOCGWINSZ , fd = os.open ( os.ctermid ( ) , os.O_RDONLY ) '1234 ' ) ) output.append ( tabulated ) return return int ( cr [ 1 ] ) output.append ( expanded_table ( rows , headers ) ) if not cr : self.pgspecial.expanded_output ) message += u '' on . '' if self.expanded_output else u '' off . '' if auto_expand and is_wider_than_terminal ( rows [ 0 ] ) : output.append ( tabulate ( cur , headers , tablefmt=table_format , tabulated , rows = tabulate ( cur , headers , tablefmt=table_format , 'Toggle expanded output . ' , arg_type=NO_QUERY ) message += u '' on . '' if self.expanded_output else u '' off . '' message = u '' Expanded display is `` line_len = sum ( [ len ( x ) for x in row ] ) + ( len ( row ) * 3 ) + 2 except : else :","['pgcli/main.py', 'pgcli/packages/pgspecial/main.py', 'pgcli/packages/tabulate.py']",Issue # 315 Add support for \x auto
392,fe6752d1f293346e6f1d3c47e12fa6a68503d6c6,2015-09-13 23:34:26-07:00,"context.cli.expect_exact ( 'SELECT 1 ' , timeout=1 ) context.cli.expect_exact ( 'INSERT 0 1 ' , timeout=2 ) except Exception : import re _expect_exact ( context , 'DELETE 1 ' , timeout=2 ) context.cli.expect_exact ( expected_line , timeout=1 ) context.cli.expect_exact ( 'nano ' , timeout=2 ) context.cli.expect_exact ( 'UPDATE 1 ' , timeout=2 ) try : context.cli.expect_exact ( 'CREATE TABLE ' , timeout=2 ) actual ) ) _expect_exact ( context , 'select * from abc ' , timeout=2 ) except : expected , raise Exception ( 'Expected : \n -- -\n { 0 } \n -- -\n\nActual : \n -- -\n { 1 } \n -- -'.format ( context.cli.expect ( pexpect.EOF , timeout=5 ) context.cli.expect_exact ( 'CREATE DATABASE ' , timeout=2 ) context.cli.expect_exact ( 'select * from abc ' , timeout=2 ) _expect_exact ( context , 'SELECT 1 ' , timeout=1 ) _expect_exact ( context , 'UPDATE 1 ' , timeout=2 ) context.cli.expect_exact ( 'DELETE 1 ' , timeout=2 ) context.cli.expect_exact ( 'You are now connected to database ' , timeout=2 ) _expect_exact ( context , pexpect.EOF , timeout=5 ) actual = re.sub ( '\x1b\ [ ( . * ) ? . { 1 } ' , `` , actual ) _expect_exact ( context , 'CREATE DATABASE ' , timeout=2 ) context.cli.expect_exact ( 'DROP DATABASE ' , timeout=2 ) context.cli.expect_exact ( expected , timeout=timeout ) _expect_exact ( context , 'refresh started in the background ' , timeout=2 ) _expect_exact ( context , 'yyy ' , timeout=1 ) _expect_exact ( context , 'You are now connected to database ' , timeout=2 ) actual = re.sub ( '\x1b\ [ [ 0-9 ; ] * m ' , `` , context.cli.before ) # Strip color codes out of the output . def _expect_exact ( context , expected , timeout ) : _expect_exact ( context , expected_line , timeout=1 ) _expect_exact ( context , 'nano ' , timeout=2 ) context.cli.expect_exact ( 'yyy ' , timeout=1 ) _expect_exact ( context , 'CREATE TABLE ' , timeout=2 ) context.cli.expect_exact ( 'DROP TABLE ' , timeout=2 ) _expect_exact ( context , 'DROP DATABASE ' , timeout=2 ) _expect_exact ( context , ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) _expect_exact ( context , 'INSERT 0 1 ' , timeout=2 ) _expect_exact ( context , 'DROP TABLE ' , timeout=2 ) 'refresh started in the background ' , timeout=2 ) context.cli.expect_exact ( raise Exception ( 'Expected : ' + expected_line.strip ( ) + ' ! ' ) try : context.cli.expect ( ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 )",['tests/features/steps/step_definitions.py'],Merge pull request # 350 from dbcli/j-bennet/improve-behave-output
393,60a8d1b9bf4b70aa4ce48cbfbca593cdb5e853f7,2015-09-12 15:02:16-07:00,"@ wip def create_toolbar_tokens_func ( get_vi_mode_enabled , get_is_refreshing ) : with self._completer_lock : for callback in callbacks : buf = PGBuffer ( always_multiline=self.multi_line , completer=completer , del self.__map , self.__end has completed the refresh . The newly created completion pop = DictMixin.pop document = cli.run ( ) actual = refresher.refresh ( pgexecute , special , callbacks ) cli = CommandLineInterface ( application=application , def __iter__ ( self ) : return self.__class__ , ( items , ) logger.debug ( 'Search path : % r ' , self.completer.search_path ) : param refresher : refreshers = OrderedDict ( ) and we refresh completions # If callbacks is a single function then push it into a list . self.cli.request_redraw ( ) completer.extend_datatypes ( executor.datatypes ( ) ) return dict.__eq__ ( self , other ) else : completer = PGCompleter ( smart_completion=True , pgspecial=special ) # views return False completer.extend_relations ( pgexecute.tables ( ) , kind='tables ' ) def popitem ( self , last=True ) : def fromkeys ( cls , iterable , value=None ) : end = self.__end history=FileHistory ( os.path.expanduser ( history_file ) ) , self._restart_refresh = threading.Event ( ) callback ( completer ) def __reversed__ ( self ) : def test_refresh_called_once ( refresher ) : then we see completions refresh started completer.extend_functions ( executor.functions ( ) ) return [ ( None , None , None , 'Auto-completions refreshed . ' ) ] return [ ( None , None , None , 'Auto-completion refresh restarted . ' ) ] document = self.handle_editor_command ( cli , document ) except AttributeError : return self.completer.get_completions ( self.__map = { } # key -- > [ key , prev , next ] # types context.cli.sendline ( '\\refresh ' ) with patch ( 'pgcli.completion_refresher.PGExecute ' , pgexecute_class ) : callbacks = Mock ( ) assert len ( actual2 ) == 1 if not self : key = iter ( self ) .next ( ) iterkeys = DictMixin.iterkeys self._completer_thread.setDaemon ( True ) curr [ 2 ] = end [ 1 ] = self.__map [ key ] = [ key , curr , end ] if get_is_refreshing ( ) : # publish , distribute , sublicense , and/or sell copies of the Software , def refresh_databases ( completer , executor ) : completer.extend_functions ( pgexecute.functions ( ) ) actual_handlers = list ( refresher.refreshers.keys ( ) ) ignore_case=True ) callbacks - A function or a list of functions to call after the thread if self.cli : buf = PGBuffer ( always_multiline=self.multi_line , completer=self.completer , from pgcli.completion_refresher import CompletionRefresher # subject to the following conditions : bg_refresh.assert_called_with ( pgexecute , special , callbacks ) try : except AttributeError : def refresh_schemata ( completer , executor ) : from .completion_refresher import CompletionRefresher assert len ( actual1 ) == 1 self.completion_refresher.refresh ( self.pgexecute , self.pgspecial , # including without limitation the rights to use , copy , modify , merge , completer.extend_datatypes ( pgexecute.datatypes ( ) ) return self._completer_thread and self._completer_thread.is_alive ( ) # Set refreshers to 0 : we 're not testing refresh logic here callbacks = [ callbacks ] refreshers [ name ] = wrapped Scenario : run refresh command Wait to see refresh output . expected_handlers = [ 'schemata ' , 'tables ' , 'views ' , 'functions ' , self.__end while 1 : def test_refresh_with_callbacks ( refresher ) : def refresher ( name , refreshers=CompletionRefresher.refreshers ) : return [ ( None , None , None , Document ( text=text , cursor_position=cursor_positition ) , None ) special = Mock ( ) Feature : Special commands self.clear ( ) # exists before trying the replace the completer object in cli . self._completer_thread.start ( ) def __delitem__ ( self , key ) : get_toolbar_tokens = create_toolbar_tokens_func ( lambda : self.vi_mode , def test_refresh_called_twice ( refresher ) : # ( the `` Software '' ) , to deal in the Software without restriction , return ' % s ( % r ) ' % ( self.__class__.__name__ , self.items ( ) ) from .pgexecute import PGExecute if isinstance ( other , OrderedDict ) : completer.extend_schemata ( pgexecute.schemata ( ) ) def copy ( self ) : application = Application ( style=style_factory ( self.syntax_style , self.cli_style ) , def refresh ( self , executor , special , callbacks ) : pgexecute = self.pgexecute pgexecute_class = Mock ( ) # FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR refresher ( completer , executor ) for key in iterable : completer.extend_columns ( executor.view_columns ( ) , kind='views ' ) # without hitting the break statement . def test_ctor ( refresher ) : # Copyright ( c ) 2009 Raymond Hettinger class CompletionRefresher ( object ) : key_bindings_registry=key_binding_manager.registry , def __repr__ ( self ) : completer = self.completer d = cls ( ) return ' % s ( ) ' % ( self.__class__.__name__ , ) completer.extend_relations ( executor.tables ( ) , kind='tables ' ) name='completion_refresh ' ) complete_while_typing=Always ( ) ) self._completer_lock = threading.Lock ( ) refresher._bg_refresh = dummy_bg_refresh # The above copyright notice and this permission notice shall be values = DictMixin.values `` `` '' if self.is_refreshing ( ) : assert len ( actual [ 0 ] ) == 4 pgexecute = Mock ( ) key_bindings_registry=key_binding_manager.registry , # When pgcli is first launched we call refresh_completions before self._restart_refresh.clear ( ) next [ 1 ] = prev Callbacks must be called def __ne__ ( self , other ) : itervalues = DictMixin.itervalues document = self.handle_editor_command ( self.cli , document ) document = self.cli.run ( ) If refresh is called a second time , it should be restarted Send refresh command . completer.set_search_path ( pgexecute.search_path ( ) ) key , prev , next = self.__map.pop ( key ) token = Token.Toolbar `` `` '' Swap the completer object in cli with the newly created completer . completer.extend_columns ( pgexecute.table_columns ( ) , kind='tables ' ) def _swap_completer_objects ( self , new_completer ) : def step_refresh_completions ( context ) : self.update ( * args , * * kwds ) curr = end [ 1 ] completer.extend_relations ( pgexecute.views ( ) , kind='views ' ) executor - PGExecute object , used to extract the credentials to connect lambda : self.completion_refresher.is_refreshing ( ) ) def refresh_types ( completer , executor ) : self.cli = CommandLineInterface ( application=application , def refresh_functions ( completer , executor ) : return list ( self ) raise KeyError ( 'dictionary is empty ' ) def __init__ ( self , * args , * * kwds ) : self.completer.set_search_path ( pgexecute.search_path ( ) ) for refresher in self.refreshers.values ( ) : completer.extend_database_names ( pgexecute.databases ( ) ) refresher.refreshers = { } try : # break statement . # After refreshing , redraw the CLI to clear the statusbar get_toolbar_tokens = create_toolbar_tokens_func ( lambda : self.vi_mode ) prev [ 2 ] = next # functions iteritems = DictMixin.iteritems # obtaining a copy of this software and associated documentation files from collections import OrderedDict # EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES except KeyError : when we run pgcli if last : completer.extend_database_names ( executor.databases ( ) ) and we wait for prompt assert len ( actual ) == 1 return self.completer.get_completions ( end = self.__end def step_see_refresh_started ( context ) : eventloop=create_eventloop ( ) ) assert ( callbacks [ 0 ] .call_count == 1 ) # databases tmp = self.__map , self.__end self.cli.current_buffer.completer = new_completer complete_while_typing=Always ( ) ) self.__map , self.__end = tmp completer.set_search_path ( executor.search_path ( ) ) def __eq__ ( self , other ) : dict.__setitem__ ( self , key , value ) assert expected_handlers == actual_handlers except ImportError : d [ key ] = value items = DictMixin.items to the database . on_exit=AbortAction.RAISE_EXCEPTION , def refresher ( ) : setdefault = DictMixin.setdefault def __setitem__ ( self , key , value ) : assert len ( actual1 [ 0 ] ) == 4 dict.__delitem__ ( self , key ) curr = curr [ 2 ] class OrderedDict ( dict , DictMixin ) : time.sleep ( 1 ) # Wait for the thread to work . layout=layout , buffer=buf , def refresh_views ( completer , executor ) : # Create a new pgexecute method to popoulate the completions . if key not in self : def wrapper ( wrapped ) : update = DictMixin.update # included in all copies or substantial portions of the Software . history=FileHistory ( os.path.expanduser ( history_file ) ) , return True self._on_completions_refreshed ) end += [ None , end , end ] # sentinel node for doubly linked list def clear ( self ) : curr = curr [ 1 ] completer.extend_schemata ( executor.schemata ( ) ) def __init__ ( self ) : if len ( args ) > 1 : # THE SOFTWARE IS PROVIDED `` AS IS '' , WITHOUT WARRANTY OF ANY KIND , assert actual [ 0 ] [ 3 ] == 'Auto-completion refresh started in the background . ' else : on_exit=AbortAction.RAISE_EXCEPTION , time.sleep ( 3 ) # seconds completion suggestions in a background thread . import pytest self.completer = new_completer return wrapper # NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT completer.reset_completions ( ) def keys ( self ) : def create_toolbar_tokens_func ( get_vi_mode_enabled , token=None ) : Refresher object should contain a few handlers while curr is not end : else : callbacks = [ Mock ( ) ] # instantiating the cli object . So it is necessary to check if cli actual1 = refresher.refresh ( pgexecute , special , callbacks ) assert len ( refresher.refreshers ) > 0 # OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND Creates a PGCompleter object and populates it with the relevant import time value = self.pop ( key ) return key , value function . def _bg_refresh ( self , pgexecute , special , callbacks ) : 'Auto-completion refresh started in the background . ' ) ] executor = PGExecute ( e.dbname , e.user , e.password , e.host , e.port , e.dsn ) token = token or Token.Toolbar # and to permit persons to whom the Software is furnished to do so , return False logger.debug ( 'Search path : % r ' , completer.search_path ) if inst_dict : from .packages.ordereddict import OrderedDict special - PGSpecial object used for creating a new completion object . from .pgcompleter import PGCompleter ignore_case=True ) def __reduce__ ( self ) : # schemata return self.__class__ ( self ) return CompletionRefresher ( ) return d with patch.object ( refresher , '_bg_refresh ' ) as bg_refresh : refresher.refresh ( pgexecute , special , callbacks ) return not self == other assert len ( actual2 [ 0 ] ) == 4 self._swap_completer_objects ( new_completer ) if self.cli : yield curr [ 0 ] continue # Start over the refresh from the beginning if the for loop hit the def refresh_tables ( completer , executor ) : # tables `` `` '' Decorator to populate the dictionary of refreshers with the current return ( self.__class__ , ( items , ) , inst_dict ) time.sleep ( 1 ) # Wait for the thread to work . completer.extend_columns ( pgexecute.view_columns ( ) , kind='views ' ) break self.__end = end = [ ] if p ! = q : actual2 = refresher.refresh ( pgexecute , special , callbacks ) def is_refreshing ( self ) : 'refresh started in the background ' , timeout=2 ) # OTHER DEALINGS IN THE SOFTWARE . eventloop=create_eventloop ( ) ) assert actual2 [ 0 ] [ 3 ] == 'Auto-completion refresh restarted . ' self._restart_refresh.set ( ) key = reversed ( self ) .next ( ) Document ( text=text , cursor_position=cursor_positition ) , None ) inst_dict = vars ( self ) .copy ( ) 'Auto-completion refresh started in the background . ' ) ] # HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , Given we have pgcli installed # Break out of while loop if the for loop finishes natually from UserDict import DictMixin self._completer_thread = threading.Thread ( target=self._bg_refresh , object will be passed in as an argument to each callback . completer.extend_columns ( executor.table_columns ( ) , kind='tables ' ) context.cli.expect_exact ( items = [ [ k , self [ k ] ] for k in self ] # # `` Refreshing completions ... '' indicator if self._restart_refresh.is_set ( ) : application = Application ( style=style_factory ( self.syntax_style , self.cli_style ) , self._completer_thread = None return wrapped raise TypeError ( 'expected at most 1 arguments , got % d ' % len ( args ) ) args= ( executor , special , callbacks ) , def dummy_bg_refresh ( * args ) : result.append ( ( token , ' Refreshing completions ... ' ) ) def _on_completions_refreshed ( self , new_completer ) : : return : dict.clear ( self ) layout=layout , buffer=buf , for p , q in zip ( self.items ( ) , other.items ( ) ) : completer.extend_relations ( executor.views ( ) , kind='views ' ) return [ ( None , None , None , 'types ' , 'databases ' ] # WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING assert actual1 [ 0 ] [ 3 ] == 'Auto-completion refresh started in the background . ' # Permission is hereby granted , free of charge , to any person curr = end [ 1 ] break if callable ( callbacks ) : if len ( self ) ! = len ( other ) : curr = end [ 2 ] e = pgexecute completer.set_search_path ( pgexecute.search_path ( ) ) import threading self.completion_refresher = CompletionRefresher ( ) from mock import Mock , patch with self._completer_lock : self.cli = None `` `` ''","['pgcli/completion_refresher.py', 'pgcli/main.py', 'pgcli/packages/ordereddict.py', 'pgcli/pgcompleter.py', 'pgcli/pgtoolbar.py', 'tests/features/iocommands.feature', 'tests/features/specials.feature', 'tests/features/steps/step_definitions.py', 'tests/test_completion_refresher.py']",Merge pull request # 345 from dbcli/amjith/completion-refresh-background
394,6e1bc6fcd1970b5f566d5b264ebc52bbd5858dad,2015-08-25 21:45:53-07:00,"when we send `` ctrl + d '' { 'type ' : 'function ' , 'schema ' : [ ] } , if pattern.match ( txt ) : ( '\\ns abc SELECT foo ' , 'SELECT foo ' , [ { 'type ' : 'keyword ' } ] ) , context.exit_sent = False import re suggestions = suggest_type ( text , before ) ( '\\ns abc SELECT t1 . FROM tabl1 t1 ' , 'SELECT t1 . ' , [ { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } , return txt full_text = strip_named_query ( full_text ) ( '\\ns abc SELECT ' , 'SELECT ' , [ def test_named_query_completion ( text , before , expected ) : ' \ns zzz SELECT * FROM abc ' - > 'SELECT * FROM abc ' pattern = re.compile ( r'^\s * \\ns\s+ [ A-z0-9\-_ ] +\s+ ' ) { 'type ' : 'function ' , 'schema ' : 't1 ' } text_before_cursor = strip_named_query ( text_before_cursor ) assert sorted_dicts ( expected ) == sorted_dicts ( suggestions ) { 'type ' : 'view ' , 'schema ' : 't1 ' } , ] ) ] ) , { 'type ' : 'table ' , 'schema ' : 't1 ' } , txt = pattern.sub ( `` , txt ) ] ) This will strip `` save named query '' command in the beginning of the line : '\ns zzz SELECT * FROM abc ' - > 'SELECT * FROM abc ' { 'type ' : 'column ' , 'tables ' : [ ] } , then pgcli exits { 'type ' : 'keyword ' } `` `` '' def strip_named_query ( txt ) :","['pgcli/packages/sqlcompletion.py', 'tests/features/crud_database.feature', 'tests/features/crud_table.feature', 'tests/features/steps/step_definitions.py', 'tests/test_sqlcompletion.py']",Merge pull request # 342 from dbcli/j-bennet/completion-in-named-query
395,31b867f632acd87636af9a38d68a5d4cd80acda3,2015-08-25 19:35:40-07:00,"if pattern.match ( txt ) : import re ( 'SELECT ' , 'SELECT ' , [ suggestions = suggest_type ( text , before ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } , full_text = strip_named_query ( full_text ) def test_named_query_completion ( text , before , expected ) : { 'type ' : 'function ' , 'schema ' : 't1 ' } text_before_cursor = strip_named_query ( text_before_cursor ) { 'type ' : 'function ' , 'schema ' : [ ] } assert sorted_dicts ( expected ) == sorted_dicts ( suggestions ) { 'type ' : 'view ' , 'schema ' : 't1 ' } , ( 'SELECT t1 . FROM tabl1 t1 ' , 'SELECT t1 . ' , [ ] ) txt = pattern.sub ( `` , txt , 1 ) ] ) , { 'type ' : 'table ' , 'schema ' : 't1 ' } , pattern = re.compile ( r'\\ ( n|nd|ns\s+ [ a-z ] + ) \s+ ' ) ] ) ( 'SELECT foo ' , 'SELECT foo ' , [ { 'type ' : 'keyword ' } ] ) , { 'type ' : 'column ' , 'tables ' : [ ] } , return txt def strip_named_query ( txt ) :","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Autocompletion in named queries . Connect # 270 .
396,e4c18532c3d9f9fbe0448d70a1f00559295b9eec,2015-08-25 19:26:16-07:00,"then we see the sql in prompt @ wip if os.path.exists ( context.editor_file_name ) : def read_from_file ( path ) : context.cli.sendline ( '\e { 0 } '.format ( context.editor_file_name ) ) and we exit the editor `` `` '' context.cli.expect_exact ( 'select * from abc ' , timeout=2 ) def step_edit_quit ( context ) : context.cli.sendline ( 'select * from abc ' ) # Cleanup the command line . # Confirm file name sending `` enter '' . and we start external editor providing a file name contents = f.read ( ) context.cli.sendcontrol ( ' x ' ) context.cli.expect_exact ( 'nano ' , timeout=2 ) os.environ [ 'EDITOR ' ] = 'nano ' Edit file with external editor . from os.path import expanduser 'vi ' : vi Feature : I/O commands when we run pgcli and we type sql in the editor and we wait for prompt context.editor_file_name = 'test_file_ { 0 } .sql'.format ( context.conf [ 'vi ' ] ) # Cleanup the edited file . context.cli.expect ( pexpect.EOF ) # Write the file . if context.editor_file_name and os.path.exists ( context.editor_file_name ) : context.cli.sendcontrol ( ' u ' ) context.cli.sendcontrol ( ' o ' ) Scenario : edit sql in file with external editor with io.open ( expanduser ( path ) , encoding='utf-8 ' ) as f : return contents def step_edit_file ( context ) : def step_edit_type_sql ( context ) : context.cli.sendcontrol ( 'm ' ) context.cli.expect ( pexpect.EOF , timeout=5 ) def step_edit_done_sql ( context ) : import io os.remove ( context.editor_file_name ) Given we have pgcli installed import os","['pgcli/packages/pgspecial/iocommands.py', 'tests/features/crud_table.feature', 'tests/features/environment.py', 'tests/features/iocommands.feature', 'tests/features/steps/step_definitions.py']",Merge pull request # 344 from dbcli/j-bennet/fix-read-from-file
397,65998b263bf203f07fe3b0db4917b3d836e5d504,2015-08-25 09:10:51-04:00,"] ) { 'type ' : 'keyword ' } { 'schema ' : [ ] , 'type ' : 'function ' } , ] def test_suggest_where_keyword ( text ) : 'select * from foo where bar ' , suggestions = suggest_type ( text , text ) 'SELECT * FROM foo where created > now ( ) - ' , assert suggestions == [ { 'tables ' : [ ( None , 'foo ' , None ) ] , 'type ' : 'column ' } , # https : //github.com/dbcli/mycli/issues/135",['tests/test_sqlcompletion.py'],Merge pull request # 343 from dbcli/amjith/where-clause-completion-tests
398,53d76659ee08df73baa823cb84603266b97d590e,2015-08-24 17:00:57-04:00,"'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'QUOTE ' , { 'type ' : 'function ' , 'schema ' : [ ] } , display_meta='function ' ) ] ) 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , elif prev_tok in ( 'any ' , 'some ' , 'all ' ) : ] ) 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , # per case 4 . However , IN is different from ANY , SOME , ALL 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'USING ' , 'VALIDATE ' , 'VALUES ' , # to not suggest keywords . # in that it can accept a * list * of columns , or a subquery . Completion ( text='CURRENT ' , start_position=-2 , display_meta='keyword ' ) , 'NUMBER ' , 'OIDS ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , Completion ( text='custom_func2 ' , start_position=-2 , display_meta='function ' ) , ] ) # But suggesting keywords for , `` SELECT * FROM foo WHERE bar IN 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , Completion ( text='custom_func2 ' , start_position=-2 , display_meta='function ' ) ] ) { 'type ' : 'keyword ' } 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'INTERVAL ' , 'INTO ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , { 'type ' : 'keyword ' } return column_suggestions + [ { 'type ' : 'keyword ' } ] 'USING ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , list ( map ( lambda f : Completion ( f , display_meta='function ' ) , completer.functions ) ) ) { 'type ' : 'function ' , 'schema ' : [ ] } , { 'type ' : 'keyword ' } ] { 'type ' : 'function ' , 'schema ' : [ ] } , ) 'MODIFY ' , 'NOAUDIT ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'INDEX ' , 'INITIAL ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'INTO ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' ] assert suggestions == [ { 'type ' : 'keyword ' } ] { 'type ' : 'function ' , 'schema ' : [ ] } , # ( baz , qux , `` would be overwhelming . So we special case 'IN ' ] ) ] ) 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OIDS ' , 'OF ' , return column_suggestions assert suggestions == [ { 'type ' : 'keyword ' } ] 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , ] ) ] ) 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' ] 'RIGHT ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'PRIVILEGES ' , 'QUOTE ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , { 'type ' : 'function ' , 'schema ' : [ ] } ] ) assert set ( result ) == set ( [ Completion ( text='MAX ' , start_position=-2 , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , list ( map ( lambda x : Completion ( x , display_meta='keyword ' ) , completer.keywords ) ) list ( map ( lambda f : Completion ( f , display_meta='function ' ) , completer.functions ) ) # Technically , we should suggest columns AND keywords , as { 'type ' : 'function ' , 'schema ' : [ ] } ] ) 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'TRUNCATE ' , 'UID ' , 'UNION ' , elif prev_tok == 'in ' : Completion ( text='MAXEXTENTS ' , start_position=-2 , display_meta='keyword ' ) , { 'type ' : 'keyword ' } ] ) { 'type ' : 'function ' , 'schema ' : [ ] } ] 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'INDEX ' , 'INITIAL ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'TRUNCATE ' , 'UID ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , 'ORDER BY ' , 'OUTER ' , 'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , { 'type ' : 'function ' , 'schema ' : [ ] } ] ) assert set ( result ) == set ( [ Completion ( text='MAX ' , start_position=-2 , display_meta='function ' ) ,","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 341 from dbcli/amjith/where-clause-completion
399,72b8e60d189bc2e1418cb7bef2eae7743729fdc5,2015-08-19 21:54:11-07:00,"'foo bar $ $ baz $ $ ' , ' $ $ `` foo '' ' , # there 's an open quote surrounding it , as is common when writing a def _parsed_is_open_quote ( parsed ) : i += 1 `` $ $ 'foo ' $ $ '' , def test_is_open_quote__open ( sql ) : def _is_complete ( sql ) : parsed = sqlparse.parse ( sql ) for ( j , tok2 ) in enumerate ( tokens [ i+1 : ] , i+1 ) : # Found the matching closing quote - continue our scan for # CREATE FUNCTION command return True i = j from pgcli.packages.parseutils import find_prev_keyword elif ( tok.ttype in Token.Name.Builtin from pgcli.packages.parseutils import find_prev_keyword , is_open_quote # No matching dollar sign quote return any ( _parsed_is_open_quote ( p ) for p in parsed ) def is_open_quote ( sql ) : and dollar_quote_regex.match ( tok.value ) ) : `` `` '' Returns true if the query contains an unclosed quote '' '' '' assert is_open_quote ( sql ) _is_complete ( text ) or # A complete SQL command return sql.endswith ( ' ; ' ) and not is_open_quote ( sql ) text.endswith ( ' ; ' ) or # Ended with a semi-colon return False ' $ $ `` foo '' $ $ ' , from sqlparse.tokens import Keyword , DML , Punctuation ' $ $ foo $ a $ ' , # open quotes thereafter ] ) break ' $ $ $ a $ ' , dollar_quote_regex = re.compile ( r'^\ $ [ ^ $ ] * \ $ $ ' ) return True `` $ a $ foo `` , tokens = list ( parsed.flatten ( ) ) 'foo bar $ $ baz ' , else : ' $ $ ' , from sqlparse.tokens import Keyword , DML , Punctuation , Token '' , # An unmatched single quote # A complete command is an sql statement that ends with a semicolon , unless ' $ a $ $ $ $ a $ ' , if tok.match ( Token.Error , `` ' '' ) : assert not is_open_quote ( sql ) i = 0 ' $ $ $ a $ $ $ ' , # parsed can contain one or more semi-colon separated commands # Find the matching closing dollar quote sign from .packages.parseutils import is_open_quote tok = tokens [ i ] while i < len ( tokens ) : 'foo $ $ bar $ $ ; foo $ $ ' , `` foo 'bar baz '' , if tok2.match ( Token.Name.Builtin , tok.value ) : # Postgresql dollar quote signs look like ` $ $ ` or ` $ tag $ ` ' $ $ foo $ $ ' , ' ; ; ; $ $ ' , def test_is_open_quote__closed ( sql ) :","['pgcli/packages/parseutils.py', 'pgcli/pgbuffer.py', 'tests/test_parseutils.py']",Merge pull request # 337 from dbcli/darikg/multiline_open_quotes
400,f8fa8497f3bd192b97dfdba071b60d47a06dad00,2015-08-19 11:00:25-04:00,"cur.execute ( split_sql ) result = run ( executor , 'select invalid command ' ) run ( executor , 'invalid syntax ! ' ) run ( executor , 'select invalid command ' ) import traceback with pytest.raises ( psycopg2.ProgrammingError ) as excinfo : result = run ( executor , 'invalid syntax ! ' ) except psycopg2.ProgrammingError as e : try : result = run ( executor , u '' select 'fooé ' ; invalid syntax é '' ) import click _logger.error ( `` sql : % r , error : % r '' , split_sql , e ) assert 'syntax error at or near `` invalid '' ' in result [ -1 ] assert 'column `` invalid '' does not exist ' in str ( excinfo.value ) assert 'syntax error at or near `` invalid '' ' in str ( excinfo.value ) assert u'fooé ' in result [ 0 ] from .encodingutils import unicode2utf8 , PY2 , utf8tounicode cur.execute ( split_sql ) run ( executor , `` select 'foo ' ; invalid syntax '' ) _logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) from .encodingutils import unicode2utf8 , PY2 executor.run ( sql ) assert 'syntax error at or near `` invalid '' ' in result [ 0 ] import psycopg2 assert 'column `` invalid '' does not exist ' in result [ 0 ] executor.run ( sql ) return ( None , None , None , click.style ( utf8tounicode ( str ( e ) ) , fg='red ' ) )","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 336 from dbcli/amjith/run-commands
401,08c1444e73ad11068b7c4bff4589310ef6ca566f,2015-08-17 11:22:28-04:00,"return [ ( None , None , None , message ) ] from .main import special_command , NO_QUERY message = '\\i : missing required argument ' def read_from_file ( path ) : try : def execute_from_file ( cur , pattern , * * _ ) : from .main import special_command return [ ( None , None , None , message ) ] from os.path import expanduser if pattern : 'Execute commands from file . ' ) return [ ( None , None , None , str ( e ) ) ] with open ( expanduser ( path ) , encoding='utf-8 ' ) as f : try : message = message + ' Error was : ' + str ( e ) query = f.read ( ) with open ( os.path.expanduser ( pattern ) , encoding='utf-8 ' ) as f : return [ ( None , cur , headers , cur.statusmessage ) ] def execute_from_file ( self , pattern , * * _ ) : message = '\\i : missing required argument ' contents = f.read ( ) self.pgspecial.register ( self.execute_from_file , '\\i ' , '\\i filename ' , headers = [ x [ 0 ] for x in cur.description ] except IOError as e : message = 'Error reading file : % s ' % pattern else : from codecs import open if cur.description : return self.pgexecute.run ( query , self.pgspecial ) query = read_from_file ( pattern ) @ special_command ( '\\i ' , '\\i file ' , 'Execute commands from file . ' ) from codecs import open if not pattern : return [ ( None , None , None , cur.statusmessage ) ] cur.execute ( query ) return [ ( None , None , None , message ) ] except IOError as e : return contents","['pgcli/main.py', 'pgcli/packages/pgspecial/iocommands.py']",Merge pull request # 334 from dbcli/amjith/run-commands
402,27c2eabc08269851ed97f3d79781aa76d4722ec5,2015-08-16 10:34:51-07:00,"dsn ) port=None , dsn=None ) : elif `` = '' in database : port=unicode2utf8 ( port ) ) dsn = `` { 0 } password= { 1 } '' .format ( dsn , password ) host=POSTGRES_HOST , password=None , port=None ) password=unicode2utf8 ( password ) , conn = psycopg2.connect ( self.connect ( dsn=dsn ) def connect ( self , database= '' , host= '' , user= '' , port= '' , passwd= '' , host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) host=unicode2utf8 ( host ) , : param sql : string port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) def __init__ ( self , database , user , password , host , port , dsn ) : # user , etc . we connected to . Let 's read it . database=unicode2utf8 ( db ) , database=unicode2utf8 ( db ) , pgexecute = PGExecute ( database , user , passwd , host , port ) self.dsn = dsn def _select_one ( self , cur , sql ) : conn = psycopg2.connect ( dsn=unicode2utf8 ( dsn ) ) pgexecute = PGExecute ( database , user , passwd , host , port , pgcli.connect_dsn ( database ) user = self._select_one ( cursor , 'select current_user ' ) db = self._select_one ( cursor , 'select current_database ( ) ' ) password=unicode2utf8 ( password ) , if password : port=None ) : def connect_dsn ( self , dsn ) : def __init__ ( self , database , user , password , host , port ) : : param cur : cursor host=unicode2utf8 ( host ) , user=unicode2utf8 ( user ) , cursor = conn.cursor ( ) Helper method to run a select and retrieve a single field value host=POSTGRES_HOST , password=None , port=None , dsn=None ) user=unicode2utf8 ( user ) , elif os.environ.get ( 'PGSERVICE ' , None ) : pgexecute = PGExecute ( database , user , passwd , host , port , dsn ) cur.execute ( sql ) # When we connect using a DSN , we do n't really know what db , : return : string def connect ( self , database= '' , host= '' , user= '' , port= '' , passwd= '' ) : port=unicode2utf8 ( port ) ) if dsn : conn = psycopg2.connect ( pgexecute = PGExecute ( database , user , passwd , host , port ) dsn = ( dsn or self.dsn ) pgcli.connect_dsn ( 'service= { 0 } '.format ( os.environ [ 'PGSERVICE ' ] ) ) dsn= '' ) : return cur.fetchone ( ) `` `` '' else :","['pgcli/main.py', 'pgcli/pgexecute.py', 'tests/conftest.py']",Merge pull request # 333 from dbcli/j-bennet/clean-pg-service-conf
403,9a35e5ef05d5f623f5362f85be9d2f240e6cac19,2015-08-13 23:40:11-07:00,"dsn ) port=None , dsn=None ) : elif `` = '' in database : port=unicode2utf8 ( port ) ) dsn = `` { 0 } password= { 1 } '' .format ( dsn , password ) host=POSTGRES_HOST , password=None , port=None ) password=unicode2utf8 ( password ) , conn = psycopg2.connect ( self.connect ( dsn=dsn ) return cur.fetchall ( ) [ 0 ] [ 0 ] def connect ( self , database= '' , host= '' , user= '' , port= '' , passwd= '' , host = self._select_one ( cursor , 'select inet_server_addr ( ) ' ) host=unicode2utf8 ( host ) , : param sql : string port = self._select_one ( cursor , 'select inet_server_port ( ) ' ) def __init__ ( self , database , user , password , host , port , dsn ) : # user , etc . we connected to . Let 's read it . database=unicode2utf8 ( db ) , database=unicode2utf8 ( db ) , pgexecute = PGExecute ( database , user , passwd , host , port ) self.dsn = dsn def _select_one ( self , cur , sql ) : conn = psycopg2.connect ( dsn=unicode2utf8 ( dsn ) ) pgexecute = PGExecute ( database , user , passwd , host , port , pgcli.connect_dsn ( database ) user = self._select_one ( cursor , 'select current_user ' ) db = self._select_one ( cursor , 'select current_database ( ) ' ) password=unicode2utf8 ( password ) , if password : port=None ) : def connect_dsn ( self , dsn ) : def __init__ ( self , database , user , password , host , port ) : : param cur : cursor host=unicode2utf8 ( host ) , user=unicode2utf8 ( user ) , cursor = conn.cursor ( ) Helper method to run a select and retrieve a single field value host=POSTGRES_HOST , password=None , port=None , dsn=None ) user=unicode2utf8 ( user ) , elif os.environ.get ( 'PGSERVICE ' , None ) : pgexecute = PGExecute ( database , user , passwd , host , port , dsn ) cur.execute ( sql ) # When we connect using a DSN , we do n't really know what db , : return : string def connect ( self , database= '' , host= '' , user= '' , port= '' , passwd= '' ) : port=unicode2utf8 ( port ) ) if dsn : conn = psycopg2.connect ( pgexecute = PGExecute ( database , user , passwd , host , port ) dsn = ( dsn or self.dsn ) pgcli.connect_dsn ( 'service= { 0 } '.format ( os.environ [ 'PGSERVICE ' ] ) ) dsn= '' ) : `` `` '' else :","['pgcli/main.py', 'pgcli/pgexecute.py', 'tests/conftest.py']",Started adding `` service '' option . Connect # 289 .
404,62fddef501465e7ffe4f4eec5562269b7fb5077c,2015-08-11 22:55:06-07:00,"os.environ.pop ( 'PAGER ' , None ) if not self.pager : msg = 'PAGER set to % s . ' % pattern 'Set PAGER . Pring the query results via PAGER . ' , os.environ [ 'LESS ' ] = '-SRXF ' self.pager = os.environ.get ( 'PAGER ' , `` ) return [ ( None , None , None , msg ) ] msg = 'Pager reset to system default . ' msg = 'Reset pager back to default . Default : % s ' % self.pager else : arg_type=PARSED_QUERY ) os.environ [ 'LESS ' ] = '-RXF ' os.environ [ 'PAGER ' ] = pattern def set_pager ( self , pattern , * * _ ) : self.register ( self.set_pager , '\\pager ' , '\\pager [ command ] ' , os.environ [ 'PAGER ' ] = self.pager if not pattern : import os else :","['pgcli/main.py', 'pgcli/packages/pgspecial/main.py']",Merge pull request # 332 from dbcli/amjith/pager
405,376588597ecf47db932ed5fee432cf6a30cb8d97,2015-08-11 13:08:49-07:00,"on_exit=AbortAction.RAISE_EXCEPTION ) 'prompt_toolkit==0.46 ' , Token.Toolbar.Arg = 'noinherit bold ' enable_system_bindings=True , on_exit=AbortAction.RAISE_EXCEPTION , Token.IncrementalSearchMatch.Current = ' # ffffff bg : # 44aa44 ' Token.Toolbar.System = 'noinherit bold ' Token.Menu.Completions.MultiColumnMeta = 'bg : # aaffff # 000000 ' Token.IncrementalSearchMatch = ' # ffffff bg : # 4444aa ' Token.Toolbar.Search = 'noinherit bold ' Token.Toolbar.Search.Text = 'nobold ' Token.SearchMatch.Current = ' # ffffff bg : # 44aa44 ' Token.Toolbar.Arg.Text = 'nobold ' multiline=True , 'prompt_toolkit==0.45 ' , ignore_case=True ) Token.SearchMatch = ' # ffffff bg : # 4444aa '","['pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgclirc', 'setup.py']",Merge pull request # 328 from jonathanslenders/prompt_toolkit-0.46
406,cec4e0bd0e2008bac9843b80f1690de4b3a5d45f,2015-08-07 09:43:44-04:00,"} ) styles.update ( { Token.IncrementalSearchMatch = ' # ffffff bg : # 4444aa ' Token.Menu.Completions.Meta = 'bg : # 448888 # ffffff ' Token.IncrementalSearchMatch.Current = ' # ffffff bg : # 44aa44 ' styles.update ( custom_styles ) def style_factory ( name ) : Token.Menu.Completions.Meta.Current = 'bg : # 44aaaa # 000000 ' Token.Toolbar = 'bg : # 222222 # aaaaaa ' Token.Menu.Completions.Meta.Current : 'bg : # 44aaaa # 000000 ' , Token.Menu.Completions.ProgressBar : 'bg : # 00aaaa ' , Token.Menu.Completions.ProgressButton : 'bg : # 003333 ' , Token.Toolbar.On : 'bg : # 222222 # ffffff ' , Token.SelectedText = ' # ffffff bg : # 6666aa ' # Named queries are queries you can execute by name . custom_styles = dict ( [ ( string_to_tokentype ( x ) , y ) application = Application ( style=style_factory ( self.syntax_style ) , for x , y in cli_style.items ( ) ] ) Token.SelectedText : ' # ffffff bg : # 6666aa ' , Token.Menu.Completions.Completion = 'bg : # 008888 # ffffff ' self.cli_style = c [ 'colors ' ] # Named queries are queries you can rexecute by name Token.Menu.Completions.ProgressButton = 'bg : # 003333 ' Token.Toolbar.Off = 'bg : # 222222 # 888888 ' from pygments.token import Token from pygments.token import string_to_tokentype Token.IncrementalSearchMatch.Current : ' # ffffff bg : # 44aa44 ' , Token.Menu.Completions.Completion.Current = 'bg : # ffffff # 000000 ' Token.Menu.Completions.ProgressBar = 'bg : # 00aaaa ' Token.Toolbar : 'bg : # 440044 # ffffff ' , def style_factory ( name , cli_style ) : Token.Toolbar : 'bg : # 222222 # aaaaaa ' , [ colors ] Token.IncrementalSearchMatch : ' # ffffff bg : # 4444aa ' , Token.Menu.Completions.Meta : 'bg : # 448888 # ffffff ' , application = Application ( style=style_factory ( self.syntax_style , self.cli_style ) , Token.Toolbar.Off : 'bg : # 222222 # 888888 ' , Token.Menu.Completions.Completion.Current : 'bg : # 00aaaa # 000000 ' , Token.Menu.Completions.Completion : 'bg : # 008888 # ffffff ' , # Custom colors for the completion menu , toolbar , etc . Token.Toolbar.On = 'bg : # 222222 # ffffff '","['pgcli/main.py', 'pgcli/pgclirc', 'pgcli/pgstyle.py']",Merge pull request # 326 from dbcli/amjith/custom_colors
407,0a02e774ff42d791326109549900eec13a0a88af,2015-08-07 09:31:57-04:00,"pgcli = PGCli ( prompt_passwd , never_prompt , pgclirc_file=pgclirc ) write_default_config ( default_config , pgclirc_file ) username , version ) : c = self.config = load_config ( pgclirc_file , default_config ) username , version , pgclirc ) : help='Location of .pgclirc file . ' ) pgexecute=None ) : pgexecute=None , pgclirc_file=None ) : pgcli = PGCli ( prompt_passwd , never_prompt ) c = self.config = load_config ( '~/.pgclirc ' , default_config ) write_default_config ( default_config , '~/.pgclirc ' )",['pgcli/main.py'],Merge pull request # 325 from dbcli/j-bennet/config-file-argument
408,e0c3545dc3e44b59d8fbc540187ad491a5dfff27,2015-08-05 22:36:45-07:00,"pgcli = PGCli ( prompt_passwd , never_prompt , pgclirc_file=pgclirc ) write_default_config ( default_config , pgclirc_file ) username , version ) : c = self.config = load_config ( pgclirc_file , default_config ) username , version , pgclirc ) : help='Location of .pgclirc file . ' ) pgexecute=None ) : pgexecute=None , pgclirc_file=None ) : pgcli = PGCli ( prompt_passwd , never_prompt ) c = self.config = load_config ( '~/.pgclirc ' , default_config ) write_default_config ( default_config , '~/.pgclirc ' )",['pgcli/main.py'],Pgclirc file location is being read from command line or env . Connect # 302 .
409,ad9c99f79028ee6a508ea3dfdad63215424a6fa1,2015-08-05 15:43:05-07:00,"sql = 'select * from `` select '' s where s . ' tables = extract_tables ( 'select * from `` Abc '' a ' ) 'SELECT * FROM `` tabl1 '' t1 , tabl2 t2 WHERE t1 . ' , { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } , 'SELECT t1 . ' ) def test_simple_select_single_table_double_quoted ( ) : 'SELECT t1 . FROM tabl1 t1 ' , { 'type ' : 'function ' , 'schema ' : 't1 ' } ] ) assert sorted_dicts ( suggestions ) == sorted_dicts ( [ def test_simple_select_multiple_tables_deouble_quoted_aliased ( ) : def test_suggest_columns_from_escaped_table_alias ( completer , complete_event ) : suggestions = suggest_type ( sql , sql ) 'sqlparse == 0.1.16 ' , tables = extract_tables ( 'select * from `` Abc '' ' ) 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' , 'SELECT t1 . FROM `` tabl1 '' t1 ' , assert tables == [ ( None , 'Abc ' , None ) ] def test_dot_suggests_cols_of_an_alias_where ( sql ) : assert set ( result ) == set ( [ 'SELECT * FROM tabl1 t1 , tabl2 t2 WHERE t1 . ' , assert tables == [ ( None , 'Abc ' , ' a ' ) ] suggestions = suggest_type ( 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' , assert tables == [ ( None , 'Abc ' , ' a ' ) , ( None , 'Def ' , 'd ' ) ] assert tables == [ ( None , 'Abc ' , None ) , ( None , 'Def ' , None ) ] def test_simple_select_multiple_tables_double_quoted ( ) : { 'type ' : 'view ' , 'schema ' : 't1 ' } , Completion ( text= ' * ' , start_position=0 , display_meta='column ' ) , complete_event ) Completion ( text= ' '' insert '' ' , start_position=0 , display_meta='column ' ) , suggestions = suggest_type ( sql , 'SELECT t1 . ' ) 'SELECT * FROM tabl1 t1 WHERE t1 . ' , { 'type ' : 'table ' , 'schema ' : 't1 ' } , 'SELECT t1 . FROM `` tabl1 '' t1 , `` tabl2 '' t2 ' , 'SELECT * FROM `` tabl1 '' t1 WHERE t1 . ' , def test_dot_suggests_cols_of_an_alias ( sql ) : tables = extract_tables ( 'select * from `` Abc '' , `` Def '' ' ) ] ) def test_simple_select_single_table_deouble_quoted_aliased ( ) : pos = len ( sql ) tables = extract_tables ( 'select * from `` Abc '' a , `` Def '' d ' ) 'sqlparse == 0.1.14 ' , def test_dot_suggests_cols_of_an_alias ( ) : Completion ( text= ' '' ABC '' ' , start_position=0 , display_meta='column ' ) , result = completer.get_completions ( Document ( text=sql , cursor_position=pos ) , Completion ( text='id ' , start_position=0 , display_meta='column ' ) ,","['setup.py', 'tests/test_parseutils.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 323 from dbcli/darikg/bugfix-283
410,4b644bf2f130ea34dc11e13ca4a3dde6e0cfeab7,2015-08-05 15:04:33-07:00,"if cmd == '\\c ' : [ { 'type ' : 'datatype ' , 'schema ' : 'foo ' } ] ) def test_c_suggests_databases ( command ) : if cmd in ( '\\c ' , '\\connect ' ) : import pytest suggestions = suggest_type ( command , command ) [ { 'type ' : 'datatype ' , 'schema ' : 'foo ' } ] ) assert suggestions == [ { 'type ' : 'database ' } ]","['pgcli/packages/sqlcompletion.py', 'tests/test_pgspecial.py']",Merge pull request # 324 from dbcli/darikg/bugfix-322
411,259f4897a222f57165bc45d6f481b58a8673bf93,2015-08-05 15:01:14-07:00,"text = 'selt * ' def test_invalid_sql ( ) : # issue 317 assert suggestions == [ { 'type ' : 'keyword ' } ] suggestions = suggest_type ( text , text )",['tests/test_sqlcompletion.py'],Merge pull request # 320 from dbcli/darikg/bugfix-317
412,9ab49a2145c5997e580bd718099e2ca9bca0cf06,2015-08-05 14:55:51-07:00,"context.conf [ 'dbname_tmp ' ] ) ) context.cli.sendline ( 'drop database pgcli_behave_tmp ; ' ) context.cli.expect ( pexpect.EOF , timeout=5 ) context.cli.expect ( ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) ) context.cli.sendline ( 'drop database { 0 } ; '.format ( 'database_name ' : 'pgcli_behave_tmp ' then we see database connected 'dbname_tmp ' : db_name_full + '_tmp ' , context.cli.expect ( ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) , timeout=5 ) context.cli.sendline ( 'create database pgcli_behave_tmp ; ' ) context.cli.expect ( pexpect.EOF ) context.cli.sendline ( 'create database { 0 } ; '.format ( when we connect to postgres 'database_name ' : context.conf [ 'dbname_tmp ' ]","['tests/features/crud_database.feature', 'tests/features/environment.py', 'tests/features/steps/step_definitions.py']",Merge pull request # 321 from dbcli/j-bennet/integration-tests
413,e97cc6586d4976eebe30d343f729cf622ad8c558,2015-08-05 09:40:31-04:00,"text = 'selt * ' def test_invalid_sql ( ) : # issue 317 assert suggestions == [ { 'type ' : 'keyword ' } ] suggestions = suggest_type ( text , text )",['tests/test_sqlcompletion.py'],Add regression test for # 317
414,e3e7b20d0eaa0684a9af71d7a2403afe101a6535,2015-08-04 09:54:26-07:00,====== * Fix an autocompletion bug that was crashing the completion engine when unknown keyword is entered . ( Thanks : ` Darik Gamble ` _ ) 0.19.1 BugFixe :,['changelog.rst'],Merge pull request # 319 from dbcli/amjith/release-0.19.1
415,863987dcba99e63c1b652fbbbb051d0353f28609,2015-08-03 08:49:53-07:00,"* Jay Zeng Hans Roman Eric Workman Add this line to your config file ( ~/.pgclirc ) to customize where to store the history file . * Fix a crashing bug in the autocompletion engine for some `` JOIN `` queries . * Jonathan Slenders xalley Charlie Arnold * Sven-Hendrik Haase * Ali Kargın while0pass * Guewen Baconnier Ali Kargın * François Pietka * Daniel Rocco Guewen Baconnier `` True `` . * Run behaviorial tests as part of TravisCI ( Thanks : ` Iryna Cherniavska ` _ ) * Upgraded prompt_toolkit version to 0.45 ( Thanks : ` Jonathan Slenders ` _ ) * Ludovic Gasc ( GMLudo ) `` wider_completion_menu `` option available . If not add it in and set it to Tiago Ribeiro François Pietka * Update the minumum required version of click to 4.1 . * Jacob Magnusson * Alexander Kukushkin * Tiago Ribeiro .. _ ` Michael Kaminsky ` : https : //github.com/mikekaminsky Internal Changes : Jacob Magnusson * Eric Workman * rrampage * while0pass * Hans Roman history_file = /path/to/history/file Daniel Schwarz * Marc Abramowitz Brett BugFixes : * Iryna Cherniavska 0.19.0 * Always use utf-8 for database encoding regardless of the default encoding used by the database . rrampage * dwalmsley Karl-Aksel Puulmann : : .. _ ` Çağatay Yüksel ` : https : //github.com/cagatay Marc Abramowitz Stuart Quin * Dhaivat Pandit Open the config file ( ~/.pgclirc ) and check if you have * Add support for running queries from a file using `` \i `` special command . ( Thanks : ` Michael Kaminsky ` _ ) * Handle KeyboardInterrupt in pager and not quit pgcli as a consequence . * Çağatay Yüksel * Darik Gamble * Daniel Schwarz * Fix for None dereference on `` \d schemaname. `` with sequence . ( Thanks : ` Nathan Jhaveri ` _ ) * Dionysis Grigoropoulos Vignesh Anand * xalley * Customizable history file location via config file . ( Thanks : ` Çağatay Yüksel ` _ ) ====== * Completion menu now has metadata information such as schema , table , column , view , etc. , next to the suggestions . ( Thanks : ` Darik Gamble ` _ ) Ludovic Gasc ( GMLudo ) Sven-Hendrik Haase Darik Gamble Daniel Rocco * Stuart Quin * Brett xa Dionysis Grigoropoulos * Vignesh Anand Dimitar Roustchev Dhaivat Pandit * David Celis .. _ ` Nathan Jhaveri ` : https : //github.com/nathanjhaveri * Wider completion menus can be enabled via the config file . ( Thanks : ` Jonathan Slenders ` _ ) * Nick Hahner * Added code coverage to the tests . ( Thanks : ` Iryna Cherniavska ` _ ) * Added more behaviorial tests ( Thanks : ` Iryna Cherniavska ` _ ) * Michael Kaminsky Features : Iryna Cherniavska * xa dwalmsley Nick Hahner Jay Zeng Alexander Kukushkin David Celis * Karl-Aksel Puulmann * Nathan Jhaveri * Charlie Arnold * Dimitar Roustchev Jonathan Slenders Core Devs :","['AUTHORS', 'changelog.rst']",Merge pull request # 314 from dbcli/amjith/changelog-0.19.0
416,68aba40b2dfc9ae68657bcd2139a1897f3ab7f84,2015-08-02 20:56:11-07:00,"# Keybindings : self.wider_completion_menu = c [ 'main ' ] .as_bool ( 'wider_completion_menu ' ) display_completions_in_columns = False self.display_completions_in_columns = c [ 'main ' ] .as_bool ( 'display_completions_in_columns ' ) wider_completion_menu = False # for end are available in the REPL . # When Vi mode is enabled you can use modal editing features offered by Vi in the REPL . display_completions_in_columns=self.display_completions_in_columns , # When Vi mode is disabled emacs keybindings such as Ctrl-A for home and Ctrl-E # Enables vi-mode display_completions_in_columns=self.wider_completion_menu ,","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 313 from dbcli/amjith/config_comment_vi_mode
417,47c9af815d062e4c1c5bd0750246b3c28cf740ec,2015-08-02 14:42:05-07:00,"tempfile_suffix='.sql ' , * * kwargs ) display_completions_in_columns=self.display_completions_in_columns , super ( self.__class__ , self ) .__init__ ( * args , is_multiline=is_multiline , # visible . ) self.display_completions_in_columns = c [ 'main ' ] .as_bool ( 'display_completions_in_columns ' ) display_completions_in_columns = False 'prompt_toolkit==0.45 ' , 'prompt_toolkit==0.42 ' , super ( self.__class__ , self ) .__init__ ( * args , is_multiline=is_multiline , * * kwargs ) enable_open_in_editor=True , # Display the completions in several columns . ( More completions will be","['pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgbuffer.py', 'pgcli/pgclirc', 'setup.py']",Merge pull request # 308 from jonathanslenders/prompt_toolkit_0.44
418,a25dc906afb675a2b9d9095553be05df84153459,2015-08-02 10:34:49-04:00,"text = 'select * from foo f left join bar b , ' return t.value , text { 'type ' : 'schema ' } ] ) assert kw.value == 'where ' and stripped == 'select * from foo where ' assert kw == ' ( ' and q2 == 'select * from tbl1 inner join tbl2 using ( ' return t , text def test_left_join_with_comma ( ) : assert kw == ' ( ' assert kw.value == ' ( ' suggestions = suggest_type ( text , text ) { 'type ' : 'view ' , 'schema ' : [ ] } , if prev_keyword == ' ( ' : if prev_keyword.value == ' ( ' : { 'type ' : 'table ' , 'schema ' : [ ] } , assert kw == 'where ' and stripped == 'select * from foo where ' assert kw.value == ' ( ' and q2 == 'select * from tbl1 inner join tbl2 using ( ' assert sorted_dicts ( suggestions ) == sorted_dicts ( [","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'tests/test_parseutils.py', 'tests/test_sqlcompletion.py']",Merge pull request # 311 from dbcli/amjith/autocompletion-crash
419,791b7710989b58832299b387cbe15bce776dd04d,2015-08-02 10:29:42-04:00,"'click > = 3.2 ' , click.echo_via_pager ( '\n'.join ( output ) ) click.echo_via_pager ( '\n'.join ( output ) ) except KeyboardInterrupt : 'click > = 4.1 ' , try : pass","['pgcli/main.py', 'setup.py']",Merge pull request # 290 from dbcli/amjith/click-bump
420,1f147f5e7adf14daea1f59d2ebc88e7539c7e4a7,2015-08-01 07:45:22-07:00,"def step_see_table_dropped ( context ) : context.cli.expect_exact ( 'UPDATE 1 ' , timeout=2 ) Feature : manipulate tables : context.cli.expect_exact ( 'DROP DATABASE ' , timeout=2 ) then we see record inserted } Wait to see insert output . then we see database dropped Scenario : create and drop temporary database context.response = { create , drop , connect , disconnect context.cli.sendline ( '\connect { 0 } '.format ( db_name ) ) context.cli.sendline ( 'select * from a ; ' ) context.cli.expect_exact ( 'CREATE DATABASE ' , timeout=2 ) import sys when we update table Send drop database . when we run pgcli and we wait for prompt pip install . pytest mock codecov behave pexpect def step_see_db_dropped ( context ) : def step_see_db_connected ( context ) : Scenario : create , insert , select from , update , drop table def step_db_connect_postgres ( context ) : 'dbname ' : context.config.userdata.get ( 'pg_test_db ' , None ) , Send create database . and we create database context.cli.sendline ( `` 'update a set x = 'yyy ' where x = 'xxx ' ; ' '' ) then we see record deleted 'user ' : context.config.userdata.get ( 'pg_test_user ' , 'postgres ' ) , def step_see_record_inserted ( context ) : when we drop table when we select from table Feature : manipulate databases : behave context.cli.sendline ( 'drop database pgcli_behave_tmp ; ' ) cn = connect ( host=hostname , user=username , database=dbname ) context.cli.sendline ( '\connect postgres ' ) pip install . pytest mock codecov def step_insert_into_table ( context ) : else : Wait to see drop database output . def step_drop_table ( context ) : when we send `` ctrl + d '' when we drop database Wait to see select output . db_name = context.config.userdata.get ( 'pg_test_db ' , None ) if 'PGHOST ' in os.environ : context.cli.sendline ( 'create database pgcli_behave_tmp ; ' ) if 'PGPASS ' in os.environ : db_name = context.conf [ 'dbname ' ] def step_see_data_deleted ( context ) : Given we have pgcli installed context.cli.expect_exact ( 'DELETE 1 ' , timeout=2 ) del os.environ [ 'PGPASS ' ] def step_db_drop ( context ) : db_name_full = ' { 0 } _ { 1 } '.format ( db_name , vi ) `` `` '' def step_see_table_created ( context ) : cd tests Send connect to database . context.cli.expect_exact ( 'INSERT 0 1 ' , timeout=2 ) Send deete from table . def step_create_table ( context ) : Send select from table . vi = ' _'.join ( [ str ( x ) for x in sys.version_info [ :3 ] ] ) def step_select_from_table ( context ) : then we see table dropped Send drop table . def step_see_record_updated ( context ) : Send insert into table . when we delete from table 'user ' : context.config.userdata.get ( 'pg_test_user ' , 'root ' ) , Wait to see delete output . cn = connect ( user=username , database=dbname ) then pgcli exits when we connect to postgres Wait to see create database output . context.cli.expect_exact ( 'yyy ' , timeout=1 ) def step_db_create ( context ) : and we connect to test database create , insert , update , select , delete from , drop Wait to see update output . 'dbname ' : db_name_full , def step_update_table ( context ) : then we see table created context.cli.expect_exact ( 'CREATE TABLE ' , timeout=2 ) then we see database connected when we create table def step_delete_from_table ( context ) : when we insert into table del os.environ [ 'PGHOST ' ] then we see database created Wait to see drop output . Wait to see create table output . context.cli.sendline ( `` 'insert into a ( x ) values ( 'xxx ' ) ; ' '' ) def step_see_db_created ( context ) : Send create table . 'database_name ' : 'pgcli_behave_tmp ' del os.environ [ 'PGPASS ' ] def step_see_data_selected ( context ) : context.cli.expect_exact ( 'DROP TABLE ' , timeout=2 ) context.cli.sendline ( 'create table a ( x text ) ; ' ) context.cli.expect_exact ( 'SELECT 1 ' , timeout=1 ) context.cli.sendline ( `` 'delete from a where x = 'yyy ' ; ' '' ) def step_db_connect_test ( context ) : Scenario : connect and disconnect from test database context.cli.expect_exact ( 'You are now connected to database ' , timeout=2 ) then we see data selected context.cli.sendline ( 'drop table a ; ' ) then we see record updated elif 'PGPASS ' in os.environ :","['.travis.yml', 'tests/features/{simple_cli_commands.feature => basic_commands.feature}', 'tests/features/crud_database.feature', 'tests/features/crud_table.feature', 'tests/features/db_utils.py', 'tests/features/environment.py', 'tests/features/steps/step_definitions.py']",Merge pull request # 300 from dbcli/j-bennet/integration-tests
421,8dfff69ec23be828d5681fae5fcd2c7b9391ced6,2015-07-30 10:20:00-07:00,"def read_from_file ( path ) : return [ ( None , None , None , cur.statusmessage ) ] with open ( expanduser ( path ) , encoding='utf-8 ' ) as f : message = message + ' Error was : ' + str ( e ) contents = f.read ( ) return [ ( None , None , None , message ) ] return [ ( None , cur , headers , cur.statusmessage ) ] from os.path import expanduser if pattern : message = 'Error reading file : % s ' % pattern try : if cur.description : message = '\\i : missing required argument ' cur.execute ( query ) else : with open ( filename , encoding='utf-8 ' ) as f : return contents return [ ( None , None , None , message ) ] except IOError as e : def execute_from_file ( cur , pattern , * * _ ) : query = read_from_file ( filename ) query = read_from_file ( pattern ) headers = [ x [ 0 ] for x in cur.description ] query = f.read ( )",['pgcli/packages/pgspecial/iocommands.py'],Merge pull request # 306 from mikekaminsky/master
422,6255017b145df5cc0d09b975e4f257590666a089,2015-07-29 11:00:08-07:00,"history_file = ~/.pgcli-history history=FileHistory ( os.path.expanduser ( '~/.pgcli-history ' ) ) , history_file = self.config [ 'main ' ] [ 'history_file ' ] history=FileHistory ( os.path.expanduser ( history_file ) ) , # history_file location .","['pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 305 from cagatay/customizable-history-file-location
423,31c9d176e0e013a46e7d45a402a09bdc50d8db4e,2015-07-29 15:58:20+00:00,"history_file = ~/.pgcli-history history=FileHistory ( os.path.expanduser ( '~/.pgcli-history ' ) ) , history_file = self.config [ 'main ' ] [ 'history_file ' ] history=FileHistory ( os.path.expanduser ( history_file ) ) , # history_file location .","['pgcli/main.py', 'pgcli/pgclirc']","Provide customizable history file location , Fixes # 304"
424,390839b945cfbeaeb4c1c07bf97fc5a99198355f,2015-07-28 13:19:52-07:00,"def find_matches ( self , text , collection , start_only=False , fuzzy=True , Completion ( text='custom_func1 ' , start_position=-2 ) , Completion ( text= ' u ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='product_name ' , start_position=0 ) , meta='table ' ) Completion ( text='typ4 ' , display_meta='datatype ' ) , Completion ( text='shipments ' , start_position=0 ) ] ) meta='table alias ' ) def find_matches ( self , text , collection , start_only=False , fuzzy=True ) : Completion ( text='custom_func2 ' , start_position=-2 ) ] ) Completion ( text= ' '' insert '' ' , start_position=0 ) , Completion ( text='last_name ' , start_position=0 ) ] ) Completion ( text='orders ' , start_position=0 , display_meta='table ' ) ] ) assert set ( map ( lambda x : Completion ( x , display_meta='keyword ' ) , Completion ( text='custom_func2 ' , start_position=0 , display_meta='function ' ) ] Completion ( text= ' o ' , start_position=0 , display_meta='table alias ' ) ] ) meta='datatype ' ) types = self.find_matches ( word_before_cursor , types , # Custom types # Truncate meta-text to 50 characters , if necessary cmd_names = commands.keys ( ) views = self.find_matches ( word_before_cursor , views , self.special_commands , Completion ( text='custom_func1 ' , start_position=-2 , display_meta='function ' ) , return match_point , 0 Completion ( text='custom ' , start_position=0 , display_meta='schema ' ) , start_only=False , fuzzy=True , completions.append ( ( len ( r.group ( ) ) , r.start ( ) , item ) ) Completion ( text='custom ' , start_position=0 ) , fuzzy=False ) Completion ( text='func1 ' , start_position=0 ) , Completion ( text='func3 ' , start_position=-len ( 'func ' ) ) , return ( Completion ( z , -len ( text ) ) for x , y , z in sorted ( completions ) ) display_meta='keyword ' ) ] ) meta_collection=desc ) meta=None , meta_collection=None ) : Completion ( text='shipments ' ) , display_meta='function ' ) ] ) Completion ( text='func3 ' , start_position=-len ( 'func ' ) , display_meta='function ' ) , Completion ( text='price ' , start_position=0 , display_meta='column ' ) ] ) def __init__ ( self , smart_completion=True , pgspecial=None ) : completer = PGCompleter ( smart_completion ) 'custom_type1 ' , 'custom_type2 ' , Completion ( text='orders ' , start_position=0 , display_meta='table ' ) , special = self.find_matches ( word_before_cursor , def extend_special_commands ( self , special_commands ) : Completion ( text= ' '' select '' ' , start_position=0 ) , completions.append ( ( sort_key , item , meta ) ) collection = zip ( collection , meta_collection ) Completion ( text='orders ' , start_position=0 ) , Completion ( text='id ' , start_position=0 , display_meta='column ' ) , desc = [ commands [ cmd ] .description for cmd in cmd_names ] # or None if the item does n't match Completion ( text='price ' , start_position=0 ) ] ) if meta_collection : dbs = self.find_matches ( word_before_cursor , self.databases ) meta='view ' ) aliases = self.find_matches ( word_before_cursor , aliases ) Completion ( text='typ3 ' ) , Completion ( text='custom_func1 ' , start_position=0 , display_meta='function ' ) , user_funcs = self.find_matches ( word_before_cursor , funcs ) Completion ( text='products ' ) , import itertools Completion ( text='func2 ' , start_position=0 ) ] # Tables fuzzy=False ) Completion ( text= ' '' select '' ' , start_position=0 ) , Completion ( text='func4 ' , start_position=-len ( 'func ' ) ) ] ) return [ Completion ( item , -len ( text ) , display_meta=meta ) for sort_key , item , meta in sorted ( completions ) ] completions = [ ] Completion ( text='users ' , start_position=0 , display_meta='table alias ' ) , self.special_commands.extend ( special_commands ) schema_names = self.find_matches ( word_before_cursor , continue completer = PGCompleter ( smart_completion , pgspecial=self.pgspecial ) def _match ( item ) : Completion ( text='users ' , start_position=0 , display_meta='table ' ) , ] + completer.datatypes fuzzy=False , meta='datatype ' ) cols = self.find_matches ( word_before_cursor , scoped_cols , Completion ( text='user_emails ' , start_position=0 ) , fuzzy=False ) Completion ( text= ' u ' , start_position=0 ) , Completion ( text='orders ' , start_position=0 ) ] ) meta='schema ' ) Completion ( text='users ' , display_meta='table ' ) , Completion ( text='email ' , start_position=0 ) , Completion ( text='phone_number ' , start_position=0 ) , Completion ( text='first_name ' , start_position=0 , display_meta='column ' ) , # The match function returns a 2-tuple used for sorting the matches , # All completions have an identical meta Completion ( text='typ4 ' ) , assert set ( map ( Completion , completer.keywords ) ) == result if meta and len ( meta ) > 50 : Completion ( text='price ' , start_position=0 , display_meta='column ' ) , if sort_key : Completion ( text='public ' , start_position=0 , display_meta='schema ' ) , aliases = self.find_matches ( word_before_cursor , aliases , Completion ( text= ' '' ABC '' ' , start_position=0 ) , Completion ( text='users ' , start_position=0 ) , assert set ( result ) == set ( [ Completion ( text='SELECT ' , start_position=-3 , assert set ( result ) == set ( collection = zip ( collection , itertools.repeat ( meta ) ) Completion ( text='products ' , start_position=0 ) , Completion ( text='users ' , start_position=0 , display_meta='table ' ) , completer.keywords ) ) == result Completion ( text='orders ' , start_position=0 ) ] ) # Each possible completion in the collection has a corresponding Completion ( text='last_name ' , start_position=0 , display_meta='column ' ) , Completion ( text= ' y ' , start_position=0 , display_meta='table alias ' ) ] ) meta='function ' ) # Built-in datatypes fuzzy=False , Completion ( text='custom_func2 ' , start_position=-2 , display_meta='function ' ) ] ) # special commands self.pgspecial = pgspecial assert set ( result ) == set ( [ start_only=False , fuzzy=True ) Completion ( text='shipments ' , start_position=0 , display_meta='table ' ) ] ) Completion ( text= ' x ' , start_position=0 , display_meta='table alias ' ) , Completion ( text='custom_type1 ' , start_position=0 , display_meta='datatype ' ) , Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) , Completion ( text='typ3 ' , display_meta='datatype ' ) , fuzzy=False , Completion ( text='orders ' , start_position=0 ) , for item , meta in collection : cols = self.find_matches ( word_before_cursor , scoped_cols ) Completion ( text= ' '' insert '' ' , start_position=0 , display_meta='column ' ) , return len ( r.group ( ) ) , r.start ( ) Completion ( text='func2 ' , start_position=0 , display_meta='function ' ) ] tables = self.find_matches ( word_before_cursor , tables , dbs = self.find_matches ( word_before_cursor , self.databases , self.special_commands = [ ] Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) ] Completion ( text='users ' , start_position=0 ) , ] ) assert set ( result ) == set ( [ Completion ( text='SELECT ' , start_position=-3 ) ] ) # Special commands are not part of all_completions since they can only meta='column ' ) Completion ( text='price ' , start_position=0 ) , Completion ( text= ' '' select '' ' , start_position=0 , display_meta='table ' ) , Completion ( text='products ' , display_meta='table ' ) , list ( map ( lambda f : Completion ( f , display_meta='function ' ) , completer.functions ) ) ) Completion ( text='custom_type2 ' , start_position=0 , display_meta='datatype ' ) , meta='function ' ) Completion ( text='user_emails ' , start_position=0 , display_meta='view ' ) ] ) Completion ( text='id ' , start_position=0 ) , Completion ( text= ' x ' , start_position=0 ) , Completion ( text='products ' , start_position=0 , display_meta='table ' ) , else : meta='named query ' ) Completion ( text='email ' , start_position=0 , display_meta='column ' ) , fuzzy=False , meta='keyword ' ) Completion ( text='product_name ' , start_position=0 , display_meta='column ' ) , commands = self.pgspecial.commands Completion ( text='custom_func2 ' , start_position=0 ) ] views = self.find_matches ( word_before_cursor , views ) list ( map ( Completion , completer.functions ) ) ) Completion ( text= ' o ' , start_position=0 ) ] ) completer.extend_special_commands ( self.pgspecial.commands.keys ( ) ) Token.Menu.Completions.Meta : 'bg : # 448888 # ffffff ' , Completion ( text='orders ' , start_position=0 , display_meta='table alias ' ) ] ) Completion ( text='func4 ' , start_position=-len ( 'func ' ) , display_meta='function ' ) ] ) Completion ( text='custom_func1 ' , start_position=0 ) , Token.Menu.Completions.Meta.Current : 'bg : # 44aaaa # 000000 ' , Completion ( text='shipments ' , display_meta='table ' ) , Completion ( text='phone_number ' , start_position=0 , display_meta='column ' ) , Completion ( text= ' y ' , start_position=0 ) ] ) for item in sorted ( collection ) : tables = self.find_matches ( word_before_cursor , tables ) Completion ( text='custom ' , start_position=0 , display_meta='schema ' ) , assert set ( result ) == set ( [ Completion ( text='MAX ' , start_position=-2 ) ] ) types = self.find_matches ( word_before_cursor , types ) special = self.find_matches ( word_before_cursor , cmd_names , Completion ( text='users ' ) , user_funcs = self.find_matches ( word_before_cursor , funcs , schema_names = self.find_matches ( word_before_cursor , schema_names ) schema_names , if not self.pgspecial : assert set ( result ) == set ( [ Completion ( text='MAX ' , start_position=-2 , Completion ( text='first_name ' , start_position=0 ) , Completion ( text='public ' , start_position=0 , display_meta='schema ' ) , meta='database ' ) Completion ( text= ' * ' , start_position=0 , display_meta='column ' ) , Completion ( text='public ' , start_position=0 ) , fuzzy=False ) Completion ( text='custom ' , start_position=0 ) , Completion ( text= ' * ' , start_position=0 ) , completions.append ( ( match_point , 0 , item ) ) def __init__ ( self , smart_completion=True ) : # be at the beginning of a line . Completion ( text='last_name ' , start_position=0 , display_meta='column ' ) ] ) meta = meta [ :47 ] + u ' ... ' list ( map ( lambda f : Completion ( f , display_meta='datatype ' ) , completer.datatypes ) ) ) Completion ( text='last_name ' , start_position=0 ) , Completion ( text='func1 ' , start_position=0 , display_meta='function ' ) , # meta-display string assert set ( result ) == set ( [ Completion ( text='public ' , start_position=0 ) , [ Completion ( t ) for t in [ Completion ( text= ' '' ABC '' ' , start_position=0 , display_meta='column ' ) , sort_key = _match ( item ) completions = [ ] Completion ( text='user_emails ' , start_position=0 ) ] ) # Construct a ` _match ` function for either fuzzy or non-fuzzy matching 'public ' , 'users ' , 'orders ' , ' '' select '' ' , Completion ( text='user_emails ' , start_position=0 , display_meta='view ' ) ,","['pgcli/main.py', 'pgcli/pgcompleter.py', 'pgcli/pgstyle.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 277 from darikg/darikg/completions-meta-display
425,f39eb99eb93b4fea7a4b4f1953bdc86be6994b36,2015-07-27 15:12:33-07:00,pip install . pytest mock codecov after_success : codecov script : pip install . pytest mock on_start : false # default : false script : py.test on_start : false # default : false coverage run -- source pgcli -m py.test,['.travis.yml'],Merge pull request # 299 from dbcli/j-bennet/add-test-coverage
426,ae94c1640c833acd0a2d5fd8dc2b037d84e02bce,2015-07-14 23:16:52-07:00,"\nd [ name ] \ns [ name [ query ] ] \ns name query context.cli.expect_exact ( expected_line ) raise Exception ( 'Expected : ' + expected_line.strip ( ) + ' ! ' ) except Exception : context.cli.expect_exact ( expected_line , timeout=1 ) try : $ cd tests \nd [ name [ query ] ] | \ns name query | Save a named query . | for line in codecs.open ( filename , 'rb ' , encoding='utf-8 ' ) : for line in codecs.open ( filename , ' r ' , encoding='utf-8 ' ) : cr.execute ( 'drop database if exists % s ' , ( AsIs ( dbname ) , ) ) | \ns [ name [ query ] ] | Save a named query . | cr.execute ( 'drop database % s ' , ( AsIs ( dbname ) , ) )","['DEVELOP.rst', 'behave.ini => tests/behave.ini', '{features => tests/features}/db_utils.py', '{features => tests/features}/environment.py', '{features => tests/features}/fixture_data/help.txt', '{features => tests/features}/fixture_data/help_commands.txt', '{features => tests/features}/fixture_utils.py', '{features => tests/features}/simple_cli_commands.feature', '{features => tests/features}/steps/step_definitions.py']",Merge pull request # 279 from dbcli/j-bennet/itegration-tests
427,198599daccae583939a7219d93699bbd32d13525,2015-07-05 16:02:29-07:00,": : Frequently typed queries can now be saved and recalled using a name using eg : .. _ ` Ali Kargın ` : https : //github.com/sancopanco pgcli > \n simple * Change the timing information to seconds . * Fix a pgcli crash when entering non-ascii characters in Windows . ( Thanks : ` Darik Gamble ` _ , ` Jonathan Slenders ` _ ) fuzzy match works like the fuzzy open in SublimeText or Vim 's Ctrl-P plugin . postgres database . ( Thanks : ` Iryna Cherniavska ` _ ) match parts of the input to the full table name . * Pasting queries into the pgcli repl is orders of magnitude faster . ( Thanks : ` Jonathan Slenders ` _ ) Internal Changes : pgcli > \ns simple select * from foo saved # Execute a saved query * Support for named queries ( favorite queries ) . ( Thanks : ` Brett Atoms ` _ ) # Delete a saved query The `` Command Time `` and `` Format Time `` are now displayed in seconds instead pgcli > \n * Completion suggestions for the `` \c `` command are not auto-escaped by default . 0.18.0 * Complete refactor of handling the back-slash commands . * Faster rendering of expanded mode output by making the horizontal separator a fixed length string . * Add support for PGPASSWORD environment variable to pass the password for the * Add integration tests using `` behave `` . ( Thanks : ` Iryna Cherniavska ` _ ) Features : * Change the config file management to use ConfigObj . ( Thanks : ` Brett Atoms ` _ ) * Upgrade prompt_toolkit to 0.42 . ( Thanks : ` Jonathan Slenders ` _ ) * Fix an error when running `` \d table_name `` when running on a table with rules . ( Thanks : ` Ali Kargın ` _ ) pgcli > \nd simple Matching very long table/column names are now easier with fuzzy matching . The of a unitless number displayed in scientific notation . newly added special commands ( `` \n [ + ] `` , `` \ns `` , `` \nd `` ) . ====== * Add fuzzy matching for the table names and column names . and you 'd like to refresh the auto-completions to pick up the new change . # List all saved queries .. _ ` Brett Atoms ` : https : //github.com/brettatoms * Add the ability to manually refresh autocompletions by typing `` \ # `` or Bug Fixes : eg : Typing `` djmv `` will match ` django_migration_views ` since it is able to # Save a query `` \refresh `` . This is useful if the database was updated by an external means",['changelog.rst'],Merge pull request # 276 from dbcli/amjith/changelog-0.18.0
428,a37713ff0754bafffb6ca7098b99d4fbb4968e8d,2015-07-04 10:23:29-07:00,"cn = create_cn ( hostname , password , username , 'postgres ' ) 'PGDATABASE ' : os.environ.get ( 'PGDATABASE ' , None ) , os.environ [ 'PGPASS ' ] = context.conf [ 'pass ' ] | \df [ + ] [ pattern ] | List functions . | | \ ? | Show Help . | } cn = connect ( host=hostname , user=username , database=dbname , def step_wait_prompt ( context ) : | \dt [ + ] [ pattern ] | List tables . | \e [ file ] then we see help output 'user ' : context.config.userdata.get ( 'pg_test_user ' , 'root ' ) , 'PGPASS ' : os.environ.get ( 'PGPASS ' , None ) , import pip if filename not in [ ' . ' , ' .. ' ] : | \nd [ name [ query ] ] | Delete a named query . | def step_see_help ( context ) : \refresh context.pgenv = { pg_test_pass = \x from behave import given , when , then def step_ctrl_d ( context ) : cr.execute ( 'drop database % s ' , ( AsIs ( dbname ) , ) ) | \l | List databases . | 'PGHOST ' : os.environ.get ( 'PGHOST ' , None ) , os.environ [ 'LINES ' ] = `` 100 '' when we run pgcli | \refresh | Refresh auto-completions . | After that , tests can be run with : from psycopg2 import connect and we wait for prompt | -- -- -- -- -- -- -- -- -- -- -- -- -- + -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -| 'dbname ' : context.config.userdata.get ( 'pg_test_db ' , None ) , | \dn [ + ] [ pattern ] | List schemas . | print ( 'Created connection : { 0 } . '.format ( cn.dsn ) ) The database user ( `` pg_test_user = postgres `` in .ini file ) has to have cn.set_isolation_level ( 0 ) \ # and we send `` \ ? '' command def step_send_help ( context ) : fullname = os.path.join ( fixture_dir , filename ) call the help command , context.conf [ 'pass ' ] , context.conf [ 'dbname ' ] ) at `` localhost `` , without the password ( authentication mode trust ) . \c [ onnect ] database_name Scenario : run the cli and exit cn = connect ( host=hostname , user=username , database=dbname ) import fixture_utils as fixutils dbutils.drop_db ( context.conf [ 'host ' ] , context.conf [ 'user ' ] , Make sure the cli exits . Run the process using pexpect . context.conf [ 'pass ' ] , # Set new env vars . context.cli.expect ( pexpect.EOF ) context.exit_sent = False cn.close ( ) close_cn ( cn ) | \d [ pattern ] | List or describe tables , views and sequences . | cn = create_cn ( hostname , password , username , dbname ) dbutils.close_cn ( context.cn ) fixture_dict = { } | \ns [ name [ query ] ] | Save a named query . | # - * - coding : utf-8 - * return lines mock > =1.0.1 for expected_line in context.fixture_data [ 'help_commands.txt ' ] : context.conf = { import db_utils as dbutils $ pip install -r requirements-dev.txt def step_run_cli ( context ) : dists = set ( [ di.key for di in pip.get_installed_distributions ( ) ] ) assert 'pgcli ' in dists for k , v in context.pgenv.items ( ) : | \n [ + ] [ name ] | List or execute named queries . | : param hostname : \ns [ name [ query ] ] def drop_db ( hostname='localhost ' , username=None , password=None , import pexpect Close connection . elif 'PGPASS ' in os.environ : | \c [ onnect ] database_name | Change to a new database . | os.environ [ 'PGHOST ' ] = context.conf [ 'host ' ] \dT [ S+ ] [ pattern ] : param password : | \ # | Refresh auto-completions . | | \e [ file ] | Edit the query with external editor . | Running the integration tests else : behave > =1.2.4 Integration tests use ` behave package http : //pythonhosted.org/behave/ ` _ . `` `` '' def after_scenario ( context , _ ) : Cleans up after each test complete . Unset env parameters . context.fixture_data = fixutils.read_fixture_files ( ) def step_install_cli ( _ ) : 'pass ' : context.config.userdata.get ( 'pg_test_pass ' , None ) , Read lines of text from file . password=password ) if password : Wait to see the prompt . Given we have pgcli installed \nd [ name [ query ] ] context.cli.expect_exact ( expected_line ) context.cli.sendcontrol ( 'd ' ) context.cn = dbutils.create_db ( context.conf [ 'host ' ] , context.conf [ 'user ' ] , | \du [ + ] [ pattern ] | List roles . | \dv [ + ] [ pattern ] pg_test_host = localhost from psycopg2.extensions import AsIs : : context.conf [ 'dbname ' ] ) current_dir = os.path.dirname ( __file__ ) Command `` `` '' : param connection : psycopg2.connection | \dT [ S+ ] [ pattern ] | List data types | Scenario : run the cli def create_db ( hostname='localhost ' , username=None , password=None , print ( 'Closed connection : { 0 } . '.format ( cn.dsn ) ) | Command | Description | Configuration settings for this package are provided via `` behave.ini `` file Steps for behavioral style tests are defined in this module . Drop database . : param username : string # Send Ctrl + D into cli Read all files inside fixture_data directory . : param dbname : string | \x | Toggle expanded output . | 'PGUSER ' : os.environ.get ( 'PGUSER ' , None ) , : param password : string then we see pgcli prompt os.environ [ 'PGUSER ' ] = context.conf [ 'user ' ] Make sure prompt is displayed . $ behave del os.environ [ 'PGPASS ' ] lines.append ( line.strip ( ) ) del os.environ [ k ] return fixture_dict \timing if context.conf [ 'pass ' ] : os.environ [ 'COLUMNS ' ] = `` 100 '' \n [ + ] [ name ] if k in os.environ and v is None : Feature : run the cli , Set env parameters . context.exit_sent = True def step_see_prompt ( context ) : \df [ + ] [ pattern ] then pgcli exits cn.close ( ) def step_wait_exit ( context ) : dbname=None ) : if hasattr ( context , 'cli ' ) and not context.exit_sent : import codecs fixture_dir = os.path.join ( current_dir , 'fixture_data/ ' ) elif v : | \ds [ + ] [ pattern ] | List sequences . | \ds [ + ] [ pattern ] exit the cli First , install the requirements for testing : os.environ [ 'PGDATABASE ' ] = context.conf [ 'dbname ' ] from __future__ import unicode_literals lines = [ ] permissions to create and drop test database . Dafault user is `` postgres `` This string is used to call the step in `` * .feature '' file . context.cli.sendcontrol ( 'd ' ) : param username : os.environ [ 'PAGER ' ] = 'cat ' import os \ ? os.environ [ k ] = v : return : Create test database . # Store get params from config . Send \ ? to see help . \dn [ + ] [ pattern ] | \dv [ + ] [ pattern ] | List views . | # Store old env vars . def create_cn ( hostname , password , username , dbname ) : Scenario : run `` \ ? '' command pg_test_db = pgcli_behave_tests if cn : pytest > =2.7.0 \dt [ + ] [ pattern ] with cn.cursor ( ) as cr : for line in codecs.open ( filename , ' r ' , encoding='utf-8 ' ) : fixture_dict [ filename ] = read_fixture_lines ( fullname ) 'host ' : context.config.userdata.get ( 'pg_test_host ' , 'localhost ' ) , pexpect > =3.3 : param filename : string name | \timing | Toggle timing of commands . | context.cli = pexpect.spawnu ( 'pgcli ' ) in root directory . context.cli.sendline ( '\ ? ' ) dbname=None ) : # ISOLATION_LEVEL_AUTOCOMMIT = 0 def before_all ( context ) : # Needed for DB creation . \di [ + ] [ pattern ] Open connection to database . # Needed for DB drop . To see stdout/stderr , use the following command : [ behave.userdata ] : param hostname : string tox > =1.9.2 def read_fixture_files ( ) : : return : psycopg2.connection pg_test_user = postgres cr.execute ( 'create database % s ' , ( AsIs ( dbname ) , ) ) \l from __future__ import print_function def close_cn ( cn=None ) : def after_all ( context ) : $ behave -- no-capture def read_fixture_lines ( filename ) : context.cli.expect ( pexpect.EOF ) : return : list of strings context.cli.expect ( ' { 0 } > '.format ( context.conf [ 'dbname ' ] ) ) Each step is defined by the string decorating it . \d [ pattern ] \du [ + ] [ pattern ] Send Ctrl + D to hopefully exit . | \di [ + ] [ pattern ] | List indexes . | # Restore env vars . and we send `` ctrl + d '' return cn Check that pgcli is in installed modules . for filename in os.listdir ( fixture_dir ) :","['DEVELOP.rst', 'behave.ini', 'features/db_utils.py', 'features/environment.py', 'features/fixture_data/help.txt', 'features/fixture_data/help_commands.txt', 'features/fixture_utils.py', 'features/simple_cli_commands.feature', 'features/steps/step_definitions.py', 'requirements-dev.txt']",Merge pull request # 269 from dbcli/j-bennet/itegration-tests
429,cb9905a44e78b2fa257fc5308341a2d010a306c7,2015-07-01 21:52:04-07:00,"if len ( sep ) < header_len : def get_separator ( num , header_len , data_len ) : sep = pad ( sep , total_len , u '' - '' ) sep = pad ( sep , header_len - 1 , u '' - '' ) + u '' + '' [ RECORD 1 ] sep = u '' - [ RECORD { 0 } ] '' .format ( num ) [ RECORD 1 ] output.append ( sep.format ( i ) ) sep = u '' - [ RECORD { 0 } ] -- -- -- -- -- -- -- -- -- -- -- -- -\n '' if len ( sep ) < total_len : return sep + u '' \n '' output.append ( get_separator ( i , header_len , max_row_len ) ) expected = `` '' '' - [ RECORD 0 ] total_len = header_len + data_len + 1 expected = `` '' '' - [ RECORD 0 ]","['pgcli/packages/expanded.py', 'tests/test_expanded.py']",Merge pull request # 262 from dbcli/amjith/expanded_output_separator_fix
430,b245e8e0d378344fa24a4ea94e9098fa842387cc,2015-07-01 17:14:09-07:00,"result.extend ( format_output ( title , rows , headers , status , 'psql ' , if special_cmd.case_sensitive : : param pgspecial : PGSpecial object command_dict [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , special.register_special_command ( self.change_db , '\\c ' , for result in special.execute ( cur , sql ) : @ special_command ( '\\ ? ' , '\\ ? ' , 'Show Help . ' , arg_type=NO_QUERY ) elif special_cmd.arg_type == PARSED_QUERY : result = run ( executor , `` SELECT d FROM jsontest LIMIT 1 '' , for result in pgspecial.execute ( cur , sql ) : COMMANDS [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , aliases= ( 'use ' , '\\connect ' , 'USE ' ) ) special_cmd = COMMANDS [ command ] message += `` on . '' if self.timing_enabled else `` off . '' completer.extend_special_commands ( self.pgspecial.commands.keys ( ) ) arg_type=PARSED_QUERY , hidden=False , case_sensitive=True , aliases= ( ) ) : pass def show_help ( self ) : if special_cmd.case_sensitive : self.pgspecial = PGSpecial ( ) if self.pgspecial.timing_enabled : try : # Special command self.pgspecial.register ( self.change_db , '\\c ' , if not value.hidden : special_cmd = COMMANDS [ command.lower ( ) ] COMMANDS [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , if special_cmd.arg_type == NO_QUERY : aliases= ( 'use ' , '\\connect ' , 'USE ' ) ) if request.param : class PGSpecial ( object ) : join=True , expanded=expanded ) if pgspecial : special.register_special_command ( self.refresh_completions , '\\refresh ' , arg_type=NO_QUERY ) `` `` '' Execute the sql in the database and return the results . `` `` '' A decorator used internally for static special commands '' '' '' self.expanded_output = False result.append ( ( value.syntax , value.description ) ) from .packages.pgspecial.main import ( COMMANDS , NO_QUERY ) def test_multiple_queries_with_special_command_same_line ( executor , pgspecial ) : def test_multiple_queries_with_special_command_same_line ( executor ) : def expanded ( request , executor ) : def show_help ( ) : headers = [ 'Command ' , 'Description ' ] command_dict=None ) : command , verbose , pattern = parse_special_command ( sql ) for title , rows , headers , status in pgspecial.execute ( cur=cur , sql=sql ) : _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) yield result def is_expanded_output ( ) : register_special_command ( * args , command_dict=self.commands , * * kwargs ) return special_cmd.handler ( ) try : def toggle_timing ( self ) : arg_type , hidden , case_sensitive , aliases ) self.pgspecial.register ( self.refresh_completions , '\\ # ' , '\\ # ' , for title , rows , headers , status in executor.run ( sql , pgspecial ) : return def run ( executor , sql , join=False , expanded=False , pgspecial=None ) : result = run ( executor , `` SELECT d FROM jsonbtest LIMIT 1 '' , message += `` on . '' if TIMING_ENABLED else `` off . '' COMMANDS = { } result = [ ] if special.is_expanded_output ( ) : return special_cmd.handler ( ) result = run ( executor , '\\ ? ' ) [ 0 ] .split ( '| ' ) # First try to run each query as special def test_special_command_help ( executor ) : '\\c [ onnect ] database_name ' , 'Change to a new database . ' , def toggle_expanded_output ( self ) : try : `` `` '' Execute the sql in the database and return the results . The results yield self.execute_normal_sql ( sql ) pgspecial = PGSpecial ( ) raise CommandNotFound ( 'Command not found : % s ' % command ) expanded=expanded ) ) '\\refresh ' , 'Refresh auto-completions . ' , arg_type=NO_QUERY ) 'Refresh auto-completions . ' , arg_type=NO_QUERY ) def run ( executor , sql , join=False ) : yield result return special_cmd.handler ( cur=cur , query=sql ) result = run ( executor , `` select 'foo ' ; \d '' ) command_dict=PGSpecial.default_commands ) arg_type=PARSED_QUERY , hidden=False , case_sensitive=True , aliases= ( ) , try : def execute ( self , cur , sql ) : return [ ( None , None , None , message ) ] def set_timing ( enable=True ) : self.table_format , global TIMING_ENABLED return special_cmd.handler ( cur=cur , pattern=pattern , verbose=verbose ) result = run ( executor , `` SELECT d FROM jsonbtest LIMIT 1 '' , join=True ) special_cmd = commands [ command ] self.pgspecial.timing_enabled = c [ 'main ' ] .as_bool ( 'timing ' ) from .packages.pgspecial.main import ( PGSpecial , NO_QUERY ) self.register ( self.toggle_expanded_output , '\\x ' , '\\x ' , message += u '' on . '' if self.expanded_output else u '' off . '' res = pgexecute.run ( document.text , self.pgspecial ) if not value.hidden : output.extend ( formatted ) elif special_cmd.arg_type == RAW_QUERY : except special.CommandNotFound : # Regular SQL # via the special_command decorator and stored in default_commands result.extend ( format_output ( title , rows , headers , status , 'psql ' ) ) self.timing_enabled = not self.timing_enabled @ pytest.yield_fixture ( params= [ True , False ] ) self.pgspecial.expanded_output ) return PGSpecial ( ) default_commands = { } from pgcli.packages.pgspecial import PGSpecial return [ ( None , result , headers , None ) ] special.register_special_command ( self.refresh_completions , '\\ # ' , 'Toggle timing of commands . ' , arg_type=NO_QUERY ) from pgcli.packages.pgspecial.main import execute @ special_command ( '\\x ' , '\\x ' , 'Toggle expanded output . ' , arg_type=NO_QUERY ) def toggle_expanded_output ( ) : yield request.param formatted = format_output ( title , cur , headers , status , def format_output ( title , cur , headers , status , table_format , expanded=False ) : self.pgspecial.register ( self.refresh_completions , '\\refresh ' , '\\refresh ' , TIMING_ENABLED = enable result.append ( ( value.syntax , value.description ) ) return [ ( None , result , headers , None ) ] message += u '' on . '' if use_expanded_output else u '' off . '' except KeyError : @ export def __init__ ( self ) : result = run ( executor , `` SELECT d FROM jsontest LIMIT 1 '' , join=True ) headers = [ 'Command ' , 'Description ' ] def register ( self , * args , * * kwargs ) : return TIMING_ENABLED TIMING_ENABLED = True for title , rows , headers , status in execute ( cur=cur , sql=sql ) : special.set_timing ( c [ 'main ' ] .as_bool ( 'timing ' ) ) def run ( self , statement , pgspecial=None ) : def format_output ( title , cur , headers , status , table_format ) : run ( executor , '\\x ' ) message = u '' Expanded display is `` def get_timing ( ) : for _ , value in sorted ( self.commands.items ( ) ) : return [ ( None , None , None , message ) ] use_expanded_output = False res = pgexecute.run ( document.text ) '\\c [ onnect ] database_name ' , message = `` Timing is `` elif special_cmd.arg_type == PARSED_QUERY : for _ , value in sorted ( COMMANDS.items ( ) ) : if ( command not in COMMANDS ) and ( command.lower ( ) not in COMMANDS ) : join=True , expanded=expanded ) self.timing_enabled = False def pgspecial ( ) : status , self.table_format ) ) # Default static commands that do n't rely on PGSpecial state are registered if special.get_timing ( ) : command , verbose , pattern = parse_special_command ( sql ) for title , rows , headers , status in executor.run ( sql ) : commands = self.commands assert u ' é ' in run ( executor , `` select * from unicodechars '' , join=True ) result = [ ] elif special_cmd.arg_type == RAW_QUERY : raise CommandNotFound self.register ( self.toggle_timing , '\\timing ' , '\\timing ' , _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) def execute ( cur , sql ) : if special_cmd.arg_type == NO_QUERY : except special.CommandNotFound : message = `` Timing is `` raise CommandNotFound raise CommandNotFound ( 'Command not found : % s ' % command ) def expanded ( request ) : 'Toggle expanded output . ' , arg_type=NO_QUERY ) except KeyError : def test_special_command_help ( executor , pgspecial ) : use_expanded_output = not use_expanded_output global use_expanded_output '\\ # ' , 'Refresh auto-completions . ' , arg_type=NO_QUERY ) result = run ( executor , '\\ ? ' , pgspecial=pgspecial ) [ 0 ] .split ( '| ' ) cur = self.conn.cursor ( ) if expanded : special_cmd = commands [ command.lower ( ) ] arg_type , hidden , case_sensitive , aliases , self.expanded_output = not self.expanded_output cur = self.conn.cursor ( ) 'Change to a new database . ' , output.extend ( format_output ( title , cur , headers , TIMING_ENABLED = not TIMING_ENABLED command_dict [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , self.register ( self.show_help , '\\ ? ' , '\\ ? ' , 'Show Help . ' , message = u '' Expanded display is `` : return : List of tuples containing ( title , rows , headers , status ) are a list of tuples . Each tuple has 4 values ( title , rows , headers , status ) . self.commands = self.default_commands.copy ( ) if ( command not in commands ) and ( command.lower ( ) not in commands ) : return request.param self.timing_enabled = True completer.extend_special_commands ( COMMANDS.keys ( ) ) def run ( self , statement ) : : param statement : A string containing one or more sql statements result = run ( executor , `` select 'foo ' ; \d '' , pgspecial=pgspecial ) return use_expanded_output @ special_command ( '\\timing ' , '\\timing ' , 'Toggle timing of commands . ' , arg_type=NO_QUERY ) yield self.execute_normal_sql ( sql ) def toggle_timing ( ) : assert u ' é ' in run ( executor , `` select * from unicodechars '' , return special_cmd.handler ( cur=cur , pattern=pattern , verbose=verbose ) return special_cmd.handler ( cur=cur , query=sql )","['pgcli/main.py', 'pgcli/packages/pgspecial/iocommands.py', 'pgcli/packages/pgspecial/main.py', 'pgcli/packages/pgspecial/tests/conftest.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py', 'tests/utils.py']",Merge pull request # 273 from dbcli/darikg/specials-refactor-more
431,63c45121abf9afa230852d6d21d774f324d91963,2015-06-22 20:48:02-07:00,"if not self.force_passwd_prompt and not passwd : # getting it from environment variable . passwd = os.environ.get ( 'PGPASSWORD ' , `` ) # If password prompt is not forced but no password is provided , try",['pgcli/main.py'],Merge pull request # 271 from dbcli/add-env-pgpassword
432,f12f2937ed3ba08c3558bf170006c97ceb7459df,2015-06-22 19:23:35-07:00,"if not self.force_passwd_prompt and not passwd : # getting it from environment variable . passwd = os.environ.get ( 'PGPASSWORD ' , `` ) # If password prompt is not forced but no password is provided , try",['pgcli/main.py'],Added support for PGPASSWORD environment variable . Connect # 220 .
433,f7cfbaab1689b50640adb75476fa14800aaf9eae,2015-06-22 15:39:09-07:00,"status = namedqueries.delete ( pattern ) status = namedqueries.usage # Delete a named query . if self.section_name in self.config and name in self.config [ self.section_name ] : > \\n simple with a short name . Think of them as favorites . @ special_command ( '\\nd ' , '\\nd [ name [ query ] ] ' , 'Delete a named query . ' ) # - * - coding : utf-8 - * ╘════════╧═══════════════════════════════════════╛ self.config.write ( ) # If either name or query is missing then print the usage and complain . def execute_named_query ( cur , pattern , verbose ) : │ a │ b │ return [ ( `` , rows , headers , status ) ] │ 日本語 │ 日本語 │ if len ( pattern ) == 0 : status = `` return [ ( None , None , None , `` Invalid argument . '' ) ] usage = u '' 'Named Queries are a way to save frequently used queries ╞════════╪════════╡ return ' % s : Deleted ' % name return [ ( None , None , None , return [ ( `` , rows , headers , `` '' ) ] except KeyError : return [ ( None , None , None , status ) ] self.config.write ( ) ╒════════╤═══════════════════════════════════════╕ try : name , _ , query = pattern.partition ( ' ' ) # Save a new named query . if not rows : usage + 'Err : Both name and query are required . ' ) ] def execute_named_query ( cur , pattern , * * _ ) : return ' % s : Not Found . ' % name ' '' if not pattern : > \\nd simple @ special_command ( '\\ns ' , '\\ns [ name [ query ] ] ' , 'Save a named query . ' ) return [ ( None , None , None , `` Deleted . '' ) ] namedqueries.delete ( pattern ) if ' ' not in pattern : > \\ns simple select * from abc where a is not Null ; │ simple │ SELECT * FROM abc where a is not NULL │ return list_named_queries ( verbose ) # List all named queries . else : return list_named_queries ( True ) │ Name │ Query │ return [ ( None , None , None , usage ) ] Examples : if ( not name ) or ( not query ) : name , query = pattern.split ( ' ' , 1 ) ╘════════╧════════╛ # Run a named query . > \\n simple : Deleted usage = 'Syntax : \\nd name.\n\n ' + namedqueries.usage ╞════════╪═══════════════════════════════════════╡ usage = 'Syntax : \\ns name query.\n\n ' + namedqueries.usage ╒════════╤════════╕","['pgcli/packages/pgspecial/iocommands.py', 'pgcli/packages/pgspecial/namedqueries.py']",Merge pull request # 268 from dbcli/amjith/named-query-docs
434,71301c695587881d7d34647f32650df3e7329b06,2015-06-22 17:26:45-04:00,except KeyError : # Regular SQL class CommandNotFound ( Exception ) : raise CommandNotFound raise KeyError ( 'Command not found : % s ' % command ) if ( command not in COMMANDS ) and ( command.lower ( ) not in COMMANDS ) : pass raise CommandNotFound ( 'Command not found : % s ' % command ) except special.CommandNotFound : # Regular SQL,"['pgcli/packages/pgspecial/main.py', 'pgcli/pgexecute.py']",Merge pull request # 267 from dbcli/amjith/special-command-not-found
435,e187105f620891a026ce3739a9f0f568e6f1bc65,2015-06-22 14:55:53-04:00,self.pgexecute.connect ( database=db ) db = pattern [ 1 : -1 ] if pattern [ 0 ] == pattern [ -1 ] == ' '' ' else pattern self.pgexecute.connect ( database=pattern ) if pattern is None : else : if pattern : else :,['pgcli/main.py'],Merge pull request # 258 from dbcli/amjith/no-escape-db-names
436,72d435338209917e2e9f6624af6591f995644b98,2015-06-20 23:41:55-07:00,"from .packages.pgspecial.namedqueries import namedqueries return [ { 'type ' : 'namedquery ' } ] completions.extend ( queries ) queries = self.find_matches ( word_before_cursor , namedqueries.list ( ) , elif suggestion [ 'type ' ] == 'namedquery ' : if cmd in [ '\\n ' , '\\ns ' , '\\nd ' ] : start_only=True , fuzzy=False )","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py']",Merge pull request # 260 from brettatoms/autocomplete-namedqueries
437,44528026d292737641ce8011b5096ade8f87a9a6,2015-06-17 22:18:37-07:00,"from .packages.pgspecial.main import ( COMMANDS , NO_QUERY ) '\\refresh ' , 'Refresh auto-completions . ' , arg_type=NO_QUERY ) # os.environ [ 'LESS ' ] += ' F ' special.register_special_command ( self.refresh_completions , '\\ # ' , # if ' F ' not in less_opts : '\\ # ' , 'Refresh auto-completions . ' , arg_type=NO_QUERY ) special.register_special_command ( self.refresh_completions , '\\refresh ' , return [ ( None , None , None , 'Auto-completions refreshed . ' ) ] # if ' X ' not in less_opts : self.special_commands = [ ] from .packages.pgspecial.main import ( COMMANDS ) # os.environ [ 'LESS ' ] += ' X '","['pgcli/main.py', 'pgcli/pgcompleter.py']",Merge pull request # 259 from dbcli/amjith/manual-refresh
438,6aefd3d2a5477ab60137dc521b0a1cf5ddf1418d,2015-06-17 21:45:37-04:00,"fuzzy=False ) text = 'user ' import re collection = [ 'api_user ' , 'user_group ' ] match user_action because the literal quotation marks in `` user '' result = [ match.text for match in completer.find_matches ( text , collection ) ] if fuzzy : match_point = item.lower ( ) .find ( text , 0 , match_end_limit ) `` `` '' assert result == [ ' '' user '' ' , 'user_action ' ] regex = '. * ? '.join ( map ( re.escape , text ) ) pat = re.compile ( ' ( % s ) ' % regex ) # schema does n't exist start_only=True , fuzzy=False ) `` `` '' Fuzzy result rank should be based on shortest match . `` `` '' When calculating result rank , identifier quotes should be ignored . This test checks that the fuzzy ranking algorithm uses the shorter start_only=True , if match_point > = 0 : def test_ranking_ignores_identifier_quotes ( completer ) : Result ranking in fuzzy searching is partially based on the length self.datatypes , start_only=True ) def find_matches ( self , text , collection , start_only=False , fuzzy=True ) : completions.append ( ( match_point , 0 , item ) ) alter the position of the match . return ( Completion ( z , -len ( text ) ) for x , y , z in sorted ( completions ) ) fuzzy=False ) from prompt_toolkit.document import Document if r : def completer ( ) : assert result == [ 'user_group ' , 'api_user ' ] since it is also a reserved word , would incorrectly fall below the fuzzy=False ) r = pat.search ( self.unescape_name ( item ) ) from re import compile yield Completion ( item , -len ( text ) ) def test_ranking_based_on_shortest_match ( completer ) : This test checks that the fuzzy ranking algorithm correctly ignores collection = [ 'user_action ' , ' '' user '' ' ] completions = [ ] from prompt_toolkit.completion import Completion The result ranking algorithm ignores identifier quotes . Without this start_only=True ) of matches : shorter matches are considered more relevant than return pgcompleter.PGCompleter ( ) import pytest self.name_pattern = re.compile ( `` ^ [ _a-z ] [ _a-z0-9\ $ ] * $ '' ) if match_point > = 0 : start_only=True ) start_only=True ) start_only=True ) for item in sorted ( collection ) : correction , the match `` user '' , which Postgres requires to be quoted match when calculating result rank . start_only=True , match_point = item.lower ( ) .find ( text , 0 , match_end_limit ) for item in sorted ( collection ) : @ staticmethod completions.append ( ( len ( r.group ( ) ) , r.start ( ) , item ) ) self.datatypes , start_only=True , 7 ( 'user_gr ' ) . self.name_pattern = compile ( `` ^ [ _a-z ] [ _a-z0-9\ $ ] * $ '' ) component of the match 'user_group ' could be either 4 ( 'user ' ) or longer ones . When searching for the text 'user ' , the length from __future__ import unicode_literals quotation marks when computing match ranks . start_only=True , fuzzy=False ) # schema does n't exist import pgcli.pgcompleter as pgcompleter def find_matches ( text , collection , start_only=False ) : else :","['pgcli/pgcompleter.py', 'tests/test_fuzzy_completion.py']",Merge pull request # 254 from dbcli/amjith/fuzzy_completion
439,0941ffc148ce65bd6c916f0ddc28f561cf2eec30,2015-06-16 19:40:57-04:00,"database = user = getuser ( ) self.pgexecute.connect ( ) return [ ( None , None , None , `` Deleted . '' ) ] db = unicode2utf8 ( database or self.dbname ) raise RuntimeError sql as $ $ select 2 $ $ ' '' ) filename = filename.strip ( ) .split ( ' ' , 1 ) [ 0 ] if filename else None # Check if the command is a \c or 'use ' . This is a special if arg == `` : headers = [ `` Name '' , `` Query '' ] global NON_CASE_SENSITIVE_COMMANDS self.port = port [ pytest ] return command.strip ( ) .endswith ( '\\e ' ) or command.strip ( ) .startswith ( '\\e ' ) def query_runner ( sql ) : return [ ( None , None , None , `` Deleted . '' ) ] if pattern == `` : # not a substring . So it 'll strip `` e '' in the end of the sql also ! case_sensitive=case_sensitive , def expanded_output ( cur , arg , verbose ) : print ( status ) return [ ( title , None , None , cur.statusmessage ) ] # TODO : should this be somehow be divined from environment ? sql , message = iospecial.open_external_editor ( filename , if len ( arg ) == 0 : if cur.description : user=unicode2utf8 ( user ) , # tables message = 'Error reading file : % s . ' % filename Returns ( title , rows , headers , status ) '' '' '' if query is None : if cur.description : TIMING_ENABLED = True return ( command , verbose , arg.strip ( ) ) message += `` on . '' if TIMING_ENABLED else `` off . '' # placeholder comment . def test_slash_dT ( executor ) : result = [ ] schema1.s1_tbl1 '' ' ) self.register_special_commands ( ) pattern = re.compile ( ' ( ^\\\e|\\\e $ ) ' ) elif isinstance ( command_executor , str ) : sql = sql.strip ( ) if ' ' not in pattern : hidden=False , case_sensitive=True , aliases= ( ) ) : namedqueries.save ( name , query ) def get_filename ( sql ) : '\\n ' : ( execute_named_query , [ '\\n [ + ] [ name ] ' , 'List or execute named queries . ' ] ) , import logging result.append ( value [ 1 ] ) Open external editor , wait for the user to type in his query , return [ ( None , result , headers , None ) ] database = user # Do n't return None for the caller to deal with . ( 'schema2 ' , 'postgres ' ) ] self.pgexecute.connect ( database=pattern ) '\ ? ' : ( show_help , [ '\ ? ' , 'Help on pgcli commands . ' ] ) , if not value.hidden : results = [ ] from . import iocommands conn = psycopg2.connect ( cur.execute ( query ) global TIMING_ENABLED result.append ( ( value.syntax , value.description ) ) def parse_special_command ( sql ) : rows = [ [ r , namedqueries.get ( r ) ] for r in namedqueries.list ( ) ] headers = [ 'Schema ' , 'Name ' , 'Description ' ] '\\timing ' : ( toggle_timing , [ '\\timing ' , 'Toggle timing of commands . ' ] ) , : return : list with one tuple , query as first element . return defn import re # default to current OS username just like psql def set_timing ( enable=True ) : pass connection.close ( ) cur.execute ( query ) command_executor = CASE_SENSITIVE_COMMANDS [ command ] [ 0 ] def __init__ ( self , config ) : # for both conditions . def change_db ( self , pattern , * * _ ) : setup_db ( connection ) TIMING_ENABLED = False verbose = '+ ' in command from . import dbcommands __all__.append ( defn.__name__ ) self.dbname = db def execute_named_query ( cur , pattern , verbose ) : return [ ( None , None , None , message ) ] # have to change the database connection that we 're connected to . special.set_timing ( c [ 'main ' ] .as_bool ( 'timing ' ) ) from prompt_toolkit.layout.processors import HighlightMatchingBracketProcessor , ConditionalProcessor sql = pattern.sub ( `` , sql ) return [ ( None , None , None , `` Saved . '' ) ] SpecialCommand = namedtuple ( 'SpecialCommand ' , name , query = pattern.split ( ' ' , 1 ) completer.extend_special_commands ( COMMANDS.keys ( ) ) except : except KeyError : # Regular SQL '\\x ' : ( expanded_output , [ '\\x ' , 'Toggle expanded output . ' ] ) , def in_progress ( cur , arg , verbose ) : self.host = host command , _ , arg = sql.partition ( ' ' ) try : conn = psycopg2.connect ( database=db , user=user , password=password , if value [ 1 ] : namedqueries.delete ( pattern ) [ 'handler ' , 'syntax ' , 'description ' , 'arg_type ' , 'hidden ' , 'case_sensitive ' ] ) hidden=True ) # special commands Stub method to signal about commands being under development . # views if filename : def is_expanded_output ( ) : `` `` '' Returns ( title , rows , headers , status ) '' '' '' return [ ( title , None , None , cur.statusmessage ) ] if special_cmd.arg_type == NO_QUERY : if sql.strip ( ) .startswith ( '\\e ' ) : TIMING_ENABLED = not TIMING_ENABLED db = ( database or self.dbname ) message = u '' Expanded display is `` '\d ' : ( describe_table_details , [ '\d [ pattern ] ' , 'List or describe tables , views and sequences . ' ] ) , COMMANDS [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , import psycopg2 '\\dT ' : ( list_datatypes , [ '\dT [ S+ ] [ pattern ] ' , 'List data types ' ] ) , # Empty string is ok . database=dbname ) rows = [ ( 'public ' , 'postgres ' ) , query = query.split ( MARKER , 1 ) [ 0 ] .rstrip ( '\n ' ) def place_holder ( ) : assert results == expected expected = [ title , rows , headers , status ] `` `` '' Delete an existing named query . message = None import pgcli.packages.pgspecial as special return [ ( None , cur , headers , cur.statusmessage ) ] if user : Open external editor , wait for the user to type in his query , cur.execute ( 'create schema schema2 ' ) create_db ( '_test_db ' ) headers = [ `` Name '' ] user = ( user or self.user ) try : Is this an external editor command ? `` `` '' Decorator to explicitly mark functions that are exposed in a lib . '' '' '' while iospecial.editor_command ( document.text ) : rows = [ [ r ] for r in namedqueries.list ( ) ] def dummy_command ( cur , arg , verbose ) : cur = self.conn.cursor ( ) dbname = sql.split ( ) [ 1 ] NO_QUERY = 0 user = unicode2utf8 ( user or self.user ) # The reason we ca n't simply do .strip ( '\e ' ) is that it strips characters , # If the command executor is a function , then call the function with the return results message += `` on . '' if TIMING_ENABLED else `` off . '' if len ( pattern ) == 0 : raise NotImplementedError headers = [ `` Name '' , `` Query '' ] headers = [ x [ 0 ] for x in cur.description ] query = 'SELECT datname FROM pg_database ; ' ( 'public ' , 'tbl2 ' , 'table ' , 'postgres ' ) ] _logger = logging.getLogger ( __name__ ) if not verbose : 'user `` % s '' ' % ( self.dbname , self.user ) ) if __name__ == '__main__ ' : try : query = f.read ( ) except : # Populate the editor buffer with the partial sql ( if available ) and a command = command.strip ( ) .replace ( '+ ' , `` ) POSTGRES_USER , POSTGRES_HOST = 'postgres ' , 'localhost ' namedqueries = NamedQueries ( '~/.pgclirc ' ) as all the rest of commands . NON_CASE_SENSITIVE_COMMANDS = { def test_slash_dt ( executor ) : cur.execute ( command_executor ) $ $ select 1 $ $ ' '' ) self.config = load_config ( filename ) extension='.sql ' ) '\\ds ' : ( list_sequences , [ '\\ds [ + ] [ pattern ] ' , 'List sequences . ' ] ) , sql , message = special.open_external_editor ( filename , if cur.description : message = 'Error reading file : % s . ' % filename from dbutils import dbtest for result in special.execute ( cur , sql ) : from .main import special_command , RAW_QUERY ( 'public ' , 'vw1 ' , 'view ' , 'postgres ' ) ] rows = [ [ r , namedqueries.get ( r ) ] for r in namedqueries.list ( ) ] yield connection '\do ' : ( in_progress , [ '\do [ S ] [ pattern ] ' , 'Not yet implemented . ' ] ) , from ... config import load_config cur.execute ( 'create schema schema1 ' ) except : database = user # datatype return list_named_queries ( verbose ) `` `` '' Save a new named query . RAW_QUERY = 2 def create_db ( dbname ) : def parse_special_command ( sql ) : def doc_only ( ) : TIMING_ENABLED = not TIMING_ENABLED import psycopg2.extras _logger = logging.getLogger ( __name__ ) `` `` '' self.config = config rows = [ ( 'public ' , 'tbl1 ' , 'table ' , 'postgres ' ) , import sys database=unicode2utf8 ( db ) , rows = [ ( 'public ' , 'func1 ' , 'integer ' , `` , 'normal ' ) ] query = click.edit ( sql + '\n\n ' + MARKER , filename=filename , message += u '' on . '' if use_expanded_output else u '' off . '' if command == '\c ' or command == '\connect ' or command.lower ( ) == 'use ' : def show_help ( ) : addopts= -- capture=sys -- showlocals register_special_command ( wrapped , command , syntax , description , return list_named_queries ( cur , arg , verbose ) from .namedqueries import namedqueries self.user = user headers = [ 'Command ' , 'Description ' ] # functions query = namedqueries.get ( pattern ) return use_expanded_output dbtest = pytest.mark.skipif ( while pattern.search ( sql ) : from .packages.pgspecial import ( CASE_SENSITIVE_COMMANDS , HighlightMatchingBracketProcessor ) '\l ' : ( `` 'SELECT datname FROM pg_database ; ' '' , [ '\l ' , 'List databases . ' ] ) , return special_cmd.handler ( cur=cur , query=sql ) return [ ( None , None , None , message ) ] _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) user = getuser ( ) from .tabulate import tabulate DROP SCHEMA IF EXISTS schema2 CASCADE '' ' ) def save_named_query ( cur , arg , verbose ) : completer.extend_special_commands ( NON_CASE_SENSITIVE_COMMANDS.keys ( ) ) port=unicode2utf8 ( port ) ) message = `` Timing is `` def editor_command ( command ) : try : # Special command headers = [ x [ 0 ] for x in cur.description ] CREATE SCHEMA public ; return cur if pattern is None : } rows = [ ( 'public ' , 'foo ' , None ) ] cur.execute ( `` 'create view schema1.s1_vw1 as select * from password = ( password or self.password ) return [ ( None , None , None , cur.statusmessage ) ] from pgcli.packages.pgspecial.main import execute cmd = alias.lower ( ) if not case_sensitive else alias def special_command ( command , syntax , description , arg_type=PARSED_QUERY , : param command : string from .. config import load_config cur.execute ( `` 'create function func1 ( ) returns int language sql as return [ ( None , None , None , `` Invalid argument . '' ) ] `` `` '' def open_external_editor ( filename=None , sql= '' ) : return [ ( None , None , None , cur.statusmessage ) ] if special.is_expanded_output ( ) : message = `` No named query : { } '' .format ( pattern ) from . import export not CAN_CONNECT_TO_DB , title = ' > { } '.format ( query ) arg_type , hidden , case_sensitive , aliases ) # Ex : `` select * from style\e '' - > `` select * from styl '' . # Populate the editor buffer with the partial sql ( if available ) and a def delete_named_query ( pattern , * * _ ) : else : def execute_named_query ( cur , arg , verbose ) : from __future__ import print_function '\du ' : ( list_roles , [ '\du [ + ] [ pattern ] ' , 'List roles . ' ] ) , 'describe ' : ( describe_table_details , [ 'DESCRIBE [ pattern ] ' , `` ] ) , from codecs import open '\\dv ' : ( list_views , [ '\\dv [ + ] [ pattern ] ' , 'List views . ' ] ) , if callable ( command_executor ) : return conn return use_expanded_output try : result = [ ] cur.execute ( 'create table schema1.s1_tbl1 ( id1 integer , txt1 text ) ' ) log = logging.getLogger ( __name__ ) with conn.cursor ( ) as cur : _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) special.register_special_command ( self.change_db , '\\c ' , self.connect ( database=dbname ) `` `` '' List all datatypes . '' '' '' message = `` No named query : { } '' .format ( arg ) port = ( port or self.port ) aliases= ( 'use ' , '\\connect ' , 'USE ' ) ) def list_named_queries ( cur , arg , verbose ) : def get_filename ( sql ) : global use_expanded_output def get_timing ( ) : # Ex : `` select * from style\e '' - > `` select * from styl '' . yield self.execute_normal_sql ( sql ) # Do n't return None for the caller to deal with . PARSED_QUERY = 1 for title , rows , headers , status in execute ( cur=cur , sql=sql ) : DROP SCHEMA public CASCADE ; def cursor ( connection ) : def connection ( ) : if pgspecial.TIMING_ENABLED : import psycopg2 '\z ' : ( in_progress , [ '\z [ pattern ] ' , 'Not yet implemented . ' ] ) , host=unicode2utf8 ( host ) , '\c ' : ( dummy_command , [ '\c database_name ' , 'Connect to a new database . ' ] ) , for command , value in sorted ( CASE_SENSITIVE_COMMANDS.items ( ) ) : query = namedqueries.get ( arg ) query = f.read ( ) name , query = arg.split ( ' ' , 1 ) if not verbose : yield result return TIMING_ENABLED special_cmd = COMMANDS [ command.lower ( ) ] def delete_named_query ( cur , arg , verbose ) : filename = filename.strip ( ) .split ( ' ' , 1 ) [ 0 ] if filename else None NON_CASE_SENSITIVE_COMMANDS , is_expanded_output ) results.extend ( ( title , list ( rows ) , headers , status ) ) def is_expanded_output ( ) : filename = special.get_filename ( document.text ) for _ , value in sorted ( COMMANDS.items ( ) ) : status = 'SELECT 2 ' else : teardown_db ( connection ) from .packages import pgspecial as special return query_runner if not user : # Empty string is ok . command = sql.split ( ) [ 0 ] Used by commands that are actually handled elsewhere . return [ ( None , None , None , message ) ] try : filename = iospecial.get_filename ( document.text ) # The reason we ca n't simply do .strip ( '\e ' ) is that it strips characters , is not supported a KeyError will be raised . conn = db_connection ( ) import click verbose = '+ ' in command import pgcli.packages.iospecial as iospecial special_cmd = COMMANDS [ command ] message += u '' on . '' if use_expanded_output else u '' off . '' def toggle_expanded_output ( ) : '\\dt ' : ( list_tables , [ '\\dt [ + ] [ pattern ] ' , 'List tables . ' ] ) , else : CAN_CONNECT_TO_DB = False COMMANDS [ cmd ] = SpecialCommand ( handler , syntax , description , arg_type , def setup_db ( conn ) : : param command : string '\\di ' : ( list_indexes , [ '\\di [ + ] [ pattern ] ' , 'List indexes . ' ] ) , from .packages import pgspecial query = sql host = unicode2utf8 ( host or self.host ) import re # not a substring . So it 'll strip `` e '' in the end of the sql also ! def register_special_commands ( self ) : def wrapper ( wrapped ) : # It is possible to have ` \e filename ` or ` SELECT * FROM \e ` . So we check def toggle_timing ( cur , arg , verbose ) : sql = sql.strip ( ) raise RuntimeError ( 'Database name missing . ' ) message = None def register_special_command ( handler , command , syntax , description , '\\ns ' : ( save_named_query , [ '\\ns [ name [ query ] ] ' , 'Save a named query . ' ] ) , CAN_CONNECT_TO_DB = True while special.editor_command ( document.text ) : return [ ( None , cur , headers , cur.statusmessage ) ] def executor ( connection ) : query = query.split ( MARKER , 1 ) [ 0 ] .rstrip ( '\n ' ) hidden , case_sensitive ) if query is not None : __all__ = [ ] headers = [ x [ 0 ] for x in cur.description ] # It is possible to have ` \e filename ` or ` SELECT * FROM \e ` . So we check raise KeyError ( 'Command not found : % s ' % command ) import pytest cur.execute ( 'create view vw1 as select * from tbl1 ' ) connection = db_connection ( '_test_db ' ) return wrapper with open ( filename , encoding='utf-8 ' ) as f : import click self.dbname = dbname command , verbose , arg = parse_special_command ( sql ) SERVER_VERSION = 0 def test_slash_d ( executor ) : else : if query is not None : def save_named_query ( pattern , * * _ ) : title = ' > { } '.format ( query ) import logging with db_connection ( ) .cursor ( ) as cur : cur = self.conn.cursor ( ) def test_slash_df ( executor ) : 'user `` % s '' ' % ( self.pgexecute.dbname , self.pgexecute.user ) ) return [ ( None , None , None , `` Saved . '' ) ] def toggle_timing ( ) : TIMING_ENABLED = enable CASE_SENSITIVE_COMMANDS = { Is this an external editor command ? cur.execute ( `` 'create function schema1.s1_func1 ( ) returns int language use_expanded_output = not use_expanded_output results = executor ( '\d ' ) from dbutils import ( create_db , db_connection , setup_db , teardown_db ) return [ ( `` , rows , headers , `` '' ) ] cur.execute ( `` ' if is_expanded_output ( ) : return [ ( `` , rows , headers , `` '' ) ] global use_expanded_output '\sf ' : ( in_progress , [ '\sf [ + ] funcname ' , 'Not yet implemented . ' ] ) , return filename.strip ( ) or None return command_executor ( cur , arg , verbose ) extension='.sql ' ) except IOError : pattern = re.compile ( ' ( ^\\\e|\\\e $ ) ' ) title = None conn = psycopg2.connect ( user=POSTGRES_USER , host=POSTGRES_HOST , try : # Special command else : cur.execute ( 'create type foo AS ( a int , b text ) ' ) cmd = command.lower ( ) if not case_sensitive else command password=unicode2utf8 ( password ) , for rows , headers , status in describe_table_details ( cur , table , False ) : `` `` '' List all schemas . '' '' '' from .packages.pgspecial.main import ( COMMANDS ) return ( query , message ) except KeyError : host=host , port=port ) results = executor ( '\dn ' ) command_executor = NON_CASE_SENSITIVE_COMMANDS [ command.lower ( ) ] [ 0 ] host = ( host or self.host ) headers = [ 'Schema ' , 'Name ' , 'Type ' , 'Owner ' ] _logger.debug ( 'Database change command detected . ' ) with open ( filename , encoding='utf-8 ' ) as f : elif special_cmd.arg_type == PARSED_QUERY : results = executor ( '\dT ' ) headers = [ `` Name '' ] message = `` Timing is `` # schemas 'Type ' ] sql = pattern.sub ( `` , sql ) def db_connection ( dbname=None ) : status = 'SELECT 3 ' def list_databases ( cur , * * _ ) : return special_cmd.handler ( cur=cur , pattern=pattern , verbose=verbose ) def show_help ( cur , arg , verbose ) : # All the parameters are ignored . def export ( defn ) : '\ef ' : ( in_progress , [ '\ef [ funcname [ line ] ] ' , 'Not yet implemented . ' ] ) , conn.autocommit = True cur = connection.cursor ( ) headers = [ 'Command ' , 'Description ' ] def editor_command ( command ) : def open_external_editor ( filename=None , sql= '' ) : return [ ( title , cur , headers , cur.statusmessage ) ] def test_slash_dn ( executor ) : But we want to keep their docstrings in the same list command , _ , arg = sql.partition ( ' ' ) use_expanded_output = False return filename.strip ( ) or None if special.get_timing ( ) : `` `` '' List all tables in public schema . '' '' '' # exception that can not be offloaded to ` pgspecial ` lib . Because we command , _ , filename = sql.partition ( ' ' ) rows = [ [ r ] for r in namedqueries.list ( ) ] return command.strip ( ) .endswith ( '\\e ' ) or command.strip ( ) .startswith ( '\\e ' ) headers = [ 'Name ' , 'Owner ' ] if special_cmd.case_sensitive : return the query . results = executor ( '\dt ' ) yield ( None , None , None , 'You are now connected to database `` % s '' as ' global TIMING_ENABLED pgspecial.TIMING_ENABLED = c [ 'main ' ] .as_bool ( 'timing ' ) self.password = password arg_type=PARSED_QUERY , hidden=False , case_sensitive=True , aliases= ( ) ) : port = unicode2utf8 ( port or self.port ) query = sql query = click.edit ( sql + '\n\n ' + MARKER , filename=filename , from collections import namedtuple return [ ( None , None , None , `` Invalid argument . '' ) ] # for both conditions . if query is None : from .main import special_command , NO_QUERY status = 'SELECT 1 ' _logger.debug ( 'Successfully switched to DB : % r ' , dbname ) yield self.execute_normal_sql ( sql ) '\\c [ onnect ] database_name ' , 'Change to a new database . ' , return [ ( None , result , headers , None ) ] headers = [ 'Schema ' , 'Name ' , 'Result data type ' , 'Argument data types ' , `` `` '' List of all named queries . except KeyError : # Regular SQL try : MARKER = ' # Type your query above this line.\n ' for alias in aliases : def teardown_db ( conn ) : ( 'schema1 ' , 'postgres ' ) , password = unicode2utf8 ( password or self.password ) print ( tabulate ( rows , headers , tablefmt='psql ' ) ) def execute ( cur , sql ) : # args . If it 's a string , then assume it 's an SQL command and run it . `` `` '' Returns ( title , rows , headers , status ) '' '' '' namedqueries = NamedQueries ( load_config ( '~/.pgclirc ' ) ) '\\nd ' : ( delete_named_query , [ '\\nd [ name ] ' , 'Delete a named query . ' ] ) , return special_cmd.handler ( ) # non-case-sensitive dict . If not there either , throw a KeyError exception . # placeholder comment . return ( command , verbose , arg.strip ( ) ) return wrapped from .namedqueries import namedqueries use_expanded_output = False # Look up the command in the case-sensitive dict , if it 's not there look in table = sys.argv [ 1 ] return [ ( title , cur , headers , cur.statusmessage ) ] except IOError : def list_named_queries ( verbose ) : COMMANDS = { } yield ( None , None , None , 'You are now connected to database `` % s '' as ' completer.extend_special_commands ( CASE_SENSITIVE_COMMANDS.keys ( ) ) from prompt_toolkit.layout.processors import ( ConditionalProcessor , `` `` '' Execute a special command and return the results . If the special command command = command.strip ( ) .replace ( '+ ' , `` ) while pattern.search ( sql ) : cur.execute ( 'create table tbl1 ( id1 integer , txt1 text ) ' ) command , verbose , pattern = parse_special_command ( sql ) reason= '' Need a postgres instance at localhost accessible by user 'postgres ' '' ) def __init__ ( self , filename ) : '\e ' : ( dummy_command , [ '\e [ file ] ' , 'Edit the query buffer ( or file ) with external editor . ' ] ) , if sql.strip ( ) .startswith ( '\\e ' ) : : return : list with one tuple , query as first element . if ' ' not in arg : '\\df ' : ( list_functions , [ '\\df [ + ] [ pattern ] ' , 'List functions . ' ] ) , def execute ( cur , sql ) : cur = con.cursor ( ) con = psycopg2.connect ( database='misago_testforum ' ) except KeyError : use_expanded_output = not use_expanded_output if filename : cur.execute ( 'create table tbl2 ( id2 integer , txt2 text ) ' ) SERVER_VERSION = conn.server_version with connection.cursor ( ) as cur : return ( query , message ) command , _ , filename = sql.partition ( ' ' ) '\dn ' : ( list_schemas , [ '\dn [ + ] [ pattern ] ' , 'List schemas . ' ] ) , elif special_cmd.arg_type == RAW_QUERY : for result in pgspecial.execute ( cur , sql ) : return the query . cur.execute ( `` 'CREATE DATABASE _test_db '' ' ) yield result _logger.debug ( 'Database name missing . ' ) results = executor ( '\df ' ) import pgcli.packages.pgspecial as pgspecial DROP SCHEMA IF EXISTS schema1 CASCADE ; ( 'public ' , 'tbl2 ' , 'table ' , 'postgres ' ) , namedqueries.save ( name , query ) message = u '' Expanded display is `` globals ( ) [ defn.__name__ ] = defn raise NotImplementedError namedqueries.delete ( arg ) MARKER = ' # Type your query above this line.\n ' return [ ( None , None , None , message ) ] from codecs import open global CASE_SENSITIVE_COMMANDS","['pgcli/main.py', 'pgcli/packages/iospecial.py', 'pgcli/packages/pgspecial/__init__.py', 'pgcli/packages/{pgspecial.py => pgspecial/dbcommands.py}', 'pgcli/packages/pgspecial/iocommands.py', 'pgcli/packages/pgspecial/main.py', 'pgcli/packages/{ => pgspecial}/namedqueries.py', 'pgcli/packages/pgspecial/tests/conftest.py', 'pgcli/packages/pgspecial/tests/dbutils.py', 'pgcli/packages/pgspecial/tests/pytest.ini', 'pgcli/packages/pgspecial/tests/test_specials.py', 'pgcli/pgexecute.py']",Merge pull request # 255 from dbcli/amjith/specials-decorator
440,6a40c7d1252c80df742f7072834ffafb092d5d97,2015-06-05 14:30:36-04:00,"print ( 'Format Time : % 0.03fs ' % total ) print ( 'Command Time : ' , duration ) print ( 'Format Time : ' , total ) print ( 'Command Time : % 0.03fs ' % duration )",['pgcli/main.py'],Merge pull request # 250 from dbcli/amjith/humanize-times
441,cd70f036f205e41cf1fb1a34785f1e7d9e80745d,2015-06-04 08:23:37-07:00,"document = cli.read_input ( False ) enable_vi_mode=Condition ( lambda cli : get_vi_mode_enabled ( ) ) ) assert callable ( get_vi_mode_enabled ) key_binding_manager.enable_vi_mode = not key_binding_manager.enable_vi_mode if get_vi_mode_enabled ( ) : from prompt_toolkit.filters import Always , HasFocus , IsDone key_binding_manager = pgcli_bindings ( get_toolbar_tokens = create_toolbar_tokens_func ( lambda : self.vi_mode ) # Highlight matching brackets while editing . 'prompt_toolkit==0.37 ' , from prompt_toolkit.layout.processors import HighlightMatchingBracketProcessor , ConditionalProcessor self.vi_mode = value ConditionalProcessor ( from prompt_toolkit.layout.processors import HighlightMatchingBracketProcessor processor=HighlightMatchingBracketProcessor ( chars= ' [ ] ( ) { } ' ) , layout=layout , buffer=buf , cli = CommandLineInterface ( application=application , from prompt_toolkit.filters import Condition eventloop=create_eventloop ( ) ) document = cli.read_input ( ) from prompt_toolkit.layout.prompt import DefaultPrompt set_vi_mode_enabled ( not get_vi_mode_enabled ( ) ) cli = CommandLineInterface ( create_eventloop ( ) , key_bindings_registry=key_binding_manager.registry , 'prompt_toolkit==0.39 ' , assert callable ( set_vi_mode_enabled ) key_binding_manager = KeyBindingManager ( def create_toolbar_tokens_func ( key_binding_manager , token=None ) : set_vi_mode_enabled=set_vi_mode ) from prompt_toolkit.filters import Always from prompt_toolkit.enums import DEFAULT_BUFFER filter=HasFocus ( DEFAULT_BUFFER ) & ~IsDone ( ) ) , application = Application ( style=style_factory ( self.syntax_style ) , document = cli.run ( False ) style=style_factory ( self.syntax_style ) , layout=layout , buffer=buf , from prompt_toolkit import CommandLineInterface , AbortAction on_exit=AbortAction.RAISE_EXCEPTION ) key_binding_manager = KeyBindingManager ( enable_vi_mode=vi_mode ) on_exit=AbortAction.RAISE_EXCEPTION ) key_bindings_registry=key_binding_manager.registry , def pgcli_bindings ( get_vi_mode_enabled , set_vi_mode_enabled ) : get_vi_mode_enabled=lambda : self.vi_mode , document = cli.run ( ) key_binding_manager = pgcli_bindings ( self.vi_mode ) def pgcli_bindings ( vi_mode=False ) : if key_binding_manager.enable_vi_mode : HighlightMatchingBracketProcessor ( ) , def set_vi_mode ( value ) : def create_toolbar_tokens_func ( get_vi_mode_enabled , token=None ) : from prompt_toolkit import CommandLineInterface , Application , AbortAction get_toolbar_tokens = create_toolbar_tokens_func ( key_binding_manager )","['pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgtoolbar.py', 'setup.py']",Merge pull request # 252 from jonathanslenders/prompt_toolkit_0.38
442,71c98101b2c343c91fb39729cdda48bdc2a22f5b,2015-05-30 15:21:33-07:00,"return default return config def load_config ( filename , default_filename=None ) : return cfg filename = expanduser ( filename ) if default_filename : cfg = ConfigObj ( ) cfg.merge ( ConfigObj ( def_cfg , interpolation=False ) ) cfg.merge ( ConfigObj ( expanduser ( usr_cfg ) , interpolation=False ) ) def load_config ( usr_cfg , def_cfg=None ) : # from prompt_toolkit.contrib.pdb import set_trace default.merge ( config ) default = load_config ( default_filename ) config = ConfigObj ( filename , interpolation=False )",['pgcli/config.py'],Merge pull request # 248 from dbcli/amjith/config_refactor
443,f20c498b1bf63cbdc16720cee9b787fd911705a8,2015-05-30 12:02:23-07:00,"def list_named_queries ( cur , arg , verbose ) : def __init__ ( self , filename ) : namedqueries.delete ( arg ) '\\nd ' : ( delete_named_query , [ '\\nd [ name ] ' , 'Delete a named query . ' ] ) , headers = [ x [ 0 ] for x in cur.description ] return [ ( None , None , None , `` Deleted . '' ) ] del self.config [ self.section_name ] [ name ] return self.config.get ( self.section_name , { } ) .get ( name , None ) '\\ns ' : ( save_named_query , [ '\\ns [ name [ query ] ] ' , 'Save a named query . ' ] ) , [ named queries ] return [ ( None , None , None , `` Saved . '' ) ] section_name = 'named queries ' self.config.write ( ) def get ( self , name ) : query = namedqueries.get ( arg ) def save ( self , name , query ) : self.config.write ( ) headers = [ `` Name '' ] self.config = load_config ( filename ) def execute_named_query ( cur , arg , verbose ) : self.config [ self.section_name ] [ name ] = query if len ( arg ) == 0 : if self.section_name not in self.config : if cur.description : namedqueries.save ( name , query ) headers = [ `` Name '' , `` Query '' ] return self.config.get ( self.section_name , [ ] ) return [ ( `` , rows , headers , `` '' ) ] rows = [ [ r ] for r in namedqueries.list ( ) ] self.config [ self.section_name ] = { } cur.execute ( query ) `` `` '' Returns ( title , rows , headers , status ) '' '' '' # Named queries are queries you can rexecute by name '\\n ' : ( execute_named_query , [ '\\n [ + ] [ name ] ' , 'List or execute named queries . ' ] ) , return [ ( title , None , None , cur.statusmessage ) ] title = ' > { } '.format ( query ) if arg == `` : if self.section_name in self.config and name in self.config [ self.section_name ] : else : from .namedqueries import namedqueries def delete_named_query ( cur , arg , verbose ) : return [ ( None , None , None , message ) ] rows = [ [ r , namedqueries.get ( r ) ] for r in namedqueries.list ( ) ] return [ ( title , cur , headers , cur.statusmessage ) ] class NamedQueries ( object ) : if ' ' not in arg : return list_named_queries ( cur , arg , verbose ) namedqueries = NamedQueries ( '~/.pgclirc ' ) return [ ( None , None , None , `` Invalid argument . '' ) ] message = `` No named query : { } '' .format ( arg ) if not verbose : def save_named_query ( cur , arg , verbose ) : if query is None : def list ( self ) : from .. config import load_config name , query = arg.split ( ' ' , 1 ) def delete ( self , name ) :","['pgcli/packages/namedqueries.py', 'pgcli/packages/pgspecial.py', 'pgcli/pgclirc']",Merge pull request # 244 from brettatoms/namedqueries
444,e3d34fb35e716546eba77c222dc242ad6cfae268,2015-05-29 06:51:36-07:00,"parser = ConfigParser ( ) self.table_format = c [ 'main ' ] [ 'table_format ' ] parser.read ( default_filename ) try : 'sqlparse == 0.1.14 ' self.table_format = c.get ( 'main ' , 'table_format ' ) return parser return config log_file = self.config [ 'main ' ] [ 'log_file ' ] config = ConfigObj ( filename , interpolation=False ) smart_completion = c [ 'main ' ] .as_bool ( 'smart_completion ' ) log_file = self.config.get ( 'main ' , 'log_file ' ) self.syntax_style = c.get ( 'main ' , 'syntax_style ' ) except ImportError : 'configobj > = 5.0.6 ' log_level = self.config.get ( 'main ' , 'log_level ' ) self.vi_mode = c.getboolean ( 'main ' , 'vi ' ) pgspecial.TIMING_ENABLED = c.getboolean ( 'main ' , 'timing ' ) smart_completion = c.getboolean ( 'main ' , 'smart_completion ' ) default = load_config ( default_filename ) pgspecial.TIMING_ENABLED = c [ 'main ' ] .as_bool ( 'timing ' ) from configobj import ConfigObj self.multi_line = c [ 'main ' ] .as_bool ( 'multi_line ' ) return default self.multi_line = c.getboolean ( 'main ' , 'multi_line ' ) from ConfigParser import SafeConfigParser as ConfigParser parser.read ( filename ) log_level = self.config [ 'main ' ] [ 'log_level ' ] # parser.read will not fail in case of IOError , default.merge ( config ) from configparser import ConfigParser self.syntax_style = c [ 'main ' ] [ 'syntax_style ' ] # so let 's not try/except here . 'sqlparse == 0.1.14 ' , self.vi_mode = c [ 'main ' ] .as_bool ( 'vi ' )","['pgcli/config.py', 'pgcli/main.py', 'setup.py']",Merge pull request # 245 from brettatoms/configobj
445,a8a7356c9b4e39b759153cabf7192fd1a1817e3d,2015-05-28 08:59:56-07:00,"status.append ( `` % s '' , ruledef ) status.append ( `` % s '' % ruledef ) ruledef += 12 ruledef += 12 ; status.append ( `` % s\n '' , ruledef ) status.append ( `` % s\n '' % ruledef )",['pgcli/packages/pgspecial.py'],Merge pull request # 246 from sancopanco/master
446,19cb4076f1c80caeb8e39825011d0651e8bb1f33,2015-05-26 06:54:30-07:00,"'prompt_toolkit==0.37 ' , * Make \di , \dv and \dt to be schema aware . ( Thanks : darikg_ ) * Make suggestions for special commands smarter . eg : \dn - only suggests schemas . ( Thanks : ` Darik Gamble ` _ ) * Fix the broken completion for multiple sql statements . ( Thanks : ` Darik Gamble ` _ ) word is in the middle of a suggestion . * Add subsequence matching for completion . ( Thanks : ` Daniel Rocco ` _ ) eg : When you type `` SELECT * FROM \e `` it will be opened in an external editor . As a result the suggestions for tables vs functions are cleaner . ( Thanks : darikg_ ) * Fix a rare crash caused by adding new schemas to a database . ( Thanks : darikg_ ) * Add auto-completion support for datatypes in CREATE , SELECT etc . ( Thanks : ` Darik Gamble ` _ ) * Add \df special command to show functions . ( Thanks : darikg_ ) * Improved psql compliance with env vars and password prompting . ( Thanks : https : //github.com/darikg ) eg : When you type 'mig ' , 'django_migrations ' will be suggested . ( Thanks : ` Daniel Rocco ` _ ) * Fix a rare crash caused by adding new schemas to a database . ( Thanks : ` Darik Gamble ` _ ) .. _ ` Dimitar Roustchev ` : https : //github.com/droustchev As a result the suggestions for tables vs functions are cleaner . ( Thanks : ` Darik Gamble ` _ ) * Added support of `` \\e `` command . Queries can be edited in an external editor . ( Thanks : ` Iryna Cherniavska ` _ ) * Add subsequence matching for completion . Previously completions only matched * IPython integration through ` ipython-sql ` _ ( Thanks : https : //github.com/darikg ) * Fixed a bug that broke ` \\e ` when prompt_tookit was updated . ( Thanks : ` François Pietka ` _ ) * Improve the auto-completion in WHERE clause with logical operators . ( Thanks : ` Darik Gamble ` _ ) * Add special command `` \dT `` to show datatypes . ( Thanks : ` Darik Gamble ` _ ) a table name if it started with the partially typed word . Now completions .. _ ` Jonathan Slenders ` : https : //github.com/jonathanslenders .. _ ` François Pietka ` : https : //github.com/fpietka * Auto-completion for Postgres schemas . ( Thanks : ` Darik Gamble ` _ ) .. _ ` Darik Gamble ` : https : //github.com/darikg * Fix broken behavior on \ ? . ( Thanks : darikg_ ) Previously completions only matched a table name if it started with the * Add support for auto-completing view names . ( Thanks : darikg_ ) * Fix a crash when pg_catalog was present in search path . ( Thanks : darikg_ ) partially typed word . Now completions will match even if the partially typed * Fix incorrect super ( ) calls in pgbuffer , pgtoolbar and pgcompleter . No change in functionality but protects against future problems . ( Thanks : ` Daniel Rocco ` _ ) * Make suggestions for special commands smarter . eg : \dn - only suggests schemas . ( Thanks : darikg_ ) * Fix the broken completion for multiple sql statements . ( Thanks : darikg_ ) will match even if the partially typed word is in the middle of a suggestion . * Updated version of prompt_toolkit , now matching braces are highlighted . ( Thanks : ` Jonathan Slenders ` ) * Auto-completion for Postgres schemas . ( Thanks : darikg_ ) * IPython integration through ` ipython-sql ` _ ( Thanks : ` Darik Gamble ` _ ) 'prompt_toolkit==0.36 ' , .. _darikg : https : //github.com/darikg * Completion for built-in tables and temporary tables are suggested after entering a prefix of `` pg_ `` . ( Thanks : ` Darik Gamble ` _ ) * Add missing schema completion for CREATE and DROP statements . ( Thanks : ` Darik Gamble ` _ ) * Fix the display of triggers as shown in the `` \d `` output . ( Thanks : ` Dimitar Roustchev ` _ ) * Completion for built-in tables and temporary tables are suggested after entering a prefix of `` pg_ `` . ( Thanks : darikg_ ) * Fix a crash when pg_catalog was present in search path . ( Thanks : ` Darik Gamble ` _ ) * Add \df special command to show functions . ( Thanks : ` Darik Gamble ` _ ) * Minor fixes around cursor cleanup . * Make \dt command honor the explicit schema specified in the arg . ( Thanks : ` Darik Gamble ` _ ) * Make \dt command honor the explicit schema specified in the arg . ( Thanks : darikg_ ) * Fix broken auto-completion for INNER JOIN , LEFT JOIN etc . ( Thanks : ` Darik Gamble ` _ ) * * Make \di , \dv and \dt to be schema aware . ( Thanks : ` Darik Gamble ` _ ) * Improved psql compliance with env vars and password prompting . ( Thanks : ` Darik Gamble ` _ ) * Fix broken behavior on \ ? . ( Thanks : ` Darik Gamble ` _ ) * Add support for auto-completing view names . ( Thanks : ` Darik Gamble ` _ ) eg : When you type 'mig ' , 'django_migrations ' will be suggested .","['changelog.rst', 'setup.py']",Merge pull request # 242 from dbcli/amjith/release-0.17.0
447,7156d2d5df5922ed729957f98a8ca26adfa83f44,2015-05-24 17:00:43-07:00,"initial_document=Document ( sql , cursor_position=len ( sql ) ) , document = cli.read_input ( document = cli.read_input ( False ) ) cli.current_buffer.document = Document ( sql , cursor_position=len ( sql ) )",['pgcli/main.py'],Merge pull request # 241 from fpietka/fix-editmode
448,637f41d8ed42e3acd908bd6d8cb7297b58f45ccf,2015-05-24 01:45:20-07:00,"assert kw == ' ( ' { 'type ' : 'table ' , 'schema ' : schema } ] { 'type ' : 'datatype ' , 'schema ' : [ ] } , elif cmd [ 1 : ] in ( 'dt ' , 'dv ' , 'df ' ) : 'SELECT * FROM foo ( ) AS bar ( baz ' , ON n.oid = t.typnamespace self.all_completions.add ( type_name ) AS `` Access privileges '' , as `` Description '' `` ' ) datatypes = [ ( schema , datatype ) 'CREATE TABLE foo ( bar ' , elif suggestion [ 'type ' ] == 'datatype ' : FROM pg_catalog.pg_type el WHERE ( t.typrelid = 0 -- non-composite types > > > last_word ( 'bac $ def ' , True ) 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) , \s ] + ) $ ' ) , AND n.nspname < > 'information_schema ' `` ' AND NOT EXISTS ( -- ignore array types ELSE CAST ( t.typlen AS pg_catalog.text ) 'CREATE TABLE foo ( bar INT , baz TEXT , qux ' , > > > last_word ( 'bac \def ' , include='most_punctuations ' ) SELECT n.nspname schema_name , AND n.nspname < > 'information_schema ' 'create table foo ( bar int , baz ' , 'SELECT foo AS bar ' , def test_cast_operator_suggests_types ( text ) : WHERE el.oid = t.typelem AND el.typarray = t.oid completions.extend ( types ) WHERE e.enumtypid = t.oid 'functions ' : [ 'custom_func1 ' , 'custom_func2 ' ] , params = [ ] assert suggestions == [ { 'type ' : 'keyword ' } ] sql += `` ' FROM pg_catalog.pg_type t elif token_v in ( 'type ' , ' : : ' ) : # Suggest datatypes [ { 'type ' : 'datatype ' , 'schema ' : 'foo ' } ] ) '\\dT ' : ( list_datatypes , [ '\dT [ S+ ] [ pattern ] ' , 'List data types ' ] ) , > > > last_word ( 'bac : :def ' , include='most_punctuations ' ) Completion ( text='users ' ) , # Built-in datatypes AND NOT EXISTS ( def test_identifier_suggests_types_in_parentheses ( text ) : 'SELECT foo FROM ( SELECT bar ' 'SELECT foo bar ' , [ { 'type ' : 'schema ' } , # SELECT Identifier < CURSOR > 'SELECT x : : ' , text = '\\dT ' 'dT ' : 'datatype ' , meta [ schema ] [ type_name ] = None executor.run ( sql ) SELECT c.relkind = ' c ' 'SELECT ( x + y ) : :bar . ' , 'custom ' : [ 'typ3 ' , 'typ4 ' ] , # dbmetadata [ 'datatypes ' ] [ schema_name ] [ type_name ] should store type SELECT 1 elif isinstance ( token , Identifier ) : if type_pattern : text = '\\dT foo . ' } , OR pg_catalog.format_type ( t.oid , NULL ) ~ % s ) `` ' datatypes = [ 'BIGINT ' , 'BOOLEAN ' , 'CHAR ' , 'DATE ' , 'DOUBLE PRECISION ' , 'INT ' , params.extend ( 2 * [ type_pattern ] ) if not schema : types = self.populate_schema_objects ( pg_catalog.obj_description ( t.oid , 'pg_type ' ) def extend_datatypes ( self , type_data ) : def test_specials_not_included_after_initial_token ( ) : suggestions = suggest_type ( 'create table foo ( dt d ' , # SELECT foo : :bar 'SELECT x : :y ' , END AS `` Size '' , schema_pattern , type_pattern = sql_name_pattern ( pattern ) 'SELECT foo : :bar . ' , # We do n't have any tests for the output of any of the special commands , { 'type ' : 'table ' , 'schema ' : [ ] } , def test_find_prev_keyword_open_parens ( sql ) : Completion ( text='typ4 ' ) , with self.conn.cursor ( ) as cur : 'CREATE FUNCTION foo ( bar INT , baz custom . ' , WHERE ( t.typrelid = 0 OR SELECT e.enumlabel 'create table foo ( dt d ' ) # If the previous token is an identifier , we can suggest datatypes if WHERE c.oid = t.typrelid ) ) sql = r'\ { command } { verbose } { pattern } '.format ( * * locals ( ) ) _logger.debug ( 'Datatypes Query . sql : % r ' , self.datatypes_query ) q = 'ALTER TABLE foo ALTER COLUMN bar TYPE ' 'SELECT foo FROM bar ' , CASE types = self.find_matches ( word_before_cursor , THEN CAST ( 'tuple ' AS pg_catalog.text ) comp.extend_datatypes ( datatypes ) FROM pg_catalog.pg_type el # This matches everything except spaces , parens , and comma if cur.description : 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) : ,\s ] + ) $ ' ) , # If we 're not in a parenthesized list , the most likely scenario is the def test_describe_special ( executor , command , verbose , pattern ) : INNER JOIN pg_catalog.pg_namespace n # Tables def test_schema_qualified_type_name ( text , completer , complete_event ) : sql += `` ' AND ( t.typname ~ % s datatypes = [ ( 'public ' , typ ) for typ in metadata [ 'datatypes ' ] ] 'CREATE FUNCTION foo ( bar INT , baz ' , AS `` Description '' ' '' t.typname type_name { 'type ' : 'datatype ' , 'schema ' : 'bar ' } , for row in cur : if schema_pattern : 'public ' : [ 'func1 ' , 'func2 ' ] , # we 're in a parenthesized column/field list , e.g . : assert suggest_type ( sql , sql ) == [ { 'type ' : 'schema ' } ] 'public ' : [ 'typ1 ' , 'typ2 ' ] , suggestions = suggest_type ( text , text ) assert sorted_dicts ( suggest_type ( q , q ) ) == sorted_dicts ( [ schema , type_name = self.escaped_names ( t ) 'custom ' : [ 'func3 ' , 'func4 ' ] } 'SELECT 1 : : ' , # types else : FROM pg_catalog.pg_enum e meta = self.dbmetadata [ 'datatypes ' ] FROM pg_catalog.pg_class c } [ cmd [ 1 : ] ] 'dv ' : 'view ' , # metadata , such as composite type field names . Currently , we 're not assert types == [ ( 'public ' , 'foo ' ) ] sql = cur.mogrify ( sql + ' ORDER BY 1 , 2 ' , params ) FROM pg_catalog.pg_class c # they 're suggested here as well 'CREATE TABLE foo ( bar custom . ' , # This matches everything except spaces , parens , comma , and period ] ) 'custom ' : [ 'func3 ' , 'func4 ' ] , 'SELECT foo ' , def test_cast_operator_suggests_schema_qualified_types ( text ) : { 'type ' : 'table ' , 'schema ' : 'bar ' } ] ) rel_type = { 'dt ' : 'table ' , ARRAY ( return [ { 'type ' : 'keyword ' } ] yield row # This matches everything except spaces , parens , colon , and comma WHERE c.oid = t.typrelid self.dbmetadata = { 'tables ' : { } , 'views ' : { } , 'functions ' : { } , prev_keyword , _ = find_prev_keyword ( text_before_cursor ) 'def ' if not ( schema_pattern or type_pattern ) : 'select * from foo ( ) as bar ( baz ' pg_catalog.format_type ( t.oid , NULL ) AS `` Name '' , `` ' # ALTER TABLE foo SET DATA TYPE bar rel_type = { 'dt ' : 'table ' , 'dv ' : 'view ' , 'df ' : 'function ' } [ cmd [ 1 : ] ] ORDER BY e.enumsortorder completions.extend ( types ) sql += r '' ' t.typname AS `` Internal name '' , cur.execute ( self.datatypes_query ) 'public ' , 'users ' , 'orders ' , ' '' select '' ' , sql += ' AND pg_catalog.pg_type_is_visible ( t.oid ) ' 'datatypes ' : { assert set ( result ) == set ( [ return [ ( None , cur , headers , cur.statusmessage ) ] 'SELECT * FROM foo bar ' , 'ALTER TABLE foo ALTER COLUMN bar TYPE ' , 'ALTER TABLE foo ALTER COLUMN bar TYPE custom . ' , sql = `` 'SELECT n.nspname as `` Schema '' , 'dT ' : ( in_progress , [ '\dT [ S+ ] [ pattern ] ' , 'Not yet implemented . ' ] ) 'SELECT * FROM foo AS bar ' , types = list ( executor.datatypes ( ) ) # types WHERE el.oid = t.typelem return suggestions SELECT 1 ] ) AND el.typarray = t.oid ) `` ' result = completer.get_completions ( for datatype in datatypes ] self.datatypes , start_only=True ) if prev_keyword == ' ( ' : return suggest_based_on_last_token ( 'type ' , text_before_cursor , run ( executor , 'create type foo AS ( a int , b text ) ' ) sql += ' AND n.nspname ~ % s ' 'SELECT foo : :bar.baz ' , 'SELECT * FROM foo ( ) AS bar ( baz INT , qux ' , 'CREATE FUNCTION foo ( bar ' , for t in type_data : > > > last_word ( 'bac \def ; ' , include='most_punctuations ' ) Completion ( text='typ3 ' ) , assert sorted_dicts ( suggestions ) == sorted_dicts ( 'SELECT 1 : :custom . ' , suggestions.append ( { 'type ' : 'schema ' } ) 'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) : ,\s ] + ) $ ' ) , completer.extend_datatypes ( pgexecute.datatypes ( ) ) # Also suggest hardcoded types pg_catalog.array_to_string ( def test_alias_suggests_keywords ( text ) : WHEN t.typrelid ! = 0 # Note that tables are a form of composite type in postgresql , so def test_schema_qualified_dT_suggests_datatypes ( ) : for schema , datatypes in metadata [ 'datatypes ' ] .items ( ) ) ) , E'\n ' ) AS `` Elements '' , else : suggestion [ 'schema ' ] , 'datatypes ' ) headers = [ x [ 0 ] for x in cur.description ] # user is about to specify an alias , e.g . : def test_datatypes_query ( executor ) : def datatypes ( self ) : pg_catalog.array_to_string ( t.typacl , E'\n ' ) full_text , identifier ) # make sure this doesnt trigger special completion def list_datatypes ( cur , pattern , verbose ) : [ Completion ( t ) for t in [ 'datatypes ' : [ 'custom_type1 ' , 'custom_type2 ' ] , sql += `` ' AND n.nspname < > 'pg_catalog ' assert sorted_dicts ( suggestions ) == sorted_dicts ( [ { 'type ' : 'keyword ' } ] ) 'df ' : 'function ' , Completion ( text='shipments ' ) , 'most_punctuations ' : re.compile ( r ' ( [ ^\ . ( ) , \s ] + ) $ ' ) , > > > last_word ( 'bac \def ; ' , True ) THEN CAST ( 'var ' AS pg_catalog.text ) FROM pg_catalog.pg_type t # SELECT foo FROM Identifier < CURSOR > # suggest custom datatypes def test_suggest_datatype ( text , completer , complete_event ) : ( SELECT c.relkind = ' c ' { 'type ' : 'schema ' } ] ) types = self.find_matches ( word_before_cursor , types ) # Custom types assert True 'CREATE TABLE foo ( dt d ' , > > > last_word ( 'bac \def ' , True ) 'INTEGER ' , 'NUMERIC ' , 'REAL ' , 'TEXT ' , 'VARCHAR ' ] # This matches everything except spaces , parens , colon , comma , and period # CREATE FUNCTION foo ( Identifier < CURSOR > elif cmd [ 1 : ] in ( 'dt ' , 'dv ' , 'df ' , 'dT ' ) : 'custom_type1 ' , 'custom_type2 ' , # CREATE TABLE foo ( Identifier < CURSOR > if not suggestion [ 'schema ' ] : ORDER BY 1 , 2 ; ' '' # storing any metadata beyond typename , so just store None ) def test_alter_column_type_suggests_types ( ) : assert set ( result ) == set ( assert sorted_dicts ( suggest_type ( text , text ) ) == sorted_dicts ( [ ON n.oid = t.typnamespace # but we can at least make sure they run without error `` `` '' Yields tuples of ( schema_name , type_name ) '' '' '' LEFT JOIN pg_catalog.pg_namespace n cur.execute ( sql ) 'public ' : [ 'func1 ' , 'func2 ' ] , suggestions = [ { 'type ' : 'datatype ' , 'schema ' : schema } , 'CREATE TABLE foo ( bar INT , baz ' , datatypes_query = `` ' params.append ( schema_pattern ) 'CREATE TABLE foo ( bar DOU ' , if verbose : pos = len ( text ) Completion ( text='products ' ) , { 'type ' : 'datatype ' , 'schema ' : [ ] } , 'functions ' : [ 'custom_func1 ' , 'custom_func2 ' ] 'SELECT ( x + y ) : : ' , self.dbmetadata = { 'tables ' : { } , 'views ' : { } , 'functions ' : { } } assert suggest_type ( sql , sql ) == [ { 'type ' : 'schema ' } ] def test_dT_suggests_schema_or_datatypes ( ) : log.debug ( sql ) schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] > > > last_word ( 'bac $ def ' , include='most_punctuations ' ) 'datatypes ' : { } } WHEN t.typlen < 0 sql += `` ' pg_catalog.obj_description ( t.oid , 'pg_type ' ) ] + completer.datatypes AND n.nspname < > 'pg_catalog ' Document ( text=text , cursor_position=pos ) , complete_event ) OR ( -- composite type , but not a table kw , _ = find_prev_keyword ( sql )","['pgcli/main.py', 'pgcli/packages/parseutils.py', 'pgcli/packages/pgspecial.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_parseutils.py', 'tests/test_pgexecute.py', 'tests/test_pgspecial.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 240 from dbcli/darikg/suggest_types
449,7440386f83fc2f51ec9e7abb4c5379f6a1fe31ed,2015-05-22 15:36:09-07:00,"def test_drop_schema_suggests_schemas ( ) : assert suggest_type ( sql , sql ) == [ { 'type ' : 'schema ' } ] elif token_v == 'schema ' : return [ { 'type ' : 'schema ' } ] sql = 'DROP SCHEMA ' # DROP SCHEMA schema_name","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 239 from dbcli/darikg/suggest_schemas_tweak
450,d0eef1bb1447737b7341da268e3dc6361d17a9c3,2015-05-15 20:21:33-07:00,"# Ignore any errors thrown when consuming the generator logger.error ( 'Closing the cursor failed . % r ' , e ) try : # 'res ' . except Exception as e : finally : if hasattr ( cur , 'close ' ) : cur.close ( ) for title , cur , _ , _ in res :",['pgcli/main.py'],Merge pull request # 234 from dbcli/amjith/general_cleanup
451,486308f8b27782b0f16fbb24b976ff633426b9bc,2015-05-14 21:30:35-07:00,"# drop_unique is used for 'tb11 JOIN tbl2 USING ( ... ' which cur.close ( ) except Exception as e : # one table logger.error ( 'Closing the cursor failed . % r ' , e ) conn = psycopg2.connect ( user=POSTGRES_USER , host=POSTGRES_HOST , database=dbname ) self.all_completions.add ( relname ) try : # drop_unique is used for 'tb11 JOIN tbl2 USING ( ... ' self.all_completions.add ( column ) # Ignore any errors thrown when consuming the generator # 'res ' . for cur , _ , _ in res : conn = psycopg2.connect ( user=POSTGRES_USER , host=POSTGRES_HOST , dbname=dbname ) # table # which should suggest only columns that appear in more than if hasattr ( cur , 'close ' ) : # should suggest only columns that appear in more than one prompt = ' % s > ' % pgexecute.dbname if hasattr ( cur , 'close ' ) : for title , cur , _ , _ in res : self.all_completions.update ( t [ 2 ] for t in column_data ) cur.close ( ) self.all_completions.update ( t [ 1 ] for t in data )","['pgcli/main.py', 'pgcli/pgcompleter.py', 'tests/utils.py']",Merge pull request # 233 from dbcli/amjith/general_cleanup
452,e4f571970c8da2c4ac68f8b5fb751ff13cd3b154,2015-05-09 07:52:19-07:00,"super ( self.__class__ , self ) .__init__ ( token=token ) super ( self.__class__ , self ) .__init__ ( ) super ( PGToolbar , self ) .__init__ ( token=token ) super ( PGBuffer , self ) .__init__ ( * args , is_multiline=is_multiline , * * kwargs ) super ( self.__class__ , self ) .__init__ ( * args , is_multiline=is_multiline , * * kwargs ) super ( PGCompleter , self ) .__init__ ( )","['pgcli/pgbuffer.py', 'pgcli/pgcompleter.py', 'pgcli/pgtoolbar.py']",Merge pull request # 231 from dbcli/drocco/fix-super
453,51be1f391af44531823da4c6e158a216f3de5457,2015-05-07 17:46:25-04:00,"# ( baz , qux , `` would be overwhelming . So we special case 'IN ' suggestions = suggest_type ( q , q ) if prev_tok == 'exists ' : if isinstance ( prev_tok , Comparison ) : def test_sub_select_suggests_keyword ( expression ) : from sqlparse.tokens import Keyword # 4 - Subquery OR array comparison like `` WHERE foo = ANY ( `` for t in reversed ( flattened ) : 'SELECT * FROM foo WHERE bar AND NOT EXISTS ( SELECT * FROM ' , 'SELECT * FROM ( S ' , if t.is_keyword or t.value == ' ( ' : elif prev_tok == 'in ' : token_v = token.value.lower ( ) for t in reversed ( list ( parsed.flatten ( ) ) ) : token_v = token.tokens [ -1 ] .value.lower ( ) 'SELECT * FROM tabl WHERE foo IN ( ' , 'SELECT * FROM foo WHERE bar AND NOT EXISTS ( S ' , # 3 - Subquery expression like `` WHERE EXISTS ( `` def test_find_prev_keyword_where ( sql ) : text = 'SELECT * FROM tabl WHERE foo = ANY ( ' 'SELECT * FROM tabl WHERE bar OR ' , # Technically , we should suggest columns AND keywords , as text = `` .join ( tok.value for tok in parsed.tokens [ : idx+1 ] ) 'select * from foo where bar ' , # Suggest columns/functions { 'type ' : 'view ' , 'schema ' : ' f ' } , # query string with everything after the keyword token removed # p.token_index ( t ) # Throws ValueError : not in list 'select * from foo where bar = 1 and baz between qux and ' , prev_keyword , text_before_cursor = find_prev_keyword ( text_before_cursor ) 'SELECT * FROM tabl WHERE ( bar > 10 AND ' , text_before_cursor , full_text , identifier ) 'SELECT * FROM tabl WHERE foo BETWEEN ' , def test_where_in_suggests_columns ( expression ) : 'SELECT * FROM tabl WHERE foo BETWEEN foo AND ' , # 1 - Parenthesized clause like `` WHERE foo AND ( `` 'SELECT * FROM foo WHERE EXISTS ( ' , 'SELECT * FROM foo WHERE EXISTS ( SELECT * FROM ' , def test_where_equals_any_suggests_columns_or_keywords ( ) : if t.value == ' ( ' or ( t.is_keyword and ( prev_tok = prev_tok.value.lower ( ) def test_outer_table_reference_in_exists_subquery_suggests_columns ( ) : token_v = token.value.lower ( ) q = 'SELECT * FROM foo f WHERE EXISTS ( SELECT 1 FROM bar WHERE f . ' suggestion = suggest_type ( 'SELECT * FROM ( SELECT * FROM ' , def test_sub_select_table_name_completion ( expression ) : 'SELECT * FROM tabl WHERE foo = ' , prev_tok = where.token_prev ( len ( where.tokens ) - 1 ) if isinstance ( token , Comparison ) : 'SELECT * FROM tabl WHERE ' , elif prev_tok in ( 'any ' , 'some ' , 'all ' ) : from sqlparse.sql import Comparison , Identifier , Where suggestions = suggest_type ( 'SELECT * FROM tabl WHERE ' , 'SELECT * FROM tabl WHERE 10 < ' , # t = list ( p.flatten ( ) ) [ -3 ] # The `` Where '' token { 'type ' : 'function ' , 'schema ' : [ ] } , 'SELECT * FROM tabl WHERE ' ) def test_sub_select_partial_text_suggests_keyword ( expression ) : text = `` .join ( tok.value for tok in flattened [ : idx+1 ] ) suggestions = suggest_type ( text , text ) # Combine the string values of all tokens in the original list else : elif ( token_v.endswith ( 'join ' ) and token.is_keyword ) or ( token_v in 'SELECT * FROM tabl WHERE foo IN ( bar , ' , # But suggesting keywords for , `` SELECT * FROM foo WHERE bar IN { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None ) ] } , # per case 4 . However , IN is different from ANY , SOME , ALL return [ { 'type ' : 'keyword ' } ] return column_suggestions + [ { 'type ' : 'keyword ' } ] suggestion = suggest_type ( expression , expression ) # e.g . `` SELECT foo FROM bar WHERE foo = ANY ( `` assert kw == 'where ' and stripped == 'select * from foo where ' # sqlparse groups all tokens from the where clause into a single token t.value.upper ( ) not in logical_operators ) ) : # Suggest columns/functions AND keywords . ( If we wanted to be 'SELECT * FROM tabl WHERE ( bar AND ( baz OR ( qux AND ( ' , def test_sub_select_table_name_completion ( ) : kw , stripped = find_prev_keyword ( sql ) # 2 - Function call like `` WHERE foo ( `` 'SELECT * FROM ( SELECT * FROM ' , # inside a TokenList , in which case token_index thows an error # list . This means that token.value may be something like # up to and including the target keyword token t , to produce a flattened = list ( parsed.flatten ( ) ) # p = sqlparse.parse ( 'select * from foo where bar ' ) # Minimal example : ] ) # suggestions in complicated where clauses correctly prev_tok = prev_tok.tokens [ -1 ] else : elif ( token_v.endswith ( 'join ' ) and token.ttype in Keyword ) or ( token_v in 'SELECT * FROM tabl WHERE foo = 1 AND ' , return column_suggestions # 'where foo > 5 and ' . We need to look `` inside '' token.tokens to handle from sqlparse.sql import Comparison , Identifier # in that it can accept a * list * of columns , or a subquery . assert suggestions == [ def test_where_suggests_columns_functions ( expression ) : 'SELECT * FROM ( ' , return suggest_based_on_last_token ( prev_keyword , text_before_cursor , if p.tokens and isinstance ( p.tokens [ -1 ] , Where ) : elif isinstance ( token , Comparison ) : 'SELECT * FROM tabl WHERE ( ' , 'select * from foo where bar = 1 and baz or ' , 'SELECT * FROM foo WHERE bar AND NOT EXISTS ( ' , assert sorted_dicts ( suggestions ) == sorted_dicts ( [ def test_sub_select_partial_text_suggests_keyword ( ) : full_text , identifier ) # Suggest keywords , in order to do a subquery # Check for a subquery expression ( cases 3 & 4 ) def test_where_suggests_columns_functions ( ) : { 'type ' : 'function ' , 'schema ' : [ ] } ] ) suggestions = suggest_type ( expression , expression ) { 'type ' : 'keyword ' } ] ) # Find the location of token t in the original parsed statement # We ca n't use parsed.token_index ( t ) because t may be a child token idx = parsed.token_index ( t ) def test_sub_select_suggests_keyword ( ) : suggestion = suggest_type ( 'SELECT * FROM ( S ' , 'SELECT * FROM ( S ' ) suggestion = suggest_type ( 'SELECT * FROM ( ' , 'SELECT * FROM ( ' ) # really fancy , we could suggest only array-typed columns ) # Four possibilities : column_suggestions = suggest_based_on_last_token ( 'where ' , elif isinstance ( token , Where ) : { 'type ' : 'function ' , 'schema ' : ' f ' } ] logical_operators = ( 'AND ' , 'OR ' , 'NOT ' , 'BETWEEN ' ) 'SELECT * FROM foo WHERE EXISTS ( S ' , else : 'SELECT * FROM ( SELECT * FROM ' ) idx = flattened.index ( t ) else : where = p.tokens [ -1 ] # to not suggest keywords . { 'type ' : 'column ' , 'tables ' : [ ( None , 'foo ' , ' f ' ) ] } , token_v = token.tokens [ -1 ] .value.lower ( ) { 'type ' : 'table ' , 'schema ' : ' f ' } ,","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'tests/test_parseutils.py', 'tests/test_sqlcompletion.py']",Merge pull request # 224 from dbcli/darikg/bugfix-compound-where
454,bcd271743d0dcc6530b784f567f8254b81bb83ab,2015-04-29 06:57:04-04:00,"event.cli.current_buffer.complete_next ( start_at_first=False ) If the menu is showing , select the next completion . Force autocompletion at cursor . _logger.debug ( 'Detected < Tab > key . ' ) event.cli.current_buffer.complete_next ( ) Force autocompletion at cursor . def _ ( event ) : appropriate completions for the context . Initialize autocompletion at cursor . `` `` '' event.cli.current_buffer.complete_next ( ) If the autocompletion menu is not showing , display it with the",['pgcli/key_bindings.py'],Merge pull request # 223 from dbcli/drocco/tab-completion
455,6aff7d96c2a3161e2d84373e45f9e2cdecfcbe08,2015-04-23 23:14:56-07:00,"message = None return ( query , message ) def get_filename ( sql ) : are a list of tuples . Each tuple has 3 values ( rows , headers , status ) . # Do n't return None for the caller to deal with . `` `` '' on_exit=AbortAction.RAISE_EXCEPTION ) filename = filename.strip ( ) .split ( ' ' , 1 ) [ 0 ] if filename else None Is this an external editor command ? def test_special_command_help ( executor ) : as all the rest of commands . def test_special_command ( executor ) : with open ( filename , encoding='utf-8 ' ) as f : query = f.read ( ) # The reason we ca n't simply do .strip ( '\e ' ) is that it strips characters , return command.strip ( ) .endswith ( '\\e ' ) or command.strip ( ) .startswith ( '\\e ' ) initial_document=Document ( sql , cursor_position=len ( sql ) ) , def handle_editor_command ( self , cli , document ) : # not a substring . So it 'll strip `` e '' in the end of the sql also ! : param cli : CommandLineInterface continue _logger = logging.getLogger ( __name__ ) def change_db ( cur , arg , verbose ) : def open_external_editor ( filename=None , sql= '' ) : '\e ' : ( in_progress , [ '\e [ file ] [ line ] ' , 'Not yet implemented . ' ] ) , # Populate the editor buffer with the partial sql ( if available ) and a run ( executor , '\\ ? ' ) return filename.strip ( ) or None by a '\e ' . The reason for a while loop is because a user try : from .encodingutils import unicode2utf8 , PY2 , PY3 click.secho ( str ( e ) , err=True , fg='red ' ) pattern = re.compile ( ' ( ^\\\e|\\\e $ ) ' ) return the query . sql , message = iospecial.open_external_editor ( filename , extension='.sql ' ) try : message = 'Error reading file : % s . ' % filename import click But we want to keep their docstrings in the same list from .encodingutils import unicode2utf8 , PY2 continue while iospecial.editor_command ( document.text ) : import logging Open external editor , wait for the user to type in his query , else : might edit a query multiple times . raise RuntimeError ( message ) # for both conditions . '\c ' : ( change_db , [ '\c database_name ' , 'Connect to a new database . ' ] ) , : param command : string query = sql import re `` `` '' sql = sql.strip ( ) '\c ' : ( dummy_command , [ '\c database_name ' , 'Connect to a new database . ' ] ) , MARKER = ' # Type your query above this line.\n ' blah where q = 'abc'\e '' to edit it again . `` select * from \e '' < enter > to edit it in vim , then come query = click.edit ( sql + '\n\n ' + MARKER , filename=filename , For eg : query = query.split ( MARKER , 1 ) [ 0 ] .rstrip ( '\n ' ) if message : # placeholder comment . # It is possible to have ` \e filename ` or ` SELECT * FROM \e ` . So we check except IOError : def editor_command ( command ) : : return : Document if query is not None : sql = pattern.sub ( `` , sql ) assert ( result [ 2 ] .find ( u'Description ' ) ! = -1 ) except RuntimeError as e : back to the prompt with the edited query `` select * from document = cli.read_input ( while pattern.search ( sql ) : return document if sql.strip ( ) .startswith ( '\\e ' ) : Editor command is any query that is prefixed or suffixed : return : list with one tuple , query as first element . are a list of tuples . Each tuple has 4 values ( title , rows , headers , status ) . assert ( result [ 1 ] .find ( u'Command ' ) ! = -1 ) '\e ' : ( dummy_command , [ '\e [ file ] ' , 'Edit the query buffer ( or file ) with external editor . ' ] ) , filename = iospecial.get_filename ( document.text ) : param document : Document if filename : # Something went wrong . Raise an exception and bail . command , _ , filename = sql.partition ( ' ' ) import pgcli.packages.iospecial as iospecial # Ex : `` select * from style\e '' - > `` select * from styl '' . logger.error ( `` sql : % r , error : % r '' , document.text , e ) from __future__ import print_function Used by commands that are actually handled elsewhere . sql=document.text ) result = run ( executor , '\\ ? ' ) [ 0 ] .split ( '| ' ) from codecs import open text.endswith ( '\e ' ) or # Ended with \e which should launch the editor . document = self.handle_editor_command ( cli , document ) def dummy_command ( cur , arg , verbose ) : # Empty string is ok . logger.error ( `` traceback : % r '' , traceback.format_exc ( ) )","['pgcli/main.py', 'pgcli/packages/iospecial.py', 'pgcli/packages/pgspecial.py', 'pgcli/pgbuffer.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 217 from amjith/fixed_branch
456,3e4d63d87db43c5e68e7cef458a1909bf2933f73,2015-04-20 10:10:59-04:00,$ git remote add upstream git @ github.com : amjith/pgcli.git __ https : //github.com/amjith/pgcli # detailed-installation-instructions thanks . ` Fork the project < https : //github.com/dbcli/pgcli > ` _ in github . Then : target : https : //travis-ci.org/amjith/pgcli https : //github.com/amjith/pgcli/blob/master/DEVELOP.rst url https : //github.com/dbcli/pgcli \ https : //github.com/dbcli/pgcli/blob/master/DEVELOP.rst .. |Build Status| image : : https : //api.travis-ci.org/amjith/pgcli.svg ? branch=master * Fix the image url in PyPI to point to github raw content . https : //raw.githubusercontent.com/amjith/pgcli/master/screenshots/image01.png : target : https : //gitter.im/dbcli/pgcli ? utm_source=badge & utm_medium=badge & utm_campaign=pr-badge & utm_content=badge thanks . ` Fork the project < https : //github.com/amjith/pgcli > ` _ in github . Then : target : https : //gitter.im/amjith/pgcli ? utm_source=badge & utm_medium=badge & utm_campaign=pr-badge & utm_content=badge print ( 'Chat : https : //gitter.im/amjith/pgcli ' ) * Fix the image url in PyPI to point to github raw content . https : //raw.githubusercontent.com/dbcli/pgcli/master/screenshots/image01.png .. |Build Status| image : : https : //api.travis-ci.org/dbcli/pgcli.svg ? branch=master __ https : //github.com/dbcli/pgcli # detailed-installation-instructions url https : //github.com/amjith/pgcli \ print ( 'Chat : https : //gitter.im/dbcli/pgcli ' ) : target : https : //travis-ci.org/dbcli/pgcli,"['DEVELOP.rst', 'README.rst', 'Vagrantfile', 'pgcli/main.py', 'release_procedure.txt']",Merge pull request # 215 from amjith/master
457,09abde0ce69538dc5068d017ad683e9be1380527,2015-04-18 20:13:05-07:00,"from .encodingutils import unicode2utf8 return json_data.decode ( self.conn.encoding ) return json_data.decode ( self.conn.encoding ) from .encodingutils import unicode2utf8 , PY2 , PY3 return json_data if PY2 : else :",['pgcli/pgexecute.py'],Merge pull request # 209 from amjith/json_py3_handler
458,0b1707bc9de935908a1b2c80d329318e44daeb4f,2015-04-18 19:37:46-07:00,"token_v = token.lower ( ) rel_type = token_v.lower ( ) elif token_v.lower ( ) in ( 'copy ' , 'from ' , 'update ' , 'into ' , 'describe ' ) or ( return [ { 'type ' : 'schema ' } , 'UPDATE ' , elif token_v.lower ( ) in ( 'set ' , 'by ' , 'distinct ' ) : suggest.append ( { 'type ' : 'view ' , 'schema ' : schema } ) elif token_v.lower ( ) in ( 'table ' , 'view ' , 'function ' ) : 'SELECT * FROM sch . ' , { 'type ' : 'view ' , 'schema ' : schema } ] elif token_v.lower ( ) .endswith ( ' ( ' ) : elif token_v.lower ( ) in ( ' c ' , 'use ' , 'database ' , 'template ' ) : { 'type ' : 'table ' , 'schema ' : [ ] } , suggest = [ { 'type ' : 'table ' , 'schema ' : schema } ] 'DESCRIBE ' , def test_from_suggests_tables_and_schemas ( ) : # Suggest schemas OR public tables/views if not schema : { 'type ' : 'view ' , 'schema ' : [ ] } ] token_v = token.value.lower ( ) { 'type ' : 'table ' , 'schema ' : [ ] } , 'DESCRIBE sch . ' , elif token_v.endswith ( ' ( ' ) : # public schema if no schema has been specified { 'type ' : 'view ' , 'schema ' : 'sch ' } ] ) elif token_v in ( 'set ' , 'by ' , 'distinct ' ) : # Only tables can be TRUNCATED , otherwise suggest views 'SELECT * FROM foo JOIN ' , token_v = token.tokens [ -1 ] .value.lower ( ) if token_v ! = 'truncate ' : elif token_v == 'on ' : suggestions = suggest_type ( 'TRUNCATE ' , 'TRUNCATE ' ) 'COPY ' , # Suggest tables from either the currently-selected schema or the { 'type ' : 'table ' , 'schema ' : 'sch ' } ] ) elif token_v in ( 'select ' , 'where ' , 'having ' ) : elif token_v in ( 'table ' , 'view ' , 'function ' ) : 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'TRUNCATE ' , 'UID ' , 'UNION ' , return [ { 'type ' : 'table ' , 'schema ' : schema } , { 'type ' : 'table ' , 'schema ' : 'sch ' } , suggestions = suggest_type ( 'SELECT * FROM ' , 'SELECT * FROM ' ) 'SELECT * FROM foo JOIN sch . ' , 'INSERT INTO ' , suggestions = suggest_type ( 'TRUNCATE sch . ' , 'TRUNCATE sch . ' ) 'INSERT INTO sch . ' , def test_truncate_suggests_qualified_tables ( ) : ( 'copy ' , 'from ' , 'update ' , 'into ' , 'describe ' , 'truncate ' ) ) : 'COPY sch . ' , if schema : ] ) # If already schema-qualified , suggest only tables/views suggest.insert ( 0 , { 'type ' : 'schema ' } ) token_v = token.value 'UPDATE ' , 'USE ' , 'USER ' , 'USING ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , token_v = token.tokens [ -1 ] .value def test_truncate_suggests_tables_and_schemas ( ) : 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'UID ' , 'UNION ' , 'UNIQUE ' , assert sorted_dicts ( suggestions ) == sorted_dicts ( [ suggestions = suggest_type ( expression , expression ) 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'USING ' , 'VALIDATE ' , 'VALUES ' , token_v = token { 'type ' : 'schema ' } ] ) elif token_v in ( ' c ' , 'use ' , 'database ' , 'template ' ) : 'UPDATE sch . ' , elif ( token_v.endswith ( 'join ' ) and token.ttype in Keyword ) or ( token_v in 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' ] rel_type = token_v 'SELECT * FROM ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] def test_expression_suggests_tables_views_and_schemas ( expression ) : # Suggest schemas else : elif token_v.lower ( ) in ( 'select ' , 'where ' , 'having ' ) : token_v.lower ( ) .endswith ( 'join ' ) and token.ttype in Keyword ) : return suggest def test_expression_suggests_qualified_tables_views_and_schemas ( expression ) : elif token_v.lower ( ) == 'on ' :","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_sqlcompletion.py']",Merge pull request # 208 from drocco007/feature/truncate
459,cd1c9eaa7336c18f1229712fc4a1eb223640b83d,2015-04-17 18:45:57-07:00,"reconnect = click.prompt ( 'Connection reset . Reconnect ( Y/n ) ' , except OperationalError as e : click.secho ( str ( e ) , err=True , fg='red ' ) try : if ( 'server closed the connection ' in utf8tounicode ( e.args [ 0 ] ) ) : if reconnect : logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) else : click.secho ( str ( e ) , err=True , fg='red ' ) click.secho ( 'Reconnected ! \nTry the command again . ' , fg='green ' ) reconnect = True logger.error ( `` sql : % r , error : % r '' , document.text , e ) except OperationalError as e : show_default=False , type=bool , default=True ) pgexecute.connect ( )",['pgcli/main.py'],Merge pull request # 210 from amjith/reconnect
460,049c51b97100f9f8e149859faad794937ed7dc93,2015-04-16 22:30:38-07:00,"return 0 return None suggestion = suggest_type ( text , text ) self [ elem ] = self_get ( elem , 0 ) + 1 ' '' Intersection is the minimum of corresponding counts . class Counter ( dict ) : ' '' Create a new , empty Counter object . And if given , count elements def __or__ ( self , other ) : # Override dict methods where the meaning changes for Counter objects . > > > c = Counter ( ) # a new , empty counter return sorted ( self.iteritems ( ) , key=itemgetter ( 1 ) , reverse=True ) def test_join_suggests_tables_and_schemas ( ) : def elements ( self ) : def test_join_table ( join_type ) : everything after the last keyword stripped def __missing__ ( self , key ) : elements ( ) will ignore it . if newcount > 0 : > > > c [ ' h ' ] # four ' h ' in which , witch , and watch # condition . So we need to ignore the keyword JOIN . # tbl1 INNER JOIN tbl2 USING ( col1 , col2 ) dict.__delitem__ ( self , elem ) ' '' # We 're probably in a function argument list > > > c = Counter ( 'gallahad ' ) # a new counter from an iterable # To strip negative and zero counts , add-in an empty counter : def most_common ( self , n=None ) : > > > Counter ( 'abbbc ' ) - Counter ( 'bccd ' ) 'Counter.fromkeys ( ) is undefined . Use Counter ( iterable ) instead . ' ) ' '' Dict subclass for counting hashable objects . Sometimes called a bag Counter ( { ' b ' : 3 , ' c ' : 2 , ' a ' : 1 } ) return Counter ( self ) text = 'select * from abc inner join def using ( ' + col_list assert kw == ' ( ' and q2 == 'select * from tbl1 inner join tbl2 using ( ' result = Counter ( ) ' '' Iterator over elements repeating each as many times as its count . return ' % s ( { % s } ) ' % ( self.__class__.__name__ , items ) for t in reversed ( list ( sqlparse.parse ( sql ) [ 0 ] .flatten ( ) ) ) : # copied from http : //code.activestate.com/recipes/576611-counter-class/ prev_keyword , text_before_cursor = find_prev_keyword ( text_before_cursor ) result [ elem ] = newcount > > > c = Counter ( 'which ' ) > > > c = Counter ( 'ABCABC ' ) Counter ( { ' b ' : 1 } ) self.update ( kwds ) elif item.ttype is Keyword and ( tables = extract_tables ( sql ) [ ' A ' , ' A ' , ' B ' , ' B ' , ' C ' , ' C ' ] # drop_unique is used for 'tb11 JOIN tbl2 USING ( ... ' tables = extract_tables ( 'SELECT * FROM abc a JOIN def d ON a.id = d.num ' ) elif item.ttype is Keyword and item.value.upper ( ) not in ( 'FROM ' , 'JOIN ' ) : def __sub__ ( self , other ) : return NotImplemented ' '' List the n most common elements and their counts from the most from operator import itemgetter if prev_tok and prev_tok.value and prev_tok.value.lower ( ) == 'using ' : except ImportError : if p.token_first ( ) .value.lower ( ) == 'select ' : Source can be an iterable , a dictionary , or another Counter instance . from pgcli.packages.parseutils import find_prev_keyword for _ in repeat ( None , count ) : common to the least . If n is None , then list all element counts . if elem in self : > > > Counter ( 'abracadabra ' ) .most_common ( 3 ) ' '' Add counts from two counters . of elements to their counts . 'Like dict.__delitem__ ( ) but does not raise KeyError for missing values . ' Counter ( { ' b ' : 2 , ' a ' : 1 } ) newcount = self [ elem ] + other [ elem ] elif p.token_first ( ) .value.lower ( ) == 'select ' : self [ elem ] = self_get ( elem , 0 ) + count # suggest columns that are present in more than one table 'tables ' : [ ( None , 'abc ' , None ) , ( None , 'def ' , None ) ] , items = ' , '.join ( map ( ' % r : % r'.__mod__ , self.most_common ( ) ) ) if suggestion.get ( 'drop_unique ' ) : > > > Counter ( 'abbb ' ) + Counter ( 'bcc ' ) Document ( text=text , cursor_position=pos ) , complete_event ) ) _min = min ' '' return t.value # ' '' Union is the maximum of value in either of the input counters . kw , q2 = find_prev_keyword ( q ) not item.value.upper ( ) == 'FROM ' ) and ( # Get the token before the parens text = 'SELECT * FROM users INNER JOIN orders USING ( ' 4 prev_keyword = find_prev_keyword ( text_before_cursor ) Counter ( { ' b ' : 4 , ' c ' : 2 , ' a ' : 1 } ) for elem , count in self.iteritems ( ) : elif token_v.lower ( ) in ( 'copy ' , 'from ' , 'update ' , 'into ' , 'describe ' , [ ( ' a ' , 5 ) , ( ' r ' , 2 ) , ( ' b ' , 2 ) ] if not self : else : # INNER JOIN , FULL OUTER JOIN , etc . 'drop_unique ' : True } ] `` `` '' # Knuth TAOCP Volume II section 4.6.3 exercise 19 def test_join_using_suggests_common_columns ( col_list ) : or multiset . Elements are stored as dictionary keys and their counts def __repr__ ( self ) : idx = parsed.token_index ( t ) _max = max def fromkeys ( cls , iterable , v=None ) : ' '' Like dict.update ( ) but add counts instead of replacing them . `` `` '' Find the last sql keyword in an SQL statement if len ( self ) < len ( other ) : return nlargest ( n , self.iteritems ( ) , key=itemgetter ( 1 ) ) raise NotImplementedError ( tables = extract_tables ( full_text ) # one table If an element 's count has been set to zero or is a negative number , assert set ( result ) == set ( [ if iterable is not None : def test_join_suggests_tables_and_schemas ( tbl_alias , join_type ) : from an input iterable . Or , initialize the count from another mapping for t in reversed ( list ( parsed.flatten ( ) ) ) : self_get = self.get 'SELECT * FROM abc a JOIN ' ) # Multiset-style mathematical operations discussed in : for elem in iterable : self , other = other , self > > > c.update ( 'witch ' ) # add elements from another iterable # and at http : //en.wikipedia.org/wiki/Multiset yield elem self.update ( iterable , * * kwds ) dict.update ( self , iterable ) # fast path when counter is empty else : def test_join_using_suggests_common_columns ( completer , complete_event ) : q = 'select * from tbl1 inner join tbl2 using ( col1 , ' def test_join_table ( ) : elif token_v.lower ( ) in ( 'copy ' , 'from ' , 'update ' , 'into ' , 'describe ' ) or ( in Counter ( scoped_cols ) .items ( ) text = `` .join ( tok.value for tok in parsed.tokens [ : idx+1 ] ) > > > c = Counter ( { ' a ' : 4 , ' b ' : 2 } ) # a new counter from a mapping from collections import Counter > > > Counter ( 'abbb ' ) & Counter ( 'bcc ' ) # which should suggest only columns that appear in more than Counter ( { ' y ' : 3 , ' z ' : 2 , ' g ' : 1 } ) def __delitem__ ( self , elem ) : suggestion = suggest_type ( 'SELECT * FROM abc a JOIN ' , from .packages.counter import Counter scoped_cols = [ col for ( col , count ) if kwds : parsed = sqlparse.parse ( sql ) [ 0 ] return None , `` def update ( self , iterable=None , * * kwds ) : from heapq import nlargest newcount = _min ( self [ elem ] , other [ elem ] ) { 'type ' : 'column ' , assert suggest_type ( text , text ) == [ def __init__ ( self , iterable=None , * * kwds ) : from itertools import repeat , ifilter > > > c = Counter ( a=4 , b=2 ) # a new counter from keyword args > > > Counter ( 'zyzygy ' ) result = set ( completer.get_completions ( 'Like dict.copy ( ) but returns a Counter instance instead of a dict . ' > > > d = Counter ( 'watch ' ) newcount = _max ( self [ elem ] , other [ elem ] ) # Outputs guaranteed to only include positive counts . return t.value , text are stored as dictionary values . def copy ( self ) : if n is None : newcount = self [ elem ] - other [ elem ] if not isinstance ( other , Counter ) : # condition . So we need to ignore the keyword JOIN and its variants Returns the value of the last keyword , and the text of the query with # c += Counter ( ) try : def __add__ ( self , other ) : if count > 1 and col ! = ' * ' ] text = 'SELECT * FROM abc { 0 } { 1 } JOIN '.format ( tbl_alias , join_type ) return result for elem , count in iterable.iteritems ( ) : sql = 'SELECT * FROM abc a { 0 } JOIN def d ON a.id = d.num'.format ( join_type ) not item.value.upper ( ) .endswith ( 'JOIN ' ) ) : token_v.lower ( ) .endswith ( 'join ' ) and token.ttype in Keyword ) : for elem in set ( self ) | set ( other ) : if self : if hasattr ( iterable , 'iteritems ' ) : > > > c.update ( d ) # add elements from another counter return None , `` > > > sorted ( c.elements ( ) ) prev_tok = p.token_prev ( len ( p.tokens ) - 1 ) pos = len ( text ) def test_find_prev_keyword_using ( ) : ' '' Subtract count , but keep only results with positive counts . for elem in ifilter ( self.__contains__ , other ) : self_get = self.get from sqlparse.tokens import Keyword 'join ' ) : Completion ( text='id ' , start_position=0 ) ] ) # python 2.6 def __and__ ( self , other ) : > > > Counter ( 'abbb ' ) | Counter ( 'bcc ' ) return ' % s ( ) ' % self.__class__.__name__ return [ { 'type ' : 'column ' , 'tables ' : tables , 'drop_unique ' : True } ]","['pgcli/packages/counter.py', 'pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_parseutils.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 190 from darikg/joins
461,fbe25db9cf1a863b8910a614150463c86a240aba,2015-04-15 11:09:53-07:00,"'\\di ' : ( list_indexes , [ '\\di [ + ] [ pattern ] ' , 'List indexes . ' ] ) , '\d ' : ( describe_table_details , [ '\d [ pattern ] ' , 'List or describe tables , views and sequences . ' ] ) , except NotImplementedError : def in_progress ( cur , arg , verbose ) : `` `` '' '\\dv ' : ( list_views , [ '\\dv [ + ] [ pattern ] ' , 'list views . ' ] ) , '\du ' : ( list_roles , [ '\du [ + ] [ pattern ] ' , 'List roles . ' ] ) , '\d ' : ( describe_table_details , [ '\d [ pattern ] ' , 'list or describe tables , views and sequences . ' ] ) , '\do ' : ( in_progress , [ '\do [ S ] [ pattern ] ' , 'Not yet implemented . ' ] ) , '\sf ' : ( in_progress , [ '\sf [ + ] funcname ' , 'Not yet implemented . ' ] ) , click.secho ( 'Not Yet Implemented . ' , fg= '' yellow '' ) '\\dt ' : ( list_tables , [ '\\dt [ + ] [ pattern ] ' , 'list tables . ' ] ) , '\e ' : ( in_progress , [ '\e [ file ] [ line ] ' , 'Not yet implemented . ' ] ) , '\\df ' : ( list_functions , [ '\\df [ + ] [ pattern ] ' , 'List functions . ' ] ) , '\\dt ' : ( list_tables , [ '\\dt [ + ] [ pattern ] ' , 'List tables . ' ] ) , 'dT ' : ( in_progress , [ '\dT [ S+ ] [ pattern ] ' , 'Not yet implemented . ' ] ) '\dn ' : ( list_schemas , [ '\dn [ + ] [ pattern ] ' , 'list schemas ' ] ) , '\z ' : ( in_progress , [ '\z [ pattern ] ' , 'Not yet implemented . ' ] ) , '\\dv ' : ( list_views , [ '\\dv [ + ] [ pattern ] ' , 'List views . ' ] ) , '\\ds ' : ( list_sequences , [ '\\ds [ + ] [ pattern ] ' , 'List sequences . ' ] ) , '\du ' : ( list_roles , [ '\du [ + ] [ pattern ] ' , 'list roles ' ] ) , '\\di ' : ( list_indexes , [ '\\di [ + ] [ pattern ] ' , 'list indexes . ' ] ) , Stub method to signal about commands being under development . '\l ' : ( `` 'SELECT datname FROM pg_database ; ' '' , [ '\l ' , 'List databases . ' ] ) , raise NotImplementedError '\ef ' : ( in_progress , [ '\ef [ funcname [ line ] ] ' , 'Not yet implemented . ' ] ) , '\\df ' : ( list_functions , [ '\\df [ + ] [ pattern ] ' , 'list functions . ' ] ) '\l ' : ( `` 'SELECT datname FROM pg_database ; ' '' , [ '\l ' , 'list databases . ' ] ) , '\dn ' : ( list_schemas , [ '\dn [ + ] [ pattern ] ' , 'List schemas . ' ] ) , '\\ds ' : ( list_sequences , [ '\\ds [ + ] [ pattern ] ' , 'list sequences . ' ] ) ,","['pgcli/main.py', 'pgcli/packages/pgspecial.py']",Merge pull request # 204 from j-bennet/master
462,7d4e57090c679e628259d5dab2fc9c0c33dfcb64,2015-04-15 06:29:43-07:00,"text = 'SELECT om ' completion only at the beginning . Otherwise , a completion is # also suggest hardcoded functions match_end_limit = len ( text ) if start_only else None user_funcs = self.find_matches ( word_before_cursor , funcs ) item.startswith ( text.lower ( ) ) ) : If ` start_only ` is True , the text will match an available result = [ c.text for c in funcs.extend ( self.functions ) text = 'SELECT IN ' keywords = self.find_matches ( word_before_cursor , self.keywords ) def test_user_function_name_completion_matches_anywhere ( completer , funcs = self.find_matches ( word_before_cursor , funcs ) text = last_word ( text , include='most_punctuations ' ) def find_matches ( text , collection , start_only=False ) : def test_builtin_function_matches_only_at_start ( completer , complete_event ) : # suggest user-defined functions using substring matching yields prompt_toolkit Completion instances for any matches found functions = [ 'AVG ' , 'COUNT ' , 'FIRST ' , 'FORMAT ' , 'LAST ' , 'LCASE ' , 'LEN ' , document = Document ( text=text , cursor_position=position ) start_only=True ) self.special_commands , considered a match if the text appears anywhere within it . completer.get_completions ( document , complete_event ) ] return self.find_matches ( word_before_cursor , self.all_completions , keywords = self.find_matches ( word_before_cursor , self.keywords , assert set ( result ) == set ( [ Completion ( text='custom_func1 ' , start_position=-2 ) , assert 'MIN ' not in result self.special_commands ) position = len ( 'SELECT IN ' ) completions.extend ( predefined_funcs ) completions.extend ( user_funcs ) def find_matches ( text , collection ) : start_only=True ) functions = [ 'AVG ' , 'COUNT ' , 'DISTINCT ' , 'FIRST ' , 'FORMAT ' , 'LAST ' , 'MAX ' , 'MIN ' , 'MID ' , 'NOW ' , 'ROUND ' , 'SUM ' , 'TOP ' , 'UCASE ' ] match_point = item.lower ( ) .find ( text , 0 , match_end_limit ) result = completer.get_completions ( Completion ( text='custom_func2 ' , start_position=-2 ) ] ) 'LCASE ' , 'LEN ' , 'MAX ' , 'MIN ' , 'MID ' , 'NOW ' , 'ROUND ' , 'SUM ' , 'TOP ' , predefined_funcs = self.find_matches ( word_before_cursor , Given the user 's input text and a collection of available if match_point > = 0 : start_only=True ) self.functions , text = last_word ( text , include='most_punctuations ' ) .lower ( ) completions.extend ( funcs ) # also suggest hardcoded functions using startswith return self.find_matches ( word_before_cursor , self.all_completions ) Document ( text=text , cursor_position=position ) , complete_event ) in the collection of available completions . `` `` '' Find completion matches for the given text . text . # matching completions , find completions matching the last word of the if ( item.startswith ( text ) or item.startswith ( text.upper ( ) ) or start_only=True ) 'UCASE ' ] `` `` '' complete_event ) : position = len ( 'SELECT om ' )","['pgcli/pgcompleter.py', 'tests/test_smart_completion_public_schema_only.py']",Merge pull request # 202 from drocco007/feature/match-anywhere
463,c7f173d4ca97819f9db5b1c704a09a82e5106e62,2015-04-14 21:57:55-07:00,"end sudo /usr/local/bin/fpm -t rpm -s dir -C build -n pgcli -v # { pgcli_version } \ rm -rf build build/usr/share/pgcli/bin/pip uninstall -y distribute after-install /pgcli/post-install \ mkdir -p build/usr/share echo `` Removing symlink to pgcli '' .vagrant/ centos.vm.provision `` shell '' , inline : < < -SHELL after-remove /pgcli/post-remove \ echo `` - > Building DEB on ` lsb_release -s ` `` config.vm.define `` centos '' do |centos| virtualenv-tools -- update-path /usr/share/pgcli > /dev/null virtualenv build/usr/share/pgcli cd build/usr/share/pgcli * .iml sudo apt-get install -y libpq-dev python-dev python-setuptools rubygems d python-devel \ echo `` - > Cleaning Virtualenv '' # ! /bin/bash # vi : set ft=ruby : # - * - mode : ruby - * url https : //github.com/amjith/pgcli \ * .deb echo `` Setting up symlink to pgcli '' SHELL find build -iname ' * .pyc ' -delete build/usr/share/pgcli/bin/pip install /pgcli description `` # { pgcli_description } '' \ sudo fpm -t deb -s dir -C build -n pgcli -v # { pgcli_version } \ sudo pip install virtualenv virtualenv-tools # ! /bin/bash echo `` - > Building RPM on ` lsb_release -s ` `` d python-dev \ sudo easy_install pip sudo yum install -y rpm-build gcc ruby-devel postgresql-devel python-devel rubygems end rm /usr/local/bin/pgcli echo `` - > Removing compiled files '' config.vm.synced_folder `` . `` , `` /pgcli '' d libpq-dev \ cd /home/vagrant/ * .iml Vagrant.configure ( 2 ) do |config| d postgresql-devel \ build/usr/share/pgcli/bin/pip install -U pip distribute # Generated Packages p /pgcli/ \ ln -sf /usr/share/pgcli/bin/pgcli /usr/local/bin/pgcli echo `` - > Creating PgCLI deb '' sudo apt-get update centos.vm.box = `` chef/centos-7.0 '' pgcli_version = ENV [ 'version ' ] pgcli_description = `` Postgres CLI with autocompletion and syntax highlighting '' find build -iname ' * .pyo ' -delete config.vm.define `` debian '' do |debian| * .rpm echo `` - > Creating PgCLI RPM '' echo `` - > Cleaning up old workspace '' # Vagrant license ' ? ? ? # TODO ( amjith ) ' sudo gem install fpm echo $ PATH a all \ debian.vm.box = `` chef/debian-7.8 '' debian.vm.provision `` shell '' , inline : < < -SHELL","['.gitignore', 'Vagrantfile', 'post-install', 'post-remove']",Merge pull request # 199 from ceocoder/add_deb_packaging
464,dc94ca382048339ffbb144da0a28f47d6b562dfb,2015-04-14 17:07:28-07:00,"assert list ( executor.views ( ) ) == [ assert set ( executor.table_columns ( ) ) > = set ( [ AND nsp.nspname ! ~ '^pg_ ' ( 'public ' , 'd ' ) ] ) # the pg_catalog tables that are implicitly on the search path AND nsp.nspname < > 'information_schema ' views = [ v for v in views if not v.startswith ( 'pg_ ' ) ] ( 'public ' , ' b ' , ' z ' ) , ( 'schema1 ' , ' c ' , ' w ' ) ] 'public ' , 'pg_catalog ' , 'information_schema ' , 'schema1 ' , 'schema2 ' ] ) tables = [ t for t in tables if not t.startswith ( 'pg_ ' ) ] AND n.nspname ! ~ '^pg_ ' # The boolean argument to the current_schemas function indicates whether # Unless we 're sure the user really wants them , do n't suggest ( 'public ' , ' b ' , ' z ' ) , ( 'schema1 ' , ' c ' , ' w ' ) ] ) ( 'public ' , ' a ' ) , ( 'public ' , ' b ' ) , ( 'schema1 ' , ' c ' ) ] ) ( 'public ' , ' a ' ) , ( 'public ' , ' b ' ) , ( 'schema1 ' , ' c ' ) ] assert list ( executor.view_columns ( ) ) == [ SELECT * FROM unnest ( current_schemas ( true ) ) ' '' if not s.startswith ( 'pg_ ' ) ] schema_names = [ s for s in schema_names AND nspname < > 'information_schema ' assert list ( executor.table_columns ( ) ) == [ # implicit schemas , e.g . pg_catalog assert set ( executor.schemata ( ) ) > = set ( [ if not word_before_cursor.startswith ( 'pg_ ' ) : ( 'public ' , 'd ' ) ] if not suggestion [ 'schema ' ] and ( ( 'public ' , 'd ' , ' e ' ) ] ) assert set ( executor.tables ( ) ) > = set ( [ assert executor.schemata ( ) == [ 'public ' , 'schema1 ' , 'schema2 ' ] SELECT * FROM unnest ( current_schemas ( false ) ) ' '' # Unless we 're sure the user really wants them , hide schema assert set ( executor.views ( ) ) > = set ( [ assert list ( executor.tables ( ) ) == [ assert set ( executor.view_columns ( ) ) > = set ( [ ( 'public ' , 'd ' , ' e ' ) ] # names starting with pg_ , which are mostly temporary schemas # do n't enforce all members of the schemas since they may include postgres assert executor.search_path ( ) == [ 'pg_catalog ' , 'public ' ] assert executor.search_path ( ) == [ 'public ' ] WHERE nspname ! ~ '^pg_ ' # temporary schemas not word_before_cursor.startswith ( 'pg_ ' ) ) :","['pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 195 from darikg/pg_catalog
465,4161f66ccaacc57b445f1a1add35c429de84c63a,2015-04-11 12:28:41-04:00,"assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'schema_name ' } ] assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'schema_name ' } ] schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] suggestions = suggest_type ( text , text ) def test_handle_pre_completion_comma_gracefully ( text ) : assert iter ( suggestions ) return [ ] else :","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 198 from drocco007/master
466,9ea8cadaccc55f10a8bec5804573f740d51bdfbb,2015-04-05 17:24:00-07:00,"{ 'type ' : 'view ' , 'schema ' : 'tabl ' } , 'join ' , 'table ' ) : # schemata Includes both views and and materialized views elif cmd [ 1 : ] == 'df ' : for row in self._relations ( kinds= [ ' r ' ] ) : # If already schema-qualified , suggest only tables/views def _relations ( self , kinds= ( ' r ' , ' v ' , 'm ' ) ) : comp.extend_functions ( functions ) columns.extend ( meta [ schema ] [ table ] ) comp.extend_columns ( columns ) table = self.escape_name ( tbl [ 1 ] ) return [ { 'type ' : 'table ' , 'schema ' : schema } ] for schema , table , column in column_data : columns.extend ( meta [ 'views ' ] [ schema ] [ relname ] ) columns.extend ( meta [ 'views ' ] [ schema ] [ relname ] ) sql = cur.mogrify ( self.tables_query , [ kinds ] ) pass assert list ( executor.tables ( ) ) == [ _logger.debug ( 'Tables Query . sql : % r ' , sql ) for schema , table in table_data : _logger.error ( 'Table % r listed in unrecognized schema % r ' , assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'myschema ' } , assert list ( executor.views ( ) ) == [ assert executor.tables ( ) == [ for view , cols in metadata [ 'views ' ] .items ( ) : # views { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] ) { 'type ' : 'view ' , 'schema ' : ' a ' } , completer.extend_relations ( pgexecute.tables ( ) , kind='tables ' ) elif cmd [ 1 : ] in ( 'dt ' , 'dv ' , 'df ' ) : Completion ( text='orders ' , start_position=0 ) , # \d can descibe tables or views # at a time { 'type ' : 'table ' , 'schema ' : [ ] } , # tables run ( executor , `` create view d as select 1 as e '' ) `` `` '' Yields ( schema_name , table_name ) tuples '' '' '' { 'type ' : 'view ' , 'schema ' : [ ] } ] yield row schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] def extend_columns ( self , column_data ) : return [ { 'type ' : 'table ' , 'schema ' : schema } , ( 'public ' , 'd ' , ' e ' ) ] # Schema not specified , so traverse the search path looking for metadata [ schema ] [ table ] .append ( column ) comp.extend_relations ( tables , kind='tables ' ) metadata [ schema ] [ relname ] .append ( column ) elif token_v.lower ( ) == 'function ' : { 'type ' : 'schema ' } ] ) # Either the schema or table does n't exist : return : `` `` '' Get table or view name metadata { 'type ' : 'table ' , 'schema ' : [ ] } , # tables try : def table_columns ( self ) : # tables and views can not share the same name , we can check one with self.conn.cursor ( ) as cur : metadata = self.dbmetadata [ kind ] completer.extend_relations ( pgexecute.views ( ) , kind='views ' ) self.all_completions = set ( self.keywords + self.functions ) return [ { 'type ' : rel_type , 'schema ' : schema } ] assert executor.search_path ( ) == [ 'public ' ] def views ( self ) : WHERE c.relkind = ANY ( % s ) 'user_emails ' : [ 'id ' , 'email ' ] } , self.dbmetadata = { 'tables ' : { } , 'views ' : { } , 'functions ' : { } } return [ { 'type ' : 'schema ' } , { 'type ' : rel_type , 'schema ' : [ ] } ] elif suggestion [ 'type ' ] == 'view ' : views = self.find_matches ( word_before_cursor , views ) { 'type ' : rel_type , 'schema ' : [ ] } ] if cmd [ 1 : ] == 'd ' : { 'type ' : 'view ' , 'schema ' : 't1 ' } , { 'type ' : 'table ' , 'schema ' : [ ] } , def test_d_dot_suggests_schema_qualified_tables_or_views ( ) : metadata [ schema ] [ relname ] = [ ' * ' ] with self.conn.cursor ( ) as cur : for row in cur : comp.extend_tables ( tables ) { 'type ' : 'view ' , 'schema ' : schema } ] continue `` `` '' extend column metadata # Get columns from the corresponding schema.table WHERE c.relkind IN ( ' r ' , ' v ' , 'm ' ) -- table , view , materialized view # E.g . 'DROP FUNCTION < funcname > ' `` `` '' Yields ( schema_name , view_name ) tuples . : param kinds : list of postgres relkind filters : relname = self.escape_name ( tbl [ 1 ] ) # schemata if cmd [ 1 : ] in ( 'd ' , 'dt ' , 'dv ' ) : columns.extend ( [ ( 'public ' , view , col ) for col in cols ] ) # each schema before checking the next schema _logger.debug ( 'Columns Query . sql : % r ' , sql ) comp.extend_schemata ( schemata ) return [ { 'type ' : 'function ' , 'schema ' : schema } ] cur.execute ( self.columns_query ) ' v ' - view { 'type ' : 'table ' , 'schema ' : [ ] } , assert executor.search_path ( ) == [ 'public ' ] self.all_completions = set ( self.keywords ) { 'type ' : 'schema ' } , try : completer.extend_columns ( pgexecute.view_columns ( ) , kind='views ' ) except KeyError : yield row ( 'public ' , 'd ' ) ] # We do n't know if schema.relname is a table or view . Since comp.extend_columns ( columns , kind='tables ' ) : return : list of ( schema_name , relation_name , column_name ) tuples : return : ( schema_name , rel_name ) tuples Completion ( text='orders ' , start_position=0 ) ] ) # If already schema-qualified , suggest only tables # a table or view that matches . Note that in order to get proper metadata [ schema ] [ table ] = [ ' * ' ] table_data = [ self.escaped_names ( d ) for d in table_data ] cur.execute ( self.tables_query ) completer.extend_columns ( pgexecute.table_columns ( ) , kind='tables ' ) : param column_data : list of ( schema_name , rel_name , column_name ) tuples return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] columns.extend ( meta [ schema ] [ table ] ) : param data : list of ( schema_name , rel_name ) tuples def _columns ( self , kinds= ( ' r ' , ' v ' , 'm ' ) ) : # A fully qualified schema.relname reference return [ { 'type ' : 'schema ' } , { 'type ' : 'function ' , 'schema ' : [ ] } ] # functions views , columns = [ ] , [ ] elif token_v.lower ( ) in ( 'table ' , 'view ' , 'function ' ) : `` `` '' Returns a list of ( schema_name , table_name , column_name ) tuples '' '' '' def test_d_suggests_tables_and_schemas ( ) : table = self.escape_name ( tbl [ 1 ] ) columns.extend ( meta [ 'tables ' ] [ schema ] [ relname ] ) # functions def extend_tables ( self , table_data ) : # E.g . 'DROP FUNCTION < funcname > ' , 'ALTER TABLE < tablname > ' self.all_completions.update ( t [ 1 ] for t in data ) comp.extend_relations ( views , kind='views ' ) ' r ' - table self.dbmetadata = { 'tables ' : { } , 'functions ' : { } } 'join ' ) : { 'type ' : 'view ' , 'schema ' : 'myschema ' } ] { 'type ' : 'view ' , 'schema ' : [ ] } , _logger.debug ( 'Columns Query . sql : % r ' , self.columns_query ) columns.extend ( meta [ 'tables ' ] [ schema ] [ relname ] ) views = self.populate_schema_objects ( # column_data is a list of ( schema_name , table_name , column_name ) tuples break WHERE cls.relkind IN ( ' r ' , ' v ' , 'm ' ) suggestion [ 'schema ' ] , 'views ' ) def test_d_suggests_tables_views_and_schemas ( ) : def test_schemata_table_views_and_columns_query ( executor ) : { 'type ' : 'view ' , 'schema ' : 't ' } , # shadowing behavior , we need to check both views and tables for comp.extend_columns ( columns , kind='views ' ) return [ { 'type ' : 'schema ' } , # Suggest schemas OR public tables # Table exists , so do n't bother checking for a view def extend_columns ( self , column_data , kind ) : { 'type ' : 'view ' , 'schema ' : 'd ' } , { 'type ' : 'view ' , 'schema ' : parent } , def test_schemata_table_and_columns_query ( executor ) : completions.extend ( views ) { 'type ' : 'view ' , 'schema ' : [ ] } ] ) _logger.debug ( 'Tables Query . sql : % r ' , self.tables_query ) { 'type ' : 'view ' , 'schema ' : [ ] } , { 'type ' : 'view ' , 'schema ' : 't2 ' } , rel_type = token_v.lower ( ) kind , relname , schema ) { 'type ' : 'table ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) # A fully qualified schema.table reference 'm ' - materialized view completer.extend_columns ( pgexecute.columns ( ) ) Completion ( text='user_emails ' , start_position=0 ) , `` `` '' Returns a list of ( schema_name , table_name ) tuples `` '' '' { 'type ' : 'table ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) meta = self.dbmetadata [ 'tables ' ] { 'type ' : 'schema ' } ] ) Completion ( text='user_emails ' , start_position=0 ) ] ) # table_data is a list of ( schema_name , table_name ) tuples for schema , relname , column in column_data : : param kind : either 'tables ' or 'views ' _logger.error ( ' % r % r listed in unrecognized schema % r ' , rel_type = { 'dt ' : 'table ' , 'dv ' : 'view ' , 'df ' : 'function ' } [ cmd [ 1 : ] ] views.append ( ( 'public ' , view ) ) cur.execute ( sql ) comp.extend_functions ( functions ) except KeyError : completer.extend_tables ( pgexecute.tables ( ) ) # views for row in self._relations ( kinds= [ ' v ' , 'm ' ] ) : table , schema ) def view_columns ( self ) : return cur.fetchall ( ) for schema , relname in data : comp.extend_schemata ( schemata ) for row in self._columns ( kinds= [ ' v ' , 'm ' ] ) : sql = cur.mogrify ( self.columns_query , [ kinds ] ) meta = self.dbmetadata data = [ self.escaped_names ( d ) for d in data ] assert list ( executor.table_columns ( ) ) == [ relname = self.escape_name ( tbl [ 1 ] ) self.all_completions.update ( t [ 1 ] for t in table_data ) # databases def extend_relations ( self , data , kind ) : pass assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'myschema ' } ] assert executor.columns ( ) == [ : param kinds : kinds : list of postgres relkind filters : # Suggest schemas OR public tables/views def test_d_dot_suggests_schema_qualified_tables ( ) : for row in self._columns ( kinds= [ ' r ' ] ) : metadata = self.dbmetadata [ 'tables ' ] WHERE cls.relkind = ANY ( % s ) `` `` '' Get column metadata for tables and views schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] assert list ( executor.view_columns ( ) ) == [ def columns ( self ) : `` `` '' `` `` '' extend metadata for tables or views 'views ' : {","['pgcli/main.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py', 'tests/test_pgspecial.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 187 from darikg/views
467,08decb025788d47ed73092563ac4d78bf0b4d704,2015-04-05 14:30:28-07:00,return ' ' * lwidth + s rwidth = 0 if xwidth < = 0 else lwidth + xwidth % 2 lwidth = width - wcswidth ( _strip_invisible ( s ) if has_invisible else s ) return wcswidth ( _strip_invisible ( s ) ) return s + ' ' * rwidth iwidth = width + len ( s ) - len ( _strip_invisible ( s ) ) if has_invisible else width rwidth = width - wcswidth ( _strip_invisible ( s ) if has_invisible else s ) width_fn = wcswidth return wcswidth ( _text_type ( s ) ) xwidth = width - wcswidth ( _strip_invisible ( s ) if has_invisible else s ) fmt = `` { 0 : < % ds } '' % iwidth lwidth = xwidth // 2 fmt = `` { 0 : > % ds } '' % iwidth return len ( _text_type ( s ) ) return len ( _strip_invisible ( s ) ) fmt = `` { 0 : ^ % ds } '' % iwidth from wcwidth import wcswidth width_fn = len return fmt.format ( s ) return ' ' * lwidth + s + ' ' * rwidth,['pgcli/packages/tabulate.py'],Merge pull request # 186 from xalley/master
468,a80eb4ea199de413b9b5fe181647316e837b7eaa,2015-03-25 00:26:38-07:00,"return [ ( cur , headers , cur.statusmessage ) ] status , self.table_format ) ) return [ ( None , None , 'Did not find any relation named % s . ' % pattern ) ] output.extend ( format_output ( cur , headers , status , self.table_format ) ) return [ ( result , headers , None ) ] yield ( None , None , 'You are now connected to database `` % s '' as ' for title , rows , headers , status in executor.run ( sql ) : return [ ( None , cur , headers , cur.statusmessage ) ] return [ ( None , None , None , cur.statusmessage ) ] return ( None , None , None , 'Something went wrong . ' ) result.extend ( format_output ( rows , headers , status , 'psql ' ) ) output.append ( title ) yield ( None , None , None , 'You are now connected to database `` % s '' as ' yield ( None , None , None , None ) def format_output ( title , cur , headers , status , table_format ) : return ( None , None , 'Something went wrong . ' ) for cur , headers , status in res : return [ ( None , cur , headers , cur.statusmessage ) ] return [ ( cur , headers , cur.statusmessage ) ] try : * Notice messages raised as part of stored procedures are no longer ignored . def format_output ( cur , headers , status , table_format ) : return [ ( None , None , cur.statusmessage ) ] yield ( None , None , None ) for title , cur , headers , status in res : return ( None , None , cur.statusmessage ) return [ ( None , None , None , 'Did not find any relation named % s . ' % pattern ) ] return ( title , cur , headers , cur.statusmessage ) return [ ( None , None , message ) ] return ( None , None , None , 'Did not find any relation with OID % s . ' % oid ) title = self.conn.notices.pop ( ) except IndexError : return [ ( None , result , headers , None ) ] output.extend ( format_output ( title , cur , headers , return ( None , cells , headers , `` '' .join ( status ) ) ====== return ( None , None , 'Did not find any relation with OID % s . ' % oid ) 0.16.3 Bug Fixes : return ( title , None , None , cur.statusmessage ) title = None return ( cur , headers , cur.statusmessage ) if title : # Only print the title if it 's not None . return [ ( None , None , None , message ) ] return ( cells , headers , `` '' .join ( status ) ) result.extend ( format_output ( title , rows , headers , status , 'psql ' ) ) for rows , headers , status in executor.run ( sql ) : * Add more SQL keywords for auto-complete suggestion .","['changelog.rst', 'pgcli/main.py', 'pgcli/packages/pgspecial.py', 'pgcli/pgexecute.py', 'tests/utils.py']",Add a title field and report the notices . Closes # 177
469,979b5e711adcfaabfe5d10087153490d8646d6f2,2015-03-24 23:27:39-07:00,"'ELSE ' , 'ENCODING ' , 'ESCAPE ' , 'EXCLUSIVE ' , 'EXISTS ' , 'FILE ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , 'ORDER BY ' , 'OUTER ' , 'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'DELETE FROM ' , 'DELIMITER ' , 'DESC ' , 'DESCRIBE ' , 'DISTINCT ' , 'DROP ' , 'FLOAT ' , 'FOR ' , 'FORMAT ' , 'FORCE_QUOTE ' , 'FORCE_NOT_NULL ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'HAVING ' , 'HEADER ' , 'IDENTIFIED ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OIDS ' , 'OF ' , 'OWNER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'QUOTE ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'UID ' , 'UNION ' , 'UNIQUE ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'FUNCTION ' , 'GRANT ' , 'GROUP BY ' , 'HAVING ' , 'IDENTIFIED ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , 'UPDATE ' , 'USE ' , 'USER ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'INDEX ' , 'INITIAL ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'INTO ' , 'NUMBER ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'VALIDATE ' , 'VALUES ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , 'INDEX ' , 'INITIAL ' , 'INSERT INTO ' , 'SYSDATE ' , 'TABLE ' , 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'UID ' , 'PRIVILEGES ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'INTEGER ' , 'INTERSECT ' , 'INTO ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'DELETE FROM ' , 'DESC ' , 'DESCRIBE ' , 'DISTINCT ' , 'DROP ' , 'ELSE ' , 'FREEZE ' , 'FROM ' , 'FULL ' , 'FUNCTION ' , 'GRANT ' , 'GROUP BY ' , 'EXCLUSIVE ' , 'EXISTS ' , 'FILE ' , 'FLOAT ' , 'FOR ' , 'FROM ' , 'FULL ' ,",['pgcli/pgcompleter.py'],Add more keywords to completion list . Closes # 149
470,7e61c6ddfcc1680d67113dde6f45977d428ce903,2015-03-10 22:08:55-07:00,"assert value in run ( executor , `` select * from numbertest '' , join=True ) run ( executor , if isinstance ( string , bool ) : def test_large_numbers_render_directly ( executor , value ) : `` insert into numbertest ( a ) values ( { 0 } ) '' .format ( value ) ) if isinstance ( string , ( bool , Decimal , ) ) : from decimal import Decimal run ( executor , `` create table numbertest ( a numeric ) '' )","['pgcli/packages/tabulate.py', 'tests/test_pgexecute.py']",Merge pull request # 172 from drocco007/master
471,55120a99589eaf896a4b56cf347affb686445f33,2015-03-08 17:50:23-07:00,"Completion ( text='shipments ' , start_position=0 ) , # word_before_cursor may include a schema qualification , like if word_before_cursor [ -1 ] == ' ( ' or word_before_cursor [ 0 ] == '\\ ' : return [ { 'type ' : 'column ' , 'tables ' : extract_tables ( full_text ) } , tables = [ t for t in tables if identifies ( identifier , * t ) ] # This matches everything except spaces , parens , and comma # separately { 'type ' : 'table ' , 'schema ' : parent } , text = 'DROP TABLE schema_name.table_name ' aliases = [ t [ 2 ] or t [ 1 ] for t in tables ] if parent : tables = [ t for t in tables if identifies ( parent , * t ) ] parent = ( identifier and identifier.get_parent_name ( ) ) or [ ] suggestions.extend ( [ { 'type ' : 'table ' , 'schema ' : identifier } , identifier = None identifier = last_word ( token_v [ : -1 ] , 'all_punctuations ' ) return suggest_based_on_last_token ( last_token , text_before_cursor , full_text ) # If already schema-qualified , suggest only tables prev_keyword , text_before_cursor , full_text ) return [ { 'type ' : 'column ' , 'tables ' : extract_tables ( full_text ) } , alias = [ t [ 2 ] or t [ 1 ] for t in tables ] { 'type ' : 'function ' , 'schema ' : [ ] } ] assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'schema_name ' } ] Completion ( text='shipments ' , start_position=0 ) ] ) p = sqlparse.parse ( word_before_cursor ) [ 0 ] full_text , identifier ) { 'type ' : 'function ' , 'schema ' : [ ] } ] Completion ( text='func4 ' , start_position=0 ) ] ) 'join ' , 'table ' ) : suggestions = suggest_type ( text , text ) # TABLE. < suggestion > or SCHEMA.TABLE. < suggestion > # This matches everything except spaces , parens , comma , and period return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] if p.tokens and isinstance ( p.tokens [ 0 ] , Identifier ) : return [ { 'type ' : 'alias ' , 'aliases ' : alias } ] return [ { 'type ' : 'column ' , 'tables ' : tables } , include='most_punctuations ' ) def test_drop_schema_qualified_table_suggests_only_tables ( ) : from sqlparse.sql import Comparison # Use table alias if there is one , otherwise the table name or word_before_cursor [ 0 ] == '\\ ' ) : # `` schema_name.partial_name '' or `` schema_name . `` , so parse it # parent can be either a schema name or table alias { 'type ' : 'function ' , 'schema ' : identifier } ] ) return [ { 'type ' : 'schema ' } , { 'type ' : 'function ' , 'schema ' : [ ] } ] tables = extract_tables ( full_text ) # SCHEMA. < suggestion > if ( word_before_cursor [ -1 ] in ( ' ( ' , ' . ' ) # Check for a table alias or schema qualification # Suggest schemas OR public tables identifier = p.tokens [ 0 ] suggestions.append ( { 'type ' : 'column ' , 'tables ' : tables } ) return [ { 'type ' : 'table ' , 'schema ' : schema } ] 'join ' , 'table ' ) : # ON < suggestion > return [ { 'type ' : 'alias ' , 'aliases ' : aliases } ] return [ { 'type ' : 'schema ' } , { 'type ' : 'function ' , 'schema ' : [ ] } ] else : return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] 'many_punctuations ' : re.compile ( r ' ( [ ^ ( ) , \s ] + ) $ ' ) , tables = extract_tables ( full_text ) include='many_punctuations ' ) suggestions = [ ] return suggestions return [ { 'type ' : 'function ' , 'schema ' : schema } ] # `` ON parent. < suggestion > '' prev_keyword , text_before_cursor , full_text , identifier ) elif token_v.endswith ( ' . ' ) : return suggest_based_on_last_token ( last_token , text_before_cursor , from sqlparse.sql import Comparison , Identifier # Use table alias if there is one , otherwise the table name Completion ( text='func3 ' , start_position=0 ) , def suggest_based_on_last_token ( token , text_before_cursor , full_text , identifier ) : if schema : # This matches everything except spaces , parens and comma . schema = ( identifier and identifier.get_parent_name ( ) ) or [ ] def suggest_based_on_last_token ( token , text_before_cursor , full_text ) : { 'type ' : 'function ' , 'schema ' : parent } ]","['pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_sqlcompletion.py']",Merge pull request # 170 from darikg/better_dots
472,1e3a5a1338b6158ccca97d608898f79ed3c627ed,2015-02-28 21:48:56-08:00,"via the given connection . The function should accept a single argument of run ( executor , `` '' '' insert into jsonbtest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) import psycopg2.extras run ( executor , `` create table jsonbtest ( d jsonb ) '' ) ext.register_type ( ext.UNICODEARRAY ) the data as a string encoded in the database 's character encoding . json_types = register_json_typecasters ( conn , lambda x : x ) `` `` '' from utils import run , dbtest reason='Postgres server unavailable or json type not defined ' ) from utils import run , dbtest , requires_json , requires_jsonb available = set ( ) `` `` '' available.add ( name ) reason='Postgres server unavailable or jsonb type not defined ' ) Returns a set that is a subset of { 'json ' , 'jsonb ' } indicating which types ext.register_type ( psycopg2.extensions.UNICODE ) See http : //initd.org/psycopg/docs/connection.html # connection.encoding run ( executor , `` '' '' insert into jsontest ( d ) values ( ' { `` name '' : `` Éowyn '' } ' ) '' '' '' ) psycopg2.extensions.register_type ( ( if any ) were successfully registered . def register_json_typecasters ( conn , loads_fn ) : psycopg2.extensions.set_wait_callback ( psycopg2.extras.wait_select ) except psycopg2.ProgrammingError : register_json_typecasters ( self.conn , self._json_typecaster ) def _json_typecaster ( self , json_data ) : http : //initd.org/psycopg/docs/extras.html # json-adaptation not JSON_AVAILABLE , try : conn = db_connection ( ) psycopg2.extensions.new_type ( ( 17 , ) , 'BYTEA_TEXT ' , psycopg2.STRING ) ) SERVER_VERSION = conn.server_version def test_jsonb_renders_without_u_prefix ( executor , expanded ) : pass psycopg2.extras.register_json ( conn , loads=loads_fn , name=name ) from pgcli.pgexecute import register_json_typecasters result = run ( executor , `` SELECT d FROM jsonbtest LIMIT 1 '' , join=True ) psycopg2 's default handler for JSON data is json.loads . CAN_CONNECT_TO_DB = JSON_AVAILABLE = JSONB_AVAILABLE = False return available requires_jsonb = pytest.mark.skipif ( ext.register_type ( ext.new_type ( ( 17 , ) , 'BYTEA_TEXT ' , psycopg2.STRING ) ) run ( executor , `` create table jsontest ( d json ) '' ) CAN_CONNECT_TO_DB = False ext.set_wait_callback ( psycopg2.extras.wait_select ) JSONB_AVAILABLE = 'jsonb ' in json_types result = run ( executor , `` SELECT d FROM jsontest LIMIT 1 '' , join=True ) ext.register_type ( ext.UNICODE ) requires_json = pytest.mark.skipif ( def test_json_renders_without_u_prefix ( executor , expanded ) : ext.register_type ( psycopg2.extensions.UNICODEARRAY ) The raw data is decoded using the connection 's encoding , which defaults to the database 's encoding . return json_data.decode ( self.conn.encoding ) assert u ' { `` name '' : `` Éowyn '' } ' in result `` `` '' Set the function for converting JSON data for a connection . JSON_AVAILABLE = 'json ' in json_types for name in [ 'json ' , 'jsonb ' ] : types . SERVER_VERSION = 0 Use the supplied function to decode JSON data returned from the database This function attempts to register the typecaster for both JSON and JSONB db_connection ( ) not JSONB_AVAILABLE , `` `` '' Interpret incoming JSON data as a string .","['pgcli/pgexecute.py', 'tests/test_pgexecute.py', 'tests/utils.py']",Merge pull request # 165 from drocco007/master
473,cb39a712f96e74b193f7c62da9d062b047703162,2015-02-28 08:56:22-08:00,"as `` Argument data types '' , elif token_v in ( 'd ' , ) : # \d identifiers = other.split ( ' . ' ) cmd , _ , arg = parse_special_command ( text ) sql = `` ' SELECT n.nspname as `` Schema '' , pg_catalog.obj_description ( p.oid , 'pg_proc ' ) as `` Description '' `` ' def list_functions ( cur , pattern , verbose ) : # Identifer ( 'd ' , Whitespace , ' < other > ' ) WHEN p.proisagg THEN 'agg ' WHEN p.provolatile = ' i ' THEN 'immutable ' WHEN p.provolatile = 's ' THEN 'stable ' sql = cur.mogrify ( sql + ' ORDER BY 1 , 2 , 4 ' , params ) suggestions = suggest_type ( '\\dn xxx ' , '\\dn xxx ' ) suggestions = suggest_type ( '\\d ' , '\\d ' ) AND n.nspname < > 'information_schema ' `` ' def test_df_suggests_schema_or_function ( ) : if ( word_before_cursor [ -1 ] in ( ' ( ' , ' . ' ) '\\df ' : ( list_functions , [ '\\df [ + ] [ pattern ] ' , 'list functions . ' ] ) suggestions = suggest_type ( '\\ ' , '\\ ' ) if statement : if not ( schema_pattern or func_pattern ) : from .pgspecial import parse_special_command def test_slash_d_suggests_special ( ) : return [ { 'type ' : 'special ' } ] params = [ ] suggestions = suggest_type ( '\\df xxx ' , '\\df xxx ' ) or word_before_cursor [ 0 ] == '\\ ' ) : schema_pattern , func_pattern = sql_name_pattern ( pattern ) { 'type ' : 'function ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) # used , e.g . `` \d schema ? ? ? .name '' whitespace = ' ' parsed = sqlparse.parse ( arg ) [ 0 ] .tokens [ 0 ] return [ { 'type ' : 'table ' , 'schema ' : identifiers [ 0 ] } ] # Note that this will fail to obtain a schema name if wildcards are END as `` Type '' `` ' + verbose_columns + `` ' pg_catalog.pg_get_function_arguments ( p.oid ) cmd = '\\dn ' # Try to distinguish `` \d name '' from `` \d schema.name '' suggestions = suggest_type ( '\\df myschema.xxx ' , '\\df myschema.xxx ' ) if cmd == '\\c ' : if tok1 and tok1.value == '\\ ' : ON l.oid = p.prolang '' ' text = text.lstrip ( ) sql += ' pg_catalog.pg_function_is_visible ( p.oid ) ' schema = None as `` Result data type '' , if len ( identifiers ) == 1 : return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] elif len ( identifiers ) == 2 : try : def suggest_special ( text ) : if cur.description : WHERE `` ' if cmd == '\\dn ' : if cmd == text : def test_dn_suggests_schemata ( ) : assert suggestions == [ { 'type ' : 'function ' , 'schema ' : 'myschema ' } ] verbose_table = `` ' LEFT JOIN pg_catalog.pg_language l if schema_pattern : # Check for special commands and handle those separately schema = None return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] else : if arg : p.prosrc as `` Source code '' , sql += ' AND p.proname ~ % s ' return [ { 'type ' : 'schema ' } ] # Be careful here because trivial whitespace is parsed as a statement , return [ { 'type ' : 'keyword ' } , { 'type ' : 'special ' } ] suggestions = suggest_type ( whitespace + cmd , whitespace + cmd ) suggestions = suggest_type ( '\\dn ' , '\\dn ' ) return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] assert suggestions == suggest_type ( cmd , cmd ) # \d schema.table return [ { 'type ' : 'database ' } ] if func_pattern : # but the statement wo n't have a first token return [ { 'type ' : 'table ' , 'schema ' : schema } ] schema = parsed.get_parent_name ( ) sql += ' n.nspname ~ % s ' other = token.tokens [ -1 ] .value assert sorted_dicts ( suggestions ) == sorted_dicts ( THEN 'trigger ' return [ { 'type ' : 'schema ' } , { 'type ' : 'function ' , 'schema ' : [ ] } ] verbose_columns = `` ' else : assert sorted_dicts ( suggestions ) == sorted_dicts ( [ headers = [ x [ 0 ] for x in cur.description ] return [ ( cur , headers , cur.statusmessage ) ] p.proname as `` Name '' , sql += `` ' AND n.nspname < > 'pg_catalog ' return suggest_special ( text_before_cursor ) def test_slash_suggests_special ( ) : pg_catalog.pg_get_function_result ( p.oid ) def test_leading_whitespace_ok ( ) : [ { 'type ' : 'special ' } ] ) ELSE 'normal ' , CASE if len ( token.tokens ) > 2 : LEFT JOIN pg_catalog.pg_namespace n ON n.oid = p.pronamespace ' '' + verbose_table + `` ' params.append ( func_pattern ) WHEN p.proiswindow THEN 'window ' verbose_columns = verbose_table = `` except AttributeError : WHEN p.prorettype = 'pg_catalog.trigger ' : :pg_catalog.regtype # Apparently `` \d < other > '' is parsed by sqlparse as pg_catalog.pg_get_userbyid ( p.proowner ) as `` Owner '' , return [ { 'type ' : 'function ' , 'schema ' : schema } ] elif cmd [ 1 : ] == 'df ' : cur.execute ( sql ) else : if cmd [ 1 : ] in ( 'd ' , 'dt ' , 'dv ' ) : CASE l.lanname as `` Language '' , END as `` Volatility '' , params.append ( schema_pattern ) if verbose : if word_before_cursor [ -1 ] in ( ' ( ' , ' . ' ) : assert suggestions == [ { 'type ' : 'schema ' } ] if schema : WHEN p.provolatile = ' v ' THEN 'volatile ' log.debug ( sql ) # Trying to complete the special command itself tok1 = statement.token_first ( ) # `` \d table '' or `` \d schema '' FROM pg_catalog.pg_proc p","['pgcli/packages/pgspecial.py', 'pgcli/packages/sqlcompletion.py', 'tests/test_pgspecial.py']",Merge pull request # 161 from darikg/special
474,bd4d3028ffefac942af1b5bbfec70ffddf3d753c,2015-02-25 14:14:56-08:00,"elif token_v.lower ( ) in ( ' c ' , 'use ' ) : # \c if not token : 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'DROP ' , 'ELSE ' , 'EXCLUSIVE ' , 'EXISTS ' , 'FILE ' , 'FLOAT ' , assert sorted_dicts ( suggestions ) == sorted_dicts ( [ { 'type ' : 'database ' } ] ) def test_specials_included_for_initial_completion ( initial_text ) : 'UID ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'DESC ' , 'DESCRIBE ' , 'DISTINCT ' , 'DROP ' , 'ELSE ' , 'EXCLUSIVE ' , special = self.find_matches ( word_before_cursor , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] return [ { 'type ' : 'keyword ' } ] 'NOAUDIT ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'COPY ' , 'CREATE ' , 'CURRENT ' , 'DATABASE ' , 'DATE ' , 'DECIMAL ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] 'ASC ' , 'AUDIT ' , 'BETWEEN ' , 'BY ' , 'CASE ' , 'CHAR ' , 'CHECK ' , 'TRIGGER ' , 'UID ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'EXISTS ' , 'FILE ' , 'FLOAT ' , 'FOR ' , 'FROM ' , 'FULL ' , 'GRANT ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , suggestions = suggest_type ( 'create table foo ( dt d ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , return [ { 'type ' : 'keyword ' } ] 'SYSDATE ' , 'TABLE ' , 'TEMPLATE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , sorted_dicts ( [ { 'type ' : 'keyword ' } , { 'type ' : 'special ' } ] ) suggestions = suggest_type ( 'create database foo with template ' , 'OUTER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'RAW ' , self.special_commands ) 'INDEX ' , 'INITIAL ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'INTO ' , if token_v.lower ( ) .endswith ( ' ( ' ) : keywords = self.keywords + self.special_commands suggestions = suggest_type ( initial_text , initial_text ) 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OF ' , 'OFFLINE ' , elif token_v.lower ( ) in ( 'set ' , 'by ' , 'distinct ' ) : 'FOR ' , 'FROM ' , 'FULL ' , 'GRANT ' , 'GROUP BY ' , 'HAVING ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , 'PCTFREE ' , # `` CREATE DATABASE < newdb > WITH TEMPLATE < db > '' 'IDENTIFIED ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , 'INDEX ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , def test_specials_not_included_after_initial_token ( ) : 'CLUSTER ' , 'COLUMN ' , 'COMMENT ' , 'COMPRESS ' , 'CONNECT ' , 'COPY ' , def test_create_db_with_template ( ) : # `` \c < db '' , `` use < db > '' , `` DROP DATABASE < db > '' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'SHARE ' , return [ { 'type ' : 'keyword ' } , { 'type ' : 'special ' } ] assert sorted_dicts ( suggestions ) == sorted_dicts ( [ { 'type ' : 'keyword ' } ] ) else : assert sorted_dicts ( suggestions ) == \ if token_v.lower ( ) in ( 'set ' , 'by ' , 'distinct ' ) : 'ASC ' , 'AUDIT ' , 'BETWEEN ' , 'BY ' , 'CASE ' , 'CHAR ' , 'CHECK ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , elif token_v.lower ( ) in ( ' c ' , 'use ' , 'database ' , 'template ' ) : 'create table foo ( dt d ' ) 'CLUSTER ' , 'COLUMN ' , 'COMMENT ' , 'COMPRESS ' , 'CONNECT ' , 'GROUP BY ' , 'HAVING ' , 'IDENTIFIED ' , 'IMMEDIATE ' , 'IN ' , 'INCREMENT ' , completions.extend ( special ) keywords = self.find_matches ( word_before_cursor , self.keywords ) 'CREATE ' , 'CURRENT ' , 'DATE ' , 'DECIMAL ' , 'DEFAULT ' , 'DELETE FROM ' , 'create database foo with template ' ) 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'IS ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , elif suggestion [ 'type ' ] == 'special ' : 'INITIAL ' , 'INSERT INTO ' , 'INTEGER ' , 'INTERSECT ' , 'INTO ' , keywords = self.find_matches ( word_before_cursor , keywords ) 'DEFAULT ' , 'DELETE FROM ' , 'DESC ' , 'DESCRIBE ' , 'DISTINCT ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'THEN ' , 'TO ' , elif token_v.lower ( ) .endswith ( ' ( ' ) :","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_sqlcompletion.py']",Merge pull request # 158 from drocco007/master
475,4d60c92184f78e91bed729db0adb2a0272a9c6b5,2015-02-18 14:17:45-08:00,"} } , funcs = self.populate_schema_objects ( if suggestion [ 'schema ' ] : # also suggest hardcoded functions Completion ( text='shipments ' , start_position=0 ) ] ) 'users ' : [ 'id ' , 'phone_number ' ] , self.dbmetadata [ schema ] [ table ] = [ ' * ' ] metadata = self.dbmetadata [ 'functions ' ] def test_function_name_completion ( completer , complete_event ) : { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } , { 'type ' : 'function ' , 'schema ' : 't1 ' } ] ) 'custom ' : [ 'func3 ' , 'func4 ' ] } 'public ' : { Completion ( text='price ' , start_position=0 ) ] # E.g . 'DROP FUNCTION < funcname > ' for func in funcs ] except KeyError : for schema in schemata : self.dbmetadata = { } funcs = self.find_matches ( word_before_cursor , funcs ) { 'type ' : 'table ' , 'schema ' : 'd ' } ] ) n.nspname schema_name , Completion ( text='price ' , start_position=0 ) , suggestions.append ( { 'type ' : 'table ' , 'schema ' : identifier } ) 'custom ' : { { 'type ' : 'table ' , 'schema ' : 't ' } ] ) for schema , tbls in metadata [ 'tables ' ] .items ( ) : 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , cur.execute ( self.functions_query ) 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , # so just default to None as a placeholder # function metadata -- right now we 're not storing any further metadata 'shipments ' : [ 'id ' , 'address ' , 'user_id ' ] { 'type ' : 'table ' , 'schema ' : 'tabl ' } , _logger.debug ( 'Functions Query . sql : % r ' , self.functions_query ) { 'type ' : 'function ' , 'schema ' : [ ] } ] Document ( text=text , cursor_position=position ) , complete_event ) { 'type ' : 'table ' , 'schema ' : 't2 ' } ] ) Completion ( text='func3 ' , start_position=0 ) , functions = [ ( 'public ' , func ) for func in metadata [ 'functions ' ] ] } , def test_user_function_name_completion ( completer , complete_event ) : objects = [ ] # dbmetadata [ 'schema_name ' ] [ 'table_name ' ] should be a list of column Completion ( text='func1 ' , start_position=0 ) , for f in func_data : Completion ( text='phone_number ' , start_position=0 ) , def functions ( self ) : assert funcs == [ ( 'public ' , 'func1 ' ) , ( 'schema1 ' , 'func2 ' ) ] { 'type ' : 'function ' , 'schema ' : [ ] } ] ) { 'type ' : 'table ' , 'schema ' : 't ' } , for tbl in meta [ schema ] .keys ( ) ] def extend_functions ( self , func_data ) : # column names . Default to an asterisk # dbmetadata [ 'tables ' ] [ 'schema_name ' ] [ 'table_name ' ] should be a list of with self.conn.cursor ( ) as cur : Completion ( text= ' '' ABC '' ' , start_position=0 ) , ] self.dbmetadata = { 'tables ' : { } , 'functions ' : { } } # func_data is an iterator of ( schema_name , function_name ) meta = self.dbmetadata Completion ( text='last_name ' , start_position=0 ) ] { 'type ' : 'table ' , 'schema ' : ' a ' } ] ) self.all_completions.add ( func ) assert result == set ( [ metadata = self.dbmetadata [ 'tables ' ] { 'type ' : 'function ' } ] self.dbmetadata [ schema ] [ table ] .append ( column ) objects = [ obj for schema in schemas { 'type ' : 'function ' , 'schema ' : 'tabl ' } ] ) 'products ' : [ 'id ' , 'product_name ' , 'price ' ] , metadata [ schema ] = { } 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , Completion ( text='custom_func2 ' , start_position=-2 ) ] ) for row in cur : FROM pg_catalog.pg_proc p # dbmetadata [ 'functions ' ] [ 'schema_name ' ] [ 'function_name ' ] should return objects = metadata [ schema ] .keys ( ) meta = self.dbmetadata 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] 'tables ' : { text = 'SELECT custom.func ' 'products ' : [ 'id ' , 'product_name ' , 'price ' ] , return objects 'functions ' : { 'shipments ' : [ 'id ' , 'address ' , 'user_id ' ] } try : { 'type ' : 'function ' , 'schema ' : 'd ' } ] ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] } , def test_schema_qualified_function_name ( completer , complete_event ) : { 'type ' : 'table ' , 'schema ' : ' a ' } , yield row } , meta = self.dbmetadata [ 'tables ' ] 'functions ' : [ 'custom_func1 ' , 'custom_func2 ' ] for table , cols in metadata [ 'tables ' ] .items ( ) : schemas = self.search_path 'public ' : [ 'func1 ' , 'func2 ' ] , Completion ( text='shipments ' , start_position=0 ) , language sql as $ $ select 1 $ $ ' '' ) Completion ( text= ' '' ABC '' ' , start_position=0 ) , for metadata in self.dbmetadata.values ( ) : 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , suggestion [ 'schema ' ] , 'tables ' ) funcs.extend ( self.functions ) { 'type ' : 'function ' } ] ) { 'type ' : 'table ' , 'schema ' : 'd ' } , metadata [ schema ] [ table ] .append ( column ) metadata [ schema ] [ func ] = None tables = [ ] def test_functions_query ( executor ) : assert set ( result ) == set ( [ Completion ( text='custom_func1 ' , start_position=-2 ) , # schema does n't exist else : # schema does n't exist { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } ] ) tables = [ tbl for schema in schemas functions_query = `` ' # data is a DataFrame with columns [ schema ] # dbmetadata.values ( ) are the 'tables ' and 'functions ' dicts suggestions.extend ( [ { 'type ' : 'table ' , 'schema ' : identifier } , { 'type ' : 'function ' , 'schema ' : ' a ' } ] ) result = completer.get_completions ( # names . Default to an asterisk funcs = self.find_matches ( word_before_cursor , self.functions ) Completion ( text='func4 ' , start_position=-len ( 'func ' ) ) ] ) Completion ( text='custom_func2 ' , start_position=0 ) ] Completion ( text='last_name ' , start_position=0 ) , ORDER BY 1 , 2 '' ' self.dbmetadata [ schema ] = { } text = 'SELECT cu ' 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] for schema , tbls in metadata.items ( ) : position = len ( 'SELECT cu ' ) def test_builtin_function_name_completion ( completer , complete_event ) : schema_names = self.dbmetadata.keys ( ) { 'type ' : 'function ' , 'schema ' : 't2 ' } ] ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] for obj in metadata [ schema ] .keys ( ) ] for table , cols in metadata.items ( ) : run ( executor , `` 'create function schema1.func2 ( ) returns int else : 'public ' : { run ( executor , `` 'create function func1 ( ) returns int functions = [ ( schema , func ) { 'type ' : 'function ' } ] ) p.proname func_name result = set ( completer.get_completions ( INNER JOIN pg_catalog.pg_namespace n { 'type ' : 'function ' } ] ) tables = self.populate_schema_objects ( { 'type ' : 'function ' , 'schema ' : identifier } ] ) suggestion [ 'schema ' ] , 'functions ' ) { 'type ' : 'function ' , 'schema ' : [ ] } ] ) 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , `` `` '' Yields tuples of ( schema_name , function_name ) '' '' '' schema_names = self.dbmetadata [ 'tables ' ] .keys ( ) 'users ' : [ 'id ' , 'phone_number ' ] , return [ { 'type ' : 'schema ' } , { 'type ' : 'function ' , 'schema ' : [ ] } ] tables = self.dbmetadata [ suggestion [ 'schema ' ] ] .keys ( ) { 'type ' : 'function ' , 'schema ' : [ ] } ] ) Completion ( text='func3 ' , start_position=-len ( 'func ' ) ) , 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , comp.extend_functions ( functions ) WHERE n.nspname NOT IN ( 'pg_catalog ' , 'information_schema ' ) Completion ( text='func2 ' , start_position=0 ) ] metadata [ schema ] [ table ] = [ ' * ' ] if not suggestion [ 'schema ' ] : `` `` '' Returns list of tables or functions for a ( optional ) schema '' '' '' language sql as $ $ select 2 $ $ ' '' ) { 'type ' : 'function ' , 'schema ' : 't ' } ] ) # schemata is a list of schema names 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , schemas = self.search_path schema , func = self.escaped_names ( f ) { 'type ' : 'table ' , 'schema ' : 't2 ' } , 'tables ' : { metadata = self.dbmetadata [ obj_type ] Completion ( text='func4 ' , start_position=0 ) ] ) completer.extend_functions ( pgexecute.functions ( ) ) metadata [ schema ] = { } Document ( text=text , cursor_position=postion ) , complete_event ) ) Completion ( text='custom_func1 ' , start_position=0 ) , for schema , funcs in metadata [ 'functions ' ] .items ( ) def populate_schema_objects ( self , schema , obj_type ) : run ( executor , 'create schema schema1 ' ) try : elif token_v.lower ( ) == 'function ' : postion = len ( text ) Completion ( text='phone_number ' , start_position=0 ) ] if schema : except KeyError : 'custom ' : { { 'type ' : 'table ' , 'schema ' : 'tabl ' } ] ) 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , SELECT DISTINCT -- multiple dispatch means possible duplicates ON n.oid = p.pronamespace funcs = list ( executor.functions ( ) )","['pgcli/main.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/test_smart_completion_public_schema_only.py', 'tests/test_sqlcompletion.py']",Merge pull request # 155 from darikg/functions
476,d06e9d2c1b010b4c628e97a376dbab698cd65e40,2015-02-12 18:26:43-08:00,"key_binding_manager = KeyBindingManager ( ) # Syntax Style . Possible values : manni , igor , xcode , vim , autumn , vs , rrt , # Timing of sql statments and table rendering . # native , perldoc , borland , tango , emacs , friendly , monokai , paraiso-dark , # Timing of sql statments and table rendering . key_binding_manager = KeyBindingManager ( enable_vi_mode=vi_mode ) self.vi_mode = c.getboolean ( 'main ' , 'vi ' ) key_bindings_registry=pgcli_bindings ( ) ) key_bindings_registry=pgcli_bindings ( self.vi_mode ) ) def pgcli_bindings ( ) : def pgcli_bindings ( vi_mode = False ) : vi = False # Enables vi-mode # native , perldoc , borland , tango , emacs , friendly , monokai , paraiso-dark , # Syntax Style . Possible values : manni , igor , xcode , vim , autumn , vs , rrt ,","['pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 154 from jayzeng/prototype_vimode
477,b05a83cce2d7f401ae5f4efad47a63c465e0603f,2015-02-12 13:14:08-08:00,"AND n.nspname ! ~ '^pg_toast ' AND n.nspname NOT IN ( 'information_schema ' , 'pg_catalog ' ) try : AND nspname < > 'information_schema ' self.dbmetadata [ schema ] [ table ] = [ ' * ' ] _logger.error ( 'Table % r listed in unrecognized schema % r ' , AND n.nspname ! ~ '^pg_ ' table , schema ) self.dbmetadata [ schema ] [ table ] = [ ' * ' ] except AttributeError :","['pgcli/pgcompleter.py', 'pgcli/pgexecute.py']",Merge pull request # 151 from darikg/bugfix_tables_query
478,cfeb299684f910d408acb0257bd823ce84018db0,2015-02-12 13:13:05-08:00,WHERE c.relkind = ANY ( % s ) `` ' AND n.nspname < > 'pg_catalog ' AND n.nspname < > 'information_schema ' AND n.nspname < > 'pg_catalog ' WHERE c.relkind = ANY ( % s ) AND n.nspname < > 'information_schema ' AND pg_catalog.pg_table_is_visible ( c.oid ) `` ' sql += `` ' AND n.nspname ! ~ '^pg_toast ' else : AND n.nspname ! ~ '^pg_toast ' `` ',['pgcli/packages/pgspecial.py'],Merge pull request # 152 from darikg/bugfix_dt
479,16bbfc3911a396c3f449b0f92727528b99abb043,2015-02-02 18:58:30-08:00,"as `` Type '' , ON n.oid = c.relnamespace pg_catalog.pg_class c2 ON i.indrelid = c2.oid WHERE c.relkind `` Type '' , pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' , sql += ' AND c.relname ~ % s ' relkinds is a list of strings to filter pg_class.relkind AND n.nspname ! ~ '^pg_toast ' `` ' WHEN ' r ' THEN 'table ' WHEN ' v ' THEN 'view ' '\di ' : ( `` 'SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE FROM pg_catalog.pg_class c , pg_catalog.pg_size_pretty ( pg_catalog.pg_table_size ( c.oid ) ) as `` Size '' , 1,2 ; ' '' , [ '\dt ' , 'list tables . ' ] ) , LEFT JOIN pg_catalog.pg_namespace n params = [ relkinds ] = c.relnamespace WHERE c.relkind IN ( ' r ' , '' ) AND n.nspname < > pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' WHEN 'S ' THEN 'sequence ' WHEN 's ' THEN 'special ' AND n.nspname < > 'pg_catalog ' AND pg_catalog.pg_table_is_visible ( c.oid ) params.append ( table_pattern ) if cur.description : return list_objects ( cur , pattern , verbose , [ ' v ' , 's ' , `` ] ) schema_pattern , table_pattern = sql_name_pattern ( pattern ) pg_catalog.pg_table_is_visible ( c.oid ) ORDER BY 1,2 ; ' '' , if schema_pattern : This method is used by list_tables , list_views , and list_indexes n.nspname < > 'pg_catalog ' AND n.nspname < > 'information_schema ' '\\dt ' : ( list_tables , [ '\\dt [ + ] [ pattern ] ' , 'list tables . ' ] ) , else : ORDER BY 1,2 ; ' '' , [ '\di ' , 'list indexes . ' ] ) , pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON n.oid def list_tables ( cur , pattern , verbose ) : sql = cur.mogrify ( sql + ' ORDER BY 1 , 2 ' , params ) AND n.nspname < > 'information_schema ' '\\dv ' : ( list_views , [ '\\dv [ + ] [ pattern ] ' , 'list views . ' ] ) , CASE c.relkind return list_objects ( cur , pattern , verbose , [ ' i ' , 's ' , `` ] ) def list_views ( cur , pattern , verbose ) : `` `` '' def list_indexes ( cur , pattern , verbose ) : pg_catalog.obj_description ( c.oid , 'pg_class ' ) as `` Description '' `` ' pg_catalog.pg_index i ON i.indexrelid = c.oid LEFT JOIN return list_objects ( cur , pattern , verbose , [ ' r ' , `` ] ) sql = `` 'SELECT n.nspname as `` Schema '' , ' '' + verbose_columns + `` ' sql += ' AND n.nspname ~ % s ' `` Type '' , pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' FROM n.oid = c.relnamespace WHERE c.relkind IN ( ' v ' , '' ) AND [ '\dv ' , 'list views . ' ] ) , 'materialized view ' WHEN ' i ' THEN 'index ' WHEN 'S ' THEN 'sequence ' verbose_columns = `` ' if table_pattern : '\dt ' : ( `` 'SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE headers = [ x [ 0 ] for x in cur.description ] return [ ( cur , headers , cur.statusmessage ) ] WHEN 's ' THEN 'special ' WHEN ' f ' THEN 'foreign table ' END as pg_catalog.pg_namespace n ON n.oid = c.relnamespace LEFT JOIN verbose_columns = `` WHEN ' f ' THEN 'foreign table ' END WHERE c.relkind = ANY ( % s ) IN ( ' i ' , '' ) AND n.nspname < > 'pg_catalog ' AND Returns ( rows , header , status ) WHEN 'm ' THEN 'materialized view ' WHEN ' i ' THEN 'index ' 'pg_catalog ' AND n.nspname < > 'information_schema ' AND n.nspname ! ~ '\dv ' : ( `` 'SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE cur.execute ( sql ) AND n.nspname ! ~ '^pg_toast ' AND c2.relname as `` Table '' FROM pg_catalog.pg_class c LEFT JOIN params.append ( schema_pattern ) if verbose : c.relkind WHEN ' r ' THEN 'table ' WHEN ' v ' THEN 'view ' WHEN 'm ' THEN c.relname as `` Name '' , log.debug ( sql ) '^pg_toast ' AND pg_catalog.pg_table_is_visible ( c.oid ) ORDER BY def list_objects ( cur , pattern , verbose , relkinds ) : '\\di ' : ( list_indexes , [ '\\di [ + ] [ pattern ] ' , 'list indexes . ' ] ) , n.nspname < > 'information_schema ' AND n.nspname ! ~ '^pg_toast '",['pgcli/packages/pgspecial.py'],Merge pull request # 144 from darikg/special_list
480,3ed89e01e495c122283053c3a91d752d0d70abce,2015-01-29 10:24:53-08:00,"full_text = full_text [ stmt_start : ] 'select * from ' ) # an empty tuple . if stmt_end > = current_pos : break statement = parsed [ 0 ] for statement in parsed : suggestions = suggest_type ( 'select * from ; select * from b ' , 'select * from a ; select ' ) suggestions = suggest_type ( 'select * from a ; select from b ' , assert sorted_dicts ( suggestions ) == sorted_dicts ( [ last_token = statement and statement.token_prev ( len ( statement.tokens ) ) or `` def test_2_statements_2nd_current ( ) : elif parsed : # current position { 'type ' : 'table ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) 'select * from a ; select * from ' ) p = parsed [ 0 ] if parsed else None # Should work even if first statement is invalid last_token = p and p.token_prev ( len ( p.tokens ) ) or `` statement = None stmt_len = len ( statement.to_unicode ( ) ) # The empty string # cumulatively summing statement lengths to find the one that bounds the suggestions = suggest_type ( 'select * from ; select * from ' , # Need to check if ` p ` is not empty , since an empty string will result in 'select ' ) def test_3_statements_2nd_current ( ) : # A single statement stmt_start , stmt_end = 0 , 0 suggestions = suggest_type ( 'select * from a ; select from b ; select * from c ' , current_pos = len ( text_before_cursor ) { 'type ' : 'function ' } ] ) # Multiple statements being edited -- isolate the current one by 'select * from ; select * from ' ) if len ( parsed ) > 1 : else : { 'type ' : 'column ' , 'tables ' : [ ( None , ' b ' , None ) ] } , { 'type ' : 'column ' , 'tables ' : [ ( None , ' a ' , None ) ] } , suggestions = suggest_type ( 'select * from a ; select * from ; select * from c ' , stmt_start , stmt_end = stmt_end , stmt_end + stmt_len suggestions = suggest_type ( 'select * from a ; select * from ' , def test_2_statements_1st_current ( ) : text_before_cursor = full_text [ stmt_start : current_pos ] suggestions = suggest_type ( 'select from a ; select * from b ' ,","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 142 from darikg/master
481,13f84bf83e0aa35c9fb9ca9fa3214fd470353327,2015-01-28 18:21:13-05:00,"full_text = full_text [ stmt_start : ] 'select * from ' ) # an empty tuple . if stmt_end > = current_pos : break statement = parsed [ 0 ] for statement in parsed : suggestions = suggest_type ( 'select * from ; select * from b ' , 'select * from a ; select ' ) suggestions = suggest_type ( 'select * from a ; select from b ' , assert sorted_dicts ( suggestions ) == sorted_dicts ( [ last_token = statement and statement.token_prev ( len ( statement.tokens ) ) or `` def test_2_statements_2nd_current ( ) : elif parsed : # current position { 'type ' : 'table ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) 'select * from a ; select * from ' ) p = parsed [ 0 ] if parsed else None # Should work even if first statement is invalid last_token = p and p.token_prev ( len ( p.tokens ) ) or `` statement = None stmt_len = len ( statement.to_unicode ( ) ) # The empty string # cumulatively summing statement lengths to find the one that bounds the suggestions = suggest_type ( 'select * from ; select * from ' , # Need to check if ` p ` is not empty , since an empty string will result in 'select ' ) def test_3_statements_2nd_current ( ) : # A single statement stmt_start , stmt_end = 0 , 0 suggestions = suggest_type ( 'select * from a ; select from b ; select * from c ' , current_pos = len ( text_before_cursor ) { 'type ' : 'function ' } ] ) # Multiple statements being edited -- isolate the current one by 'select * from ; select * from ' ) if len ( parsed ) > 1 : else : { 'type ' : 'column ' , 'tables ' : [ ( None , ' b ' , None ) ] } , { 'type ' : 'column ' , 'tables ' : [ ( None , ' a ' , None ) ] } , suggestions = suggest_type ( 'select * from a ; select * from ; select * from c ' , stmt_start , stmt_end = stmt_end , stmt_end + stmt_len suggestions = suggest_type ( 'select * from a ; select * from ' , def test_2_statements_1st_current ( ) : text_before_cursor = full_text [ stmt_start : current_pos ] suggestions = suggest_type ( 'select from a ; select * from b ' ,","['pgcli/packages/sqlcompletion.py', 'tests/test_sqlcompletion.py']",Fix # 106 - autocompletion in multiple statements
482,c2d539df8aaba9bc15031cb9234f401694e0d5ee,2015-01-26 23:07:10-08:00,"return arg.encode ( 'utf-8 ' ) def unicode2utf8 ( arg ) : In Python 3 the args are expected as unicode . `` `` '' if PY2 and isinstance ( arg , str ) : import sys Only in Python 2 . Psycopg2 expects the args as bytes not unicode . return arg auto_passwd_prompt ) : PY2 = sys.version_info [ 0 ] == 2 import sys return arg.decode ( 'utf-8 ' ) PY3 = sys.version_info [ 0 ] == 3 from .encodingutils import utf8tounicode PY3 = sys.version_info [ 0 ] == 3 return arg.encode ( 'utf-8 ' ) `` `` '' def unicode2utf8 ( arg ) : In Python 3 the errors are returned as unicode . Only in Python 2 . Psycopg2 returns the error message as utf-8 . def utf8tounicode ( arg ) : if ( 'no password supplied ' in utf8tounicode ( e.args [ 0 ] ) and return arg if PY2 and isinstance ( arg , unicode ) : Only in Python 2 . Psycopg2 expects the args as bytes not unicode . self.logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) from .encodingutils import unicode2utf8 if PY2 and isinstance ( arg , unicode ) : if 'no password supplied ' in e.args [ 0 ] and auto_passwd_prompt : In Python 3 the args are expected as unicode . PY2 = sys.version_info [ 0 ] == 2","['pgcli/encodingutils.py', 'pgcli/main.py', 'pgcli/pgexecute.py']",Convert psycopg2 erros to unicode . Fixes # 124
483,6944ef60f83e7e116aa687a972b5402f1a1bbe04,2015-01-26 20:26:52-08:00,"scoped_cols = self.populate_scoped_cols ( scope ) columns = defaultdict ( lambda : [ ' * ' ] ) from mock import Mock def schemata ( self ) : return 'tables-or-aliases ' , tables.keys ( ) cls.relname table_name , { 'type ' : 'table ' , 'schema ' : 't ' } ] ) return False 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , suggestion = suggest_type ( 'SELECT DISTINCT ' , 'SELECT DISTINCT ' ) def test_dot_suggests_cols_of_a_table ( ) : def completer ( ) : _logger.debug ( `` Completion : 'columns ' Scope : % r '' , scope ) return tables , columns assert tables_aliases == expected assert extract_tables ( suggestions = suggest_type ( 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' , att.attname column_name assert suggestion == ( 'columns ' , [ ] ) def test_dot_col_comma_suggests_cols ( ) : { 'type ' : 'function ' } ] ) all_completions = set ( keywords + functions ) tables = extract_tables ( full_text ) # [ ( schema , table , alias ) , ... ] Completion ( text='users ' , start_position=0 ) , self.databases = [ ] suggestions = suggest_type ( 'SELECT * FROM tabl WHERE col_n ' , { 'type ' : 'table ' , 'schema ' : [ ] } , { 'type ' : 'schema ' } ] ) tables = extract_tables ( full_text , include_alias=True ) suggestions = suggest_type ( 'SELECT FROM tabl ' , 'SELECT ' ) # `` \d table '' or `` \d schema '' ORDER BY 1,2 ; ' '' yield ( schema_name , real_name , item.get_alias ( ) ) Completion ( text='email ' , start_position=0 ) , # table_data is a list of ( schema_name , table_name ) tuples completer.set_search_path ( pgexecute.search_path ( ) ) AND att.attnum > 0 return completions expected = { ' a ' : 'abc ' , 'd ' : 'def ' } assert suggestion == ( 'tables ' , [ ] ) comp.extend_tables ( tables ) def columns ( self ) : yield ( item.get_name ( ) , item.get_name ( ) ) assert suggestion == ( 'columns-and-functions ' , [ 'tbl ' ] ) columns [ table ] .append ( column ) { 'type ' : 'table ' , 'schema ' : 'd ' } ] ) text = 'SELECT from custom.users ' def test_join_suggests_tables ( ) : comp = pgcompleter.PGCompleter ( smart_completion=True ) if name and ( ( not self.name_pattern.match ( name ) ) def test_dot_suggests_cols_of_a_table_or_schema_qualified_table ( ) : If include_alias=True , then a dictionary is returned where the keys are elif suggestion [ 'type ' ] == 'alias ' : return id == alias or id == table or ( : param scoped_tbls : list of ( schema , table , alias ) tuples assert suggestions == [ { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , None ) ] } ] schemata , tables , columns = [ ] , [ ] , [ ] suggestions = suggest_type ( 'SELECT * FROM ( SELECT FROM abc ' , 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] , yield ( None , item.get_name ( ) , item.get_name ( ) ) schema_name = item.get_parent_name ( ) suggestion = suggest_type ( 'SELECT * FROM ( SELECT t. FROM tabl t ' , expected = { 'm ' : 'my_table ' } def test_schema_or_visible_table_completion ( completer , complete_event ) : def test_into_suggests_tables ( ) : suggestions = suggest_type ( 'SELECT * FROM ( SELECT a , FROM abc ' , comp.extend_column_names ( t , tables [ t ] ) assert suggestions == [ { 'type ' : 'table ' , 'schema ' : 'myschema ' } ] elif suggestion [ 'type ' ] == 'function ' : ORDER BY 1 , 2 , 3 '' ' complete_event ) # note that sql may be a multi-command query , but status belongs to an from test_sqlcompletion import sorted_dicts position = len ( text ) def test_suggested_column_names_from_qualified_shadowed_table ( completer , complete_event ) : return Mock ( ) return self.find_matches ( word_before_cursor , self.keywords tables = [ t for t in tables if identifies ( identifier , * t ) ] def test_suggested_column_names_in_function ( completer , complete_event ) : return 'columns ' , extract_tables ( full_text ) scoped_cols = [ ] # A fully qualified schema.table reference suggestions = suggest_type ( 'SELECT ' , 'SELECT ' ) else : for schema , table in table_data : suggestions = suggest_type ( 'SELECT a , b , FROM tbl ' , 'SELECT a , b , ' ) position = len ( 'SELECT u.id , u . ' ) table_set = set ( tables ) aliases and values are real table names . `` `` '' Returns tuple ( sorted_tables , columns ) . Columns is a dictionary of print ( extract_tables ( sql , True ) ) 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'RAW ' , 'RENAME ' , def test_select_suggests_cols_with_qualified_table_scope ( ) : tables = [ ] return suggestions assert sorted ( tables ) == [ ( None , 'abc ' , None ) , ( None , 'def ' , None ) ] schemas = self.search_path { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None ) ] } ] def identifies ( id , schema , table , alias ) : self.all_completions.update ( t [ 2 ] for t in column_data ) comp.extend_table_names ( tables.keys ( ) ) Suggest column names on table alias and dot suggestion = suggest_type ( 'SELECT * FROM ( SELECT FROM abc ' , # Since sql could be a multi-line query , it 's hard to robustly def test_d_dot_suggests_schema_qualified_tables ( ) : Completion ( text='price ' , start_position=0 ) ] return self.find_matches ( word_before_cursor , self.databases ) WHERE c.relkind IN ( ' r ' , ' v ' , 'm ' ) -- table , view , materialized view _logger.debug ( `` Completion : 'keywords ' Scope : % r '' , scope ) def test_from_suggests_tables ( ) : AND nsp.nspname ! ~ '^pg_ ' # Identifer ( 'd ' , Whitespace , ' < other > ' ) LEFT JOIN pg_catalog.pg_namespace n assert tables == [ ' a ' , ' b ' ] self.columns [ unescaped_table_name ] .extend ( columns ) columns.extend ( meta [ schema ] [ table ] ) tables = extract_tables ( 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' ) suggestions = suggest_type ( 'INSERT INTO abc ( i ' , 'INSERT INTO abc ( i ' ) assert suggestion == ( 'columns ' , [ 'def ' ] ) if suggestion [ 'schema ' ] : cur.execute ( `` 'DROP SCHEMA public CASCADE ; CREATE SCHEMA public '' ' ) for tbl in scoped_tbls : if len ( token.tokens ) > 2 : completions.extend ( cols ) pgexecute = self.pgexecute INNER JOIN pg_catalog.pg_namespace nsp for table , cols in metadata.items ( ) : { 'type ' : 'schema ' } ] ) suggestions = suggest_type ( 'SELECT * FROM tabl WHERE ' , table = table [ 1 : -1 ] if table [ 0 ] == ' '' ' and table [ -1 ] == ' '' ' else table return 'columns-and-functions ' , extract_tables ( full_text ) } suggestion = suggest_type ( 'SELECT * FROM tabl WHERE ' , tables = [ x [ 0 ] for x in cur.fetchall ( ) ] def extract_tables ( sql ) : when selecting multiple columns from table suggestion = suggest_type ( 'SELECT * FROM ( SELECT a , FROM abc ' , unescaped_table_name = self.unescape_name ( table ) : param completer : meta = self.dbmetadata assert suggestion == ( 'columns-and-functions ' , [ 'abc ' ] ) def test_simple_select_with_cols_single_table_schema_qualified ( ) : suggestions = [ ] elif category == 'columns-and-functions ' : if name and name [ 0 ] == ' '' ' and name [ -1 ] == ' '' ' : run ( executor , `` create schema schema2 '' ) completer.extend_columns ( pgexecute.columns ( ) ) position = len ( 'SELECT p . ' ) def test_select_suggests_cols_with_visible_table_scope ( ) : return [ { 'type ' : 'column ' , 'tables ' : extract_tables ( full_text ) } ] tables , columns = executor.tables ( ) _logger.debug ( `` Completion : 'columns-and-functions ' Scope : % r '' , column_data = [ self.escaped_names ( d ) for d in column_data ] SELECT nspname tables = suggestion [ 'tables ' ] special_commands = [ ] yield ( real_name , identifier.get_alias ( ) or real_name ) table_data = [ self.escaped_names ( d ) for d in table_data ] schema = self.escape_name ( tbl [ 0 ] ) : param complete_event : self.dbmetadata [ schema ] = { } completer.extend_schemata ( pgexecute.schemata ( ) ) suggestion = suggest_type ( 'SELECT a , b FROM tbl1 , ' , assert tables == sorted ( expected.values ( ) ) _logger.debug ( `` Completion : 'databases ' Scope : % r '' , scope ) pass Completion ( text= ' x ' , start_position=0 ) , { 'type ' : 'function ' } ] ) def test_suggested_column_names ( completer , complete_event ) : WHERE cls.relkind IN ( ' r ' , ' v ' , 'm ' ) category , scope = suggest_type ( document.text , # pick out the variable name that 's been set . Err on the side of self.dbmetadata = { } assert set ( scope ) == set ( [ ' a ' , ' b ' ] ) assert suggestion == ( 'columns-and-functions ' , [ 'tabl ' ] ) text = 'SELECT from custom.products ' 'information_schema ' AND n.nspname ! ~ '^pg_toast ' AND metadata = { assert tables == [ ( None , 'abc ' , None ) ] suggestion = suggest_type ( 'SELECT * FROM ' , 'SELECT * FROM ' ) except Exception : prev_keyword , text_before_cursor , full_text ) Completion ( text='users ' , start_position=0 ) , assert sorted ( tables ) == [ ( None , 'abc ' , ' a ' ) , ( None , 'def ' , 'd ' ) ] table = self.escape_name ( tbl [ 1 ] ) funcs = self.find_matches ( word_before_cursor , self.functions ) cur.execute ( self.search_path_query ) return self.find_matches ( word_before_cursor , scope ) def test_simple_select_multiple_tables_schema_qualified ( ) : suggestions.append ( { 'type ' : 'column ' , 'tables ' : tables } ) return [ { 'type ' : 'alias ' , 'aliases ' : alias } ] return [ x [ 0 ] for x in extract_table_identifiers ( stream ) ] suggestion = suggest_type ( 'SELECT * FROM abc a JOIN def d ON a . ' , completions.extend ( tables ) _logger.debug ( 'Schemata Query . sql : % r ' , self.schemata_query ) try : keywords = self.find_matches ( word_before_cursor , keywords ) 'SELECT * FROM my_table AS m WHERE m.a > 5 ' ) == \ self.all_completions = set ( self.keywords + self.functions ) suggestions = suggest_type ( 'INSERT INTO abc ( ' , 'INSERT INTO abc ( ' ) self.search_path = [ ] def test_d_suggests_tables_and_schemas ( ) : `` `` '' Returns a list of ( schema_name , table_name , column_name ) tuples '' '' '' return 'tables ' , [ ] return [ x [ 0 ] for x in cur.fetchall ( ) ] assert executor.search_path ( ) == [ 'public ' ] AND NOT att.attisdropped assert executor.schemata ( ) == [ 'public ' , 'schema1 ' , 'schema2 ' ] position = len ( 'SELECT ' ) return 'keywords ' , [ ] for table , column in cur.fetchall ( ) : Completion ( text='shipments ' , start_position=0 ) ] ) completer.reset_completions ( ) position = len ( 'SELECT MAX ( ' ) # individual query , since pgexecute handles splitting up multi-commands completer.extend_database_names ( pgexecute.databases ( ) ) Completion ( text='custom ' , start_position=0 ) , # data is a DataFrame with columns [ schema ] suggestions = suggest_type ( 'SELECT DISTINCT ' , 'SELECT DISTINCT ' ) def extend_tables ( self , table_data ) : def extract_tables ( sql , include_alias=False ) : def test_suggested_column_names_from_schema_qualifed_table ( completer , complete_event ) : return dict ( ( alias , t ) for t , alias in extract_table_identifiers ( stream ) ) 'SELECT * FROM my_table AS m WHERE m.a > 5 ' , True ) == expected def test_simple_select_single_table_schema_qualified ( ) : table = self.escape_name ( tbl [ 1 ] ) tables.append ( ( 'public ' , table ) ) ] ) self.dbmetadata [ schema ] [ table ] .append ( column ) try : self.columns = defaultdict ( lambda : [ ' * ' ] ) # names . Default to an asterisk search_path_query = `` ' return 'columns ' , [ tables.get ( current_alias ) or current_alias ] 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , def test_from_suggests_tables_and_schemas ( ) : # Apparently `` \d < other > '' is parsed by sqlparse as tables = extract_tables ( 'select * from abc.def ' ) elif suggestion [ 'type ' ] == 'keyword ' : `` `` '' def test_suggested_column_names_from_shadowed_visible_table ( completer , complete_event ) : assert suggestion == ( 'keywords ' , [ ] ) tables = extract_tables ( full_text ) 'users ' : [ 'id ' , 'phone_number ' ] , def test_join_table_schema_qualified ( ) : def sorted_dicts ( dicts ) : assert sorted ( tables ) == [ ( None , 'tabl1 ' , 't1 ' ) , ( None , 'tabl2 ' , 't2 ' ) ] Completion ( text='products ' , start_position=0 ) , columns.extend ( [ ( schema , table , col ) for col in cols ] ) assert tables == [ 'abc ' , 'def ' ] for schema in self.search_path : : return : list of column names suggestion = suggest_type ( 'INSERT INTO abc ( id , ' , 'INSERT INTO abc ( id , ' ) def search_path ( self ) : completions.extend ( dbs ) return comp elif category == 'keywords ' : from prompt_toolkit.document import Document suggestion = suggest_type ( 'SELECT t1 . FROM tabl1 t1 , tabl2 t2 ' , def test_table_comma_suggests_tables_and_schemas ( ) : c.relname table_name Suggest column and function names when selecting multiple suggestions = suggest_type ( 'SELECT * FROM ( SELECT t. FROM tabl t ' , # Either the schema or table does n't exist # column_data is a list of ( schema_name , table_name , column_name ) tuples yield ( None , name , item.get_alias ( ) or name ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'def ' , 'd ' ) ] } , `` `` '' input is a list of dicts '' '' '' if status.lower ( ) == 'set ' : DROP SCHEMA IF EXISTS schema2 CASCADE '' ' ) break Completion ( text='last_name ' , start_position=0 ) ] completer.set_search_path ( pgexecute.search_path ( ) ) assert tables == [ ( 'abc ' , 'def ' , ' x ' ) , ( 'ghi ' , 'jkl ' , ' y ' ) ] CREATE SCHEMA public ; tables , columns = [ ] , [ ] assert sorted ( tables ) == [ ( 'abc ' , 'def ' , None ) , ( 'def ' , 'ghi ' , None ) ] suggestions = suggest_type ( document.text , document.text_before_cursor ) schema_names = self.dbmetadata.keys ( ) self.completer.extend_table_names ( tables ) if category == 'columns ' : def populate_scoped_cols ( self , scoped_tbls ) : `` `` '' Returns the current search path as a list of schema names '' '' '' self.tables = [ ] self.completer.reset_completions ( ) Returns a list of ( schema , table , alias ) tuples tables = { ( 'public ' , ' b ' , ' z ' ) , ( 'schema1 ' , ' c ' , ' w ' ) ] { 'type ' : 'table ' , 'schema ' : 't2 ' } ] ) def test_suggested_column_names_with_table_dot ( completer , complete_event ) : # \d schema.table suggestions = suggest_type ( 'SELECT tabl . FROM tabl ' , 'SELECT tabl . ' ) except KeyError : for schema , tbls in metadata.items ( ) : for table in tables : return [ { 'type ' : 'keyword ' } ] def test_join_suggests_tables_and_schemas ( ) : assert tables == [ ( None , 'abc ' , 'abc ' ) ] Completion ( text='orders ' , start_position=0 ) ] ) c.relkind IN ( ' r ' , '' ) AND n.nspname < > 'pg_catalog ' AND n.nspname < > AND n.nspname ! ~ '^pg_toast ' completer.extend_tables ( pgexecute.tables ( ) ) document.text_before_cursor ) def need_search_path_refresh ( sql , status ) : try : { 'type ' : 'table ' , 'schema ' : 'tabl ' } ] ) 'custom ' : { assert set ( scope ) == set ( [ 'abc ' , 'bcd ' ] ) ON att.attrelid = cls.oid Completion ( text='first_name ' , start_position=0 ) , 'shipments ' : [ 'id ' , 'address ' , 'user_id ' ] return [ { 'type ' : 'table ' , 'schema ' : identifiers [ 0 ] } ] Suggest column and function names when selecting from a qualified-table return suggest_based_on_last_token ( prev_keyword , text_before_cursor , full_text ) completions.extend ( funcs ) aliases = suggestion [ 'aliases ' ] text = 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON x.id = ' return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] DROP SCHEMA public CASCADE ; tables = extract_tables ( 'insert into abc.def ( id , name ) values ( 1 , `` def '' ) ' ) suggestions = suggest_type ( '\d ' , '\d ' ) return columns self.completer.extend_column_names ( table , columns [ table ] ) { 'type ' : 'table ' , 'schema ' : 't1 ' } , assert suggestions == [ { 'type ' : 'alias ' , 'aliases ' : [ 'abc ' , 'bcd ' ] } ] def test_table_names_after_from ( completer , complete_event ) : Completion ( text='phone_number ' , start_position=0 ) ] schema and ( id == schema + ' . ' + table ) ) Document ( text=text , cursor_position=position ) , complete_event ) ) elif category == 'databases ' : INNER JOIN pg_catalog.pg_class cls self.all_completions.update ( t [ 1 ] for t in table_data ) tables = [ tbl for schema in schemas completions.extend ( keywords ) tables_aliases = extract_tables ( 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , assert suggestion == ( 'columns ' , [ 'tabl2 ' ] ) # Get columns from the corresponding schema.table tables = self.dbmetadata [ suggestion [ 'schema ' ] ] .keys ( ) { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] ) Completion ( text= ' y ' , start_position=0 ) ] ) ORDER BY 1 `` ' meta = self.dbmetadata Document ( text=text , cursor_position=position ) , columns_query = `` ' 'public ' : { comp.set_search_path ( [ 'public ' ] ) Document ( text=text , cursor_position=position ) , assert tables == [ ( None , 'my_table ' , 'm ' ) ] def test_table_comma_suggests_tables ( ) : ( 'public ' , ' a ' ) , ( 'public ' , ' b ' ) , ( 'schema1 ' , ' c ' ) ] def populate_scoped_cols ( self , tables ) : elif category == 'tables ' : assert executor.columns ( ) == [ { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None ) ] } , text = 'SELECT id , from custom.products ' def test_suggested_column_names_with_dot ( completer , complete_event ) : # TABLE. < suggestion > or SCHEMA.TABLE. < suggestion > FROM pg_catalog.pg_attribute att self.dbmetadata [ schema ] [ table ] = [ ' * ' ] elif suggestion [ 'type ' ] == 'schema ' : FROM pg_catalog.pg_class c assert suggestion == ( 'columns-and-functions ' , [ ] ) pg_catalog.pg_table_is_visible ( c.oid ) ORDER BY 1 ; ' '' return self.find_matches ( word_before_cursor , scoped_cols ) } , if suggestion [ 'type ' ] == 'column ' : { 'type ' : 'function ' } ] ) `` `` '' Returns a list of ( schema_name , table_name ) tuples `` '' '' elif category == 'tables-or-aliases ' : self.all_completions.update ( tables ) self.completer.extend_database_names ( self.pgexecute.databases ( ) ) return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] text = 'SELECT * FROM custom . ' def complete_event ( ) : suggestion = suggest_type ( 'SELECT FROM tabl ' , 'SELECT ' ) def extend_table_names ( self , tables ) : tables = extract_tables ( 'select a , b from abc.def , def.ghi ' ) import pgcli.pgcompleter as pgcompleter assert columns [ ' b ' ] == [ ' z ' ] suggestions.append ( { 'type ' : 'table ' , 'schema ' : identifier } ) category , scope = suggest_type ( assert tables == [ 'abc ' ] assert suggestion == ( 'columns ' , [ 'abc ' ] ) tables = extract_tables ( 'select a , b from abc.def ' ) suggestions = suggest_type ( 'SELECT * FROM abc a JOIN def d ON a . ' , return scoped_cols if table in table_set : other = token.tokens [ -1 ] .value aliases = self.find_matches ( word_before_cursor , aliases ) schemata = [ 'public ' ] Completion ( text= ' '' select '' ' , start_position=0 ) , Completion ( text='custom ' , start_position=0 ) , run ( executor , `` create schema schema1 '' ) def test_suggested_column_names_with_qualified_alias ( completer , complete_event ) : # This will create a defaultdict which is initialized with a list that has suggestions = suggest_type ( 'INSERT INTO abc ( id , ' , 'INSERT INTO abc ( id , ' ) print ( extract_tables ( sql ) ) identifier = last_word ( token_v [ : -1 ] , 'all_punctuations ' ) from pgcli.packages.sqlcompletion import suggest_type result = completer.get_completions ( AND n.nspname NOT IN ( 'information_schema ' , 'pg_catalog ' ) else : from prompt_toolkit.completion import Completion _logger.debug ( 'Suggestion type : % r ' , suggestion [ 'type ' ] ) AND nsp.nspname < > 'information_schema ' tables_query = `` 'SELECT c.relname as `` Name '' FROM pg_catalog.pg_class c import pytest def extend_schemata ( self , schemata ) : if name [ 0 ] == ' '' ' and name [ -1 ] == ' '' ' : assert sorted ( tables ) == [ ( 'abc ' , 'def ' , None ) , ( 'ghi ' , 'jkl ' , None ) ] 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] , 'users ' : [ 'id ' , 'email ' , 'first_name ' , 'last_name ' ] , for suggestion in suggestions : 'SELECT * FROM abc a JOIN def d ON a.id = d.num ' , True ) def test_select_with_hanging_period_multiple_tables ( ) : def test_suggested_multiple_column_names_with_alias ( completer , complete_event ) : assert columns [ ' a ' ] == [ ' x ' , ' y ' ] else : _logger.debug ( `` Completion column scope : % r '' , tables ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl1 ' , 't1 ' ) ] } ] ) return self.find_matches ( word_before_cursor , scoped_cols { 'type ' : 'column ' , 'tables ' : [ ( 'sch ' , 'tabl ' , None ) ] } , schemata.append ( schema ) table name - > list of columns `` '' '' FROM pg_catalog.pg_namespace { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , ' a ' ) ] } , return self.find_matches ( word_before_cursor , self.tables ) def test_table_and_columns_query ( executor ) : text = 'SELECT p. from custom.products p ' # SCHEMA. < suggestion > `` `` '' Returns a list of schema names in the database '' '' '' # assert tables == [ ( None , 'abc ' , None ) ] if ( ( not self.name_pattern.match ( name ) ) assert set ( result ) == set ( [ Completion ( text='public ' , start_position=0 ) , tables = extract_tables ( 'select * from abc.def , ghi.jkl ' ) dbs = self.find_matches ( word_before_cursor , self.databases ) run ( executor , `` create table schema1.c ( w text ) '' ) tables = [ ] ON cls.relnamespace = nsp.oid unescaped_table_name = self.unescape_name ( table ) scoped_cols = self.populate_scoped_cols ( tables ) cur.execute ( `` ' tables = self.escaped_names ( tables ) cols = self.find_matches ( word_before_cursor , scoped_cols ) `` `` '' Find all columns in a set of scoped_tables yield ( real_name , item.get_alias ( ) or real_name ) suggestion = suggest_type ( 'INSERT INTO abc ( ' , 'INSERT INTO abc ( ' ) alias = [ t [ 2 ] or t [ 1 ] for t in tables ] text = 'SELECT p.id , p. from custom.products p ' { 'type ' : 'column ' , 'tables ' : [ ( None , 'tbl ' , None ) ] } , self.all_completions.update ( columns ) else : for tbl in meta [ schema ] .keys ( ) ] assert suggestion == [ 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'PUBLIC ' , 'RAW ' , 'RENAME ' , tables_query = `` ' return cur.fetchall ( ) def test_simple_select_with_cols_multiple_tables ( ) : { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl2 ' , 't2 ' ) ] } , { 'type ' : 'function ' } ] keywords = self.keywords + self.special_commands assert suggestions == [ { 'type ' : 'alias ' , 'aliases ' : [ ' a ' , ' b ' ] } ] SELECT * FROM unnest ( current_schemas ( false ) ) ' '' completions.extend ( schema_names ) suggestions = suggest_type ( 'SELECT a , b FROM tbl1 , ' , position = len ( 'SELECT * FROM ' ) tables.append ( ( schema , table ) ) columns = [ ] tables = extract_tables ( 'SELECT * FROM my_table AS m WHERE m.a > 5 ' ) suggestion = suggest_type ( 'SELECT t1.a , t2 . FROM tabl1 t1 , tabl2 t2 ' , assert suggestion == ( 'columns ' , [ 'tabl1 ' ] ) assert suggestions == [ { 'type ' : 'column ' , 'tables ' : [ ] } ] 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] 'orders ' : [ 'id ' , 'user_id ' , 'ordered_date ' , 'status ' ] , def test_simple_insert_single_table_schema_qualified ( ) : for table , cols in tbls.items ( ) : schema_names = self.find_matches ( word_before_cursor , schema_names ) suggestions = suggest_type ( 'SELECT t1.a , t2 . FROM tabl1 t1 , tabl2 t2 ' , Suggest column and function names when selecting from table # false positives here , since the worst case is we refresh the schemata = self.escaped_names ( schemata ) if len ( identifiers ) == 1 : cur.execute ( self.schemata_query ) Completion ( text='orders ' , start_position=0 ) , suggestions = suggest_type ( '\d myschema.xxx ' , '\d myschema.xxx ' ) suggestion = suggest_type ( 'SELECT a , b , FROM tbl ' , 'SELECT a , b , ' ) suggestions = suggest_type ( '\d xxx ' , '\d xxx ' ) 'sqlparse > = 0.1.14 ' , complete_event ) ) complete_event ) Completion ( text= ' * ' , start_position=0 ) , # a ' * ' by default . # search path when it 's not necessary return [ { 'type ' : 'column ' , 'tables ' : extract_tables ( full_text ) } , Document ( text=text , cursor_position=position ) , complete_event ) { 'type ' : 'column ' , 'tables ' : [ ( None , 'abc ' , None ) ] } , def test_suggested_aliases_after_on_right_side ( completer , complete_event ) : logger.debug ( 'Search path : % r ' , completer.search_path ) columns = self.escaped_names ( columns ) self.functions ) if include_alias : for t in tables : 'products ' : [ 'id ' , 'product_name ' , 'price ' ] , def test_suggested_table_names_with_schema_dot ( completer , complete_event ) : assert suggestion == ( 'columns ' , [ 'tbl ' ] ) _logger.debug ( `` Completion : 'tables ' Scope : % r '' , scope ) self.tables.extend ( tables ) text = 'SELECT MAX ( from custom.products ' columns_query = `` 'SELECT table_name , column_name FROM information_schema.columns '' ' { 'type ' : 'table ' , 'schema ' : [ ] } , with self.conn.cursor ( ) as cur : yield ( schema_name , real_name , identifier.get_alias ( ) ) self.special_commands = [ ] assert category == 'tables-or-aliases ' def test_into_suggests_tables_and_schemas ( ) : WHERE nspname ! ~ '^pg_ ' tables = extract_tables ( 'update abc.def set id = 1 ' ) # schema does n't exist return sorted ( tuple ( x.items ( ) ) for x in dicts ) scope ) Completion ( text='price ' , start_position=0 ) ] ) list ( map ( Completion , completer.functions ) ) ) yield ( name , item.get_alias ( ) or name ) assert tables == [ ( 'abc ' , 'def ' , None ) ] Completion ( text='product_name ' , start_position=0 ) , for schema in schemata : databases = [ ] completions = [ ] def set_search_path ( self , search_path ) : tables = self.find_matches ( word_before_cursor , tables ) schemata_query = `` ' suggestions = suggest_type ( '\d myschema . ' , '\d myschema . ' ) Completion ( text='id ' , start_position=0 ) , ON n.oid = c.relnamespace tables , columns = self.pgexecute.tables ( ) if tbl [ 0 ] : _logger.debug ( 'Search path query . sql : % r ' , self.search_path_query ) sorted ( expected.values ( ) ) self.special_commands ) elif suggestion [ 'type ' ] == 'table ' : elif len ( identifiers ) == 2 : { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , None ) ] } , self.all_completions.update ( schemata ) columns from table comp.extend_columns ( columns ) return [ { 'type ' : 'keyword ' } ] except KeyError : def test_suggested_multiple_column_names ( completer , complete_event ) : # Use table alias if there is one , otherwise the table name suggestions = suggest_type ( 'SELECT FROM sch.tabl ' , 'SELECT ' ) self.search_path = self.escaped_names ( search_path ) Completion ( text='public ' , start_position=0 ) , AND nspname < > 'information_schema ' return 'keywords ' , [ ] def extend_column_names ( self , table , columns ) : columns = defaultdict ( list ) text = 'SELECT * FROM ' suggestion = suggest_type ( 'SELECT tabl . FROM tabl ' , 'SELECT tabl . ' ) logger.debug ( 'Refreshing search path ' ) return 'databases ' , [ ] return False assert set ( result ) == set ( [ Returns a list of table names if include_alias=False ( default ) . ( 'public ' , ' a ' , ' x ' ) , ( 'public ' , ' a ' , ' y ' ) , return 'search_path ' in sql.lower ( ) { 'type ' : 'table ' , 'schema ' : ' a ' } ] ) tables = extract_tables ( 'SELECT * FROM abc.def x JOIN ghi.jkl y ON x.id = y.num ' ) } return [ { 'type ' : 'database ' } ] { 'type ' : 'column ' , 'tables ' : [ ] } , text = 'SELECT from users ' completer = self.completer suggestions = suggest_type ( columns.extend ( meta [ schema ] [ table ] ) def test_suggested_aliases_after_on ( completer , complete_event ) : def extend_columns ( self , column_data ) : if need_search_path_refresh ( document.text , status ) : def test_schemata_table_and_columns_query ( executor ) : `` `` '' yields tuples of ( schema_name , table_name , table_alias ) '' '' '' def test_suggested_column_names_from_visible_table ( completer , complete_event ) : completions.extend ( aliases ) 'select ' : [ 'id ' , 'insert ' , 'ABC ' ] columns.extend ( [ ( 'public ' , table , col ) for col in cols ] ) return [ { 'type ' : 'schema ' } , { 'type ' : 'table ' , 'schema ' : [ ] } ] assert sorted_dicts ( suggestions ) == sorted_dicts ( [ : return : position = len ( 'SELECT id , ' ) assert executor.tables ( ) == [ result = set ( completer.get_completions ( suggestions = suggest_type ( 'SELECT * FROM ' , 'SELECT * FROM ' ) return list ( extract_table_identifiers ( stream ) ) SELECT nsp.nspname schema_name , Completion ( text= ' '' select '' ' , start_position=0 ) , current_alias = last_word ( token_v [ : -1 ] ) return suggest_based_on_last_token ( _logger.debug ( `` Completion : 'tables-or-aliases ' Scope : % r '' , scope ) 'sqlparse > = 0.1.14 ' identifiers = other.split ( ' . ' ) status = status.split ( ) [ 0 ] # sqlparse mistakenly assigns an alias to the table elif suggestion [ 'type ' ] == 'database ' : from collections import defaultdict { 'type ' : 'column ' , 'tables ' : [ ( None , 'tabl ' , 't ' ) ] } , def test_simple_update_table ( ) : def test_select_suggests_cols_with_table_scope ( ) : LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE comp.extend_schemata ( schemata ) for schema , table , column in column_data : } pass suggestion = suggest_type ( 'SELECT ' , 'SELECT ' ) DROP SCHEMA IF EXISTS schema1 CASCADE ; schema_name = identifier.get_parent_name ( ) def test_dot_col_comma_suggests_cols_or_schema_qualified_table ( ) : SELECT n.nspname schema_name , assert suggestion == ( 'columns ' , [ 'tabl ' ] ) assert sorted_dicts ( suggestion ) == sorted_dicts ( [ assert suggestion == [ { 'type ' : 'keyword ' } ] suggestion = suggest_type ( 'INSERT INTO abc ( i ' , 'INSERT INTO abc ( i ' ) suggestion = suggest_type ( 'SELECT * FROM tabl WHERE col_n ' , # dbmetadata [ 'schema_name ' ] [ 'table_name ' ] should be a list of column text = 'SELECT x.id , y.product_name FROM custom.products x JOIN custom.products y ON ' `` `` '' scoped_cols.extend ( self.columns [ unescaped_table_name ] )","['pgcli/main.py', 'pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'pgcli/pgexecute.py', 'setup.py', 'tests/test_parseutils.py', 'tests/test_pgexecute.py', 'tests/test_pgspecial.py', 'tests/test_smart_completion_multiple_schemata.py', 'tests/{test_smart_completion.py => test_smart_completion_public_schema_only.py}', 'tests/test_sqlcompletion.py', 'tests/utils.py']",Merge pull request # 127 from darikg/schema_autocomplete
484,750206c779060ea8b1cf19e2058a87cd536363e2,2015-01-26 00:19:49-08:00,"import psycopg2.extensions psycopg2.extensions.register_type ( psycopg2.extensions.UNICODE ) psycopg2.extensions.register_type ( psycopg2.extensions.UNICODEARRAY ) import psycopg2.extensions as ext ext.register_type ( psycopg2.extensions.UNICODE ) ext.register_type ( ext.new_type ( ( 705 , ) , `` UNKNOWN '' , ext.UNICODE ) ) ext.register_type ( psycopg2.extensions.UNICODEARRAY ) ext.register_type ( ext.new_type ( ( 51766 , ) , `` HSTORE '' , ext.UNICODE ) )",['pgcli/pgexecute.py'],Handle unicode for hstore and unknown types . Fixes # 134 .
485,35909de7517077444bc9db39aee009b59fc10e1f,2015-01-23 21:08:00-08:00,"return self.completer.get_completions ( self.completer.reset_completions ( ) smart_completion = c.getboolean ( 'main ' , 'smart_completion ' ) completer.extend_column_names ( table , columns [ table ] ) refresh_completions ( pgexecute , completer ) completer = PGCompleter ( self.smart_completion ) # Initialize completer self.completer = completer self.smart_completion = c.getboolean ( 'main ' , 'smart_completion ' ) completer.extend_special_commands ( NON_CASE_SENSITIVE_COMMANDS.keys ( ) ) tables , columns = self.pgexecute.tables ( ) self.refresh_completions ( ) completer.extend_special_commands ( CASE_SENSITIVE_COMMANDS.keys ( ) ) self.completer.extend_database_names ( self.pgexecute.databases ( ) ) def get_completions ( self , text , cursor_positition ) : table = table [ 1 : -1 ] if table [ 0 ] == ' '' ' and table [ -1 ] == ' '' ' else table from prompt_toolkit.document import Document self.refresh_completions ( ) refresh_completions ( pgexecute , completer ) completer.extend_database_names ( pgexecute.databases ( ) ) table = table [ 1 : -1 ] if table [ 0 ] == ' '' ' and table [ -1 ] == ' '' ' else table completer = PGCompleter ( smart_completion ) completer.extend_table_names ( tables ) def refresh_completions ( pgexecute , completer ) : def refresh_completions ( self ) : completer = self.completer self.completer.extend_table_names ( tables ) tables , columns = pgexecute.tables ( ) completer.reset_completions ( ) completer.extend_special_commands ( NON_CASE_SENSITIVE_COMMANDS.keys ( ) ) self.completer.extend_column_names ( table , columns [ table ] ) for table in tables : Document ( text=text , cursor_position=cursor_positition ) , None ) completer.extend_special_commands ( CASE_SENSITIVE_COMMANDS.keys ( ) ) for table in tables :",['pgcli/main.py'],Merge pull request # 137 from darikg/api
486,591534cfc8998dcdc1c40beca4f4895074ed7099,2015-01-21 21:33:48-08:00,"# Postgres 9+ and as escaped binary in earlier versions . run ( executor , '\\ ? ' ) psycopg2.extensions.register_type ( run ( executor , `` create table binarydata ( c bytea ) '' ) run ( executor , psycopg2.extensions.new_type ( ( 17 , ) , 'BYTEA_TEXT ' , psycopg2.STRING ) ) assert u'\\xdeadbeef ' in run ( executor , `` select * from binarydata '' , join=True ) run ( executor , '\\ ? ' ) # Cast bytea fields to text . By default , this will render as hex strings with def test_bytea_field_support_in_output ( executor ) : `` insert into binarydata ( c ) values ( decode ( 'DEADBEEF ' , 'hex ' ) ) '' )","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 133 from drocco007/master
487,244c356116238de38bc24c21501ffc4103357e84,2015-01-19 22:35:41-08:00,"'select abc.x , bcd.y from abc join bcd on ' , For example , ` \l ` is a meta-command that lists all the databases . The way you result = set ( completer.get_completions ( assert set ( scope ) == set ( [ ' a ' , ' b ' ] ) : : to produce that result . In most cases it 's a single sql statement , but sometimes The first item in the tuple is either a string ( sql statement ) or a function . the dictionary key , and the value is a tuple . command itself with possible options and the second item is the plain english def test_on_suggests_tables_right_side ( ) : ` cd ` into the local clone of pgcli folder and install pgcli using pip as for that special command . The list will have two items , the first item is the is to launch ` psql -E ` and entering ` \l ` . position = len ( 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' ) assert set ( scope ) == set ( [ 'abc ' , 'bcd ' ] ) Document ( text=text , cursor_position=position ) , That will print the results and also print the sql statement that was executed elif token_v.endswith ( ' , ' ) or token_v == '= ' : Create a virtualenv ( let 's call it pgcli-dev ) . Activate it : If you want to work on adding new meta-commands ( such as ` \dp ` , ` \ds ` , ` dy ` ) , source ./pgcli-dev/bin/activate 'select abc.x , bcd.y from abc join bcd on ' ) 'select a.x , b.y from abc a join bcd b on a.id = ' , assert set ( result ) == set ( [ you 'll be changing the code of ` packages/pgspecial.py ` . Search for the The second item in the tuple is a list of strings which is the documentation can see the SQL statement issued by PostgreSQL when this command is executed and install pgcli using pip as follows : 'select a.x , b.y from abc a join bcd b on a.id = ' ) Completion ( text= ' o ' , start_position=0 ) ] ) Create a virtualenv ( let 's call it pgcli-dev ) . Once the virtualenv is activated assert category == 'tables-or-aliases ' complete_event ) ) def test_on_suggests_aliases_right_side ( ) : text = 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = ' follows : category , scope = suggest_type ( the final result . * [ ] Write a doc about how to add new pgspecial commands . ( psql -E ) Completion ( text='users ' , start_position=0 ) , text = 'SELECT u.name , o.id FROM users u JOIN orders o ON o.user_id = ' description of that command . def test_suggested_tables_after_on_right_side ( completer , complete_event ) : Completion ( text= ' u ' , start_position=0 ) , def test_suggested_aliases_after_on_right_side ( completer , complete_event ) : Once the virtualenv is activated , ` cd ` into the local clone of pgcli folder Adding PostgreSQL Special ( Meta ) Commands Completion ( text='orders ' , start_position=0 ) ] ) position = len ( 'SELECT users.name , orders.id FROM users JOIN orders ON orders.user_id = ' ) it 's a series of sql statements that feed the results to each other to get to elif token_v.endswith ( ' , ' ) : * [ X ] Write a doc about how to add new pgspecial commands . ( psql -E ) dictionary called ` CASE_SENSITIVE_COMMANDS ` . The special command us used as","['DEVELOP.rst', 'TODO', 'pgcli/packages/sqlcompletion.py', 'tests/test_smart_completion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 129 from j-bennet/master
488,a1cad195ece7289e147fb5c15f0753351291d0ad,2015-01-17 22:51:21-08:00,"'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'TRIGGER ' , 'UID ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'RESOURCE ' , 'REVOKE ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'PRIMARY ' , 'PRIOR ' , 'PRIVILEGES ' , 'PUBLIC ' , 'RAW ' , 'RENAME ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'UID ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , 'PCTFREE ' , 'JOIN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LIMIT ' , 'LOCK ' , 'LONG ' , 'PRIVILEGES ' , 'PUBLIC ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'SELECT ' , 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'THEN ' , 'TO ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'VALIDATE ' , 'VALUES ' , ] 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OF ' , 'OFFLINE ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'MINUS ' , 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'NOCOMPRESS ' ,",['pgcli/pgcompleter.py'],Add the LIMIT keyword . Fix # 125
489,05865f4b39e4af2087ae89382bbc9e4c42f69564,2015-01-17 22:25:06-08:00,"return 'tables-or-aliases ' , tables.keys ( ) 'select abc.x , bcd.y from abc join bcd on ' , 'orders ' : [ 'id ' , 'ordered_date ' , 'status ' ] assert set ( scope ) == set ( [ ' a ' , ' b ' ] ) result = set ( completer.get_completions ( return self.find_matches ( word_before_cursor , scope ) position = len ( 'SELECT u.name , o.id FROM users u JOIN orders o ON ' ) def test_on_suggests_tables ( ) : def test_on_suggests_aliases ( ) : _logger.debug ( `` Completion : 'tables-or-aliases ' Scope : % r '' , scope ) elif category == 'tables-or-aliases ' : assert set ( scope ) == set ( [ 'abc ' , 'bcd ' ] ) Document ( text=text , cursor_position=position ) , elif token_v.lower ( ) == 'on ' : 'select abc.x , bcd.y from abc join bcd on ' ) assert set ( result ) == set ( [ def test_suggested_tables_after_on ( completer , complete_event ) : Completion ( text= ' o ' , start_position=0 ) ] ) 'select a.x , b.y from abc a join bcd b on ' ) assert category == 'tables-or-aliases ' complete_event ) ) 'orders ' : [ 'id ' , 'user_id ' , 'ordered_date ' , 'status ' ] `` `` '' Unquote a string . '' '' '' category , scope = suggest_type ( Completion ( text='users ' , start_position=0 ) , def test_suggested_aliases_after_on ( completer , complete_event ) : Completion ( text= ' u ' , start_position=0 ) , 'select a.x , b.y from abc a join bcd b on ' , Completion ( text='orders ' , start_position=0 ) ] ) tables = extract_tables ( full_text , include_alias=True ) text = 'SELECT users.name , orders.id FROM users JOIN orders ON ' text = 'SELECT u.name , o.id FROM users u JOIN orders o ON ' position = len ( 'SELECT users.name , orders.id FROM users JOIN orders ON ' )","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_smart_completion.py', 'tests/test_sqlcompletion.py']",Merge pull request # 126 from j-bennet/master
490,2a7d8aa79c8b9b0146e5339df15c030043d58c34,2015-01-14 13:46:27-08:00,"for command , value in sorted ( CASE_SENSITIVE_COMMANDS.items ( ) ) : run ( executor , '\\ ? ' ) def test_special_command ( executor ) : for command , value in sorted ( CASE_SENSITIVE_COMMANDS.iteritems ( ) ) :","['pgcli/packages/pgspecial.py', 'tests/test_pgexecute.py']",Merge pull request # 120 from darikg/iteritems_bugfix
491,72ab7f6e87deb2e2167ff4d0b69bd0d6537e14a4,2015-01-13 22:25:03-08:00,"If it does n't exist , use your linux package manager to install ` pip ` . This : : $ sudo apt-get install python-pip : : $ sudo apt-get install python-pip # Debian , Ubuntu , Mint etc for this to work . Check if `` pip `` is installed on the system . might look something like : $ sudo pip install pgcli $ sudo yum install python-pip Done ! install these via your operating system package manager . manager called called `` pip `` . You will need postgres installed on your system Easiest way to install pgcli is using brew . For installing Python packages it is recommended to use the package manager or called ` pip ` . Check if ` pip ` is installed on the system . $ brew install pgcli If it does n't exist , use your linux package manager to install ` pip ` . This $ sudo yum install python-devel postgresql-devel `` pgcli `` requires python-dev , libpq-dev and libevent-dev packages . You can $ sudo yum install python-pip # RHEL , Centos , Fedora etc might look something like : $ sudo apt-get install python-dev libpq-dev libevent-dev or Alternatively , you can install `` pgcli `` as a python package using a package If it does then install pgcli using the pip command as follows : $ brew install pgcli # Only on OS X or",['README.rst'],Update readme to mention the dev packages in linux . Fix # 118
492,5c56855d6ffec63139b1e53b0b476f910b84766c,2015-01-13 21:53:53-08:00,"@ click.argument ( 'database ' , default= '' , envvar='PGDATABASE ' ) # Choose which ever one has a valid database name . help='database name to connect to . ' ) user = user or username def cli ( database , user , host , port , prompt_passwd , never_prompt , dbname , pgcli = PGCli ( prompt_passwd , never_prompt ) help='Force password prompt . ' ) username ) : pgcli = PGCli ( prompt_passwd , never_prompt ) def cli ( database , user , host , port , prompt_passwd , never_prompt ) : help='Force password prompt . ' ) default=False , help='Never issue a password prompt ' ) default=False , help='Never prompt for password . ' ) database = database or dbname",['pgcli/main.py'],Add -d option and username as argument . Fix # 65
493,15a88ea05d5d14f250f17da6a3d87f9bb9000024,2015-01-13 21:07:37-08:00,"self.connect ( ) self.conn = conn conn = psycopg2.connect ( database=database or self.dbname , user=user or self.user , password=password or self.password , host=host or self.conn = psycopg2.connect ( database=self.dbname , user=self.user , def connect ( self , database=None , user=None , password=None , host=None , def connect ( self ) : password=self.password , host=self.host , port=self.port ) self.connect ( database=dbname ) port=None ) : self.host , port=port or self.port )",['pgcli/pgexecute.py'],Fix the crash when db change fails . Fix # 117
494,7b47919e3deb59100f4351584741140531068fc8,2015-01-10 18:04:42-08:00,"pgcli = PGCli ( ) mutating = [ 'insert ' , 'update ' , 'delete ' , 'alter ' , 'create ' , 'drop ' ] # I ca n't figure out how to get the underylying psycopg2 connection if q.mutating : self.query_history.append ( Query ( document.text , successful ) ) Query = namedtuple ( 'Query ' , [ 'query ' , 'successful ' , 'mutating ' ] ) return status.split ( None , 1 ) [ 0 ] .lower ( ) in mutating # for now , assume line is connection string e.g . postgres : //localhost conn._pgcli = pgcli u = conn.session.engine.url uri = line return ipython.run_cell_magic ( 'sql ' , line , q.query ) except AttributeError : pgcli.connect_uri ( uri ) _logger.debug ( 'pgcli magic called : % r ' , line ) # A corresponding pgcli object already exists parsed = sql.parse.parse ( line , { } ) return return ipython.run_cell_magic ( 'sql ' , uri , q.query ) ipython.register_magic_function ( pgcli_line_magic , 'line ' , 'pgcli ' ) pgcli.connect ( u.database , u.host , u.username , u.port , u.password ) # Keep track of whether or not the query is mutating . In case self.query_history.append ( query ) from .main import PGCli import logging # new connection # of a multi-statement query , the overall query is considered pgcli = PGCli ( ) import sql.connection mutating = False # mutating if any one of the component statements is mutating _logger.debug ( 'New pgcli : % r ' , str ( u ) ) pgcli = conn._pgcli Query = namedtuple ( 'Query ' , [ 'query ' , 'successful ' ] ) conn = sql.connection.Connection.get ( parsed [ 'connection ' ] ) def is_mutating ( status ) : import sql.parse _logger.debug ( 'Reusing existing pgcli ' ) query = Query ( document.text , successful , mutating ) _logger = logging.getLogger ( __name__ ) _logger.debug ( 'Mutating query detected -- ignoring ' ) try : # from the sqlalchemy connection , so just grab the url and make a from pgcli.main import PGCli ipython.register_magic_function ( pgcli_line_magic , 'line ' , 'pgcli ' ) mutating = mutating or is_mutating ( status )","['pgcli/magic.py', 'pgcli/main.py']",Merge pull request # 104 from darikg/ipythonmagic
495,c9f651ba39562bc7fa471f75fb859c26400b5dfe,2015-01-10 17:05:50-08:00,# default to current OS username just like psql database = user else : # default to current OS username just like psql database = user = getuser ( ) database = user = getuser ( ) if user :,['pgcli/main.py'],Merge pull request # 105 from fpietka/master
496,39a039fb8eb731495ef5774199502154a08e75ad,2015-01-10 16:59:47-08:00,root_logger = logging.getLogger ( 'pgcli ' ) self.logger.setLevel ( level_map [ log_level.upper ( ) ] ) root_logger.setLevel ( level_map [ log_level.upper ( ) ] ) root_logger.debug ( 'Initializing pgcli logging . ' ) root_logger.addHandler ( handler ) self.logger.debug ( 'Log file `` % s '' . ' % log_file ) self.logger.addHandler ( handler ) self.logger.debug ( 'Initializing pgcli logging . ' ) root_logger.debug ( 'Log file `` % s '' . ' % log_file ),['pgcli/main.py'],Merge pull request # 103 from darikg/logging
497,b1797001f936c5a856a5066597498d01dcff874b,2015-01-10 16:31:34-08:00,.idea/ * .iml .idea/ pyvenv/ if 'no password supplied ' in e.message and auto_passwd_prompt : if 'no password supplied ' in e.args [ 0 ] and auto_passwd_prompt :,"['.gitignore', 'pgcli/main.py']",Merge pull request # 100 from Eyepea/fix_auto_passwd_prompt
498,78819664cd923e459213625c521963aa686102d4,2015-01-10 15:00:25-08:00,"cur.execute ( split_sql ) cur.execute ( sql ) if request.param : return [ self.execute_normal_sql ( query ) for query in queries ] result = run ( executor , `` select 'foo ' ; select 'bar ' '' ) return pgspecial.execute ( cur , sql ) assert u ' é ' in run ( executor , `` select * from unicodechars '' , join=True ) run ( executor , 'invalid syntax ! ' ) self.conn = psycopg2.connect ( database=dbname , sql = sql.strip ( ) assert `` foo '' in result [ 0 ] def test_multiple_queries_same_line_syntaxerror ( executor ) : @ pytest.fixture ( params= [ True , False ] ) yield request.param # single query fails , the rest are not run and no results are shown . queries = sqlparse.split ( sql ) self.connect ( ) assert u ' é ' in run ( executor , `` select * from unicodechars '' , join=True ) port=self.port ) def execute_normal_sql ( self , split_sql ) : except KeyError : return [ ( None , None , cur.statusmessage ) ] assert 'column `` invalid '' does not exist ' in str ( excinfo.value ) _logger.debug ( 'Regular sql statement . sql : % r ' , split_sql ) assert 'syntax error at or near `` invalid '' ' in str ( excinfo.value ) return pgspecial.execute ( cur , sql ) # Split the sql into separate queries and run each one . If any try : try : _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) with pytest.raises ( psycopg2.ProgrammingError ) as excinfo : return ( None , None , cur.statusmessage ) run ( executor , '\\x ' ) return request.param assert len ( result ) == 4 # 2 * ( output+status ) # Remove spaces and EOL run ( executor , `` select 'foo ' ; invalid syntax '' ) def test_invalid_column_name ( executor ) : return ( cur.fetchall ( ) , headers , cur.statusmessage ) assert `` bar '' in result [ 2 ] import sqlparse # Special command except KeyError : _logger.debug ( 'Regular sql statement . sql : % r ' , sql ) sql = sql.strip ( ) def expanded ( request ) : return [ ( cur.fetchall ( ) , headers , cur.statusmessage ) ] with self.conn.cursor ( ) as cur : user=self.user , password=self.password , host=self.host , _logger.debug ( 'Trying a pgspecial command . sql : % r ' , sql ) run ( executor , '\\x ' ) self.conn.autocommit = True def test_invalid_syntax ( executor ) : if expanded : def expanded ( request , executor ) : run ( executor , 'select invalid command ' ) def test_multiple_queries_same_line ( executor ) :","['pgcli/pgexecute.py', 'tests/test_pgexecute.py']",Merge pull request # 98 from macobo/master
499,447c54ea743478b375099ab0347b9bfff08e3f78,2015-01-09 23:37:40-08:00,"if cli.current_buffer.completer.smart_completion : is_multiline = lambda doc : self.always_multiline and not _multiline_exception ( doc.text ) 'prompt_toolkit==0.25 ' , # Need to pin this to 0.25 since APIs change quite a bit after this . key_binding_factories= [ emacs_bindings , pgcli_bindings ] ) buf = PGBuffer ( always_multiline=multi_line , completer=completer , def is_multiline ( self , value ) : event.cli.current_buffer.complete_next ( ) line = cli_ref ( ) .line registry = Registry ( ) buf.completer.smart_completion = not buf.completer.smart_completion @ is_multiline.setter buf.always_multiline = not buf.always_multiline super ( self.__class__ , self ) .__init__ ( * args , * * kwargs ) line.completer.smart_completion = not line.completer.smart_completion pass class PGBuffer ( Buffer ) : 'jedi == 0.8.1 ' , # Temporary fix for installation woes . from prompt_toolkit.key_binding.registry import Registry buf = event.cli.current_buffer return False from prompt_toolkit.key_binding.bindings.emacs import load_emacs_bindings def is_multiline ( self ) : if self.always_multiline and _multiline_exception ( self.text ) : line = PGLine ( always_multiline=multi_line , completer=completer , @ property if cli.line.completer.smart_completion : return True if cli.line.always_multiline : from prompt_toolkit.buffer import Buffer @ handle ( Keys.ControlSpace , in_mode=InputMode.INSERT ) line.always_multiline = not line.always_multiline from .pgbuffer import PGBuffer if cli.current_buffer.always_multiline : cli = CommandLineInterface ( style=PGStyle , layout=layout , buffer=buf , load_emacs_bindings ( registry ) def pgcli_bindings ( ) : cli = CommandLineInterface ( style=PGStyle , layout=layout , line=line , from prompt_toolkit import filters def pgcli_bindings ( registry , cli_ref ) : from prompt_toolkit.key_bindings.emacs import emacs_bindings key_bindings_registry=pgcli_bindings ( ) ) from prompt_toolkit.enums import InputMode if not self.always_multiline : super ( self.__class__ , self ) .__init__ ( * args , is_multiline=is_multiline , * * kwargs ) from prompt_toolkit.line import Line class PGLine ( Line ) : 'jedi == 0.8.1 ' , # Temporary fix for installation woes . line.complete_next ( ) 'prompt_toolkit==0.26 ' , `` `` '' from .pgline import PGLine Dynamically determine whether we 're in multiline mode . return registry","['pgcli/key_bindings.py', 'pgcli/main.py', 'pgcli/{pgline.py => pgbuffer.py}', 'pgcli/pgtoolbar.py', 'setup.py']",Merge pull request # 89 from macobo/karl-update-keybindings
500,97b36a993d5481c71824088834c66f3164a286ad,2015-01-09 13:10:17-08:00,"# Restart connection to the database def connect ( self ) : pgexecute.connect ( ) click.secho ( `` cancelled query '' , err=True , fg='red ' ) import psycopg2.extras self.connect ( ) psycopg2.extensions.set_wait_callback ( psycopg2.extras.wait_select ) # See http : //initd.org/psycopg/articles/2014/07/20/cancelling-postgresql-statements-python/ except KeyboardInterrupt : if hasattr ( self , 'conn ' ) : _logger.debug ( `` cancelled query , sql : % r '' , document.text ) # When running a query , make pressing CTRL+C raise a KeyboardInterrupt self.conn.close ( )","['pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 92 from macobo/karl-cancel-queries
501,21486c5b0aa9ecb8c8639e4b4e020e8065804515,2015-01-09 10:39:47-08:00,"columns = self.escaped_names ( columns ) tables = self.escaped_names ( tables ) if not self.name_pattern.match ( name ) or name in self.keywords or name in self.functions : unescaped_table_name = self.extend_unescape_name ( table ) return [ self.escape_name ( name ) for name in names ] def escape_name ( self , name ) : databases = self.escaped_names ( databases ) unescaped_table_name = self.unescape_name ( table ) def escaped_names ( self , names ) : def extend_escaped_names ( self , names ) : databases = self.extend_escaped_names ( databases ) unescaped_table_name = self.extend_unescape_name ( table ) def unescape_name ( self , name ) : def extend_escape_name ( self , name ) : tables = self.extend_escaped_names ( tables ) if not self.name_pattern.match ( name ) or name.upper ( ) in self.keywords or name.upper ( ) in self.functions : return [ self.extend_escape_name ( name ) for name in names ] unescaped_table_name = self.unescape_name ( table ) columns = self.extend_escaped_names ( columns ) def extend_unescape_name ( self , name ) :",['pgcli/pgcompleter.py'],Merge pull request # 95 from qwesda/master
502,63fb6b1bd1068960ab2536bb027f0858d4d68d06,2015-01-09 09:08:02-08:00,"python : install : pip install tox sep = u '' - [ RECORD { 0 } ] '' .format ( num ) script : tox -e $ TOX_ENV env : # See issue # 24 , this raises an exception without proper handling TOX_ENV=py26 commands = py.test from .tabulate import _text_type if expanded : script : py.test row_len = max ( [ len ( _text_type ( x ) ) for x in row ] ) def expanded ( request ) : `` 2.7 '' # coding=UTF-8 addopts= -- capture=sys -- showlocals row_result += u '' { 0 } { 1 } \n '' .format ( item [ 0 ] , item [ 1 ] ) `` 2.6 '' sep = u '' - [ RECORD { 0 } ] '' .format ( unicode ( num ) ) [ pytest ] pip install . pytest mock `` 3.3 '' row_result += item [ 0 ] + u '' `` + unicode ( item [ 1 ] ) + u '' \n '' TOX_ENV=py27 commands = py.test -- capture=sys -- showlocals TOX_ENV=py33 run ( executor , `` create table unicodechars ( t text ) '' ) run ( executor , `` insert into unicodechars ( t ) values ( ' é ' ) '' ) `` 3.4 '' TOX_ENV=py34 return request.param install : def test_unicode_support_in_output ( executor , expanded ) : run ( executor , '\\x ' ) row_len = max ( [ len ( str ( x ) ) for x in row ] ) assert u ' é ' in run ( executor , `` select * from unicodechars '' , join=True )","['.travis.yml', 'pgcli/packages/expanded.py', 'tests/pytest.ini', 'tests/test_pgexecute.py', 'tox.ini']",Merge pull request # 94 from macobo/karl-test-travis
503,9632546c4b52362b21ddf9072c68f0b3411c6d1d,2015-01-09 00:16:55-08:00,"assert tables == [ ' a ' , ' b ' ] def all_columns ( self ) : run ( executor , `` create table a ( x text , y text ) '' ) assert columns [ ' a ' ] == [ ' x ' , ' y ' ] cols = [ x [ 0 ] for x in cur.fetchall ( ) ] assert '_test_db ' in databases assert columns [ ' b ' ] == [ ' z ' ] table_name = % s ; ' '' table_set = set ( tables ) def columns ( self , table ) : columns_query = `` 'SELECT table_name , column_name FROM information_schema.columns '' ' columns.update ( self.columns ( table ) ) columns_query = `` 'SELECT column_name FROM information_schema.columns WHERE run ( executor , `` create table b ( z text ) '' ) `` `` '' Returns tuple ( sorted_tables , columns ) . Columns is a dictionary of table name - > list of columns `` '' '' def test_database_list ( executor ) : completer.extend_column_names ( table , columns [ table ] ) return columns return tables , columns if table in table_set : completer.extend_column_names ( table , pgexecute.columns ( table ) ) return cols databases = executor.databases ( ) tables = pgexecute.tables ( ) with self.conn.cursor ( ) as cur : columns = set ( ) cur.execute ( self.columns_query ) tables , columns = pgexecute.tables ( ) return [ x [ 0 ] for x in cur.fetchall ( ) ] tables = [ x [ 0 ] for x in cur.fetchall ( ) ] from collections import defaultdict columns = defaultdict ( list ) for table , column in cur.fetchall ( ) : cur.execute ( self.columns_query , ( table , ) ) for table in self.tables ( ) : def test_table_and_columns_query ( executor ) : tables , columns = executor.tables ( ) columns [ table ] .append ( column )","['pgcli/main.py', 'pgcli/pgexecute.py', 'tests/test_pgexecute.py']","Do only one query for all columns , instead of len ( tables ) queries . Should fix # 25"
504,1464a3396f7f9dd8737b97963a33cd1afeef421b,2015-01-08 22:50:32-08:00,"databases = self.extend_escaped_names ( databases ) unescaped_table_name = self.extend_unescape_name ( table ) name = name [ 1 : -1 ] name = ' '' % s '' ' % name if name [ 0 ] == ' '' ' and name [ -1 ] == ' '' ' : def extend_unescape_name ( self , name ) : return [ self.extend_escape_name ( name ) for name in names ] columns = self.extend_escaped_names ( columns ) if item_unescaped.startswith ( text ) or item_unescaped.startswith ( text.upper ( ) ) : scoped_cols.extend ( self.columns [ unescaped_table_name ] ) def extend_escaped_names ( self , names ) : elif token_v.lower ( ) in ( 'from ' , 'update ' , 'into ' , 'describe ' , 'join ' , 'table ' ) : return name yield ( name , item.get_alias ( ) or name ) elif token_v.lower ( ) in ( 'from ' , 'update ' , 'into ' , 'describe ' , 'join ' ) : scoped_cols.extend ( self.columns [ table ] ) self.name_pattern = compile ( `` ^ [ _a-z ] [ _a-z0-9\ $ ] * $ '' ) unescaped_table_name = self.extend_unescape_name ( table ) else : item_unescaped = item [ 1 : ] if item [ 0 ] == ' '' ' else item return first_token.lower ( ) in ( 'alter ' , 'create ' , 'use ' , '\c ' , 'drop ' ) self.columns [ unescaped_table_name ] .extend ( columns ) tables = self.extend_escaped_names ( tables ) if item.startswith ( text ) or item.startswith ( text.upper ( ) ) : return first_token in ( 'alter ' , 'create ' , 'use ' , '\c ' , 'drop ' ) def extend_escape_name ( self , name ) : from re import compile table = table [ 1 : -1 ] if table [ 0 ] == ' '' ' and table [ -1 ] == ' '' ' else table name = item.get_name ( ) self.columns [ table ] .extend ( columns ) if not self.name_pattern.match ( name ) or name in self.keywords or name in self.functions :","['pgcli/main.py', 'pgcli/packages/parseutils.py', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py']",Merge pull request # 83 from qwesda/master
505,f444e3dbe1fb1afacef12f6545693c580cad73a2,2015-01-08 20:51:20-08:00,"if inquotes and i + 1 < pattern_len and pattern [ i + 1 ] == ' '' ' : FROM pg_catalog.pg_class c inquotes = not inquotes if c == ' $ ' or inquotes and c in '| * + ? ( ) [ ] { } .^\\ ' : LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace relname += ' '' ' if relname : ORDER BY 2,3 '' '' '' # Found schema/name separator , move current pattern to schema pattern_len = len ( pattern ) params.append ( relname ) # Dollar is always quoted , whether inside quotes or not . sql = '' '' '' SELECT c.oid , n.nspname , c.relname params = [ ] elif not inquotes and c == ' . ' : elif not inquotes and c.isupper ( ) : relname = '^ ( ' + relname + ' ) $ ' sql = cur.mogrify ( sql + `` ORDER BY 1 '' , params ) if relname : ' AND n.nspname ~ ' + schema if schema else `` ) relname += c sql = cur.mogrify ( sql , params ) inquotes = False FROM pg_catalog.pg_class c i += 1 if c == ' '' ' : where = [ ] relname = `` % s > > > sql_name_pattern ( 'foo * . `` b '' '' $ ar * '' ' ) Returns ( rows , headers , status ) if cur.description : `` `` '' % ( ' WHERE c.relname ~ ' + relname if relname else `` , relname += ' . * ' return [ ( cur.fetchall ( ) , headers , cur.statusmessage ) ] def list_schemas ( cur , pattern , verbose ) : relname = `` '^ ( `` + replacements ( relname ) + `` ) $ ' '' schema = relname '\dn ' : ( list_schemas , [ '\dn [ + ] [ pattern ] ' , 'list schemas ' ] ) , elif not inquotes and c == ' ? ' : else : pg_catalog.array_to_string ( n.nspacl , E'\\n ' ) AS `` Access privileges '' , sql += '~ % s ' `` `` '' + ( 'WHERE ' + ' AND '.join ( where ) if where else `` ) + `` '' '' AND pg_catalog.pg_table_is_visible ( c.oid ) relname = `` _ , schema = sql_name_pattern ( pattern ) where.append ( 'pg_catalog.pg_table_is_visible ( c.oid ) ' ) schema = `` '^ ( `` + replacements ( schema ) + `` ) $ ' '' schema = '^ ( ' + schema + ' ) $ ' params.append ( schema ) `` `` '' schema = None while i < pattern_len : result = pattern.replace ( ' * ' , ' . * ' ) pg_catalog.pg_get_userbyid ( n.nspowner ) AS `` Owner '' ' '' + ( `` ' , relname += ' . ' FROM pg_catalog.pg_namespace n WHERE n.nspname `` '' '' if not pattern : else : result = result.replace ( ' ? ' , ' . ' ) where.append ( ' c.relname ~ % s ' ) i += 1 i = 0 LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace sql += `` ! ~ '^pg_ ' AND n.nspname < > 'information_schema ' '' else : headers = [ x [ 0 ] for x in cur.description ] where.append ( ' n.nspname ~ % s ' ) def replacements ( pattern ) : result = result.replace ( ' $ ' , '\\ $ ' ) sql = `` 'SELECT n.nspname AS `` Name '' , if pattern : relname += c.lower ( ) cur.execute ( sql ) pg_catalog.obj_description ( n.oid , 'pg_namespace ' ) AS `` Description '' ' '' if verbose else `` ) + `` '' '' c = pattern [ i ] return result relname += '\\ ' sql = `` '' '' SELECT c.oid , n.nspname , c.relname schema , _ , relname = pattern.rpartition ( ' . ' ) log.debug ( sql ) ( '^ ( foo . * ) $ ' , '^ ( b '' \\\\ $ ar\\\\ * ) $ ' ) ORDER BY 2,3 if schema : elif not inquotes and c == ' * ' :",['pgcli/packages/pgspecial.py'],Merge pull request # 62 from CyberDem0n/master
506,f01fea4c4b039364d1afacb8262b7ac5826f3916,2015-01-08 18:48:30-08:00,"def cli ( database , user , host , port , prompt_passwd , never_prompt ) : passwd = parsed.password # ( no -w flag ) , prompt for a passwd and try again . if not database : from psycopg2 import OperationalError port = parsed.port elif ' : // ' in database : pgexecute = PGExecute ( database , user , passwd , host , port ) if prompt_passwd and not passwd : from getpass import getuser passwd = `` # for it , even with the -W flag # avoids wasting time trying to connect to the database and catching a help='Force password prompt . ' ) if 'no password supplied ' in e.message and auto_passwd_prompt : pgexecute = PGExecute ( database , user , passwd , host , port ) # fails . Do n't prompt if the -w flag is supplied # Connect to the database . show_default=False , type=str ) passwd = click.prompt ( 'Password ' , hide_input=True , @ click.argument ( 'database ' , envvar='USER ' ) # Prompt for a password immediately if requested via the -W flag . This 'postgres instance is listening . ' ) try : auto_passwd_prompt = not passwd and not never_prompt help='Host address of the postgres database . ' ) host = parsed.hostname @ click.option ( '-U ' , ' -- user ' , prompt=True , envvar='USER ' , help='User name to ' except OperationalError as e : database = user = getuser ( ) if password : else : raise e # Default host is `` so psycopg2 can default to either localhost or unix socket # Prompt for a password after 1st attempt to connect without a password @ click.option ( '-h ' , ' -- host ' , default= '' , help='Host address of the ' # a URI connection string # default to current OS username just like psql default=False , help='Never issue a password prompt ' ) from urlparse import urlparse else : def cli ( database , user , password , host , port ) : passwd = `` # no-password exception . # If we successfully parsed a password from a URI , there 's no need to prompt @ click.option ( '-W ' , ' -- password ' , is_flag=True , help='Force password prompt . ' ) parsed = urlparse ( database ) # Attempt to connect to the database . user = parsed.username # Note that passwd may be empty on the first attempt . If connection fails 'postgres instance is listening . ' , envvar='PGPORT ' ) database = parsed.path [ 1 : ] # ignore the leading fwd slash pgexecute = PGExecute ( database , user , passwd , host , port ) 'postgres database . ' ) # because of a missing password , but we 're allowed to prompt for a password ,",['pgcli/main.py'],Merge pull request # 42 from darikg/master
507,2039349597bd2a6831e568d294d894bf34d072a0,2015-01-08 11:50:52-08:00,"return 'keywords ' , [ ] if prev_keyword : return 'keywords ' , [ ] return suggest_based_on_last_token ( prev_keyword , text_before_cursor , full_text ) return suggest_based_on_last_token ( prev_keyword , text_before_cursor , full_text ) else :",['pgcli/packages/sqlcompletion.py'],Merge pull request # 85 from Erethon/master
508,643cd4cf589e1a88bb3dbc36bd5344e80e1be514,2015-01-08 11:45:35-08:00,1 Execute a simple 'select * from users ; ' test that will pass . but not yet released in PyPI . 1 Execute a simple 'select * from users ; ' test taht will pass . but not yet released inPyPI .,"['README.rst', 'sanity_checks.txt']",Merge pull request # 84 from rrampage/master
509,e57dee60a5ab6266ed375adce12df18e0a3dda0c,2015-01-08 11:29:56-08:00,* Config file is automatically created at ~/.pglirc at first launch . * Primitive support for `` psql `` back-slash commands . ` SELECT * FROM users WHERE < tab > ` will only show column names . * Primitive support for ` psql ` back-slash commands . ` SELECT * FROM < tab > ` will only show table names . `` SELECT * FROM < tab > `` will only show table names . * Config file is automatically created at `` ~/.pglirc `` at first launch . `` SELECT * FROM users WHERE < tab > `` will only show column names .,['README.rst'],Merge pull request # 87 from msabramo/patch-5
510,1f850df753cae1b24c5be218c73728abd18ef89c,2015-01-07 21:45:18-08:00,"sql = `` '' '' SELECT c.relchecks , c.relkind , c.relhasindex , c.relhasrules , pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' FROM ORDER BY 1,2 '' '' '' c.relkind WHEN ' r ' THEN 'table ' WHEN ' v ' THEN 'view ' WHEN 'm ' THEN 'materialized view ' WHEN ' i ' THEN 'index ' WHEN 'S ' THEN 'sequence ' WHEN c.relpersistence FROM pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_class FROM pg_catalog.pg_class c WHERE c.relkind IN ( ' r ' , ' v ' , 'm ' , 'S ' , ' f ' , '' ) ORDER BY 2,3 SELECT a.attname , pg_catalog.format_type ( a.atttypid , a.atttypmod ) , END as `` Type '' , c.relhastriggers , c.relhasoids , % s , c.reltablespace , CASE WHEN c.reloftype LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace schema , relname = sql_name_pattern ( pattern ) END , schema , relname = sql_name_pattern ( pattern ) ELSE c.reloftype : :pg_catalog.regtype : :pg_catalog.text % s , JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace `` ' n.nspname ! ~ '^pg_toast ' AND pg_catalog.pg_table_is_visible ( c.oid ) sql = `` '' '' SELECT a.attname , pg_catalog.format_type ( a.atttypid , a.atttypmod ) , AND n.nspname < > 'information_schema ' FROM pg_catalog.pg_class c sql += ' AND n.nspname ~ ' + schema WHEN ' f ' THEN 'foreign table ' sql = `` '' '' sql = '' '' '' SELECT c.oid , n.nspname , c.relname WHEN ' i ' THEN 'index ' sql += ' WHERE c.relname ~ ' + relname LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace sql += ' ORDER BY 2,3 ' = 0 THEN `` ELSE c.reloftype : :pg_catalog.regtype : :pg_catalog.text END , WHERE c.oid = ' % s ' '' '' '' % ( suffix , oid ) if schema : pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' sql = '' '' '' SELECT c.relchecks , c.relkind , c.relhasindex , c.relhasrules , c.relhastriggers , c.relhasoids , `` `` '' % ( ' WHERE c.relname ~ ' + relname if relname else `` , sql = `` 'SELECT c.oid , n.nspname , c.relname FROM pg_catalog.pg_class c LEFT AND n.nspname < > 'pg_catalog ' % s WHEN 's ' THEN 'special ' sql = `` '' '' SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE WHEN 'S ' THEN 'sequence ' AND n.nspname ! ~ '^pg_toast ' ' AND n.nspname ~ ' + schema if schema else `` ) sql = `` '' '' SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE WHEN c.reloftype = 0 THEN `` sql += ' AND pg_catalog.pg_table_is_visible ( c.oid ) ' c.relnamespace WHERE c.relkind IN ( ' r ' , ' v ' , 'm ' , 'S ' , ' f ' , '' ) AND AND pg_catalog.pg_table_is_visible ( c.oid ) if relname : pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON n.oid = ORDER BY 1,2 `` '' '' n.nspname < > 'pg_catalog ' AND n.nspname < > 'information_schema ' AND tc ON ( c.reltoastrelid = tc.oid ) WHERE c.oid = ' % s ' '' '' '' % ( suffix , oid ) c.relpersistence c.reltablespace , WHEN ' v ' THEN 'view ' WHEN 'm ' THEN 'materialized view ' CASE c.relkind WHEN ' r ' THEN 'table ' 's ' THEN 'special ' WHEN ' f ' THEN 'foreign table ' END as `` Type '' , LEFT JOIN pg_catalog.pg_class tc ON ( c.reltoastrelid = tc.oid )",['pgcli/packages/pgspecial.py'],Merge pull request # 51 from simnim/master
511,5dad6e9b3ae8992ecbe1f90d3d561dc771853abd,2015-01-07 14:47:14-08:00,"return ( command.strip ( ) , verbose , arg.strip ( ) ) command = command.strip ( ) .replace ( '+ ' , `` ) return ( command , verbose , arg.strip ( ) )",['pgcli/packages/pgspecial.py'],Merge pull request # 69 from macobo/karl-fix-syntaxerror-with-plus
512,e2419c50f6a43f5476aa0e9c0725925e1b0670f6,2015-01-07 14:22:34-08:00,"For installing Python packages it is recommended to use the package manager If you do n't know how to install python pacakges , please check the For installing Python pacakges it is recommended to use the package manager interface to Postgres database . If you do n't know how to install python packages , please check the interface to Postgres dataabase .",['README.rst'],Merge pull request # 74 from seegno/support/fix-typo
513,6a9065df1c40d4b18ed15ca1882d13ae00f5070b,2015-01-07 14:10:44-08:00,"script : tox python : TOX_ENV=py26 commands = py.test TOX_ENV=py33 deps = pytest envlist = py26 , py27 , py33 , py34 env : script : tox -e $ TOX_ENV `` 2.7 '' envlist = py26 , py27 , py33 , py34 `` 2.6 '' `` 3.4 '' `` 3.3 '' TOX_ENV=py27 [ tox ] TOX_ENV=py34 [ testenv ] envlist = py26 , py27 , py33","['.travis.yml', 'tests/tox.ini', 'tox.ini']",Merge pull request # 71 from macobo/karl-travis-once-per-python-version
514,835a24252f6c31846349bd84fd2d543cb8046556,2015-01-06 22:29:40-08:00,"click.secho ( e.message , err=True , fg='red ' ) click.secho ( str ( e ) , err=True , fg='red ' ) _logger.debug ( 'Database connection failed : % r . ' , e ) _logger.debug ( 'Database connection failed : % r . ' , e.message )",['pgcli/main.py'],Merge pull request # 50 from snahor/patch-1
515,3f78ce7d643e10034795cd51405dff39b944b1f5,2015-01-06 22:28:34-08:00,"_logger.debug ( `` sql : % r , error : % r '' , document.text , e.pgerror ) from psycopg2 import Error except Error as e : click.secho ( e.pgerror , err=True , fg='red ' )",['pgcli/main.py'],Merge pull request # 49 from Walms/master
516,29a1451210a111b0038e593962973cc12fc23796,2015-01-07 00:51:09-05:00,"click.secho ( e.message , err=True , fg='red ' ) click.secho ( str ( e ) , err=True , fg='red ' ) _logger.debug ( 'Database connection failed : % r . ' , e ) _logger.debug ( 'Database connection failed : % r . ' , e.message )",['pgcli/main.py'],Fix # 45
517,e4e9828640fc9046f65fb3791627a8ca91ad7e55,2015-01-06 21:21:41-08:00,"_logger.debug ( `` sql : % r , error : % r '' , document.text , e.message ) _logger.error ( `` traceback : % r '' , traceback.format_exc ( ) ) # See http : //initd.org/psycopg/docs/usage.html # unicode-handling for more info . click.secho ( e.message , err=True , fg='red ' ) # Cast all database input to unicode automatically . psycopg2.extensions.register_type ( psycopg2.extensions.UNICODEARRAY ) click.secho ( str ( e ) , err=True , fg='red ' ) _logger.error ( `` sql : % r , error : % r '' , document.text , str ( e ) ) import traceback psycopg2.extensions.register_type ( psycopg2.extensions.UNICODE ) import psycopg2.extensions","['pgcli/main.py', 'pgcli/pgexecute.py']",Merge pull request # 40 from macobo/master
518,0238697de663d0045844195347d7aee08952183b,2015-01-07 17:50:48+13:00,"_logger.debug ( `` sql : % r , error : % r '' , document.text , e.pgerror ) from psycopg2 import Error except Error as e : click.secho ( e.pgerror , err=True , fg='red ' )",['pgcli/main.py'],ISSUE # 32 More graceful error management
519,3f5d0c0143677e3256401f7eade7d5b4bd4ebcdf,2015-01-03 19:16:51-08:00,"n.oid = c.relnamespace WHERE c.relkind IN ( ' v ' , '' ) AND `` Type '' , pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' , '\dv ' : ( `` 'SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE '\di ' : ( `` 'SELECT n.nspname as `` Schema '' , c.relname as `` Name '' , CASE WHEN 's ' THEN 'special ' WHEN ' f ' THEN 'foreign table ' END as c2.relname as `` Table '' FROM pg_catalog.pg_class c LEFT JOIN `` Type '' , pg_catalog.pg_get_userbyid ( c.relowner ) as `` Owner '' FROM IN ( ' i ' , '' ) AND n.nspname < > 'pg_catalog ' AND AND pg_catalog.pg_table_is_visible ( c.oid ) [ '\dv ' , 'list views . ' ] ) , n.nspname < > 'information_schema ' AND n.nspname ! ~ '^pg_toast ' n.nspname < > 'pg_catalog ' AND n.nspname < > 'information_schema ' AND n.nspname ! ~ '^pg_toast ' AND pg_catalog.pg_index i ON i.indexrelid = c.oid LEFT JOIN pg_catalog.pg_class c LEFT JOIN pg_catalog.pg_namespace n ON pg_catalog.pg_table_is_visible ( c.oid ) ORDER BY 1,2 ; ' '' , c.relkind WHEN ' r ' THEN 'table ' WHEN ' v ' THEN 'view ' WHEN 'm ' THEN pg_catalog.pg_namespace n ON n.oid = c.relnamespace LEFT JOIN pg_catalog.pg_class c2 ON i.indrelid = c2.oid WHERE c.relkind ORDER BY 1,2 ; ' '' , [ '\di ' , 'list indexes . ' ] ) , 'materialized view ' WHEN ' i ' THEN 'index ' WHEN 'S ' THEN 'sequence '",['pgcli/packages/pgspecial.py'],Merge pull request # 15 from j-bennet/master
520,4255e4e654af4d68765204cf6b2929e86306c292,2014-12-30 15:53:30-08:00,"# parser.read will not fail in case of IOError , def load_config ( filename ) : config = load_config ( '~/.pgclirc ' , default_config ) parser.read ( default_filename ) config = load_config ( '~/.pgclirc ' ) # so let 's not try/except here . if default_filename : def load_config ( filename , default_filename=None ) :","['pgcli/config.py', 'pgcli/main.py']",Merge pull request # 14 from j-bennet/master
521,f2ecb2ed6752fa6acd476c47f1e17eb4f0c2f051,2014-12-30 15:36:11-08:00,"# parser.read will not fail in case of IOError , def load_config ( filename ) : config = load_config ( '~/.pgclirc ' , default_config ) parser.read ( default_filename ) config = load_config ( '~/.pgclirc ' ) # so let 's not try/except here . if default_filename : def load_config ( filename , default_filename=None ) :","['pgcli/config.py', 'pgcli/main.py']",Fix for bug # 12 : Config reading is failing when an option is missing .
522,2bec134c7ae9755f16ef3542df01daabbcbd186a,2014-12-29 14:31:46-08:00,"multi_line = config.getboolean ( 'main ' , 'multi_line ' ) * [ ] Set multi-line via config file . line = PGLine ( always_multiline=multi_line , completer=completer , multi_line = False line = PGLine ( always_multiline=False , completer=completer , * [ X ] Set multi-line via config file .","['TODO', 'pgcli/main.py', 'pgcli/pgclirc']",Merge pull request # 11 from j-bennet/master
523,e9868b7d98de19672b0737bb69287b1f450a5417,2014-12-28 15:11:00-08:00,"def test_suggested_multiple_column_names ( completer , complete_event ) : result = set ( completer.get_completions ( position = len ( 'SELECT id , ' ) : return : Completion ( text='first_name ' , start_position=0 ) , `` `` '' text = 'SELECT users.id , users . from users u ' position = len ( 'SELECT u.id , u . ' ) : param complete_event : Document ( text=text , cursor_position=position ) , Suggest column and function names when selecting from table def test_suggested_multiple_column_names_with_dot ( completer , complete_event ) : assert set ( result ) == set ( [ text = 'SELECT id , from users u ' position = len ( 'SELECT ' ) text = 'SELECT u.id , u. from users u ' map ( Completion , completer.functions ) ) Suggest column names on table names and dot when selecting multiple columns from table Suggest column and function names when selecting multiple : param completer : complete_event ) ) Completion ( text='last_name ' , start_position=0 ) ] ) text = 'SELECT from users ' Completion ( text= ' * ' , start_position=0 ) , Completion ( text='id ' , start_position=0 ) , Suggest column names on table alias and dot Suggest column names on table name and dot position = len ( 'SELECT users.id , users . ' ) Completion ( text='last_name ' , start_position=0 ) ] columns from table def test_suggested_multiple_column_names_with_alias ( completer , complete_event ) : Completion ( text='email ' , start_position=0 ) , def test_suggested_column_names ( completer , complete_event ) :",['tests/test_smart_completion.py'],Merge pull request # 8 from j-bennet/master
524,fe2832d8b0959e486c09d1be23c44e16e83d5fd3,2014-12-27 14:48:10-08:00,"result = set ( completer.get_completions ( def test_suggested_column_names_with_alias ( completer , complete_event ) : Completion ( text='first_name ' , start_position=0 ) , complete_event ) ) assert set ( result ) == set ( [ Completion ( text='last_name ' , start_position=0 ) ] ) position = len ( 'SELECT u . ' ) text = 'SELECT users . from users ' Completion ( text= ' * ' , start_position=0 ) , text = 'SELECT u. from users u ' Completion ( text='email ' , start_position=0 ) , Completion ( text='id ' , start_position=0 ) , def test_suggested_column_names_with_dot ( completer , complete_event ) : Document ( text=text , cursor_position=position ) , position = len ( 'SELECT users . ' )",['tests/test_smart_completion.py'],Merge pull request # 7 from j-bennet/master
525,181348fd4ef76cc5833539cf1ef432830ef7b85e,2014-12-27 14:09:14-08:00,"text = 'SELECT MA ' result = set ( completer.get_completions ( # assert set ( map ( Completion , completer.keywords ) ) == set ( completer.get_completions ( Document ( text= '' ) ) ) from mock import Mock all_completions = set ( keywords ) # assert False Completion ( text='MAXEXTENTS ' , start_position=-2 ) ] ) text = `` Document ( text=text , cursor_position=position ) , position = len ( 'SEL ' ) assert result == set ( [ Completion ( text='SELECT ' , start_position=-3 ) ] ) assert result == set ( [ def test_empty_string_completion ( completer ) : position = len ( 'SELECT ' ) pass all_completions = set ( keywords + functions ) position = len ( 'SELECT MA ' ) def test_empty_string_completion ( completer , complete_event ) : def test_select_keyword_completion ( completer , complete_event ) : complete_event ) ) text = 'SELECT FROM users ' position = 0 def test_function_name_completion ( completer , complete_event ) : Completion ( text='MAX ' , start_position=-2 ) , # print set ( completer.get_completions ( Document ( text= '' ) ) ) def complete_event ( ) : text = 'SEL ' assert result == set ( map ( Completion , completer.all_completions ) ) # print set ( map ( Completion , completer.all_completions ) ) return Mock ( ) def test_column_name_completion ( completer , complete_event ) :","['pgcli/pgcompleter.py', 'tests/test_naive_completion.py']",Merge pull request # 6 from j-bennet/master
526,c47c647e7dc8f2582af657736bc87c153f4fb576,2014-12-19 23:05:13-08:00,"'NUMBER ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'OPTION ' , 'OR ' , 'ORDER ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , 'SESSION ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'RESOURCE ' , 'REVOKE ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] 'MLSLABEL ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'NOCOMPRESS ' , 'NOT ' , 'TRIGGER ' , 'UID ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , from prompt_toolkit.enums import InputMode 'LEVEL ' , 'LIKE ' , 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'MLSLABEL ' , 'UNION ' , 'UNIQUE ' , 'UPDATE ' , 'USE ' , 'USER ' , 'VALIDATE ' , 'VALUES ' , Force autocompletion at cursor 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'THEN ' , 'TO ' , 'TRIGGER ' , 'UID ' , def _ ( event ) : ] 'VALIDATE ' , 'VALUES ' , 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'LEFT ' , 'LEVEL ' , 'LIKE ' , 'LOCK ' , 'LONG ' , 'MAXEXTENTS ' , 'MINUS ' , 'NOWAIT ' , 'NULL ' , 'NUMBER ' , 'OF ' , 'OFFLINE ' , 'ON ' , 'ONLINE ' , 'PCTFREE ' , 'PRIOR ' , 'PRIVILEGES ' , 'PUBLIC ' , 'RAW ' , 'RENAME ' , 'SET ' , 'SHARE ' , 'SIZE ' , 'SMALLINT ' , 'START ' , 'SUCCESSFUL ' , 'OPTION ' , 'OR ' , 'ORDER BY ' , 'OUTER ' , 'PCTFREE ' , 'PRIMARY ' , 'PRIOR ' , 'RIGHT ' , 'ROW ' , 'ROWID ' , 'ROWNUM ' , 'ROWS ' , 'SELECT ' , 'SESSION ' , 'MODE ' , 'MODIFY ' , 'NOAUDIT ' , 'NOCOMPRESS ' , 'NOT ' , 'NOWAIT ' , 'NULL ' , line.complete_next ( ) `` `` '' 'PRIVILEGES ' , 'PUBLIC ' , 'RAW ' , 'RENAME ' , 'RESOURCE ' , 'REVOKE ' , 'SUCCESSFUL ' , 'SYNONYM ' , 'SYSDATE ' , 'TABLE ' , 'THEN ' , 'TO ' ,","['pgcli/key_bindings.py', 'pgcli/pgcompleter.py']",Merge pull request # 3 from j-bennet/master
527,8bd1d9dd7e2f33aed255c607efab6a2daf55fc92,2014-12-19 00:10:15-08:00,"def test_select_suggest_cols_and_funcs ( self ) : assert ( suggestion and suggestion [ 0 ] == 'columns ' ) import itertools suggestion = suggest_type ( 'SELECT ' , 'SELECT ' ) class TestSqlCompletion : suggestion = suggest_type ( 'SELECT * FROM ' , 'SELECT * FROM ' ) if last_token.lower ( ) in ( 'set ' , 'by ' ) : def test_distinct_suggest_cols ( self ) : if is_function_word ( word_before_cursor ) : from pgcli.packages.sqlcompletion import suggest_type assert ( suggestion and suggestion [ 0 ] == 'tables ' ) suggestion = suggest_type ( 'SELECT DISTINCT ' , 'SELECT DISTINCT ' ) elif last_token.lower ( ) in ( 'set ' , 'by ' , 'distinct ' ) : assert ( suggestion and suggestion [ 0 ] == 'columns-and-functions ' ) suggestion = suggest_type ( 'SELECT MAX ( FROM table_name ' , 'SELECT MAX ( ' ) def test_from_suggest_tables ( self ) : return word and len ( word ) > 1 and word [ -1 ] == ' ( ' def is_function_word ( word ) : return ( 'columns ' , extract_tables ( full_text ) ) def test_lparen_suggest_cols ( self ) :","['pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py', 'tests/test_sqlcompletion.py']",Merge pull request # 2 from j-bennet/master
528,01fc25f919df5023eafe64e98bc6a7a87361debd,2014-12-17 22:30:15-08:00,"'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHEN ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] 'VARCHAR ' , 'VARCHAR2 ' , 'VIEW ' , 'WHENEVER ' , 'WHERE ' , 'WITH ' , ] return self.find_matches ( word_before_cursor , self.columns # PyCharm 'order by ' , 'group by ' ) : 'FOR ' , 'FROM ' , 'GRANT ' , 'GROUP ' , 'HAVING ' , 'IDENTIFIED ' , 'FOR ' , 'FROM ' , 'FULL ' , 'GRANT ' , 'GROUP BY ' , 'HAVING ' , 'IDENTIFIED ' , 'UCASE ' ] if last_token.lower ( ) in ( 'select ' , 'where ' , 'having ' , 'set ' , elif last_token.lower ( ) in ( 'select ' , 'where ' , 'having ' ) : 'ASC ' , 'AUDIT ' , 'BETWEEN ' , 'BY ' , 'CASE ' , 'CHAR ' , 'CHECK ' , 'CLUSTER ' , self.functions ) if last_token.lower ( ) in ( 'set ' , 'order by ' , 'group by ' ) : .idea/ elif category == 'columns-and-functions ' : 'ASC ' , 'AUDIT ' , 'BETWEEN ' , 'BY ' , 'CHAR ' , 'CHECK ' , 'CLUSTER ' , functions = [ 'AVG ' , 'COUNT ' , 'DISTINCT ' , 'FIRST ' , 'FORMAT ' , 'LAST ' , 'LCASE ' , 'LEN ' , 'MAX ' , 'MIN ' , 'MID ' , 'NOW ' , 'ROUND ' , 'SUM ' , 'TOP ' , return ( 'columns-and-functions ' , None )","['.gitignore', 'pgcli/packages/sqlcompletion.py', 'pgcli/pgcompleter.py']",Merge pull request # 1 from j-bennet/master
